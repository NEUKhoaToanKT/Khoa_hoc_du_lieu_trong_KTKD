[{"path":"index.html","id":"lời-nói-đầu","chapter":"Lời nói đầu","heading":"Lời nói đầu","text":" Khoa học dữ liệu (KHDL) là ngành khoa học kết hợp giữa toán học - xác suất thống kê với khoa học máy tính và kiến thức chuyên môn trong một lĩnh vực cụ thể như kinh tế, tài chính, y học, giáo dục, thể thao, v.v., để khám phá những thông tin hữu ích và có giá trị nằm trong dữ liệu liên quan đến lĩnh vực chuyên môn đó. Những thông tin hữu ích này được sử dụng để hướng dẫn việc ra quyết định và lập kế hoạch chiến lược cho các cơ quan, tổ chức, doanh nghiệp và các cá nhân hoạt động trong lĩnh vực này.Cuốn sách “Khoa học dữ liệu trong Kinh tế và Kinh doanh” được viết xuất phát từ nhu cầu học tập và tìm hiểu về KHDL của những bạn đọc đang học tập, nghiên cứu và làm việc trong lĩnh vực kinh tế, quản lý, quản trị kinh doanh. Cuốn sách ít tập trung vào các khái niệm mang tính kỹ thuật trong toán học hay khoa học máy tính, mà tập trung nhiều hơn vào việc mô tả và áp dụng các phương pháp trên những vấn đề cụ thể. Trong mỗi chương đều sẽ có phần thực hành sử dụng phần mềm thống kê R để minh họa cách triển khai các phương pháp kỹ thuật. Những phần thực hành này sẽ cung cấp cho bạn đọc những trải nghiệm thực tiễn có giá trị.Cuốn sách phù hợp với sinh viên đại học hoặc cao học các ngành kinh tế, khoa học quản lý, quản trị kinh doanh, thương mại, tài chính ngân hàng, bảo hiểm, v.v., muốn nâng cao hiểu biết và tăng cường kinh nghiệm về làm việc với dữ liệu. Cuốn sách có thể làm giáo trình hoặc sách tham khảo cho một môn học kéo dài trong hai học kỳ.Nội dung của cuốn sách bao gồm hầu hết những chủ đề quan trọng trong KHDL: thu thập dữ liệu, tiền xử lý, sắp xếp và biến đổi, trực quan hóa, và xây dựng mô hình trên dữ liệu. Các mô hình được trình bày trong cuốn sách bao gồm cả các mô hình đơn giản như hồi quy tuyến tính hay cây quyết định, và các mô hình phức tạp như mô hình tuyến tính tổng quát, mô hình cộng tính tổng quát, mô hình rừng ngẫu nhiên, học tăng cường hoặc mô hình mạng nơ-ron. Song song với việc trình bày và giải thích các mô hình, chúng tôi sẽ cung cấp các gói lệnh có sẵn để bạn đọc thực hành trên các dữ liệu cụ thể.Đây là phiên bản đầu tiên của cuốn sách nên không thể tránh được những sai sót. Chúng tôi hy vọng rằng sẽ nhận được sự góp ý của bạn đọc về nội dung của cuốn sách để chúng tôi có thể hoàn thiện trong các phiên bản tiếp theo.Xin chân thành cảm ơn các đồng nghiệp tại Khoa Toán Kinh tế nói riêng và Đại học Kinh tế Quốc dân nói chung đã đồng hành cùng với chúng tôi trong suốt quá trình hoàn thành cuốn sách này. Xin cảm ơn các thành viên của Actuarial Sciences Lab đã nỗ lực hết sức để cuốn sách này có thể đến tay người đọc trong thời gian ngắn nhất!","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"giới-thiệu-về-cuốn-sách","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"Chương 1 Giới thiệu về cuốn sách","text":"","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"giới-thiệu-về-khoa-học-dữ-liệu-và-các-ứng-dụng","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.1 Giới thiệu về Khoa học dữ liệu và các ứng dụng","text":"Khoa học dữ liệu là một ngành liên ngành kết hợp kiến thức từ nhiều lĩnh vực như toán học, thống kê, khoa học máy tính và kỹ thuật dữ liệu để thu thập, xử lý, phân tích và diễn giải dữ liệu. Mục tiêu của khoa học dữ liệu là biến dữ liệu thô thành thông tin hữu ích, hỗ trợ ra quyết định và giải quyết các vấn đề phức tạp trong nhiều lĩnh vực khác nhau. Một quá trình ứng dụng KHDL vào giải quyết một vấn đề cụ thể thường bao gồm các bước được mô tả như Hình 1.1.\nHình 1.1: Quy trình áp dụng Khoa học dữ liệu để giải quyết một vấn đề thực tế\nNhập liệu là quá trình tìm kiếm và thu thập dữ liệu từ các nguồn khác nhau để phục vụ cho mục đích ra quyết định. Có những dự án làm việc trực tiếp trên dữ liệu có sẵn và đã được thiết kế sẵn sàng cho mục tiêu phân tích, nhưng cũng có những dự án mà quá trình nhập liệu lại chiếm phần lớn thời gian và quyết định sự thành công hay thất bại của dự án.Nhập liệu là quá trình tìm kiếm và thu thập dữ liệu từ các nguồn khác nhau để phục vụ cho mục đích ra quyết định. Có những dự án làm việc trực tiếp trên dữ liệu có sẵn và đã được thiết kế sẵn sàng cho mục tiêu phân tích, nhưng cũng có những dự án mà quá trình nhập liệu lại chiếm phần lớn thời gian và quyết định sự thành công hay thất bại của dự án.Sắp xếp (tổ chức) dữ liệu, hay còn được gọi là tiền xử lý dữ liệu, là các bước biến dữ liệu từ dạng thô thành dữ liệu theo đúng như định dạng mong muốn.Sắp xếp (tổ chức) dữ liệu, hay còn được gọi là tiền xử lý dữ liệu, là các bước biến dữ liệu từ dạng thô thành dữ liệu theo đúng như định dạng mong muốn.Biến đổi dữ liệu là quá trình tính toán trên các biến hoặc các quan sát của dữ liệu để dữ liệu có thể đưa vào các công cụ trực quan hoặc các mô hình phân tích.Biến đổi dữ liệu là quá trình tính toán trên các biến hoặc các quan sát của dữ liệu để dữ liệu có thể đưa vào các công cụ trực quan hoặc các mô hình phân tích.Xây dựng mô hình là quá trình tính toán và đánh giá mối liên hệ giữa các biến trong dữ liệu đến các biến mục tiêu, là đầu ra của toàn bộ quá trình. Mô hình thường được xây dựng với một trong hai mục đích: xem xét sự tác động của một biến đến các biến mục tiêu hoặc dự đoán giá trị của các biến mục tiêu.Xây dựng mô hình là quá trình tính toán và đánh giá mối liên hệ giữa các biến trong dữ liệu đến các biến mục tiêu, là đầu ra của toàn bộ quá trình. Mô hình thường được xây dựng với một trong hai mục đích: xem xét sự tác động của một biến đến các biến mục tiêu hoặc dự đoán giá trị của các biến mục tiêu.Mô hình trên dữ liệu được xây dựng dựa trên những nguyên lý của toán học và xác suất thống kê. Dữ liệu được sử dụng để xây dựng mô hình có thể là các dữ liệu nhỏ với một vài cột và vài chục quan sát, nhưng cũng có thể là các dữ liệu lớn với hàng nghìn cột dữ liệu và hàng triệu quan sát. Dữ liệu thậm chí không có dạng bảng biểu như chúng ta gặp hàng ngày mà có thể là các hình ảnh, các văn bản, giọng nói, dạng đồ thị,… Để xử lý các bộ dữ liệu khổng lồ, hay các dữ liệu không có cấu trúc bảng thông thường, người xử lý dữ liệu cần có kiến thức về khoa học máy tính và lập trình để thực hiện các tính toán trên máy tính điện tử. Những ứng dụng của KHDL có thể thuộc về bất kỳ lĩnh vực nào như kinh doanh, y học, vật lý, thiên văn, quản lý nhà nước, chính sách công,… nên đòi hỏi người xây dựng mô hình cũng cần có kiến thức chuyên môn trong lĩnh vực tương ứng để không bị sai định hướng trong quá trình làm việc với dữ liệu.Để minh họa ứng dụng của KHDL trong lĩnh vực kinh tế và kinh doanh, chúng tôi thảo luận ngắn gọn về ba dữ liệu được thu thập trong thế giới thực được xem xét trong cuốn sách này.","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"dữ-liệu-chi-phí-quảng-cáo","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.1.1 Dữ liệu chi phí quảng cáo","text":"Đây là một dữ liệu dạng bảng về chiến dịch quảng cáo của một công ty thu thập được từ 55 cửa hàng trên toàn quốc. Dữ liệu bao gồm thông tin về doanh thu bán sản phẩm và chi phí công ty đã chi cho ba phương thức quảng cáo là quảng cáo qua truyền hình, quảng cáo qua các nền tảng mạng xã hội, và quảng cáo bằng hình thức phát tờ rơi. Mối liên hệ của chi phí cho mỗi phương thức quảng cáo đến doanh thu từ bán sản phẩm được mô tả trong Hình 1.2\nHình 1.2: Doanh thu bán hàng (tỷ đồng) và mối liên hệ với chi phí quảng cáo. Hình bên trái: Chi phí quảng cáo trên Tivi. Hình ở giữa: chi phí quảng cáo qua các nền tảng mạng xã hội. Hình bên phải: quảng cáo theo hình thức phát tờ rơi\nTừ Hình 1.2 có thể đưa ra nhận định khá chắc chắn là chi tiền cho quảng cáo có ý nghĩa trong việc tăng doanh thu bán sản phẩm. Có thể thấy trong các đồ thị ở hàng phía trên rằng có mối liên hệ cùng chiều giữa chi phí chi cho các hình thức quảng cáo đến doanh thu bán sản phẩm. Mối liên hệ này là phù hợp với logic nói chung về quảng cáo sản phẩm: khi công ty chi tiền cho quảng cáo, nhiều khách hàng sẽ có cơ hội tiếp cận về sản phẩm hơn, làm tăng số lượng người mua sản phẩm và tăng doanh thu cho các cửa hàng.Tuy nhiên, vẫn còn","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"dữ-liệu-bảo-hiểm-xã-hội","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.1.2 Dữ liệu bảo hiểm xã hội","text":"","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"dữ-liệu-về-giá-xe-ôtô-cũ","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.1.3 Dữ liệu về giá xe ôtô cũ","text":"","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"sơ-lược-quá-trình-phát-triển-của-xây-dựng-mô-hình-dữ-liệu","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.2 Sơ lược quá trình phát triển của xây dựng mô hình dữ liệu","text":"Mặc dù thuật ngữ xây dựng mô hình trên dữ liệu, hay được gọi một cách kỹ thuật hơn là học máy, còn khá mới mẻ, nhưng những khái niệm nền tảng cho lĩnh vực này đã được phát triển từ lâu. Vào đầu thế kỷ 19, phương pháp bình phương nhỏ nhất đã được phát triển và áp dụng để ước lượng các mô hình hồi quy tuyến tính. Mô hình này lần đầu tiên được áp dụng và cho kết quả thành công trong các vấn đề liên quan đến thiên văn học. Vào đầu thế kỷ 20, mô hình hồi quy tuyến tính được sử dụng để dự đoán các giá trị định lượng, chẳng hạn như mức lương của một cá nhân hoặc để dự đoán các giá trị định tính, chẳng hạn như bệnh nhân sống hay chết, hay thị trường chứng khoán tăng hay giảm. Vào những năm 1940, nhiều tác giả đã đưa ra một cách tiếp cận khác, đó là hồi quy logistic. Vào đầu những năm 1970, thuật ngữ mô hình tuyến tính tổng quát đã được phát triển để mô tả toàn bộ lớp phương pháp học thống kê bao gồm cả hồi quy tuyến tính và hồi quy logistic như các trường hợp đặc biệt. Vào cuối những năm 1970, nhiều kỹ thuật xây dựng mô hình trên dữ liệu đã xuất hiện. Tuy nhiên, các mô hình này chỉ xoay quanh các phương pháp tuyến tính vì việc tạo ra các mối quan hệ phi tuyến tính rất khó khăn về mặt tính toán.Đến những năm 1980, sự phát triển của máy tính điện tử đã hỗ trợ tích cực về mặt tính toán cho các phương pháp phi tuyến tính. Các mô hình phi tuyến được giới thiệu vào đầu những năm 1980 bao gồm mô hình cây quyết định và mô hình cộng tính tổng quát. Những năm cuối thập niên 1980 và đầu thập niên 1990, mô hình mạng nơ-ron được giới thiệu đến cộng đồng nghiên cứu nhưng chưa nhận được nhiều sự quan tâm vì dữ liệu chưa đủ phong phú và sự phổ biến của các mô hình học máy khác.\nHình 1.3: Quá trình phát triển của các mô hình học máy\nGiai đoạn cuối thế kỷ XX và đầu thế kỷ XXI là giai đoạn chiếm ưu thế hoàn toàn của các mô hình học máy rừng ngẫu nhiên và thuật toán học tăng cường. Thuật toán học tăng cường với các biến thể như XGBoost hay LightGBM chiến thắng trong hầu hết các cuộc thi về khoa học dữ liệu.Từ năm 2010, với sự bùng nổ của các thiết bị thông minh và kết nối internet, dữ liệu trở nên phong phú và đa dạng hơn cũng là thời điểm quay trở lại của mô hình mạng nơ-ron, hay còn được gọi với tên gọi khác là mô hình mạng học sâu (deep learning). Mô hình mạng học sâu vượt trội hoàn toàn các mô hình học máy thông thường khi làm việc với dữ liệu kiểu hình ảnh, video, ngôn ngữ tự nhiên bao gồm cả văn bản và giọng nói. Sự kiện đánh dấu sự phát triển vượt bậc của các mô hình mạng học sâu là sự ra đời của ChatGPT vào cuối năm 2022, một mô hình ngôn ngữ lớn cho phép người dùng tương tác, hỏi đáp và trò chuyện một cách hoàn toàn tự nhiên theo định hướng của người sử dụng như phong cách, mức độ chi tiết, hình thức ngôn ngữ. ChatGPT nhanh chóng đạt đến 100 triệu người dùng sau hơn hai tháng phát hành và giúp cho công ty phát hành OpenAI được định giá khoảng 30 tỷ USD. Cho đến thời điểm cuối năm 2023 khi nhóm tác giả bắt đầu viết cuốn sách này, ChatGPT đã được cập nhật đến phiên bản 3.5.","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"tại-sao-lại-sử-dụng-phần-mềm-r","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.3 Tại sao lại sử dụng phần mềm R?","text":"Trong thế giới ngày nay, hầu hết các cơ quan, tổ chức, tập đoàn, doanh nghiệp từ lớn đến nhỏ đều sử dụng một lượng dữ liệu nhất định để phân tích các sự kiện trong quá khứ và cố gắng dự đoán xu hướng trong tương lai để đưa ra các quyết định có lợi cho mình. Tuy nhiên, khi dữ liệu ngày càng tăng lên cả về số lượng và sự phức tạp, các cơ quan tổ chức cần một công cụ giúp họ thực hiện các phân tích trên dữ liệu một cách nhanh hơn và chính xác hơn. Một trong những công cụ hiệu quả nhất hiện nay là phần mềm R.","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"phần-mềm-r-là-gì","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.3.1 Phần mềm R là gì?","text":"Trước tiên, R là ngôn ngữ lập trình được xây dựng để phục vụ cho toán học và thống kê, đồng thời R cũng là một môi trường phần mềm mã nguồn mở miễn phí cho người sử dụng. R được giới thiệu lần đầu tiên vào năm 1992 bởi các giáo sư Ross Ihaka và Robert Gentleman như một ngôn ngữ lập trình để dạy thống kê tại Đại học Auckland. Tên của ngôn ngữ, R, xuất phát từ chữ cái đầu tiên của các tác giả là Ross và Robert.Trước khi trở thành ngôn ngữ lập trình cho khoa học dữ liệu, R thường được coi là ngôn ngữ lập trình cho các nhà toán học và thống kê. Sau nhiều năm phát triển, R luôn được coi là một trong những ngôn ngữ lập trình phổ biến nhất trong giới học thuật vì độ tin cậy. Mỗi thư viện của R đều được phát triển một cách hoàn chỉnh và trải qua quá trình kiểm soát chặt chẽ. Tạp chí R (R Journal) là tạp chí học thuật về các phương pháp tính toán trong toán học và thống kê sử dụng phần mềm R luôn nằm trong danh sách các tạp chí khoa học uy tín (Science Citation Index Expanded hay SCIE) của Web Science. Chính vì sự uy tín trong học thuật nên đa số các trường đại học và viện nghiên cứu hàng đầu trên thế giới sử dụng R như là một ngôn ngữ chính trong đào tạo về tính toán, toán học và thống kê.","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"tại-sao-r-lại-được-sử-dụng-trong-khdl","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.3.2 Tại sao R lại được sử dụng trong KHDL?","text":"Trong khoảng hơn 10 năm trở lại đây, R không còn chỉ là ngôn ngữ lập trình thông thường như trước đây nữa. Mặc dù vẫn là một công cụ mạnh mẽ trong tính toán toán học và thống kê, nhưng còn có rất nhiều công cụ tuyệt vời khác mà bạn đọc có thể làm với R, đặc biệt là những ứng dụng trong khoa học dữ liệu (KHDL). Nguyên nhân chính giúp cho phần mềm R nhanh chóng trở thành ngôn ngữ phổ biến trong KHDL là nền tảng quan trọng nhất của KHDL chính là toán học và thống kê. Đồng thời, ngôn ngữ lập trình R cũng đủ linh hoạt để người sử dụng viết các chương trình yêu cầu tính toán phức tạp trong khoa học máy tính. Một cách tự nhiên, những nhà toán học, thống kê học và các tổ chức sử dụng R như là một ngôn ngữ chính sẽ tìm cách phát triển R để đáp ứng được yêu cầu xử lý dữ liệu của chính họ. Một nguyên nhân khác khiến cho R phổ biến trong KHDL là đặc thù mã nguồn mở của phần mềm này. Những người làm việc trong lĩnh vực KHDL sử dụng R có thể chia sẻ kiến thức và kinh nghiệm một cách nhanh chóng và rộng rãi.","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"r-có-thể-làm-những-gì","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.3.3 R có thể làm những gì?","text":"Danh sách những việc bạn có thể làm trong R là không thể liệt kê hết bởi vì phần mềm này vẫn đang được phát triển không ngừng. Dưới đây là một số ứng dụng phổ biến mà R vượt trội hơn với các ngôn ngữ khác:Lập trình trong toán học, tính toán tối ưu, giải tối ưu bằng phương pháp số.Tính toán liên quan đến lý thuyết xác suất.Thực hiện các kiểm định thống kê.Phát triển phần mềm thống kê.Xây dựng mô hình kinh tế lượng.Mô phỏng ngẫu nhiên.Các tính năng của R dành cho khoa học dữ liệu được liệt kê dưới đây:Thu thập tập dữ liệu, bao gồm cả dữ liệu lớn và không có cấu trúc.Khai phá dữ liệu.Xử lý, sắp xếp, biến đổi dữ liệu.Phân tích dữ liệu.Trực quan hóa dữ liệu.Xây dựng các mô hình từ đơn giản đến phức tạp.","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"tại-sao-cuốn-sách-này-lại-sử-dụng-r","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.3.4 Tại sao cuốn sách này lại sử dụng R?","text":"Mặc dù có một số phần mềm khác có thể được sử dụng thay thế cho R trong phân tích dữ liệu, nhưng chúng tôi lựa chọn ngôn ngữ R vì:R là một phần mềm uy tín và đáng tin cậy được sử dụng bởi các trường đại học và các viện nghiên cứu hàng đầu trên thế giới. R cũng được sử dụng rộng rãi trong các công ty công nghệ hàng đầu như Microsoft, Facebook, Google, và IBM.R là ngôn ngữ lập trình rất dễ hiểu cho người mới bắt đầu, kể cả với những người không có kinh nghiệm lập trình. Còn nếu bạn đã có kinh nghiệm về một ngôn ngữ lập trình, bạn sẽ chỉ cần một khoảng thời gian ngắn để có thể viết các chương trình với R.Phần mềm R là một phần mềm mã nguồn mở, nghĩa là bạn có thể sử dụng R và hơn 12.000 thư viện mở rộng mà không cần phải bỏ ra bất kỳ chi phí nào. Điều này giúp cho R trở nên rất dễ tiếp cận đối với sinh viên và người học không sẵn sàng chi trả một khoản chi phí để học về khoa học dữ liệu. Đồng thời, giảng viên cũng có thể tận dụng tối đa môi trường phần mềm này khi giảng dạy cho sinh viên.Cuối cùng và cũng không kém phần quan trọng, đó là sự hỗ trợ từ cộng đồng. Với số lượng người dùng lên đến hàng triệu người, nhiều trong số đó là những nhà toán học, thống kê học, giáo sư tại các trường đại học, bạn sẽ luôn tìm thấy sự hỗ trợ mỗi khi gặp bất kỳ vấn đề khi làm việc với R.","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"các-lựa-chọn-thay-thế-và-bổ-sung-cho-r-trong-khdl","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.3.5 Các lựa chọn thay thế và bổ sung cho R trong KHDL","text":"Như chúng ta đã thấy, R là một trong những ngôn ngữ lập trình tốt nhất cho người mới bắt đầu bước chân vào lĩnh vực khoa học dữ liệu (KHDL). Tuy nhiên, bạn cũng có thể tìm thấy các phần mềm/ngôn ngữ có thể sử dụng để thay thế cho R trong quá trình học tập và làm việc:Python - Vào thời điểm chúng tôi hoàn thành cuốn sách này, Python là ngôn ngữ lập trình được sử dụng nhiều nhất trong KHDL. Python được giới thiệu lần đầu tiên vào năm 1991 và đã không ngừng tiến hóa và phát triển. Cũng như R, Python có mã nguồn mở và hoàn toàn miễn phí cho người sử dụng. Câu lệnh của Python rất dễ học và đặc biệt mạnh mẽ trong lập trình hướng đối tượng.Julia - Xuất hiện lần đầu tiên vào năm 2012, Julia là một trong những ngôn ngữ lập trình mới nhất và là lựa chọn tối ưu cho các nhà khoa học dữ liệu. Ngôn ngữ lập trình cấp cao và hiệu suất cao này rất năng động và phù hợp để viết bất kỳ loại ứng dụng nào. Mặc dù Python và R vẫn được ưu tiên cho KHDL và học máy, nhưng Julia dự báo sẽ vượt qua cả hai trong tương lai gần. Mặc dù đây là ngôn ngữ lập trình tổng quát, nhưng nó có tất cả các đặc điểm cần thiết để xử lý phân tích, thống kê và dữ liệu lớn.MATLAB - Được phát triển bởi MathWorks, ngôn ngữ lập trình này là một môi trường điện toán được phát triển đặc biệt để phân tích số và thống kê. Nhờ có số lượng lớn các thư viện có sẵn cho người dùng, MATLAB cho phép lập trình viên truy cập dữ liệu, xử lý dữ liệu và tạo các mô hình học máy từ đơn giản đến phức tạp. Mặc dù MATLAB là một hệ thống hiệu suất cao, nhưng lại không phải là nguồn mở hoặc miễn phí. Thay vào đó, nó được xây dựng bởi các nhà phát triển chuyên nghiệp.Java - Là một trong những ngôn ngữ lập trình phổ biến nhất và cũng là một lựa chọn cho những người mới bước vào lĩnh vực KHDL. Mặc dù vẫn có thể tải xuống miễn phí, một số ứng dụng chỉ có sẵn trong phiên bản trả phí. Cú pháp của Java cũng tương đối dễ học đối với người mới bắt đầu. Nhìn chung, Java vẫn là ngôn ngữ có mục đích chung và được các nhà khoa học dữ liệu coi là một lựa chọn bổ sung cho R hoặc Python.Ngoài việc thành thạo R hoặc một phần mềm chuyên dùng trong KHDL, bạn nên bổ sung cho mình các ngôn ngữ lập trình khác để đạt hiệu suất công việc tốt nhất:SQL hay ngôn ngữ truy vấn dữ liệu có cấu trúc. SQL xuất hiện từ năm 1974 và đã không ngừng được cải tiến và sửa đổi để giúp cho ngôn ngữ này luôn nằm trong nhóm những ngôn ngữ lập trình được lựa chọn hàng đầu trong KHDL. SQL có cả các phiên bản miễn phí và các phiên bản thương mại mà người sử dụng phải trả chi phí.C và C++ là các ngôn ngữ lập trình hiệu suất cao có thể giúp bạn tăng hiệu quả của các chương trình. Hầu như tất cả các ứng dụng trên hệ điều hành máy tính và điện thoại di động hiện nay đều sử dụng C và C++. Viết các chương trình dưới ngôn ngữ C hoặc C++ sẽ hiệu quả về mặt thời gian hơn nhiều với các ngôn ngữ khác.","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"cài-đặt-r-và-rstudio","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.3.6 Cài đặt R và RStudio","text":"Bạn đọc sẽ bắt đầu bằng cài đặt phần mềm R và sau đó là cài đặt RStudio - một môi trường phát triển phổ biến dành cho R. Phần mềm R dành cho các hệ điều hành MAC OS, Windows, và Linux đều có sẵn để tải xuống từ trang web chính thức:https://cran.r-project.org/Tại thời điểm chúng tôi viết cuốn sách này, R đang là phiên bản 4.1.0. Sau khi tải xuống, chúng ta chỉ cần cài đặt R giống như tất cả các phần mềm khác với tất cả các tùy chọn mặc định.Sau khi cài đặt phần mềm R, bạn đọc cài đặt Rstudio. Chúng ta hoàn toàn có thể sử dụng R mà không cần có Rstudio. Tuy nhiên, Rstudio sẽ hỗ trợ bạn rất nhiều trong quá trình sử dụng R, đó, lời khuyên của chúng tôi là hãy sử dụng Rstudio cùng với R. Để tải xuống Rstudio, bạn truy cập vào trang web chính thức:https://posit.co/download/rstudio-desktop/RStudio là một công cụ linh hoạt giúp bạn tạo các phân tích dễ đọc và giữ mã, hình ảnh, nhận xét và sơ đồ của bạn ở cùng một nơi. Sử dụng RStudio để lập trình và phân tích dữ liệu trong R mang lại nhiều lợi ích. Dưới đây là một vài ví dụ về những gì RStudio cung cấp:Giao diện trực quan cho phép chúng ta theo dõi các đối tượng, tập lệnh và số liệu đã lưu.Trình soạn thảo văn bản có các tính năng như tự động gợi ý câu lệnh, hiển thị màu giúp cho việc viết các câu lệnh rõ ràng.Hiển thị mô tả hàm số, dữ liệu bằng thao tác đơn giản.Thanh công cụ có đầy đủ các tính năng trực quan để bạn đọc sử dụng thay vì phải viết câu lệnh.Mỗi khi bạn đọc mở RStudio, R cũng được khởi chạy tự động. Giao diện RStudio rất trực quan và dễ sử dụng. Các cửa sổ quan trọng bao gồm:Cửa số Console là nơi chúng ta có thể chạy các câu lệnh R.Cửa sổ Environment là chúng ta theo dõi các đối tượng, tập lệnh và số liệu đã lưu.Cửa sổ File là nơi hiển thị địa chỉ thư mục đang làm việc, hiển thị đồ thị trực quan, hoặc hiển thị mô tả dữ liệu, hàm số, thư viện.Bạn đọc sẽ làm quen dần với giao diện và các cửa sổ làm việc khác nhau của RStudio trong quá trình thực hành trên các câu lệnh và dữ liệu cụ thể. Chúng tôi sẽ không đi quá sâu vào chi tiết tại đây.","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"về-cuốn-sách-và-tác-giả","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.4 Về cuốn sách và tác giả","text":"Cuốn sách được viết với mục tiêu là để thành sách tham khảo chính cho các môn học “Phân tích và dự báo” và “Khoa học dữ liệu cơ bản” cho sinh viên và học viên cao học ngành Toán Kinh tế tại Đại học Kinh tế Quốc dân. Chúng tôi tin rằng những kiến thức và công cụ được giới thiệu trong cuốn sách này sẽ là những hành trang quan trọng cho những nhà kinh tế và kinh doanh tương lai trước khi bước chân vào thế giới việc làm đầy tính cạnh tranh như hiện nay.","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"đôi-lời-từ-tác-giả","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.4.1 Đôi lời từ tác giả","text":"Tôi không phải là một nhà kinh tế, cũng không phải là một chuyên gia dữ liệu, và tôi cũng chưa từng được đào tạo bài bản về máy tính hay lập trình, tôi là một Actuary. Cuốn sách được viết dựa trên kinh nghiệm làm việc và giảng dạy của tôi trong những lĩnh vực khoa học tính toán (Actuarial science). Tôi bắt đầu sử dụng R như một phần mềm thống kê khi còn là một sinh viên đại học. Ấn tượng đầu tiên của tôi về R là khi phần mềm này được sử dụng để mô phỏng các chuyển động Brown hình học vô cùng bắt mắt. Và R vẫn tiếp tục đồng hành với tôi cho đến nay trong cả môi trường doanh nghiệp và học thuật:Trong thời gian nghiên cứu sinh từ 2011 đến 2014, tôi sử dụng R là công cụ chính để thực hiện các tính toán cho luận án của mình. Với nội dung nghiên cứu tập trung vào tính toán và mô phỏng xác suất của các sự kiện cực hiếm, R là lựa chọn tối ưu vào thời điểm đó. Trong một vài tính toán mà chưa có thư viện hỗ trợ, chẳng hạn như tính toán với độ chính xác siêu nhỏ, dưới \\(10^{-100}\\), tôi đã sử dụng Python là một giải pháp bổ sung.Trong thời gian nghiên cứu sinh từ 2011 đến 2014, tôi sử dụng R là công cụ chính để thực hiện các tính toán cho luận án của mình. Với nội dung nghiên cứu tập trung vào tính toán và mô phỏng xác suất của các sự kiện cực hiếm, R là lựa chọn tối ưu vào thời điểm đó. Trong một vài tính toán mà chưa có thư viện hỗ trợ, chẳng hạn như tính toán với độ chính xác siêu nhỏ, dưới \\(10^{-100}\\), tôi đã sử dụng Python là một giải pháp bổ sung.Công việc đầu tiên trong môi trường doanh nghiệp của tôi liên quan đến dữ liệu là xây dựng các thuật toán để đầu tư trên thị trường tài chính tại một quỹ đầu tư. Tôi được làm quen với một kho dữ liệu khổng lồ bao gồm dữ liệu hỗ trợ phân tích kỹ thuật, dữ liệu hỗ trợ phân tích cơ bản, và dữ liệu kiểu tin tức liên quan đến tất cả các công cụ tài chính có thể sử dụng để giao dịch, bao gồm cổ phiếu, trái phiếu, hợp đồng tương lai, quyền chọn. Các mô hình trên dữ liệu được chúng tôi - những người nghiên cứu thị trường - xây dựng bằng nhiều phương pháp để tìm ra các chiến lược mang lại lợi nhuận cho quỹ đầu tư. Mặc dù không có cơ hội sử dụng R để phân tích dữ liệu các yêu cầu liên quan đến bảo mật, nhưng tôi lại được học những kỹ năng lập trình C++ mà tôi nhận ra là vô cùng quan trọng cho công việc của mình sau này.Công việc đầu tiên trong môi trường doanh nghiệp của tôi liên quan đến dữ liệu là xây dựng các thuật toán để đầu tư trên thị trường tài chính tại một quỹ đầu tư. Tôi được làm quen với một kho dữ liệu khổng lồ bao gồm dữ liệu hỗ trợ phân tích kỹ thuật, dữ liệu hỗ trợ phân tích cơ bản, và dữ liệu kiểu tin tức liên quan đến tất cả các công cụ tài chính có thể sử dụng để giao dịch, bao gồm cổ phiếu, trái phiếu, hợp đồng tương lai, quyền chọn. Các mô hình trên dữ liệu được chúng tôi - những người nghiên cứu thị trường - xây dựng bằng nhiều phương pháp để tìm ra các chiến lược mang lại lợi nhuận cho quỹ đầu tư. Mặc dù không có cơ hội sử dụng R để phân tích dữ liệu các yêu cầu liên quan đến bảo mật, nhưng tôi lại được học những kỹ năng lập trình C++ mà tôi nhận ra là vô cùng quan trọng cho công việc của mình sau này.Khi bắt đầu công việc như một chuyên gia tính toán, tôi làm việc thường xuyên với dữ liệu trong bảo hiểm. Với những dữ liệu nhỏ, tôi nhận thấy rằng Microsoft Excel kết hợp với lập trình VBA là vừa đủ để xử lý. Khi dữ liệu trở nên ngày càng lớn và phức tạp, Excel và VBA không còn đáp ứng được nhu cầu, đó là lúc tôi quay lại sử dụng R trong công việc của mình. Ngoài sử dụng R như là một công cụ chính để định phí, đánh giá hợp đồng bảo hiểm, tôi còn sử dụng R để thực hiện các công việc liên quan đến dữ liệu như:\nThu thập dữ liệu nhận được từ các phòng ban như tài chính, kế toán, nghiệp vụ, , kiểm tra; làm sạch và cập nhập dữ liệu lên cơ sở dữ liệu để phục vụ tính toán. R cho phép xử lý và tính toán những dữ liệu hàng chục triệu dòng với hiệu quả thực sự đáng kinh ngạc.\nTrích xuất dữ liệu từ cơ sở dữ liệu, biến đổi và tính toán để thực hiện các nghiệp vụ như tái bảo hiểm, quản lý tài sản nợ/có, tính toán báo cáo kinh nghiệm.\nXây dựng các dashboard để cập nhật tình hình bồi thường bảo hiểm y tế với thời gian thực. Thư viện Shiny là công cụ tuyệt vời để tạo ra những dashboard như vậy. \nXây dựng mô hình để phân loại rủi ro, dự báo những chủ hợp đồng, người được bảo hiểm có khả năng cao là trục lợi trong bảo hiểm y tế.\nKhi bắt đầu công việc như một chuyên gia tính toán, tôi làm việc thường xuyên với dữ liệu trong bảo hiểm. Với những dữ liệu nhỏ, tôi nhận thấy rằng Microsoft Excel kết hợp với lập trình VBA là vừa đủ để xử lý. Khi dữ liệu trở nên ngày càng lớn và phức tạp, Excel và VBA không còn đáp ứng được nhu cầu, đó là lúc tôi quay lại sử dụng R trong công việc của mình. Ngoài sử dụng R như là một công cụ chính để định phí, đánh giá hợp đồng bảo hiểm, tôi còn sử dụng R để thực hiện các công việc liên quan đến dữ liệu như:Thu thập dữ liệu nhận được từ các phòng ban như tài chính, kế toán, nghiệp vụ, , kiểm tra; làm sạch và cập nhập dữ liệu lên cơ sở dữ liệu để phục vụ tính toán. R cho phép xử lý và tính toán những dữ liệu hàng chục triệu dòng với hiệu quả thực sự đáng kinh ngạc.Trích xuất dữ liệu từ cơ sở dữ liệu, biến đổi và tính toán để thực hiện các nghiệp vụ như tái bảo hiểm, quản lý tài sản nợ/có, tính toán báo cáo kinh nghiệm.Xây dựng các dashboard để cập nhật tình hình bồi thường bảo hiểm y tế với thời gian thực. Thư viện Shiny là công cụ tuyệt vời để tạo ra những dashboard như vậy. Xây dựng mô hình để phân loại rủi ro, dự báo những chủ hợp đồng, người được bảo hiểm có khả năng cao là trục lợi trong bảo hiểm y tế.Khi tôi quay trở lại với công việc học thuật vào đầu năm 2018, cũng là lúc mà làn sóng về khoa học dữ liệu bắt đầu ảnh hưởng đến đa số các lĩnh vực khác, bao gồm cả ngành khoa học tính toán. Các chứng chỉ về khoa học dữ liệu là điều kiện bắt buộc đối với những người muốn trở thành thành viên của các Hiệp hội chuyên gia tính toán. Tôi cùng với các đồng nghiệp của mình đưa môn học “Phân tích và dự báo” vào trong chương trình đào tạo Định phí bảo hiểm và quản trị rủi ro để cung cấp cho sinh viên các kiến thức và kỹ năng cần thiết khi làm việc với dữ liệu và có thể lấy được chứng chỉ nghề nghiệp của Hiệp hội. Môn học “Phân tích và dự báo” sau đó chính thức được giảng dạy cho sinh viên ngành Toán Kinh tế vào năm 2021 với tên gọi “Khoa học dữ liệu trong Kinh tế và Kinh doanh”. Nội dung của cuốn sách xoay quanh các kiến thức mà tôi đã đang và sẽ giảng dạy cho sinh viên và học viên của mình.Khi tôi quay trở lại với công việc học thuật vào đầu năm 2018, cũng là lúc mà làn sóng về khoa học dữ liệu bắt đầu ảnh hưởng đến đa số các lĩnh vực khác, bao gồm cả ngành khoa học tính toán. Các chứng chỉ về khoa học dữ liệu là điều kiện bắt buộc đối với những người muốn trở thành thành viên của các Hiệp hội chuyên gia tính toán. Tôi cùng với các đồng nghiệp của mình đưa môn học “Phân tích và dự báo” vào trong chương trình đào tạo Định phí bảo hiểm và quản trị rủi ro để cung cấp cho sinh viên các kiến thức và kỹ năng cần thiết khi làm việc với dữ liệu và có thể lấy được chứng chỉ nghề nghiệp của Hiệp hội. Môn học “Phân tích và dự báo” sau đó chính thức được giảng dạy cho sinh viên ngành Toán Kinh tế vào năm 2021 với tên gọi “Khoa học dữ liệu trong Kinh tế và Kinh doanh”. Nội dung của cuốn sách xoay quanh các kiến thức mà tôi đã đang và sẽ giảng dạy cho sinh viên và học viên của mình.","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"ai-nên-đọc-cuốn-sách-này","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.4.2 Ai nên đọc cuốn sách này","text":"Cuốn sách này dành cho bất kỳ bạn đọc nào quan tâm đến việc sử dụng dữ liệu và các phương pháp thống kê hiện đại để giải quyết các vấn đề gặp phải trong học tập và trong công việc hàng ngày. Độc giả có thể là bất kỳ ai, bao gồm các nhà khoa học, kỹ sư, người phân tích dữ liệu, và người nghiên cứu định lượng, hoặc cũng có thể bao gồm những cá nhân với nền tảng có ít tính kỹ thuật hơn như sinh viên, học viên cao học trong các lĩnh vực không định lượng như khoa học xã hội hoặc kinh doanh. Mặc dù không bắt buộc, chúng tôi kỳ vọng rằng bạn đọc đã từng học ít nhất một khóa học cơ bản về xác suất thống kê và một khóa học về lập trình.Mức độ toán học của cuốn sách này là vừa phải và không cần phải có kiến thức chi tiết về các phép toán phức tạp liên quan đến đại số tuyến tính hay giải tích nhiều chiều. Cuốn sách này cung cấp một phần giới thiệu về ngôn ngữ lập trình thống kê R. Việc đã từng tiếp xúc với một ngôn ngữ lập trình, chẳng hạn như C, C++, hoặc Python, sẽ hữu ích cho bạn đọc nhưng không phải là yêu cầu bắt buộc. Cuốn sách này có thể được sử dụng để giảng dạy cho sinh viên thạc sĩ và tiến sĩ trong các lĩnh vực kinh doanh, kinh tế, sinh học, và nhiều lĩnh vực khác của khoa học tự nhiên và xã hội.Cuốn sách đã được sử dụng để giảng dạy cho sinh viên đại học ở mức độ cơ bản như chúng tôi đã đề cập ở trên, nhằm cung cấp cho người học những kiến thức về xây dựng mô hình học máy cao cấp hơn mô hình hồi quy tuyến tính thông thường. Trong mỗi chương sách, chúng tôi luôn cố gắng thêm vào các luận giải về mặt toán học cho các mô hình, với mục đích để các học viên cao học, nghiên cứu sinh khi tham khảo cuốn sách có hiểu biết cặn kẽ hơn. Việc này giúp cho việc giảng dạy khoa học dữ liệu cho người học có thể được tiếp cận từ các khía cạnh khác nhau.","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"các-ký-hiệu-thông-dụng","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.4.3 Các ký hiệu thông dụng","text":"","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"cấu-trúc-của-cuốn-sách","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.4.4 Cấu trúc của cuốn sách","text":"","code":""},{"path":"giới-thiệu-về-cuốn-sách.html","id":"các-dữ-liệu-sử-dụng-trong-cuốn-sách","chapter":"Chương 1 Giới thiệu về cuốn sách","heading":"1.4.5 Các dữ liệu sử dụng trong cuốn sách","text":"","code":""},{"path":"kiến-thức-r-cơ-bản.html","id":"kiến-thức-r-cơ-bản","chapter":"Chương 2 Kiến thức R cơ bản","heading":"Chương 2 Kiến thức R cơ bản","text":"","code":""},{"path":"kiến-thức-r-cơ-bản.html","id":"làm-quen-với-các-dòng-lệnh-cơ-bản","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.1 Làm quen với các dòng lệnh cơ bản","text":"Đây là cuốn sách dành cho sinh viên và học viên các ngành kinh tế, quản lý, và quản trị kinh doanh muốn tìm hiểu sang lĩnh vực khoa học dữ liệu. Những bạn đọc đã có nền tảng kiến thức cơ bản về toán học, xác suất thống kê, và lập trình sẽ cảm thấy dễ dàng hơn khi bắt đầu. Cuốn sách sử dụng R làm ngôn ngữ và công cụ chính để thực hiện các thao tác trên dữ liệu.Nếu bạn đọc đã có nền tảng cơ bản về lập trình thì cuốn sách này không giúp bạn lập trình tốt hơn. Mục đích chính của cuốn sách là giúp bạn có thể sử dụng được R và thực hiện được các thao tác trên dữ liệu trong môi trường R một cách nhanh nhất. Theo quan điểm của chúng tôi, R không phải là một ngôn ngữ thích hợp để bắt đầu cho học lập trình. Muốn trở thành một lập trình viên giỏi, bạn đọc nên bắt đầu với các ngôn ngữ lập trình cơ bản như Pascal, C++, Java, hay cũng có thể bắt đầu với ngôn ngữ Python.Cách viết các dòng lệnh của R có thể nói là khá tùy tiện, thậm chí có thể làm cho những người có chuyên môn về lập trình cảm thấy khó chịu. Tuy nhiên, như đã đề cập trong phần giới thiệu của cuốn sách, R có các thế mạnh riêng mà các ngôn ngữ khác không có được và chúng tôi tin rằng R có thể giải quyết được tất cả những yêu cầu của bạn đọc từ những yêu cầu đơn giản đến những yêu cầu phức tạp nhất.Cuốn sách hướng đến cả các bạn đọc chưa từng làm quen với lập trình. Với những ai đã có kinh nghiệm với lập trình có thể bỏ qua các phần không cần thiết như biến, vòng lặp, viết hàm số và có thể bắt đầu ngay kể từ phần phân tích dữ liệu.","code":""},{"path":"kiến-thức-r-cơ-bản.html","id":"sử-dụng-r-như-một-máy-tính-cầm-tay","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.1.1 Sử dụng R như một máy tính cầm tay","text":"Để R hiểu và thực hiện được các yêu cầu của mình, bạn đọc cần phải viết các câu lệnh dưới ngôn ngữ của phần mềm. Hãy bắt đầu với câu lệnh đầu tiên và đơn giản nhất: hiển thị một giá trị lên cửa sổ Console. Trước hết bạn đọc hãy nhấp chuột vào cửa sổ Console, sau đó gõ trực tiếp đoạn câu lệnh như ở dưới và kết thúc câu lệnh bằng cách sử dụng phím Enter:Bạn đọc có thể bắt đầu làm quen với các dòng lệnh của R bằng cách viết lên cửa sổ Console các công thức để thực hiện tính toán các phép toán dưới đây. R có thể được sử dụng đơn giản như một máy tính cầm tay:Một vài lưu ý bạn đọc có thể nhận thấy khi gõ các dòng lệnh ở trên: các phép tính cộng trừ nhân chia, dấu thập phân, dấu lũy thừa,…, hoàn toàn giống như khi sử dụng máy tính cầm tay. Các hàm số quen thuộc như hàm logarit, hàm lũy thừa cơ số tự nhiên cũng không có gì đặc biệt.Bạn đọc có thể tiếp tục thực hành các câu lệnh cơ bản bằng cách sử dụng R để tính toán kết quả của các biểu thức dưới đây:\\[\\begin{align}\n) \\ \\cfrac{1}{4^{1/6}} \\ \\ \\ b) \\ \\cfrac{7 - 4}{12 - 7} \\ \\ \\ c) \\ \\sqrt{\\cfrac{4}{22}} \\ \\ \\ d) (12-5)^{4/3} \\ \\ \\ e) \\ \\log\\left( \\cfrac{2 + 4}{2^5 -1} \\right)\n\\end{align}\\]Khi viết câu lệnh trên cửa sổ Console, R luôn thực hiện câu lệnh mỗi khi bạn đọc sử dụng phím Enter. Khi muốn viết hai hay nhiều câu lệnh trên một dòng trên cửa sổ Console, bạn đọc hãy ngăn cách các câu lệnh bằng dấu  ’’ ; ” . Hãy thử câu lệnh ở dưới và quan sát R cách trả kết quả:Khi bạn đọc viết các câu lệnh đơn giản thì sử dụng nhiều phép tính trên một dòng lệnh có thể hạn chế việc dùng phím Enter nhiều lần. Tuy nhiên chúng tôi khuyên bạn đọc khi muốn thực hiện nhiều câu lệnh khác nhau hãy sử dụng cửa sổ Script thay vì viết câu lệnh trực tiếp lên cửa sổ Console. Phần tiếp theo của chương chúng tôi sẽ thảo luận về cách viết và thực thi câu lệnh trên cửa sổ Script.","code":"\nprint(\"I am MFEer\")\n1+0.001\n2*pi - 3 # Số pi trong R được viết là pi\nexp(1)-exp(-1) # Hàm lũy thừa cơ số tự nhiên.\nlog(3.2) # Hàm logarit cơ số tự nhiên.\nlog(1000,10) # Hàm logarit cơ số 10.\n2*pi - 3; exp(1)-exp(-1) # Một dòng lệnh thực hiện hai câu lệnh.## [1] 3.283185## [1] 2.350402"},{"path":"kiến-thức-r-cơ-bản.html","id":"sử-dụng-cửa-sổ-script-để-viết-câu-lệnh","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.1.2 Sử dụng cửa sổ Script để viết câu lệnh","text":"Cách tốt nhất để bạn đọc viết, quản lý, và thực thi câu lệnh đó là sử dụng cửa sổ Script. Để mở cửa sổ Script trên Rstudio, bạn đọc có thể tìm trên thanh công cụ theo trình tự File \\(\\rightarrow\\) New file \\(\\rightarrow\\) R Script, hoặc bạn đọc sử dụng tổ hợp phím tắt Ctrl + Shift + N. Khi viết câu lệnh trên cửa sổ Script, R chỉ thực hiện câu lệnh khi bạn đọc yêu cầu. đó, bạn đọc có thể sử dụng cửa sổ Script để viết các chương trình lớn với nhiều dòng lệnh kế tiếp nhau.Sau khi mở của sổ Script, bạn có thể viết các dòng lệnh và sử dụng Enter để xuống dòng và không cần quan tâm đến việc R có thực thi câu lệnh đó hay không. Trong một dòng lệnh trên cửa sổ Script mỗi khi bạn đọc sử dụng dấu ngắt câu lệnh “;” R vẫn hiểu rằng bạn đọc đang viết hai câu lệnh khác nhau trên một dòng. Bạn đọc có thể bắt đầu mở cửa sổ Script và gõ các dòng lệnh dưới đây:Phím Enter cho phép xuống dòng và không thực thi câu lệnh khi bạn đọc viết trên cửa sổ Script. Thay vào đó, để thực thi các dòng lệnh, bạn đọc có hai lựa chọn: thứ nhất, sử dụng con trỏ bấm vào nút Run nằm ở phía góc trên bên phải của cửa sổ này, và thứ hai các bạn sử dụng tổ hợp phím tắt Ctrl + Enter nếu bạn sử dụng R trên hệ điều hành Windows và Cmd + Enter nếu bạn sử dụng R trên hệ điều hành MacOS. Để thực thi một dòng lệnh riêng lẻ trên cửa sổ Script, bạn đọc di chuyển con trỏ đến dòng lệnh đó và thực hiện thao tác như ở trên. Để thực thi nhiều dòng lệnh bạn đọc sử dụng chuột trái lựa chọn các dòng lệnh và sau đó thực hiện thao tác chạy. Khi lựa chọn nhiều dòng lệnh một lúc để thực thi, R sẽ thực hiện các câu lệnh lần lượt theo thứ tự từ trên xuống dưới và từ bên trái qua bên phải nếu một dòng có nhiều câu lệnh.Lưu ý, khi bạn đọc viết một chương trình bao gồm nhiều dòng lệnh, bạn thường phải sử dụng ngôn ngữ thông thường và dễ hiểu bằng tiếng Việt, hoặc tiếng Anh, để ghi chú lại các dòng lệnh hoặc nhóm các dòng lệnh đó có ý nghĩa là gì. Việc này giúp cho bản thân bạn khi xem lại các dòng lệnh của mình và cho những người tiếp nhận khi đọc các dòng lệnh hiểu được ý nghĩa của các câu lệnh. Các câu ghi chú đó theo ngôn ngữ lập trình được gọi là các câu ghi chú, hay comment. Bạn đọc sử dụng dấu Script bắt đầu trước câu ghi chú:Phần tiếp theo của chương sẽ thảo luận về các khái niệm cơ bản nhất trong lập trình, đó là khái niệm về các kiểu biến.","code":"\n1+0.001 ; 2*pi - 3 ; exp(1)-exp(-1)\nlog(3.2)\nlog(1000,10)\n# Đây là cách tính xấp xỉ số e\nn<-1000\ncat(\"e = \", (1+1/n)^n) # Khi n càng lớn thì kết quả càng chính xác"},{"path":"kiến-thức-r-cơ-bản.html","id":"biến-trong-ngôn-ngữ-r","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.2 Biến trong ngôn ngữ R","text":"Biến là khái niệm cơ bản nhất trong mọi ngôn ngữ lập trình. Có bốn loại biến cơ bản trong R bao gồmBiến kiểu số, được gọi trong ngôn ngữ R là kiểu numeric;\nBiến kiểu số, được gọi trong ngôn ngữ R là kiểu numeric;Biến kiểu ký tự, hay chuỗi ký tự, được gọi trong ngôn ngữ R là kiểu character;\nBiến kiểu ký tự, hay chuỗi ký tự, được gọi trong ngôn ngữ R là kiểu character;Biến kiểu logic, được gọi trong ngôn ngữ R là kiểu logical;\nBiến kiểu logic, được gọi trong ngôn ngữ R là kiểu logical;Biến kiểu thời gian, được gọi trong ngôn ngữ R là kiểu Date và kiểu POSIXct.\nBiến kiểu thời gian, được gọi trong ngôn ngữ R là kiểu Date và kiểu POSIXct.Nhiều sách tham khảo khi viết về kiểu biến trong ngôn ngữ lập trình R phân loại biến thành nhiều kiểu hơn, chẳng hạn như có thêm kiểu số nguyên (integer), kiểu factor,… Tuy nhiên theo quan điểm của chúng tôi, phân loại biến quá chi tiết sẽ gây khó khăn cho bạn đọc, nhất là với bạn đọc mới làm quen với lập trình. đó, chúng tôi phân chia kiểu biến trong ngôn ngữ R thành bốn kiểu như ở trên. Trong các phần tiếp theo của chương chúng tôi sẽ thảo luận chi tiết về từng kiểu biến cụ thể và các kiểu biến khác có thể có liên quan.Để tạo một biến trong R và gán giá trị cho biến đó, bạn đọc sử dụng một trong ba cách như sau:Trong các dòng lệnh ở trên, tenbien là tên của biến mà bạn muốn đặt, giatri là giá trị mà bạn muốn gán cho biến. Ký tự <- là ký tự gán giá trị được sử dụng trong các phiên bản R đầu tiên. Gán giá trị cho biến sử dụng ký tự -> khi bạn đọc viết tên biến sang phía bên phải. Cách viết này hiếm khi được dùng. Từ các phiên bản 3.0 của phần mềm R trở đi, dấu = cũng có thể được sử dụng để gán giá trị cho biến. Tuy nhiên dấu = có thể gây nhầm lẫn khi sau này bạn đọc sử dụng cùng lúc với ký hiệu sánh ==. Đồng thời ký hiệu = cũng được sử dụng trong truyền giá trị cho tham số khi viết hàm số. đó, trong cuốn sách này, chúng tôi luôn sử dụng <- để gán giá trị cho biến.Dưới đây là một vài ví dụ về tạo biến và gán giá trị cho biến:Trong các câu lệnh ở trên, x, y hay z là tên biến. Quy tắc đặt tên biến hay tên một đối tượng trong R cần tuân theo các quy tắc sau:Tên biến có thể là tổ hợp của tất cả các chữ cái viết hoa, chữ cái viết thường và các chữ số.\nTên biến có thể là tổ hợp của tất cả các chữ cái viết hoa, chữ cái viết thường và các chữ số.Trong tên biến có thể chứa hai ký tự đặc biệt là “.” và “_“.\nTrong tên biến có thể chứa hai ký tự đặc biệt là “.” và “_“.Tên biến không được phép bắt đầu bằng số hoặc ký tự “_“.\nTên biến không được phép bắt đầu bằng số hoặc ký tự “_“.Không được dùng từ khóa của R để đặt tên biến.\nKhông được dùng từ khóa của R để đặt tên biến.Để kiểm tra các quy tắc ở trên, bạn đọc có thể thử thực thi các câu lệnh tạo biến dưới đây và xem dòng lệnh nào báo lỗi và dòng lệnh nào không báo lỗi:Lưu ý rằng R có phân biệt chữ viết hoa với chữ viết thường trong tên biến. Ví dụ như khi bạn đọc sử dụng x để đặt tên và sau đó dùng X để đặt tên thì R sẽ hiểu đây là hai biến khác nhau:Để biết danh sách các tên biến đang tồn tại trên môi trường làm việc và giá trị của các biến đó, ngoài cách giá trị biến lên cửa sổ Console, bạn đọc có thể sử dụng cửa sổ Environment ở góc phía trên bên phải, của Rstudio. Để xóa một biến hoặc một đối tượng đang tồn tại trong môi trường làm việc hiện tại, bạn đọc sử dụng câu lệnh rm():Một điều cũng cần lưu ý khi đặt tên biến hay khi đặt tên các đối tượng khác trong R là tên biến không được phép trùng với các từ khóa. Danh sách các từ khóa thường sử dụng trong R nằm trong bảng 2.1\nBảng 2.1: Danh sách các từ khóa không được dùng để đặt tên\nTrong phần tiếp theo, chúng ta sẽ thảo luận chi tiết về từng kiểu biến.","code":"\n# Cách thứ nhất\ntenbien <- giatri # dấu \"<-\" là dấu gán giá trị\n\n# Cách thứ hai\ngiatri -> tenbien\n\n# Cách thứ ba\ntenbien = giatri # dấu \"=\" cũng được sử dụng để gán giá trị\n# Cách thứ nhất:\nx <- 3  # Tạo một biến tên là x có giá trị 3.\n\n# Cách thứ hai:\n\"MFE\" -> y # Tạo một biến tên y có giá trị bằng ký tự \"MFE\".\n\n# Cách thứ ba:\nz = 1 + 2\n# Tạo một biến tên z và nhận giá trị bằng kết quả của phép cộng.x1 <- 3 # Biến tên x1 sẽ được tạo với giá trị bằng 3.\n1x <- 3 # Sẽ có lỗi, tên biến không được phép bắt đầu bằng số.\n.x <- 3 # Biến tên .x hợp lệ.\n_x <- 3 # Sẽ báo lỗi, tên biến không được phép bắt đầu bằng _\nx<-3 # Tạo một biến tên x, giá trị bằng 3.\nX<-5 # Tạo một biến tên X, giá trị bằng 5.\nX-x # Hiệu số cho kết quả bằng 2 do x và X là khác nhau.\nx # R trả lại giá trị bằng 3.\nrm(x) # Xóa biến x khỏi môi trường làm việc.\nx # Sẽ báo lỗi vì biến x không còn tồn tại."},{"path":"kiến-thức-r-cơ-bản.html","id":"biến-kiểu-số","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.2.1 Biến kiểu số","text":"Biến kiếu số, được gọi trong R là kiểu numeric, là các biến nhận giá trị kiểu số thập phân. Để tạo một biến kiểu số, bạn đọc gán một giá trị kiểu số bất kỳ cho tên biến mà bạn muốn đặt. Đây cũng là cách tạo biến chung trong R. Câu lệnh dưới đây khởi tạo một biến tên x kiểu số và nhận giá trị bằng 5:Để kiểm tra một biến tên x có phải là biến kiểu số không, bạn đọc sử dụng hàm .numeric(). Hàm số này trả lại giá trị là kiểu logic. Giá trị TRUE cho biết biến được hỏi đúng là kiểu số trong khi giá trị FALSE cho biết biến được hỏi không phải là kiểu số. Ngoài sử dụng hàm .numeric(), bạn đọc cũng có thể sử dụng hàm class(). Hàm class() cho biết kiểu giá trị của một đối tượng bất kỳ trong R. Cách sử dụng hai hàm này như sau:Trong phép gán cho giá trị của biến x ở trên, mặc dù giá trị khởi tạo 5 là số nguyên nhưng R vẫn cho rằng x là kiểu số thập phân. Để tạo một biến kiểu số nguyên, bạn đọc cần phải sử dụng thêm chữ L phía sau số nguyên đó. Chữ L là viết tắt cho Long nghĩa là số nguyên kiểu Long trong các ngôn ngữ lập trình cơ bản như Pascal hay C. Số nguyên kiểu Long là các số nguyên cần 32 bytes để lưu và nhận \\(2^{32}\\) giá trị từ −2,147,483,648 (\\(-2^{31}\\)) đến 2,147,483,647 (\\(2^{31}-1\\)). Để tạo biến x nhận giá trị là số nguyên bằng 5 chúng ta viết như sau:Phân biệt số nguyên và số thập phân trong các ngôn ngữ lập trình có ý nghĩa khi bạn đọc cần tiết kiệm bộ nhớ cho chương trình. Trong R, khi sử dụng số thập phân thay cho số nguyên, dung lượng bộ nhớ máy tính sẽ tăng gấp 2 lần. Hình vẽ dưới đây mô tả dung lượng bộ nhớ cần sử dụng cho các véc-tơ chứa các số nguyên và các véc-tơ chứa các số thập phân với số lượng phần tử chạy từ 1 đến 100. Từ hình 2.1 bạn đọc có thể thấy rằng không có sự khác biệt về bộ nhớ với các véc-tơ có độ dài dưới 10 nhưng khi véc-tơ có độ dài từ 10 trở lên, véc-tơ kiểu số thập phân cần trung bình khoảng 2 lần bộ nhớ với véc-tơ kiểu số nguyên.\nHình 2.1: Sự khác nhau về dung lượng bộ nhớ cần sử dụng để lưu véc-tơ kiểu số nguyên và véc-tơ kiểu số thập phân.\nBiến kiểu số được sử dụng chủ yếu để thực hiện trong các phép tính toán. Các phép tính toán thông thường được liệt kê trong bảng 2.2\nBảng 2.2: Các phép toán cơ bản thường được sử dụng với biến kiểu số\nLưu ý rằng các phép toán lấy phần dư %%, và phép lấy thương số trong phép chia %/%, cũng có thể thực hiện được với cả số kiểu thập phân. Bạn đọc quan sát kết quả của các phép toán này trong ví dụ dưới đây:Một cách viết số kiểu khoa học và các giá trị kiểu số đặc biệt được liệt kê trong bảng 2.3.\nBảng 2.3: Các giá trị số được viết kiểu khoa học và các giá trị số đặc biệt\nBạn đọc cần đặc biệt lưu ý khi thực hiện các phép tính toán có kết quả là các giá trị đặc biệt. Dưới đây là các ví dụ:","code":"\nx <- 5 # 5 là giá trị kiểu số nên R tự hiểu x là biến kiểu số.\nis.numeric(x) # 5 là giá trị kiểu số nên R trả lại TRUE.## [1] TRUE\nclass(x) # Cho biết kiểu giá trị của đối tượng x.## [1] \"numeric\"\ny<-\"abc\" # Khởi tạo một biến y kiểu ký tự.\nis.numeric(y) # Kết quả là FALSE vì y không phải số.## [1] FALSE\nx <- 5L # 5L nghĩa là số nguyên 5, L là viết tắt của Long.\nclass(x) # x là số tự nguyên (integer)## [1] \"integer\"\nis.numeric(x) # x không còn là số thập phân, nhưng vẫn là kiểu số.## [1] TRUE\n6.5 %% 2 # Phần dư của phép chia 6.5 cho 2## [1] 0.5\n6.5 %/% 2 # Phần nguyên của phép chia 6.5 cho 2## [1] 3\n1/0 # Kết quả của 1/0 là dương vô cùng.\n(-1)/0 # Kết quả của -1/0 là âm vô cùng.\nInf - 10^10 # Trong các phép tính có Inf sẽ có kết quả Inf.\n1/0 + (-1)/0 # Inf + (-Inf) là không thể xác định được.\nlog(-2) # Kết quả của các phép tính vô nghĩa là NaN."},{"path":"kiến-thức-r-cơ-bản.html","id":"biến-kiểu-logical","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.2.2 Biến kiểu logical","text":"Biến kiểu logic, được gọi là kiểu logical, là kiểu biến đơn giản nhất nhưng lại quan trọng nhất trong R nói riêng và trong đa số các ngôn ngữ lập trình nói chung. Biến kiểu logical chỉ nhận một trong hai giá trị là TRUE hoặc FALSE. R phân biệt chữ viết hoa và chữ viết thường nên khi viết giá trị cho biến kiểu logic bạn đọc cần viết bao gồm toàn bộ các chữ cái viết hoa. Để tạo một biến kiểu logic, chúng ta chọn tên biến và gán một trong hai giá trị logic. Việc này hoàn toàn giống như khi tạo một biến kiểu số:Biến kiểu logic có thể đặt trong các phép tính toán giống như biến kiểu số. Khi gặp một công thức có bao gồm cả biến kiểu số và biến kiểu logic, R sẽ đổi biến kiểu logic có giá trị TRUE thành giá trị 1 và biến kiểu logic có giá trị FALSE thành giá trị 0 rồi thực hiện phép tính toán:Trong thực tế, ít khi chúng ta khởi tạo giá trị cho biến kiểu logic như trên. Biến kiểu logic thường nhận được từ kết quả các phép sánh. Các phép toán sánh thường được sử dụng trong R được liệt kê trong bảng 2.4\nBảng 2.4: Các phép sánh cơ bản cho kết quả là một biến logic\nNgoài ra, các biến kiểu logic còn là kết quả của việc kết hợp \\(|\\) nhiều biến kiểu logic khác bằng các toán tử logic. Các toán tử logic bao gồm có toán tử “và”, toán tử “hoặc”, và toán tử “phủ định”. Các toán tử này được liệt kê trong bảng 2.5\nBảng 2.5: Bảng 2.6: Các toán tử sử dụng cùng với biến kiểu logic\nBạn đọc cần lưu ý rằng các biến logic khi kết hợp với nhau bằng các toán tử trong bảng 2.5 sẽ cho kết quả là một biến kiểu logic. Quy tắc kết hợp các biến kiểu logic bằng các toán tử logic được tổng hợp trong bảng 2.7\nBảng 2.7: Các biến logic được kết hợp bằng các toán tử logic\nNhư chúng tôi đã đề cập ở trên, các biến kiểu logic khi đặt trong các biểu thức tính toán sẽ được tự động đổi sang biến kiểu số trước khi thực hiện phép tính. Ngược lại, khi biến kiểu số xuất hiện trong các biểu thức có toán tử logic, biến kiểu số cũng sẽ được chuyển sang kiểu logic. R sẽ mặc định quy tắc đổi từ số sang kiểu logic như sau: chỉ có số 0 khi đặt trong biểu thức có toán tử logic mới được chuyển thành FALSE, mọi số khác 0 khi đổi sang kiểu logic đều được chuyển thành TRUE. Bạn đọc hãy quan sát nguyên tắc đổi từ biến kiểu số sang logic trong các phép toán dưới đâyBạn đọc có thể thực hành việc tính toán trên các toán tử logic như ở dưới đây. Trước khi sử dụng R để xem kết quả, hãy thử suy nghĩ xem các biểu thức từ 1. đến 4. dưới đây cho kết quả như thế nào?","code":"\nx <- TRUE\nFALSE + TRUE * 10 # Sẽ cho kết quả giống như 0 + 1 * 10## [1] 10\n10 & -0.1 # Tương đương với TRUE & TRUE## [1] TRUE\n0 & -0.1 # Tương đương với FALSE & TRUE## [1] FALSE\n0 | 0.2 # Tương đương với FALSE | TRUE## [1] TRUE\n# 1.\n(1<=2) | (2<=3)\n# 2.\n(1<=2) + (2<=3)\n# 3.\n((1<=2) * (2^2 == 4)) | (2!=3) #\n# 4.\n!((1<=2) * (2^2 == 4)) & !(2!=3) #\n# 5.\n((2 + 2) | (2 - 2)) & !(2 ^ 2) #"},{"path":"kiến-thức-r-cơ-bản.html","id":"biến-kiểu-chuỗi-ký-tự","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.2.3 Biến kiểu chuỗi ký tự","text":"Biến kiểu ký tự hay chuỗi ký tự còn được gọi trong ngôn ngữ R là kiểu character. Biến kiểu chuỗi ký tự tương tự như biến kiểu xâu ký tự hay kiểu string trong các ngôn ngữ lập trình cơ bản. Biến kiểu chuỗi ký tự có thể chỉ ngắn gọn là một ký tự trống, một chữ cái, nhưng đôi khi có thể là một câu, hoặc cũng có thể là cả một đoạn văn bản. Khi làm việc với biến kiểu chuỗi ký tự, bạn đọc hãy luôn ghi nhớ rằng R phân biệt chữ viết hoa và chữ viết thường.Để tạo một biến có kiểu ký tự trong R, bạn đọc chọn tên cho biến và gán giá trị kiểu chuỗi ký tự. R sẽ hiểu một biến là chuỗi ký tự khi chuỗi ký tự đó nằm trong dấu ngoặc kép \" \" hoặc trong dấu ngoặc đơn ' '.Để biết một biến có phải kiểu chuỗi ký tự không, bạn đọc sử dụng hàm .character() hoặc hàm class(). Hàm .character() trả lại giá trị TRUE nếu một biến có kiểu chuỗi ký tự và trả lại giá trị FALSE trong các trường hợp còn lại. Hàm class(), như chúng tôi đã giới thiệu ở trên, cho biết một đối tượng bất kỳ là đối tượng có kiểu như thế nào:Khi xử lý biến kiểu chuỗi ký tự, bạn đọc nên sử dụng các hàm số đã được xây dựng sẵn. Bảng 2.8 liệt kê các hàm thường được sử dụng khi xử lý biến kiểu chuỗi ký tự và kết quả của các hàm này.\nBảng 2.8: Các hàm thường sử dụng để xử lý biến kiểu chuỗi ký tự\nBạn đọc có thể thực thi các hàm liệt kê trong bảng 2.8 và quan sát giá trị trả ra của các hàm đó trong các câu lệnh dưới đây để hiểu cách sử dụng của các hàm này:Nhìn chung, trong bất kỳ ngôn ngữ lập trình nào, xử lý biến kiểu chuỗi ký tự sẽ luôn khó khăn hơn với xử lý biến kiểu số. Để thực hiện được các yêu cầu phức tạp hơn, bạn đọc có thể kết hợp các hàm số ở trên để có hiệu quả tốt hơn. Có các thư viện được phát triển dành riêng cho việc xử lý các biến kiểu chuỗi ký tự mà tiêu biểu là thư viện stringr. Các hàm hữu ích trong thư viện stringr sẽ được thảo luận chi tiết trong phần phân tích dữ liệu.","code":"\nx <- \"Ice cream\" # \"Ice cream\" với chữ I viết hoa.\nx == \"ice cream\" # Kết quả trả lại là FALSE## [1] FALSE\nis.character(x)\nclass(x)\n# Khởi tạo hai biến kiểu chuỗi ký tự x1 và x2\nx1 <- \"I am an Actuary\"; x2<-\"I am Vietnamese\"\nnchar(x1) # Cho biết x1 có bao nhiêu ký tự.\npaste(x1, x2, sep = \" and \") # Ghép x1 và x2 lại và thêm \" and \" vào giữa.\ntoupper(x1); tolower(x1) # Chuyển tất cả các ký tụ sang viết hoa/viết thường\nchartr(\"an\",\"bm\",x1) # Thay tất cả các chữ \"a\" trong x1 bằng \"b\" và \"n\" bằng \"m\"\nsubstr(x1, 9, 15) # Lấy ra đoạn ký tự từ ký tự thứ 9 (chữ A) đến ký tự thứ 15 (chữ \"y\")\nsub(\"a\", \"XYZ\", x1) # Thay chữ \"a\" đầu tiên trong x1 bằng đoạn \"XYZ\"\ngsub(\"a\", \"XYZ\", x1) # Thay tất cả chữ \"a\" trong x1 bằng đoạn \"XYZ\"\ngrepl(\"Vietnam\", x2) # Cho biết đoạn ký tự \"Vietnam\" có nằm trong x2 hay không"},{"path":"kiến-thức-r-cơ-bản.html","id":"biến-kiểu-thời-gian","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.2.4 Biến kiểu thời gian","text":"Trong ngôn ngữ R có hai kiểu biến thời gian là biến kiểu ngày tháng, được gọi trong ngôn ngữ R là kiểu Date) và biến kiểu thời gian chi tiết, được gọi trong ngôn ngữ R là kiểu POSIXct. Thời gian POSIX hay còn được biết đến với tên gọi là thời gian Unix là một cách quy ước về thời gian của một thời điểm cụ thể được tính bằng số giây từ cột mốc thời gian Unix đến thời điểm đó. Cột mốc thời gian Unix được các kỹ sư xây dựng hệ điều hành Unix lựa chọn là thời điểm 0 giờ, 0 phút, 0 giây, ngày 01 tháng 01 năm 1970 theo giờ phối hợp quốc tế (giờ UTC). Chữ “ct” là viết tắt của canlendar time. Bạn đọc cũng có thể gặp biến kiểu thời gian chi tiết trong R dưới dạng POSIXlt trong đó lt là chữ viết tắt của local time. Sự khác biệt của biến kiểu POSIct và POSIXlt chỉ là cách R lưu trữ các biến này dưới dạng số nguyên hay dưới dạng véc-tơ. Trong cuốn sách này khi nói đến biến kiểu thời gian chúng tôi luôn sử dụng biến kiểu POSIXct.Để tạo biến kiểu thời gian trong R, bạn đọc sử dụng hàm .Date() cho biến kiểu ngày tháng và hàm .POSIXct() cho biến kiểu thời gian chi tiết:Khi xử lý biến kiểu thời gian, bạn đọc nên đổi sang dạng số hoặc lưu biến kiểu thời gian dưới dạng một véc-tơ số lưu lại các thành phần của thời gian theo một thứ tự nhất định. Hàm .numeric() sẽ đổi các biến kiểu ngày tháng hoặc thời gian chi tiết ra thành số ngày đối với biến kiểu ngày tháng, hoặc số giây đối với biến kiểu thời gian chi tiết, tính từ mốc thời gian Unix.múi giờ UTC của Việt Nam là UTC + 7 nên thời điểm tính làm mốc sẽ là 7 giờ, 0 phút, 0 giây, ngày 01 tháng 01 năm 1970. Điều này giải thích tại sao khi đổi biến time2 dưới đây thành dạng số ta sẽ thu được kết quả là 30 giây.Khi sử dụng các hàm .Date() hoặc .POSIXct() giá trị được đưa vào phải là biến dạng chuỗi ký tự được viết theo đúng quy tắc YYYY-MM-DD và YYYY-MM-DD hh:mm:ss. Trong trường hợp chuỗi ký tự được đưa vào không đúng định dạng, bạn đọc cần phải thông báo cho R biết định dạng của biến chuỗi ký tự đó bằng cách sử dụng thêm tham số format. Bạn đọc có thể tham khảo cách khai báo định dạng của biến chuỗi ký tự trong các hàm .Date() hoặc .POSIXct() như sau:Trong rất nhiều trường hợp, biến kiểu thời gian sẽ được lấy từ các nguồn khác nhau vào R và được lưu dưới dạng số tự nhiên. Điển hình là khi bạn đọc lấy dữ liệu từ các file được lưu từ phần mềm Microsoft Excel. Các hàm .Date() và .POSIXct() cũng có thể chuyển giá trị số biến kiểu ngày tháng và biến kiểu thời gian chi tiết. Bạn đọc cần sử dụng thêm tham số biến origin trong các hàm này để quy định mốc thời gian.Sau khi thực thi các câu lệnh ở trên, biến date1 tương ứng với ngày thứ 19,000 tính từ mốc ngày 1 tháng 1 năm 1970 và biến time1 tương ứng với thời điểm giây thứ 1 tỷ tính từ 07 giờ 00 phút 00 giây ngày 1 tháng 1 năm 1970.Vấn đề thường gặp phải khi lấy dữ liệu từ các nguồn ngoài là cách chuyển đổi từ thời gian thành số của phần mềm lưu dữ liệu gốc có mốc thời gian khác với R. Chẳng hạn như biến kiểu thời gian từ Microsoft Excel khi chuyển đổi thành số sử dụng mốc thời gian là ngày 30 tháng 12 năm 1899. Giả sử khi bạn đọc lấy một biến thời gian từ Microsoft Excel vào R và thấy giá trị là 45678. Nếu không sử dụng mốc thời gian của Microsoft Excel để chuyển đổi, giá trị thời gian nhận được sẽ không đúng. Để biến ngày tháng nhận giá trị đúng, chúng ta cần khai báo tham số origin như sau:Nguyên tắc cơ bản khi xử lý và tính toán với biến kiểu thời gian trong R là luôn luôn đổi biến sang kiểu số nguyên hoặc đổi một biến kiểu thời gian thành một véc-tơ chứa các thành phần ngày, tháng, năm, giờ, phút, giây dưới dạng số. Để tách biến kiểu ngày tháng ra thành ngày, tháng, năm bạn đọc có thể sử dụng hàm sub.str() để lấy ra các đoạn ký tự chứa giá trị ngày, tháng, và năm rồi sau đó sử dụng hàm .numeric() để đổi các biến thành biến kiểu số:Xử lý biến kiểu ngày tháng và biến kiểu thời gian phức tạp hơn với xử lý biến kiểu số và thường cần thêm các thư viện bổ sung. Thư viện chúng tôi thường sử dụng khi làm việc với biến kiểu thời gian là thư viện lubridate hoặc thư viện hms. Bạn đọc sẽ sử dụng các thư viện này để thực hành với biến kiểu thời gian trong chương phân tích dữ liệu.","code":"\n# Tạo biến date1 nhận giá trị là ngày 31/08/2023\ndate1 <- as.Date(\"2023-08-31\")\n\n# Biến time1 là 16 giờ, 41 phút, 30 giây ngày 31/08/2023\ntime1 <- as.POSIXct(\"2023-08-31 16:41:30\")\n# Cho biết số ngày tính từ 01/01/1970 đến date1\nas.numeric(date1)## [1] 19600\n# Cho biết số giây tính từ 7 giờ, 0 phút, 0 giây ngày 01/01/1970 đến time1\nas.numeric(time1)## [1] 1693474890\n# Cho biết số giây tính từ 7 giờ, 0 phút, 0 giây ngày 01/01/1970 đến time2\ntime2 <- as.POSIXct(\"1970-01-01 07:00:30\")\nas.numeric(time2)## [1] -3570\n# date1 là ngày 27 tháng 02 năm 1992\ndate1 <- as.Date(\"02/27/92\", format = \"%m/%d/%y\")\n\n# date2 là ngày 02 tháng 01 năm 2010\ndate2 <- as.Date(\"02 Jan 2010\", format = \"%d %b %Y\")\ndate1 <- as.Date(19000, origin = \"1970-01-01\")\ntime1 <- as.POSIXct(10^9, origin = \"1970-01-01 07:00:00\")\n# 45678 là giá trị của biến lấy từ nguồn Microsoft Excel\ndate1 <- as.Date(45678, origin = \"1970-01-01\")\ndate1 # date1 sai do sử dụng mốc thời gian ngày 01 tháng 01 năm 1970.## [1] \"2095-01-23\"\ndate2 <- as.Date(45678, origin = \"1899-12-30\")\ndate2 # date2 có giá trị ĐÚNG do dùng đúng mốc thời gian của Excel.## [1] \"2025-01-21\"\n# Lấy ra giá trị năm trong biến date2\nyear <- as.numeric(substr(date2,1,4))\n\n# Lấy ra giá trị tháng trong biến date2\nmonth <- as.numeric(substr(date2,6,7))\n\n# Lấy ra giá trị ngày trong biến date2\nday <- as.numeric(substr(date2,9,10))"},{"path":"kiến-thức-r-cơ-bản.html","id":"véc-tơ","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.3 Véc-tơ","text":"Trong phần này của cuốn sách chúng tôi giới thiệu các khái niệm cơ bản về véc-tơ và giải thích tại sao xử lý véc-tơ lại là thế mạnh của ngôn ngữ R. Chúng tôi sẽ không đi quá chi tiết vào các kỹ thuật xử lý véc-tơ mà chỉ tập trung vào các công cụ cơ bản. Các yêu cầu về xử lý véc-tơ sẽ được lặp lại trong tất cả các chương tiếp sau của cuốn sách, đó đi quá sâu vào chi tiết trong phần này là không cần thiết.","code":""},{"path":"kiến-thức-r-cơ-bản.html","id":"tại-sao-xử-lý-véc-tơ-là-thế-mạnh-của-r","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.3.1 Tại sao xử lý véc-tơ là thế mạnh của R?","text":"Véc-tơ là một tập hợp các phần tử có cùng kiểu được sắp xếp theo một thứ tự nhất định. Thứ tự của một phần tử trong véc-tơ được gọi là chỉ số của phần tử đó. Phần tử đầu tiên trong một véc-tơ của R có chỉ số là 1. Bạn đọc lưu ý điều này bởi trong một vài ngôn ngữ khác chỉ số của phần tử đầu tiên trong véc-tơ sẽ là 0. Véc-tơ là đối tượng quan trọng nhất trong R và xử lý vec-tơ chính là một thế mạnh của R, giúp cho R có thể thực hiện được những phân tích mà nhiều ngôn ngữ khác không đáp ứng được.Khi bạn đọc làm việc với dữ liệu, các thao tác biến đổi hay phân tích dữ liệu thường sẽ là được thực hiện đồng thời trên các giá trị trên cùng một hàng hoặc một cột dữ liệu. Hiếm khi các thao tác này được thực hiện với một giá trị riêng lẻ. Đối tượng véc-tơ là một công cụ hiệu quả để thực hiện các công việc này. Hiệu quả ở đây không chỉ bao gồm sự tiện lợi khi viết các câu lệnh, mà còn hiệu quả ở cả thời gian thực hiện tính toán. Trong phần Lập trình với R, chúng tôi sẽ thảo luận kỹ hơn về hiệu quả về thời gian tính toán. Hãy nói về sự tiện lợi khi sử dụng véc-tơ trước. Chúng ta hãy lấy ví dụ khi thực hiện một phân tích trên dữ liệu có tên là trump_tweets bằng cách thực thi một đoạn lệnh sauDữ liệu trump_tweets trong thư viện dslabs là dữ liệu chứa 20.761 câu trạng thái trên các nền tảng mạng xã hội của cựu tổng thống Mỹ Donald Trump trong khoảng thời gian từ năm 2009 đến năm 2017. Đoạn câu lệnh trên thực hiện một phân tích cho biết cựu tổng thống Donald Trump có thói quen viết các câu trạng thái trên các nền tảng mạng xã hội vào các khoảng thời gian nào trong ngày. Kết quả này thu được bằng việc thực hiện 1 chuỗi các phép biến đổi và tính toán trên cột dữ liệu có tên là created_at. Các biến đổi và tính toán được liệt kê như sau:Lấy ra đoạn ký tự chứa giá trị là giờ của cột created_at. Được thực hiện bằng cách dùng hàm substr();Chuyển đổi dữ liệu kiểu chuỗi ký sang kiểu số sử dụng hàm .numeric();Chuyển đổi dữ liệu kiểu số sang kiểu factor sử dụng hàm .factor();Tổng hợp lại dữ liệu kiểu factor theo các nhóm bằng hàm table();Vẽ đồ thị kiểu Barplot để người đọc hiểu về dữ liệu một cách nhanh chóng và trực quan hơn.Để biến đổi từ cột dữ liệu created_at có kiểu .POSIXct() đến kết quả là đồ thị Barplot mà chỉ cần một dòng lệnh là việc gần như không thể đối với đa số các ngôn ngữ lập trình. Các ngôn ngữ lập trình cơ bản chỉ cho phép người sử dụng tác động đển từng phần tử của véc-tơ một cách lần lượt và riêng lẻ. Điều thú vị là khi bạn đọc thực hiện một phép biến đổi hay tính toán trên đối tượng là véc-tơ trong R, các phép tính toán hay biến đổi này sẽ được thực hiện một cách đồng thời cho tất cả các phần tử trong véc-tơ. Ngoài việc giúp cho các câu lệnh trở nên đơn giản, dể hiểu, R cũng được phát triển để những tính toán trên véc-tơ được thực hiện theo cơ chế song song. Cơ chế song song hiểu một cách đơn giản là việc thực hiện các phép toán trên các phần tử của một véc-tơ sẽ diễn ra cùng một lúc chứ không thực hiện một cách lần lượt. Việc này cho phép rút ngắn được thời gian tính toán.Hầu hết các hàm số trên R đều được phát triển theo cơ chế lập trình véc-tơ, nghĩa là các hàm số được dùng cho một biến kiểu số đều có thể áp dụng được cho một véc-tơ kiểu số, các hàm số được dùng cho một biến kiểu chuỗi ký tự đều có thể áp dụng được cho một véc-tơ kiểu chuỗi ký tự, tương tự với các véc-tơ kiểu logic hay kiểu ngày tháng. Trong ví dụ trên, cột (véc-tơ) created_at của dữ liệu trump_tweets là một véc-tơ kiểu thời gian chi tiết đã liên tục được biến đổi bằng các hàm số như substr(), .numeric(),… Các hàm này đều cho phép đầu vào là một véc-tơ và trả lại giá trị cũng là một véc-tơ có độ dài tương ứng.Ngoài việc thực hiện tính toán trên các véc-tơ riêng lẻ, cơ chế hoạt động của ngôn ngữ R cũng cho phép thực hiện tính toán tương tác giữa các véc-tơ với nhau. Tương tác giữa hai hay nhiều véc-tơ với nhau luôn được thực hiện trên nguyên tắc các phần tử có cùng chỉ số của các véc-tơ sẽ tương tác với nhau. Thậm chí các véc-tơ tương tác với nhau có thể không có cùng kích thước mà vẫn cho kết quả. Chi tiết sẽ được thảo luận trong các phần tiếp theo.","code":"\nlibrary(dslabs) # cần gọi thư viện dslabs chứa dữ liệu trump_tweets\nbarplot(table(as.factor(as.numeric(substr(trump_tweets$created_at,12,13)))),\n        main = \"Tổng thống Trump viết tweet vào thời gian nào trong ngày\",\n        col = \"white\", border = \"#640514\", xlabs = \"Giờ trong ngày\")"},{"path":"kiến-thức-r-cơ-bản.html","id":"khởi-tạo-véc-tơ-và-các-phép-toán-trên-véc-tơ","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.3.2 Khởi tạo véc-tơ và các phép toán trên véc-tơ","text":"","code":""},{"path":"kiến-thức-r-cơ-bản.html","id":"khởi-tạo-véc-tơ-bằng-các-hàm-có-sẵn","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.3.2.1 Khởi tạo véc-tơ bằng các hàm có sẵn","text":"Để khởi tạo một véc-tơ trong R, bạn đọc có thể sử dụng bất kỳ một hàm số có sẵn miễn là có đầu ra là một véc-tơ với kiểu giá trị phù hợp. Hàm số thông dụng nhất được dùng để tạo véc-tơ trong R là hàm c(); c là viết tắt của concatenate, hoặc một vài tài liệu cho rằng c là viết tắt của combine. Về mặt ý nghĩa, hàm c() tập hợp các đối tượng được liệt kê trong dấu ngoặc \\(()\\) lại để tạo thành một véc-tơ duy nhất. Nếu các phần tử được liệt kê ra có cùng kiểu dữ liệu, đối tượng tượng tạo thành sẽ là một véc-tơKhi các biến được liệt kê bên trong hàm c() không cùng kiểu, R sẽ cố gắng phân tích các giá trị đó để đưa ra kết quả phù hợp. Nguyên tắc chung là nếu các giá trị được liệt kê bên trong hàm c() bao gồm kiểu số, kiểu logic, và kiểu thời gian thì véc-tơ được tạo thành sẽ là véc-tơ kiểu số. Trong trường hợp có 1 biến được liệt kê ra là kiểu chuỗi ký tự, véc-tơ được tạo thành sẽ là véc-tơ kiểu chuỗi ký tự. Bạn đọc có thể kiểm tra giá trị của các véc-tơ sau:Các giá trị bên trong hàm c() cũng có thể là một véc-tơ khác, thậm chí có thể là một ma trận (matrix), hoặc là một đối tượng kiểu mảng (array). Giá trị đầu ra của hàm c() luôn luôn là một véc-tơ. Nếu là ma trận hoặc mảng hàm c() sẽ chuyển hóa các phần tử ra thành 1 véc-tơ theo thứ tự các cột bắt đầu từ cột có chỉ số 1. Chúng ta sẽ quay lại vấn đề này khi thảo luận về ma trận và mảng trong phần kiến thức R nâng cao.Như chúng tôi đã nói ở trên, bất kỳ hàm số sẵn có nào có đầu ra là một véc-tơ đều có thể dùng để tạo thành véc-tơ. Các hàm mà chúng tôi hay sử dụng để khởi tạo véc-tơ, ngoài hàm c(), còn có các hàm rep() và hàm seq().Hàm số rep() có thể được sử dụng để lặp đi lặp lại một biến, một véc-tơ nào đó nhiều lần. Cụ thể rep(x,n) với n là một số nguyên dương và x là một biến hoặc một véc-tơ sẽ cho kết quả là một véc-tơ được tạo thành bằng cách lặp lại giá trị x theo thứ tự từ trái sang phải n lần.Hàm số seq() được dành riêng cho véc-tơ kiểu số. Câu lệnh seq(= , = b,length = n) tạo thành một dãy số tăng dần (hoặc giảm dần) bắt đầu từ kết thúc tại b và véc-tơ có độ dài là n.Các hàm rep() và seq() được sử dụng như sau:Đầu ra của hàm seq() luôn là một véc-tơ kiểu số. Nếu không sử dụng tham số length, bạn đọc có thể sử dụng tham số là khoảng cách giữa hai số liên tiếp trong dãy số như ví dụ dưới đâyKhi thực hiện các phép tính toán tổng hợp các véc-tơ kiểu số, chúng ta thường quan tâm đến các giá trị như tổng, giá trị trung bình, tích, độ lệch chuẩn, hoặc quan tâm đến việc sắp xếp các giá trị trong véc-tơ đó. Các hàm số được liệt kê trong bảng 2.9 là các hàm số thường sử dụng để thực hiện các tính toán như vậy,\nBảng 2.9: Các hàm thường sử dụng trên véc-tơ\nBạn đọc lưu ý rằng còn nhiều hàm số hữu ích khác được xây dựng sẵn khi tính toán với véc-tơ mà chúng tôi không liệt kê ở đây. Đồng thời, mỗi hàm số trong bảng kể trên còn có các tham số để có thể sử dụng trong các hoàn cảnh khác nhau. Chẳng hạn khi trong véc-tơ \\(x\\) có các giá trị không có ý nghĩa NaN hoặc không quan sát được NA thì các hàm như sum(x), mean(x), … sẽ không thực hiện tính toán được. Trong trường hợp này, bạn đọc cần sử dụng thêm tham số na.rm=TRUE để R hiểu rằng các phép tính toán chỉ thực hiện trên các giá trị có ý nghĩa.Cách tốt nhất để hiểu và sử dụng hiệu quả và đúng mục đích các hàm số liệt kê ở trên là đọc hướng dẫn của hàm số đó. Trong cuốn sách này chúng tôi chỉ nhấn mạnh những hàm số và tham số của nó mà chúng tôi cho rằng quan trọng khi ứng dụng các hàm số trong thực tế.Các hàm số sử dụng trên các véc-tơ kiểu số như sum(), mean(), hay thậm chí cả var() hay sd() đều có thể hoạt động trên véc-tơ kiểu thời gian hoặc kiểu logic. Nếu phép toán thực hiện không thể giữ nguyên kiểu dữ liệu của véc-tơ, R sẽ đổi véc-tơ kiểu thời gian và véc-tơ kiểu logic sang kiểu số để thực hiện tính toán như ví dụ dưới đây:Ngoài các nguyên tắc tính toán thông thường, bạn đọc thấy rằng R có thể sắp xếp thứ tự các phần tử trong một véc-tơ bất kỳ tăng dần hoặc giảm dần bằng hàm sort(). Hoặc R cũng có thể lấy ra giá trị lớn nhất hoặc nhỏ nhất của một véc-tơ bằng hàm max() hoặc hàm min(). Điều này là khá hiển nhiên với các véc-tơ kiểu số. Trong trường hợp véc-tơ là véc-tơ kiểu logic hay kiểu ngày tháng, R sẽ đổi giá trị của véc-tơ đó sang kiểu số để tiến hành sắp xếp hay tìm ra giá trị lớn nhất hoặc giá trị nhỏ nhất. Điều gì sẽ xảy ra nếu véc-tơ cần được sắp xếp, hay tìm giá trị lớn nhất và nhỏ nhất là véc-tơ kiểu chuỗi ký tự. Đây là một vấn đề phức tạp liên quan đến việc mã hóa các ký tự trên máy tính và vượt quá phạm vi của cuốn sách. Bạn đọc chỉ cần ghi nhớ các nguyên tắc sau khi sắp xếp một véc-tơ kiểu chuỗi ký tự:Nếu véc-tơ kiểu chuỗi ký tự được biến đổi thành kiểu factor thì thứ tự sắp xếp tăng dần sẽ phụ thuộc vào cách định nghĩa các mức độ (level) của véc-tơ kiểu factor.\nNếu véc-tơ kiểu chuỗi ký tự được biến đổi thành kiểu factor thì thứ tự sắp xếp tăng dần sẽ phụ thuộc vào cách định nghĩa các mức độ (level) của véc-tơ kiểu factor.Khi sánh hai chuỗi ký tự, phép sánh sẽ được thực hiện ở ký tự thứ nhất trước, nếu hai ký tự đầu tiên giống nhau thì sẽ sánh ký tự tiếp theo, và tiếp tục như thế đến khi có sự khác biệt.\nKhi sánh hai chuỗi ký tự, phép sánh sẽ được thực hiện ở ký tự thứ nhất trước, nếu hai ký tự đầu tiên giống nhau thì sẽ sánh ký tự tiếp theo, và tiếp tục như thế đến khi có sự khác biệt.Các ký tự đặc biệt luôn được xếp trước (nhỏ hơn), sau đó đến các ký tự là các số, rồi đến chữ cái. Thứ tự sắp xếp của các ký tự số theo đúng thứ tự tăng dần từ 0 đến 9 trong khi thứ tự sắp xếp của các chữ cái là tăng dần theo bảng chữ cái. Chữ viết thường được viết trước (nhỏ hơn) chữ viết hoa của chữ cái đó. Chữ viết hoa của chữ cái đứng trước lại “nhỏ hơn” chữ viết thường của chữ đứng sau trong bảng chữ cái.\nCác ký tự đặc biệt luôn được xếp trước (nhỏ hơn), sau đó đến các ký tự là các số, rồi đến chữ cái. Thứ tự sắp xếp của các ký tự số theo đúng thứ tự tăng dần từ 0 đến 9 trong khi thứ tự sắp xếp của các chữ cái là tăng dần theo bảng chữ cái. Chữ viết thường được viết trước (nhỏ hơn) chữ viết hoa của chữ cái đó. Chữ viết hoa của chữ cái đứng trước lại “nhỏ hơn” chữ viết thường của chữ đứng sau trong bảng chữ cái.Trước khi sử dụng R để ra kết quả, bạn đọc hãy thử đoán xem R sẽ cho kết quả như thế nào khi chạy các câu sắp xếp các véc-tơ sau theo thứ tự tăng dần:Hàm sort() nếu không sử dụng thêm tham số sẽ luôn sắp xếp véc-tơ theo thứ tự tăng dần. Để sắp xếp véc-tơ theo thứ tự giảm dần, bạn đọc có thể sử dụng thêm tham số decreasing = TRUE hoặc ngắn gọn hơn là decreasing = T trong hàm sort().","code":"\n# Khởi tạo x là một vec-tơ kiểu số\nx <- c(1,1,2,3,5,8,13,21)\n\n# Khởi tạo \"qua\" là vec-tơ chứa tên các loại quả\nqua = c(\"chuối\", \"táo\", \"cam\", \"chanh\")\n# Véc-tơ bao gồm kiểu số và logic\nx <- c(1,TRUE, FALSE)\nclass(x)## [1] \"numeric\"\n# Véc-tơ bao gồm kiểu logic và ngày tháng\nx <- c(TRUE, as.Date(\"2023-12-31\"))\n\n# Véc-tơ bao gồm kiểu số,logic,ngày tháng, và chuỗi ký tự\nx <- c(1, TRUE, as.Date(\"2023-12-31\"),\"MFE\")\nclass(x)## [1] \"character\"\n# Khai báo véc-tơ x\nx <- c(1, TRUE, as.Date(\"2023-12-31\"),\"MFE\")\n\n# Khai báo véc-tơ y chứa x\ny <- c(x,\"Actuary\",x) # dùng véc-tơ x trong khai báo véc-tơ y\n# Véc-tơ x kiểu số, các giá trị đều là 1, độ dài 1000\nx <- rep(1,10^3)\n\n# Véc-tơ y kiểu chuỗi ký tự, độ dài 200 vì lặp lại véc-tơ (\"a\",\"b\") 100 lần\ny <- rep(c(\"a\",\"b\"),100) #\n\n# z là cấp số cộng từ 0 đến 1, độ dài là 101\nz <- seq(from = 0,to = 1,length = 101)\n# z1 là cấp số cộng từ 0 đến 1, tăng dần 0.01\nz1 <- seq(from = 0,to = 1, 0.01)\n\n# z2 là cấp số trừ từ 1 về 0, giảm dần 0.01\nz2 <- seq(from = 1,to = 0, -0.01)\n# Khởi tạo véc-tơ x có chứa NA\nx <- c(rep(1,10),2,3,NA)\n\n# Hàm sum trả lại giá trị NA\nsum(x)## [1] NA\n# tham số na.rm = TRUE loại NA ra khỏi tổng\nsum(x,na.rm=TRUE)## [1] 15\n# Khởi tạo x là véc-tơ kiểu thời gian\nx <- c(as.Date(\"2023-01-01\"),as.Date(\"2023-12-31\"))\n\n# Hàm mean trên véc-tơ kiểu thời gian\nmean(x)## [1] \"2023-07-02\"\n# Hàm sd trên véc-tơ kiểu thời gian\nsd(x)## [1] 257.3869\n# Xếp véc-tơ kiểu ký tự tăng dần\nsort(c(\"a\",\"az\",\"z\")) # chữ cái đầu tiên để so sánh\n\n# Xếp chữ cái đứng trước trong bảng chữ cái nhỏ hơn\nsort(c(\"a\",\"az\",\"z\",\"A\",\"Z\"))\n\n# Xếp số đứng trước chữ cái\nsort(c(\"a\",\"az\",\"z\",\"A\",\"Z\",\"1a\"))\n\n# Xếp ký tự đặc biệt trước ký tự số\nsort(c(\"a\",\"az\",\"z\",\"A\",\"Z\",\"1a\",\"@a\"))\n\n# ký tự đặc biệt trước số, số trước chữ cái\nsort(c(\"a\",\"az\",\"z\",\"A\",\"Z\",\"1a\",\"@a\", \"0123\"))\n# Xếp véc-tơ theo thứ tự giảm dần\nsort(c(1,1,2,3,5,8,13,21), decreasing = TRUE)## [1] 21 13  8  5  3  2  1  1\n# Viết ngắn gọn TRUE bằng T\nsort(c(\"a\",\"az\",\"z\",\"A\",\"Z\",\"1a\",\"@a\", \"0123\"),decreasing = T)## [1] \"Z\"    \"z\"    \"az\"   \"A\"    \"a\"    \"1a\"   \"0123\" \"@a\""},{"path":"kiến-thức-r-cơ-bản.html","id":"tính-toán-trên-véc-tơ","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.3.2.2 Tính toán trên véc-tơ","text":"Như chúng tôi đã đề cập ở trên, R là ngôn ngữ lập trình véc-tơ, nghĩa là bạn đọc có thể sử dụng véc-tơ như một đối tượng trong các phép tính toán hoặc sánh mà không cần phải tác động đến từng phần tử riêng lẻ của véc-tơ đó. Đây chính là thế mạnh của R mà nhiều ngôn ngữ lập trình khác không thực hiện được.Trước hết, chúng ta có thể cho một véc-tơ x kiểu số vào trong các phép tính toán thông thường như cộng, trừ, nhân, chia, lũy thừa với các số thực. Kết quả thu được sẽ là một véc-tơ có độ dài bằng với véc-tơ ban đầu:Quan sát kết quả được ra, bạn đọc có thể nhận thấy rằng nguyên tắc R thực hiện phép tính nhân véc-tơ x với số 2, hay bất kỳ phép tính nào khác giữa véc-tơ x với một số, là lấy lần lượt các phần tử riêng lẻ trong véc-tơ x nhân lên 2 và tạo thành một véc-tơ mới theo đúng thứ tự như trong x. Tương tự như phép tính toán, phép sánh cũng có thể thực hiện giữa một véc-tơ với một biến để cho kết quả là một véc-tơ kiểu logic:Hầu hết các hàm số sẵn có trong R, hoặc các hàm số được phát triển trong các thư viện của R, đều có thể áp dụng trên đối tượng là véc-tơ và nguyên tắc áp dụng hàm số trên véc-tơ cũng tương tự như nguyên tắc tính toán giữa véc-tơ với một số. Việc thực hiện tính toán sẽ được thực hiện trên các phần tử riêng lẻ của véc-tơ và sau đó lưu lại trong một véc-tơ mới có độ dài bằng với véc-tơ ban đầu. Ví dụ như hàm nchar() cho biết một biến kiểu chuỗi ký tự có bao nhiêu ký tự. Khi sử dụng hàm nchar() với một véc-tơ kiểu chuỗi ký tự sẽ cho kết quả là một véc-tơ kiểu số mà mỗi phần tử là số ký tự của phần tử tương ứng trong véc-tơ kiểu chuỗi ký tựBằng cách kết hợp các hàm số trên véc-tơ và tương tác giữa véc-tơ với một biến, bạn đọc có thể tự tạo ra các hàm số, các phương pháp của riêng mình để giải quyết các vấn đề phức tạp hơn. Chẳng hạn như chúng ta muốn biết có bao nhiêu phần tử trong véc-tơ thỏa mãn một điều kiện nào đó, chúng ta có thể kết hợp hàm sum() với một biểu thức sánh giữa véc-tơ với một số:Khi thực hiện phép sánh x > 10 , x là một véc-tơ kiểu số nên phép sánh sẽ trả lại giá trị TRUE tại các vị trí mà kết quả sánh là đúng và trả lại giá trị FALSE tại các vị trí còn lại. Khi kết hợp với hàm sum(), các giá trị TRUE sẽ được đổi thành số 1 và FALSE được đổi thành 0. Kết quả thu được sẽ là số lượng các giá trị TRUE trong phép sánh, hay nói một cách khác, là số các phần tử trong x thỏa mãn điều kiện lớn hơn 10.Tất nhiên với véc-tơ x có độ dài nhỏ như ở trên, bạn đọc có thể nhìn được một cách trực quan mà không cần hỗ trợ của máy tính. Nhưng thực tế thì các véc-tơ mà chúng ta cần thực hiện tính toán trên thực tế sẽ có độ dài lớn hơn rất nhiều và bạn đọc không thể tính toán trực quan như với véc-tơ x kể trên. Chẳng hạn như bạn muốn biết có bao nhiêu câu đăng trạng thái của cựu tổng thống Donald Trump mà có nhiều hơn 10.000 lượt yêu thích. Bạn có thể kết hợp sum() với biểu thức sánh để trả lời câu hỏi này. Lưu ý rằng véc-tơ chứa số lượt yêu thích với mỗi câu đăng trạng thái là cột favorite_count trong dữ liệu:Thay vì tính số tổng, bạn đọc cũng có thể tính tỷ lệ số câu đăng trạng thái có số lượt yêu thích nhiều hơn 10.000 bằng cách kết hợp thêm với hàm length() :Có rất nhiều cách kết hợp các hàm số trong bảng 2.9 lại để đạt được kết quả mong muốn. Một kết quả phân tích có thể đạt được bằng các cách kết hợp khác nhau. Để sử dụng thành thạo các hàm này chỉ có một cách duy nhất là hãy thực hành nhiều trên R và tự đúc kết kinh nghiệm cho chính mình!","code":"\n# Khởi tạo véc-tơ kiểu số x\nx <- 1:5\n\n# Nhân véc-tơ x với một số\nx * 2## [1]  2  4  6  8 10\n# Phép lũy thừa trên đối tượng véc-tơ\nx ^ 2## [1]  1  4  9 16 25\n# Phép lấy phần dư trên đối tượng véc-tơ\nx %% 2## [1] 1 0 1 0 1\n# Khởi tạo véc-tơ kiểu số x\nx <- c(1,1,2,3,5,8,13,21)\n\n# So sánh véc-tơ x với một số, kết quả là véc-tơ logic\nx == 1## [1]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n# Kết hợp các véc-tơ logic bằng toán tử logic\n(x > 10) | (x < 3)## [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE  TRUE\n# Khởi tạo véc-tơ s kiểu chuỗi kỹ tự\ns <- c(\"a\",\"az\",\"z\",\"A\",\"Z\",\"1a\",\"@a\", \"0123\")\n\n# So sánh s với một biến kiểu chuỗi ký tự\ns == \"a\"## [1]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n# Khởi tạo véc-tơ s kiểu chuỗi kỹ tự\ns <- c(\"a\",\"az\",\"z\",\"A\",\"Z\",\"1a\",\"@a\", \"0123\")\n\n# Áp dụng hàm nchar trên véc-tơ s\nnchar(s)## [1] 1 2 1 1 1 2 2 4\n# Khởi tạo véc-tơ x kiểu số\nx <- c(1,1,2,3,5,8,13,21)\n\n# Đếm xem có phần tử trong x lớn hơn 10\nsum(x > 10)## [1] 2\n# Tính tỷ lệ số phần tử lớn hơn 10\nsum(x > 10)/length(x)## [1] 0.25\n# Khởi tạo véc-tơ x chứa số lượt yêu thích\nx <- trump_tweets$favorite_count\n\n# Đếm xem có bao nhiêu phần tử trong x lớn hơn 10^4\nsum(x>10^4)## [1] 4958\n# Tính tỷ lệ phần tử trong x lớn hơn 10^4\nsum(x>10^4)/length(x)## [1] 0.2388132"},{"path":"kiến-thức-r-cơ-bản.html","id":"lấy-các-thành-phần-con-từ-một-véc-tơ","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.3.3 Lấy các thành phần con từ một véc-tơ","text":"Khi làm việc với véc-tơ, chúng ta thường phải lấy các phần tử của véc-tơ ra theo một thứ tự hoặc lấy các phần tử con thỏa mãn các điều kiện nào đó và lưu kết quả vào một véc-tơ mới. Các kỹ thuật này liên quan đến chỉ số của các phần tử trong véc-tơ và sẽ được thảo luận trong phần dưới đây.","code":""},{"path":"kiến-thức-r-cơ-bản.html","id":"hai-cách-lấy-véc-tơ-con-từ-một-véc-tơ","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.3.3.1 Hai cách lấy véc-tơ con từ một véc-tơ","text":"Để lấy một phần tử con của một véc-tơ x chúng ta sử dụng dấu ngoặc vuông [] . Chẳng hạn như để lấy ra phần tử thứ nhất của véc-tơ, chúng ta sử dụng x[1] . Số 1 nằm trong dấu ngoặc vuông được gọi là chỉ số. Nhắc lại với bạn đọc rằng chỉ số của các phần tử của một véc-tơ trong R bắt đầu từ 1 và phần tử cuối cùng trong véc-tơ có chỉ số bằng với độ dài của véc-tơ đó. Nếu chúng ta sử dụng chỉ số lớn hơn độ dài của véc-tơ, R sẽ trả lại giá trị là NA.Bạn đọc có thể đặt câu hỏi là điều gì xảy ra nều sử dụng chỉ số 0 hoặc chỉ số là số âm. Hãy nói về chỉ số 0 trước; khi gọi phần tử ở vị trí thứ 0 trong một véc-tơ bất kỳ bạn sẽ nhận được một phần tử rỗng. Khái niệm rỗng có thể hiểu giống như khái niệm rỗng khi nói về một tập hợp không có phần tử. Tùy theo kiểu giá trị của véc-tơ ta sẽ có một phần tử rỗng với kiểu giá trị tương ứng như bảng 2.10\nBảng 2.10: Giá trị tại chỉ số 0 của các kiểu véc-tơ\nKhi sử dụng chỉ số âm đối với véc-tơ, R hiểu rằng chúng ta đang loại đi các phần tử. Thật vậy, x[-1] sẽ trả lại kết quả là một véc-tơ giống với véc-tơ x sau khi loại đi phần tử thứ nhất. Với số tự nhiên \\(k, (k \\\\mathbb{N}),\\), câu lệnh x[-k] sẽ trả lại kết quả là véc-tơ x sau khi loại đi phần tử thứ \\(k\\). Nếu \\(k\\) lớn hơn độ dài của véc-tơ x, véc-tơ nhận được sẽ vẫn là x. Sử dụng chỉ số âm cũng có thể hiểu là một cách để lấy một véc-tơ con từ một véc-tơ ban đầu bằng cách sử dụng véc-tơ chỉ số kiểu số nguyên.Ngoài cách lấy một véc-tơ con từ một véc-tơ bằng chỉ số kiểu số nguyên, chúng ta cũng có thể lấy một véc-tơ con từ một véc-tơ bằng cách sử dụng chỉ số là một véc-tơ kiểu logic. Hai cách lấy véc-tơ con sẽ được thảo luận ngay dưới đây.Trước hết, từ véc-tơ x ban đầu, để lấy ra một véc-tơ con, trong trường hợp chúng ta đã biết chính xác các vị trí và thứ tự của các phần tử con mà chúng ta muốn lấy ra, chúng ta có thể lưu vị trí, hay chỉ số của các phần tử con này vào một véc-tơ tạm gọi là véc-tơ y. Véc-tơ y còn được gọi là véc-tơ chỉ số. Sau đó, chúng ta chỉ cần sử dụng câu lệnh x[y] để lấy ra các phần tử của x tại các vị trí được lưu ở véc-tơ y. Thật vậy, hãy thử quan sát ví dụ sauNếu trong véc-tơ chỉ số có giá trị lớn hơn độ dài của véc-tơ ban đầu, R sẽ trả lại giá trị là NA tại vị trí đóNếu chúng ta sử dụng véc-tơ chỉ số là số âm, R sẽ hiểu rằng chúng ta đang muốn loại đi một hay một số phần tử nào đó.Bạn đọc cần lưu ý là R sẽ báo lỗi nếu véc-tơ chỉ số y chứa cả số âm và số dương. Trong thực tế thì hiếm khi chúng ta biết chính xác vị trí mà chúng ta muốn lấy ra, hay nói cách khác chúng ta không thể trực tiếp khai báo giá trị cho véc-tơ chỉ số y giống như ví dụ trên. Thông thường véc-tơ chỉ số y sẽ là kết quả của các hàm số tạo chỉ số. Các hàm () và hàm match() được thảo luận ở phần tiếp theo của chương là các phương pháp tuyệt vời để tạo ra các véc-tơ chỉ số kiểu số như vậy.Phương pháp thứ hai để lấy một véc-tơ con từ véc-tơ x đó là sử dụng véc-tơ chỉ số kiểu logic. Cách lấy này sẽ rất thuận tiện khi bạn đọc muốn lấy ra một véc-tơ con của x bao gồm các phần tử thỏa mãn một điều kiện nào đó. Véc-tơ chỉ số, tạm gọi tên là véc-tơ y, được tạo ra từ một phép sánh, sau đó câu lệnh x[y] sẽ trả lại giá trị là một véc-tơ con của x bao gồm các phần tử mà vị trí tương ứng của nó trong véc-tơ y là TRUE. Lấy véc-tơ con bằng cách này, bạn đọc hãy luôn để độ dài của véc-tơ y bằng độ dài của véc-tơ x. Khi độ dài của y không bằng độ dài của x, câu lệnh x[y] vẫn trả lại kết quả, tuy nhiên hiểu được kết quả là khá phức tạp. đó chúng tôi khuyên bạn đọc hãy luôn đảm bảo rằng véc-tơ chỉ số kiểu logic và véc-tơ ban đầu luôn có cùng độ dài.Giả sử với véc-tơ x[y] chứa tên các loại quả, chúng ta muốn lấy ra tên các loại quả có tên dài hơn 3 ký tự. Chúng ta không biết chính xác các quả này nằm ở vị trí nào trong x[y] nên không thể tạo véc-tơ chỉ số kiểu số. Trong trường hợp này, chúng ta sẽ tạo một véc-tơ chỉ số y kiểu logic như sauĐây là cách lấy ra véc-tơ con rất hiệu quả khi làm việc với dữ liệu. Các cột dữ liệu là các véc-tơ có cùng độ dài, đó chỉ số y có thể được tạo thành từ phép sánh một cột dữ liệu trong khi véc-tơ x cần lấy các phần tử con lại là một cột dữ liệu khác. Chẳng hạn như chúng ta muốn lấy ra các câu đăng trạng thái của cựu tổng thống Donald Trump có nhiều hơn 10.000 lần like và sau đó lưu vào một véc-tơ mới có tên là z, chúng ta chỉ cần thực hiện như sau:Điều gì xảy ra nếu độ dài của y không giống như độ dài của x. Trong trường hợp y có độ dài nhỏ hơn độ dài của x, R sẽ tạo ra một véc-tơ, tạm gọi là y1 có độ dài bằng với độ dài của x bằng cách lặp lại giá trị của y cho đến khi véc-tơ thu được có độ dài bằng x. Khi chúng ta gọi câu lệnh x[y], R sẽ lấy chỉ số là véc-tơ y1. Hãy quan sát ví dụ sauKết quả thu được tương tự như khi chúng ta thực hiện phép lấy véc-tơ con thông qua một véc-tơ chỉ số y1 có độ dài bằng 5 như sauNếu độ dài của véc-tơ chỉ số y lớn hơn độ dài của x, tại các vị trí của y mà chỉ số vẫn nhỏ hơn hoặc bằng chiều dài của x, việc lấy ra phần tử con vẫn theo quy tắc thông thường, nghĩa là lấy ra các phần tử tương ứng với giá trị TRUE và bỏ qua các phần tử tương ứng với giá trị FALSE. Tại các vị trí của y mà chỉ số lớn hơn chiều dài của x, R sẽ bỏ qua các phần tử có giá trị là FALSE và sẽ trả lại giá trị là NA mỗi khi gặp giá trị TRUE. Bạn đọc có thể quan sát ví dụ sauDo sự phức tạp khi tương tác giữa các véc-tơ có không cùng độ dài nên chúng tôi khuyên bạn đọc hãy luôn luôn thực hiện các phép tính toán với các véc-tơ có cùng độ dài để kiểm soát được kết quả khi làm việc với R. Trong phần tiếp theo chúng ta sẽ thảo luận về các hàm số để tạo ra véc-tơ chỉ số.","code":"\n# Khởi tạo véc-tơ x kiểu số\nx <- c(1,1,2,3,5,8,13,21)\n\n# Lấy ra phần tử thứ nhất trong x\nx[1]## [1] 1\n# Lấy ra phần tử có chỉ số lớn hơn độ dài\nx[length(x)+1]## [1] NA\n# Khởi tạo véc-tơ kiểu chuỗi ký tự\nx <- c(\"cam\",\"táo\",\"kiwi\",\"chuối\",\"nho\")\n\n# Tạo véc-tơ chỉ số y tại các vị trí muốn lấy\ny <- c(3,5,2,3,1)\n\n# Lấy ra các phần tử con của x theo chỉ số y\nx[y] # thứ thự là x[3] -> x[5] -> x[2] -> x[3] -> x[1]## [1] \"kiwi\" \"nho\"  \"táo\"  \"kiwi\" \"cam\"\n# Khởi tạo véc-tơ kiểu chuỗi ký tự\nx <- c(\"cam\",\"táo\",\"kiwi\",\"chuối\",\"nho\")\n\n# Tạo véc-tơ chỉ số y tại các vị trí muốn lấy\ny <- c(3,5,2,10,3,1) # Có chỉ số 10 lớn hơn độ dài của x\n\n# Lấy ra các phần tử con của x theo chỉ số y\nx[y] # Vị trí thứ tư (chỉ số 10) là NA## [1] \"kiwi\" \"nho\"  \"táo\"  NA     \"kiwi\" \"cam\"\n# Khởi tạo véc-tơ kiểu chuỗi ký tự\nx <- c(\"cam\",\"táo\",\"kiwi\",\"chuối\",\"nho\")\n\n# Tạo véc-tơ chỉ số y gồm các chỉ số âm\ny <- c(-3,-5,-2,-3)\n\n# Lọc ra các phần tử con của x theo chỉ số y\nx[y] # loại đi phần tử thứ 2, 3, 5 của x (chỉ còn x[1] rồi x[4])## [1] \"cam\"   \"chuối\"\n# Khởi tạo véc-tơ kiểu chuỗi ký tự\nx <- c(\"cam\",\"táo\",\"kiwi\",\"chuối\",\"nho\")\n\n# Tạo véc-tơ chỉ số y kiểu logic\ny <- (nchar(x)>3) # y có giá trị TRUE tại vị trí phần tử có độ dài > 3\n\n# Hiển thị giá trị của y\nprint(y)## [1] FALSE FALSE  TRUE  TRUE FALSE\n# Lấy phần tử con của x theo chỉ số y\nx[y] # Trả lại phần tử trong x có độ dài > 3## [1] \"kiwi\"  \"chuối\"\n# Khởi tạo véc-tơ x chứa các câu status\nx <- trump_tweets$text\n\n# Tạo véc-tơ chỉ số kiểu logic y\ny <- trump_tweets$favorite_count > 10^4\n\n# Lấy ra các câu status có nhiều hơn 10.000 like\nz <- x[y]\n# Khởi tạo véc-tơ kiểu chuỗi ký tự độ dài 5\nx <- c(\"cam\",\"táo\",\"kiwi\",\"chuối\",\"nho\")\n\n# Khởi tạo véc-tơ chỉ số độ dài 2\ny <- c(TRUE,FALSE) # y có độ dài là 2\n\n# Lấy chỉ số của x theo y\nx[y] # Là véc-tơ có độ dài 5## [1] \"cam\"  \"kiwi\" \"nho\"\n# Tạo véc-tơ chỉ số độ dài 6\ny1<-rep(y,3) # lặp lại y cho đến khi có độ dài lớn hơn x\n\n# Cho độ dài của chỉ số bằng độ dài của x\ny1<-y1[1:length(x)]\n\n# Lấy véc-tơ con theo chỉ số y1\nx[y1] # cho kết quả giống như x[y]## [1] \"cam\"  \"kiwi\" \"nho\"\n# Khởi tạo véc-tơ kiểu chuỗi ký tự độ dài 5\nx <- c(\"cam\",\"táo\",\"kiwi\",\"chuối\",\"nho\")\n\n# Khởi tạo véc-tơ chỉ số độ dài 7\ny <- c(nchar(x)>3,FALSE,TRUE) # chỉ số thứ 6 là FALSE, thứ 7 là TRUE\n\n# Lấy véc-tơ con của x theo chỉ số y\nx[y]## [1] \"kiwi\"  \"chuối\" NA"},{"path":"kiến-thức-r-cơ-bản.html","id":"các-hàm-tạo-chỉ-số","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.3.4 Các hàm tạo chỉ số","text":"Có một nhóm các hàm số thường được sử dụng khi làm việc với chỉ số của các phần tử trong véc-tơ. Các hàm số này có thể được phỏng theo bằng cách kết hợp một vài kỹ thuật chỉ số đã đề cập đến ở chương trước. Tuy nhiên chúng tôi khuyên bạn đọc nên sử dụng các hàm có sẵn được trình bày trong phần này bởi sự tiện lợi và sự dễ hiểu của các dòng lệnh. Các hàm số liên quan đến chỉ số của véc-tơ được liệt kê trong bảng 2.11\nBảng 2.11: Bảng 2.12: Các hàm số liên quan đến chỉ số của véc-tơ\n","code":""},{"path":"kiến-thức-r-cơ-bản.html","id":"hàm-which","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.3.4.1 Hàm which()","text":"Hàm () áp dụng trên một véc-tơ kiểu logic và cho biết các vị trí nào trong véc-tơ có giá trị là TRUE. Có hai biến thể của hàm () thường được sử dụng là .min() và .max() cho biết chỉ số của giá trị lớn nhất và chỉ số của giá trị nhỏ nhất.Trong trường hợp x có nhiều giá trị bằng với giá trị lớn nhất, hoặc có nhiều giá trị bằng với giá trị nhỏ nhất, các hàm .min() và .max() luôn luôn trả lại giá trị là chỉ số nhỏ hơn.Bạn đọc sử dụng hàm () để tạo ra véc-tơ chỉ số khi muốn lấy ra các phần tử của một véc-tơ thỏa mãn một điều kiện nào đó. Ví dụ như chúng ta muốn lấy ra các các câu đăng trạng thái của cựu tổng thống Donald Trum có nhiểu hơn 10.000 lượt yêu thích bằng một véc-tơ chỉ số:","code":"\n# Khởi tạo véc-tơ x kiểu số\nx <- c(20,40,60,50,30,10)\n\n# Các chỉ số trong véc-tơ x có giá trị > 40\nwhich(x>40)## [1] 3 4\n# Chỉ số của số nhỏ nhất\nwhich.min(x)## [1] 6\n# Chỉ số của số lớn nhất\nwhich.max(x)## [1] 3\n# Khởi tạo véc-tơ x kiểu số\nx <- c(20,40,60,50,30,10,60,10)\n\n# Số nhỏ nhất nằm ở vị trí nào đầu tiên\nwhich.min(x)## [1] 6\n# Số lớn nhất nằm ở vị trí nào đầu tiên\nwhich.max(x)## [1] 3\n# Tạo véc-tơ chứa tất cả các câu tweet\nx <- trump_tweets$text\n\n# Tạo chỉ số kiểu số cho các câu nhiều hơn 10.000 like\ny <- which(trump_tweets$favorite_count>10^4)\n\n# Lấy ra véc-tơ con của x theo chỉ số y\nz <- x[y] # z chứa các câu tweet nhiều hơn 10.000 like"},{"path":"kiến-thức-r-cơ-bản.html","id":"hàm-match-và-toán-tử-in","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.3.4.2 Hàm match() và toán tử %in%","text":"Hàm match() là hàm số cho phép tương tác giữa hai véc-tơ có độ dài khác nhau. Với x và y là hai véc-tơ có cùng kiểu biến, câu lệnh z <- match(y,x) sẽ trả lại giá trị là một véc-tơ, tạm gọi là z có các tính chất sau đâyCó độ dài bằng với độ dài của véc-tơ yGiá trị z[] cho biết y[] có chỉ số, hay nằm ở vị trí nào, trong véc-tơ x; ví dụ, z[1] bằng 3 nghĩa là y[1] nằm ở vị trí, hay chỉ số thứ 3, trong véc-tơ xGiá trị z[] bằng NA có nghĩa là y[] không xuất hiện trong x.Bạn đọc quan sát ví dụ về hàm match() như sau:Chúng ta có thể thấy rằng giá trị 70 không xuất hiện trong x nên giá trị thứ 3 trong véc-tơ kết quả là NA. Lưu ý rằng hàm match() luôn luôn tìm đến chỉ số đầu tiên trong véc-tơ x có giá trị khớp với giá trị của véc-tơ y, nghĩa là nếu trong x có nhiều hơn một giá trị khớp với giá trị của y, hàmmatch()cho kết quả là chỉ số nhỏ hơn. Bạn đọc quan sát ví dụ dưới đây khi véc-tơ y có các phần tử xuất hiện nhiều hơn một lần trong x:Các giá trị 10 và 20 của y xuất hiện hai lần trong x, tuy nhiên hàmmatch()sẽ trả lại giá trị là 6 và 1 bởi vì số 10 xuất hiện lần đầu tiên ở vị trí thứ 6 trong x và số 20 xuất hiện lần đầu tiên ở vị trí thứ 1 trong x.Hàm match() trả lại kết quả là véc-tơ chỉ số nên sẽ phù hợp với việc lấy véc-tơ con theo chỉ số kiểu số. Một phương pháp khác để tạo chỉ số của véc-tơ là toán tử %%. Toán tử %% được sử dụng để cho biết mỗi phần tử của một véc-tơ có nằm trong một véc-tơ khác hay không. Câu lệnh y %% x sẽ trả lại giá trị là một véc-tơ kiểu logic, tạm gọi là z, có độ dài bằng với độ dài của y, đồng thời z[] nhận giá trị là TRUE nếu y[] có xuất hiện trong x, và nhận giá trị là FALSE nếu y[] không xuất hiện trong x. Bạn đọc hãy quan sát ví dụ dưới đây:Những bạn đọc mới làm quen với R thường dễ nhầm lẫn cách sử dụng hàm match() và toán tử %%. Cách duy nhất để hiểu và thực hiện thành thạo đó là thực hành trên dữ liệu thực tế nhiều lần. Hình 2.2 dưới đây minh họa sự khác nhau trong kết quả được trả ra của hàm match()và toán tử %%\nHình 2.2: Sự khác nhau giữa hàm match() và toán tử %%\nHàm match() và toán tử %% cho phép tương tác giữa các véc-tơ có độ dài khác nhau nên rất hiệu quả khi bạn đọc muốn kết nối nhiều dữ liệu khác nhau. Bạn đọc hãy đọc ví dụ dưới đây để hình dung cách sử dụng hàmmatch()khi kết nối hai dữ liệu.Giả sử chúng ta có danh sách điểm học tại trường đại học của ba sinh viên ngành actuary có mã sinh viên lần lượt là MSV001, MSV002, MSV003 khi học các môn học Xác suất, Toán tài chính, và Đầu tư và thị trường tài chính. Thông tin được lưu trong một dữ liệu tên là diem_hoc_DH. Sinh viên ngành actuary ngoài các môn học ở trường đại học có thể thi các môn học tại các hiệp hội nghề nghiệp actuary để lấy chứng chỉ hành nghề. Thông tin về điểm thi chứng chỉ được lưu trong dữ liệu có tên là diem_chung_chi_Actuary. Khi xét tốt nghiệp, sinh viên có quyền lấy điểm thi chứng chỉ tại các hiệp hội để thay thế cho điểm học tại trường đại học của môn học tương ứng nếu điểm thi chứng chỉ cao hơn. Dữ liệu về điểm thi tại trường đại học và thi chứng chỉ hành nghề như sau:\nBảng 2.13: Điểm thi tại trường đại học (diem_hoc_DH)\n\nBảng 2.14: Điểm thi chứng chỉ (diem_chung_chi_Actuary)\nĐể tìm được điểm thi chứng chỉ của sinh viên trong bảng diem_hoc_DH chúng ta phải kết nối bảng này với bảng “diem_chung_chi_Actuary” thông qua mã sinh viên và tên môn học bằng cách sử dụng hàm match(). Việc kết nối sẽ được thực hiện bằng cách tạo ra trên mỗi bảng một biến có tên là key là tổ hợp của mã sinh viên và tên môn học.Trước hết bạn đọc có thể tạo hai dữ liệu dựa trên thông tin của hai bảng bằng đoạn lệnh như dưới đây:Chúng ta tạo ra biến key trêm hai bảng để kết nối hai bảng; véc-tơ tạo ra bằng cách kết hợp từ véc-tơ chứa mã sinh viên và véc-tơ tên môn họcToán tử %% sẽ cho chúng ta biết những phần tử nào trong véc-tơ diem_hoc_DH_key nằm trong véc-tơ diem_chung_chi_Actuary_key hay nói một cách khác, sinh viên nào trong bảng diem_hoc_DH có thi chứng chỉ tương ứng với môn học ở trường đại học:Chỉ số y là kết quả của toán tử %% nên sẽ là véc-tơ kiểu logic. y có độ dài là 9 bằng với số quan sát của dữ liệu diem_hoc_DH và cho biết tương ứng mỗi sinh viên có thi chứng chỉ môn học tương ứng hay không. Chẳng hạn như muốn tạo ra danh sách thi chứng chỉ của sinh viên lớp Actuary chúng ta sử dụng cách lấy véc-tơ con với chỉ số y như sauĐể tìm được điểm thi chứng chỉ của các sinh viên lớp Actuary chúng ta cần biết kết nối mã sinh viên và môn học từ bảng diem_hoc_DH đến bảng diem_chung_chi_Actuary bằng cách sử dụng hàm match()Véc-tơ y có độ dài bằng 9, cho biết mỗi quan sát của dữ liệu diem_hoc_DH tương ứng với dòng thứ bao nhiêu (chỉ số) của dữ liệu diem_chung_chi_Actuary. Giá trị NA trong y có ý nghĩa là quan sát đó của dữ liệu diem_hoc_DH không xuất hiện trong diem_chung_chi_Actuary, hay nói cách khác sinh viên không thi chứng chỉ môn học tương ứng. Chúng ta có thể thêm một cột (véc-tơ) gọi là diem_CT cho bảng diem_hoc_DHNhư vậy chúng ta đã có một dữ liệu với điểm học trên lớp và điểm thi chứng chỉ của các sinh viên\nBảng 2.15: Điểm thi tại trường đại học và điểm thi chứng chỉ\n","code":"\n# Khởi tạo véc-tơ x và véc-tơ y kiểu số\nx <- c(20,40,60,50,30,10)\ny <- c(60,10,70)\n\n# Chỉ số của các phần tử của y trong véc-tơ x\nmatch(y,x)## [1]  3  6 NA\n# Khởi tạo véc-tơ x và véc-tơ y kiểu số\nx<-c(20,40,60,50,30,10,20,10) # 10 và 20 xuất hiện nhiều lần\ny<-c(10,20) # các phần tử của y xuất hiện nhiều lần trong x\n\n# Chỉ số của các phần tử của y trong véc-tơ x\nmatch(y,x)## [1] 6 1\n# Khởi tạo véc-tơ x và véc-tơ y kiểu số\nx <- c(20,40,60,50,30,10)\ny <- c(60,10,70)\n\n# Cho biết các phần tử của y có nằm trong x hay không\ny %in% x## [1]  TRUE  TRUE FALSE\n# du lieu diem_hoc_DH\nMSV <- rep(c( \"MSV001\", \"MSV002\", \"MSV003\"),3)\nMon_hoc <- c(rep(\"Xác suất\",3),rep(\"Toán tài chính\",3),rep(\"Đầu tư và thị trường tài chính\",3))\nDiem <- c(5,7,9,10,6,8,9,5,10)\ndiem_hoc_DH <- data.frame(MSV, Mon_hoc, Diem)\n\n# du lieu diem_chung_chi_Actuary\nMSV <- c(\"MSV005\", \"MSV002\", \"MSV004\", \"MSV003\", \"MSV002\", \"MSV001\")\nMon_hoc <- c(\"Xác suất\", \"Xác suất\", \"Xác suất\", \"Toán tài chính\", \"Toán tài chính\", \"Đầu tư và thị trường tài chính\")\nDiem <- c(8,9,10,10,9,8)\ndiem_chung_chi_Actuary <- data.frame(MSV, Mon_hoc, Diem)\ndiem_hoc_DH_key<- paste(diem_hoc_DH$MSV, diem_hoc_DH$Mon_hoc)\ndiem_chung_chi_Actuary_key<-paste(diem_chung_chi_Actuary$MSV, diem_chung_chi_Actuary$Mon_hoc)\ny<-diem_hoc_DH_key %in% diem_chung_chi_Actuary_key\n# Lọc véc-tơ cột MSV bằng véc-tơ kiểu logic y\n# Lọc véc-tơ cột tên môn học bằng véc-tơ kiểu logic y\ndata.frame(MSV = diem_hoc_DH$MSV[y],\n           Diem = diem_hoc_DH$Mon_hoc[y])##      MSV                           Diem\n## 1 MSV002                       Xác suất\n## 2 MSV002                 Toán tài chính\n## 3 MSV003                 Toán tài chính\n## 4 MSV001 Đầu tư và thị trường tài chính\ny<-match(diem_hoc_DH_key,diem_chung_chi_Actuary_key)\n# Lọc véc-tơ con bằng véc-tơ chỉ số y kiểu số\ndiem_hoc_DH$diem_CT<-diem_chung_chi_Actuary$Diem[y]"},{"path":"kiến-thức-r-cơ-bản.html","id":"hàm-rank-và-hàm-order","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.3.4.3 Hàm rank() và hàm order()","text":"Hàm rank() trả lại giá trị là thứ tự (rank) của một phần tử trong véc-tơ x khi sắp xếp x theo thứ tự tăng dần. Thứ tự tăng dần ở đây được hiểu đối với cả các véc-tơ kiểu chuỗi ký tự. Bạn đọc có thể quan sát kết quả của hàm rank() trong ví dụ dưới đây:Lưu ý rằng hàm rank() có một tham số quan trọng là ties.method. Khi bạn đọc không sử dụng tùy chọn này, giá trị mặc định là average. Tham số ties.method chỉ có ý nghĩa khi trong véc-tơ x có các giá trị giống nhau. Nếu các phần tử trong x là đôi một khác nhau, bất kỳ tùy chọn nào đối với ties.method cũng trả lại một kết quả duy nhất.Khi x có các giá trị bị lặp lại, các giá trị khác nhau của ties.method sẽ cho kết quả khác nhau. Bạn đọc hãy quan sát ví dụ sau để thấy sự khác biệt:Khi ties.method nhận giá trị là first, giá trị trả lại là 1, 2, 3, 4, 5. Ba giá trị 10 liền nhau ở phần đầu của véc-tơ x được xếp thứ tự theo nguyên tắc số nào xuất hiện trước là có thứ tự nhỏ hơn, đó thứ tự của ba giá trị trong véc-tơ x khi xếp x theo thứ tự tăng dần là 1, 2, 3. Tương tự với hai giá trị 20 ở cuối vec-tơ x, số 20 xuất hiện trước được hiểu là có thứ tự trước số 20 xuất hiện sau, đó thứ tự của hai giá trị 20 sẽ là 4, 5Khi ties.method nhận giá trị là last giá trị trả lại là 3, 2, 1, 5, 4. Ba giá trị 10 liền nhau ở phần đầu của véc-tơ x được xếp thứ tự theo nguyên tắc số nào xuất hiện trước là có thử tự lớn hơn, đó thứ tự của ba số 10 này trong véc-tơ x khi xếp x theo thứ tự tăng dần là 3, 2, 1. Tương tự với hai số 20 ở cuối vec-tơ x, số 20 xuất hiện trước được hiểu là có thứ tự lớn hơn số 20 xuất hiện sau, đó thứ tự của hai số 20 sẽ là 5, 4Khi ties.method nhận giá trị là min, giá trị trả lại là 1, 1, 1, 4, 4. Ba số 10 liền nhau ở phần đầu của véc-tơ x có thứ tự bằng nhau là 1. Đây chính là thứ tự nhỏ nhất của ba số khi xếp các số này theo tùy chọn ties.method nhận giá trị là first. Tương tự ta có thứ tự của hai số 20 tiếp theo bằng nhau và bằng 4.Tham số ties.method nhận giá trị max sẽ cho kết quả ngược lại với min. Thứ tự của ba số 10 đầu tiên trong x đều bằng 3 - là số lớn nhất trong (1, 2, 3) đồng thời thứ tự của hai số 20 tiếp theo đều là 5 - là số lớn nhất trong (4,5).Khi ties.method nhận giá trị là average, cũng là giá trị mặc định khi sử dụng hàm rank(), thứ tự của ba số 10 ở đầu véc-tơ x được tính là trung bình của thứ tự khi xếp theo giá trị first. Thứ tự của ba giá trị 10 khi ties.method nhận giá trị là first là 1, 2, 3. Thứ tự khi ties.method nhận giá trị là average là\n\\[\\begin{align}\n\\cfrac{1 + 2 + 3}{3} = 2\n\\end{align}\\]\nvà thứ tự của hai số 20 ở cuối véc-tơ là\\[\\begin{align}\n\\cfrac{4 + 5}{2} = 4.5\n\\end{align}\\]Cuối cùng, khi ties.method nhận giá trị là random, thứ tự của ba số 10 ở đầu véc-tơ x là một hoán vị ngẫu nhiên của (1,2,3) cũng là thứ tự của ba số khi ties.method nhận giá trị là first. Bạn đọc có thể thấy rằng hai lần gọi hàm rank() với tham số ties.method = random có thể cho kết quả là khác nhau.Một hàm số khác trả lại giá trị là chỉ số của véc-tơ là hàm order(). Câu lệnh y <- order(x) trả lại giá trị là một véc-tơ y là các chỉ số của x sao cho:y[1] là chỉ số của số nhỏ nhất trong véc-tơ x;y[1] là chỉ số của số nhỏ nhất trong véc-tơ x;y[2] là chỉ số của số nhỏ thứ hai trong véc-tơ x; …y[2] là chỉ số của số nhỏ thứ hai trong véc-tơ x; …Số cuối cùng trong véc-tơ y là chỉ số của số lớn nhất trong véc-tơ x.Số cuối cùng trong véc-tơ y là chỉ số của số lớn nhất trong véc-tơ x.Khi muốn lấy chỉ số của véc-tơ x nhưng theo thứ tự giảm dần, bạn đọc sử dụng tham số decreasing = TRUE trong hàm order(). Khái niệm tăng dần và giảm dần cũng có thể hiểu cho các véc-tơ kiểu thời gian, kiểu factor hay kiểu chuỗi ký tự.Câu lệnh order(x) cho kết quả là 6 tại vị trí thứ nhất có nghĩa là số nhỏ nhất trong x nằm ở vị trí thứ sáu trong véc-tơ này (số 10). Vị trí thứ hai trong order(x) nhận giá trị là 1 có nghĩa là số nhỏ thứ hai trong x nằm ở vị trí thứ nhất trong véc-tơ này, và cứ tiếp tục như thế. Vị trí cuối cùng trong order(x) có giá trị là 3 có nghĩa là số lớn nhất trong véc-tơ x nằm ở vị trí thứ 3 trong véc-tơ này.Câu lệnh order(x) có thể được phỏng theo được bằng cách khớp chỉ số của véc-tơ x với véc-tơ được tạo thành từ câu lệnh rank(x, ties.method = ‘first’), thật vậy:Sử dụng hàm order() bạn đọc có thể dễ dàng lấy ra các giá trị nhỏ (hoặc lớn) thứ k trong một véc-tơ. Chẳng hạn như bạn đọc muốn lấy ra câu status có số lượt yêu thích nhiều thứ hai của cựu tổng thống Donald Trump trong dữ liệu trump_tweet, bạn có thể sử dụng hàm order() như sau:Như vậy, chúng tôi đã giới thiệu với bạn đọc những khái niệm cơ bản nhất của R, bao gồm có biến, véc-tơ và các phép tính toán trên các đối tượng này. Trong phần tiếp theo, chúng tôi sẽ nói về lập trình với ngôn ngữ R. Mặc dù R được phát triển để các câu lệnh được viết dưới dạng đơn giản nhất có thể, nhưng trong đa số các dự án liên quan đến dữ liệu, yêu cầu về viết các vòng lặp, hay viết hàm số là không thể tránh khỏi. Phần tiếp theo của cuốn sách sẽ thảo luận về các khái niệm cơ bản về cách lập trình trong ngôn ngữ R.","code":"\n# Khởi tạo véc-tơ x kiểu số\nx<-c(20,40,60,50,30,10)\n\n# Áp dụng hàm rank trên véc-tơ x\nrank(x) # số lớn nhất (60) có chỉ số 6, số nhỏ nhất (10) có chỉ số 1## [1] 2 4 6 5 3 1\n# Khởi tạo véc-tơ x kiểu số\nx<-c(10,10,10,20,20)\n\n# ties.method = \"first\" -> giá trị xuất hiện TRƯỚC có rank NHỎ hơn\nrank(x,ties.method = \"first\")## [1] 1 2 3 4 5\n# ties.method = \"last\" -> giá trị xuất hiện TRƯỚC có rank LỚN hơn\nrank(x,ties.method = \"last\")## [1] 3 2 1 5 4\n# ties.method = \"min\" -> các số bằng nhau có rank bằng nhau và bằng min\nrank(x,ties.method = \"min\")## [1] 1 1 1 4 4\n# ties.method = \"max\" -> các số bằng nhau có rank bằng nhau và bằng max\nrank(x,ties.method = \"max\")## [1] 3 3 3 5 5\n# ties.method = \"average\" -> các số bằng nhau có rank bằng nhau và bằng mean\nrank(x,ties.method = \"average\")## [1] 2.0 2.0 2.0 4.5 4.5\n# ties.method = \"average\" -> các số bằng nhau có rank là hoán vị ngẫu nhiên\nrank(x,ties.method = \"random\")## [1] 1 2 3 4 5\n# Khởi tạo véc-tơ x kiểu số\nx<-c(20,40,60,50,30,10)\n\n# Áp dụng hàm order trên x\norder(x) # chỉ số khi xếp x theo thứ tự TĂNG dần## [1] 6 1 5 2 4 3\n# Áp dụng hàm order trên x, với tham số decreasing = TRUE\norder(x, decreasing = TRUE) # chỉ số khi xếp x theo thứ tự GIẢM dần## [1] 3 4 2 5 1 6\n# Khởi tạo véc-tơ x kiểu số\nx<-c(20,20,10,10,10) # véc-tơ x kiểu số có các giá trị lặp lại\n\n# Khởi tạo chỉ số tăng dần\nchiso<-1:length(x)\n\n# match véc-tơ chiso với rank của x để được order của x\nmatch(chiso,rank(x, ties.method = \"first\"))## [1] 3 4 5 1 2\n# Áp dụng order trên x cho kết quả tương tự\norder(x)## [1] 3 4 5 1 2\n# Cột chứa số lượng like là cột favorite_count\n# Chỉ số của câu status được like nhiều thứ hai\ny<-order(trump_tweets$favorite_count, decreasing = T)[2]\n\n# Lấy ra câu status tại vị trí y\ntrump_tweets$text[y] # là câu tweet được like nhiều thứ hai## [1] \"Why would Kim Jong-un insult me by calling me \\\"old,\\\" when I would NEVER call him \\\"short and fat?\\\" Oh well, I try so hard to be his friend - and maybe someday that will happen!\""},{"path":"kiến-thức-r-cơ-bản.html","id":"ngôn-ngữ-lập-trình-r","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.4 Ngôn ngữ lập trình R","text":"Để viết các chương trình phức tạp, bạn đọc sẽ cần kiểm soát tốt trình tự mà các dòng lệnh thực thi. Một cách cơ bản để làm được việc này là thực hiện một số câu lệnh nhất định phụ thuộc vào một hoặc một số điều kiện hay còn gọi là viết các câu lệnh rẽ nhánh. Một cách kiểm soát khác là sử dụng vòng lặp nhằm lặp lại một nhóm các câu lệnh một số lần nhất định. Trong phần này, chúng ta sẽ khám phá những kiến thức lập trình cơ bản này trong ngôn ngữ lập trình R. Các kiến thức về lập trình bao gồm có cách sử dụng câu lệnh rẽ nhánh (-else), cách sử dụng vòng lặp (, , và repeat) và một vài cấu trúc khác giúp bạn đọc điều khiển được cách thực hiện các dòng lệnh của mình. Bạn đọc đã có kiến thức về lập trình trong bất kỳ ngôn ngữ nào khác có thể chỉ cần xem qua để nắm được cách viết ngôn ngữ lập trình của R. Với các bạn đọc mới làm quen với lập trình, hãy cố gắng đọc kỹ từng phần dưới đây để có thể tự viết được các chương trình phức tạp.","code":""},{"path":"kiến-thức-r-cơ-bản.html","id":"câu-lệnh-điều-kiện","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.4.1 Câu lệnh điều kiện","text":"","code":""},{"path":"kiến-thức-r-cơ-bản.html","id":"câu-lệnh-if-và-if-else","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.4.1.1 Câu lệnh if và if-else","text":"Bạn đọc sử dụng câu lệnh điều kiệu để thông báo cho R biết một câu lệnh, hay một nhóm câu lệnh chỉ thực hiện khi một điều kiện nào đó được thực thi. Dưới đây là cách viết của câu lệnh trong ngôn ngữ RBạn đọc có thể thực hiện một đoạn lệnh có biểu thức điều kiện cụ thể như sau trên cửa sổ ConsoleKhi thực hiện nhóm các câu lệnh ở trên, dòng lệnh thứ 3 chỉ được thực hiện nếu biểu thức điều kiện được viết trong dấu ngoặc () sau từ khóa ở dòng lệnh thứ 2 nhận giá trị là TRUE. Nếu biểu thức điều kiện đó nhận giá trị là FALSE, R sẽ không thực hiện các dòng lệnh thứ 3. Sau khi R thực thi các dòng lệnh 1, biến x nhận giá trị là 1 nên phép sánh (x<10) sẽ cho kết quả là TRUE. đó, dòng lệnh 3 gán giá trị mới bằng 4 cho biến y sẽ được thực hiện. Bạn đọc có thể kiểm tra được rằng sau khi thực hiện đoạn lệnh ở trên, giá trị của biến y sẽ bằng 4 chứ không phải là 2 như khởi tạo ở dòng lệnh số 1.Khi sử dụng câu lệnh điều kiện , sẽ không có câu lệnh nào được thực hiện trong trường hợp biểu thức điều kiện nhận giá trị là sai. Trong thực tế, đa phần các đoạn lệnh rẽ nhánh sẽ có các câu lệnh phải thực thi khi biểu thức điều kiện nhận giá trị là sai. Để thực hiện được việc này, bạn đọc sử dụng câu lệnh kết hợp với else như sauBạn đọc có thể quan sát sự thay đổi giá trị của biến y sau khi thực hiện đoạn lệnh như sauDo biểu thức điều kiện (x==10) nhận giá trị là FALSE nên R sẽ không thực hiện dòng lệnh số 3 mà chuyển qua thực hiện dòng lệnh số 5. Giá trị của y sau khi thực hiện dòng lệnh thứ 5 ở trên sẽ là 8. Nếu trong dòng lệnh 1, bạn đọc sửa giá trị của x thành 10 thay vì 1, dòng lệnh 3 sẽ được thực hiện và dòng lệnh số 5 không được thực hiện đó giá trị của y sau khi thực hiện đoạn lệnh lúc này sẽ là 4.Biểu thức điều kiện trong dấu ngoặc () đứng sau phải là một biến kiểu logic. Nếu sơ ý, biểu thức điều kiện là một véc-tơ của các biến kiểu logic, câu lệnh sẽ chỉ tính đến giá trị đầu tiên trong véc-tơ.Bạn đọc có thể sẽ gặp câu lệnh ifelse() trong các đoạn câu lệnh của R. Tuy nhiên đây không phải là cách viết của câu lệnh rẽ nhánh. Hàm ifelse() được sử dụng khi muốn tạo ra một véc-tơ từ hai véc-tơ dựa trên giá trị của một véc-tơ kiểu logic. Cách sử dụng ifelse() được minh họa thông qua ví dụ dưới đâyHàm ifelse() ở trên sẽ tạo ra một véc-tơ có độ dài bằng với véc-tơ x và tương ứng với các vị trí x chia hết cho 2 sẽ cho kết quả là “chẵn” và tương ứng với các vị trí mà x không chia hết cho 2 sẽ cho kết quả là “lẻ”.Khi sử dụng câu lệnh rẽ nhánh để thực hiện các yêu cầu phức tạp hơn, bạn đọc thường phải sử dụng các câu lệnh và else lồng vào nhau để có được kết quả. Hãy lấy một ví dụ như sau: để viết một đoạn câu lệnh để trả lại giá trị giá vé vào rạp chiếu phim của một khách hàng dựa trên hai yếu tố là độ tuổi và việc có thẻ thành viên hay không, bạn đọc không thể chỉ dùng một câu lệnh điều kiện duy nhất.\n(#tab:table777 input)Ví dụ về câu lệnh điều kiện\nGiả sử biến Age là biến kiểu số cho biết độ tuổi của khách hàng và biến Member là biến kiểu logic nhận giá trị TRUE nếu khách hàng là thành viên và FALSE nếu khách hàng không phải là thành viên. Bạn đọc có thể sử dụng câu lệnh điều kiện để ra màn hình giá vé của khách hàng đó bằng một trong hai cách như sau","code":"\nif (\"Biểu thức điều kiện\"){\n  \"Nhóm các câu lệnh thực hiện khi biểu thức điều kiện là ĐÚNG\"\n}\nx<-1; y<-2 # Dòng lệnh 1: tạo biến x = 1 và biến y = 2\nif (x<10){ # Dòng lệnh 2: Nếu x < 10 thì thực hiện các câu lệnh nằm trong {}\n  y<-4 # Dòng lệnh 3: Gán giá trị y bằng 4\n} # Dòng lệnh 4: kết thúc câu lệnh if\nif (\"Biểu thức điều kiện\"){\n  \"Nhóm các câu lệnh thực hiện khi biểu thức điều kiện là ĐÚNG\"\n} else {\n  \"Nhóm các câu lệnh thực hiện khi biểu thức điều kiện là SAI\"\n}\nx<-1; y<-2 # Dòng lệnh 1: tạo biến x = 1 và biến y = 2\nif (x==10){ # Dòng 2: Nếu x bằng 10 thì thực hiện các câu lệnh của if\n  y<-4 # Dòng 3: Gán giá trị y bằng 4\n} else { # Dòng 4: Nếu x KHÁC 10 thì thực hiện các câu lệnh của else\n  y<-8 # Dòng 5: gán giá trị y bằng 4\n} # Dòng lệnh 6: kết thúc câu lệnh if-else\ndieukien<-c(TRUE,FALSE,FALSE)\nif (dieukien){ # dieukien là một véc-tơ kiểu logic\n  print(\"Xin chào\") #R CÓ chạy dòng lệnh này\n} # kết thúc câu lệnh if\n# Khởi tạo véc-tơ x là số tự nhiên từ 1 đến 10\nx<-1:10\n\n# Áp dụng hàm ifelse trên véc-tơ x\nifelse(x%%2==0,\"chẵn\",\"lẻ\")##  [1] \"lẻ\"   \"chẵn\" \"lẻ\"   \"chẵn\" \"lẻ\"   \"chẵn\" \"lẻ\"   \"chẵn\" \"lẻ\"   \"chẵn\"\n# Cách thứ nhất: sử dụng bốn câu lệnh if\nAge<-50; Member<-TRUE # tạo giá trị cho các biến Age, Member\nif ((Age < 6) & Member){ # nếu khách hàng dưới 6 tuổi và là thành viên\n  print(\"70.000 đồng\")\n}\nif ((Age < 6) & Member){ # nếu khách hàng trên 6 tuổi và là thành viên\n  print(\"100.000 đồng\")\n}\nif ((Age < 6) & Member){ # nếu khách hàng dưới 6 tuổi và không phải thành viên\n  print(\"120.000 đồng\")\n}\nif ((Age < 6) & Member){ # nếu khách hàng trên 6 tuổi và không phải thành viên\n  print(\"150.000 đồng\")\n}\n# Cách thứ hai: câu lệnh if-else\nAge<-50; Member<-TRUE # tạo giá trị cho các biến Age, Member\nif (Age<6){\n  if(Member){\n    print(\"70.000 đồng\")\n  } else {\n    print(\"100.000 đồng\")\n  }\n} else {\n  if(Member){\n    print(\"120.000 đồng\")\n  } else {\n    print(\"150.000 đồng\")\n  }\n}"},{"path":"kiến-thức-r-cơ-bản.html","id":"viết-vòng-lặp","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.4.2 Viết vòng lặp","text":"Vòng lặp là một cơ chế lập trình với mục đích để R lặp lại việc chạy một dòng lệnh hay một đoạn lệnh cụ thể. Có hai kiểu viết lặp đó là vòng lặp hoạt động theo cách cho một phần tử nhận lần lượt từng giá trị trong một véc-tơ và vòng lặp hoạt động theo cách lặp lại một đoạn mã cho đến khi một điều kiện cụ thể nhận giá trị là FALSE. Cách thức hoạt động kiểu vòng lặp cũng có thể được áp dụng khi sử dụng nhóm các hàm apply() trong R và sẽ được thảo luận ở một phần riêng của cuốn sách.","code":""},{"path":"kiến-thức-r-cơ-bản.html","id":"vòng-lặp-for","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.4.2.1 Vòng lặp for","text":"Những câu lệnh sau dùng để ra màn hình tất cả các giá trị nằm trong véc-tơ qua bằng cách sử dụng một vòng lặp forCác dòng lệnh bắt đầu từ đến kết thúc dấu ngoặc {} của vòng lặp có ý nghĩa như sau: cho một biến ten nhận lần lượt các giá trị trong véc-tơ qua từ giá trị ở vị trí thứ nhất đến giá trị ở vị trí cuối cùng; với mỗi giá trị mà biến ten nhận được, đoạn lệnh thực hiện nhóm các câu lệnh nằm trong dấu ngoặc {} của vòng lặp một lần. Trong đoạn lệnh ở trên các câu lệnh được lặp lại là câu lệnh print() với tham số là biến ten.Bạn đọc hãy thử một ví dụ khó hơn một chút, chẳng hạn như bạn muốn tính tổng các số trong một véc-tơ x và không sử dụng hàm sum(). Bạn có thể thực hiện việc này bẳng một vòng lặp như sau:Cho biến tên tong nhận giá trị bằng 0. tong sẽ là giá trị của tổng sau khi kết thúc vòng lặpCho một biến tên là gia_tri nhận lần lượt các giá trị trong véc-tơ bắt đầu từ vị trí thứ nhất, tại mỗi lần lặp tăng giá trị biến tong lên đúng bằng giá trị của gia_triSau khi vòng lặp chạy qua tất cả các giá trị trong véc-tơ cần tính tổng, biến tong sẽ chứa giá trị của tổng các số trong véc-tơ.Giả sử x là véc-tơ Airpassengers là một dữ liệu có sẵn trong R. Đây là một véc-tơ kiểu số, ở dạng chuỗi thời gian chứa thông tin về số lượng khách hàng đi máy bay hàng tháng, đơn vị là nghìn người, tính từ tháng 1 năm 1949 đến tháng 12 năm 1960. Chúng ta sử dụng vòng lặp để tính tổng các số trong véc-tơ sau đó sánh kết quả với hàm sum() có sẵn.Mặc dù đây là chương giới thiệu về viết vòng lặp, nhưng lời khuyên của chúng tôi là bạn đọc hãy luôn cố gắng viết câu lệnh trên các đối tượng vec-tơ nếu có thể thay vì viết vòng lặp. Sử dụng véc-tơ trong R hiệu quả hơn nhiều cả về thời gian chạy lẫn sự đơn giản của các dòng lệnh. Để đánh giá về hiệu quả thời gian, bạn đọc có thể xem ví dụ dưới đây khi sử dụng vòng lặp cho những véc-tơ có độ dài lớn và sánh với thời gian tính toán nếu viết dưới dạng đối tượng véc-tơ. Véc-tơ được sử dụng để kiểm tra tính hiệu quả là véc-tơ có độ dài \\(10^8\\):Bạn đọc có thể thấy rằng trên máy tính của chúng tôi, sử dụng vòng lặp để tính tổng các số trong véc-tơ có độ dài \\(10^8\\) mất khoảng 2 giây trong khi dùng hàm sum() trực tiếp trên véc-tơ chỉ mất 0.1 giây. Nghĩa là thời gian để thực hiện tính toán trên véc-tơ nhanh hơn gấp 20 lần nếu bạn đọc viết dưới dạng đối tượng véc-tơ. Ngoài ra, sử bạn đọc cũng có thể thấy rằng câu lệnh gọi hàm sum() là đơn giản hơn nhiều với viết vòng lặp.Trong các ví dụ ở trên, chúng tôi sử dụng trực tiếp giá trị trong véc-tơ để thực hiện vòng lặp. Bạn đọc cũng có thể sử dụng vòng lặp theo chỉ số của véc-tơ và cho kết quả tương tự. Chẳng hạn như đối với véc-tơ qua, bạn đọc có thể cho một chỉ số nhận giá trị lần lượt từ 1 đến độ dài của véc-tơ qua để lấy từng phần tử của véc-tơ qua:Trong nhiều trường hợp, bạn đọc cần phải sử dụng một vòng lặp nằm trong một vòng lặp khác để giải quyết được vấn đề của mình. Ví dụ như bạn cần ra tất cả các cách kết hợp giữa hai cách pha chế là Nước ép và Sinh tố với bốn loại quả ở trên. Bạn đọc cần sử dụng 2 vòng lặp lồng nhau để làm được việc này:Trong ví dụ ở trên, tổng số lần câu lệnh print() được lặp là \\(4 \\times 2 = 8 (\\text{lần})\\). Mỗi khi viết vòng lặp , đặc biệt là khi viết các vòng lặp lồng vào nhau, bạn đọc hãy luôn cân nhắc thời gian R chạy vòng lặp. Một cách để kiểm tra thời gian vòng lặp chạy là thay vì cho chỉ số chạy qua độ dài của cả véc-tơ thì hãy cho vòng lặp thực hiện với một số lượng nhỏ chỉ số ban đầu để ước tính ra tổng thời gian. Nói một cách đơn giản, vòng lặp chạy qua 100 giá trị ban đầu của véc-tơ sẽ mất thời gian bằng khoảng \\(\\cfrac{1}{100}\\) thời gian để chạy vòng lặp qua 10.000 giá trị của toàn bộ véc-tơ. Thời gian để thực hiện các vòng lặp lồng nhau sẽ tăng lên theo cấp số nhân.","code":"\n# Khởi tạo véc-tơ qua chứa tên các loại quả\nqua = c(\"chuối\", \"táo\", \"cam\", \"chanh\")\n\n# Viết vòng lặp for\n# Cho một biến ten nhận lần lượt các giá trị trong qua\nfor (ten in qua){\n  print(ten) # in ten ra màn hình\n} # kết thúc vòng lặp for## [1] \"chuối\"\n## [1] \"táo\"\n## [1] \"cam\"\n## [1] \"chanh\"\ntong<-0\nfor (gia_tri in x){\n  tong<-tong + gia_tri\n}\nprint(tong)\n# Tạo biến có tên tong nhận giá trị 0\ntong<-0\n# Dùng vòng lặp for\n# Cho biến gia_tri nhận lần lượt các giá trị trong Airpassengers\nfor (gia_tri in AirPassengers){\n  tong<-tong + gia_tri # tăng tong thêm giá trị bằng gia_tri\n} # kết thúc vòng lặp\ntong # in tong ra màn hình## [1] 40363\n# So sánh kết quả ở trên với hàm sum()\nsum(AirPassengers) # cho kết quả tương tự## [1] 40363\n# Khời tạo véc-tơ my_vector có độ dài 10^8\nmy_vector<-rep(1,10^8)\n\n## Tính tổng véc-tơ có độ dài 10^8 bằng vòng lặp\nstart<-proc.time()\ntong<-0\nfor (value in my_vector){\n  tong<-tong+value\n}\nproc.time()-start##    user  system elapsed \n##   1.101   0.016   1.117\n## Tính tổng véc-tơ có độ dài 10^8 bằng véc-tơ\nstart<-proc.time()\ntong<-sum(my_vector)\nproc.time()-start##    user  system elapsed \n##   0.157   0.001   0.158\nfor (i in 1:length(qua)){ # i sẽ nhận giá trị lần lượt 1,2,3,4\n  print(qua[i]) # in ra giá trị thứ i trong véc-tơ qua\n} # kết thúc vòng lặp## [1] \"chuối\"\n## [1] \"táo\"\n## [1] \"cam\"\n## [1] \"chanh\"\npha_che<-c(\"Nước ép\", \"Sinh tố\") # 2 cách pha chế\nfor (i in 1:length(pha_che)){ # i sẽ nhận giá trị lần lượt 1,2\n  for (j in 1:length(qua)){ # VỚI MỐI i, j sẽ nhận giá trị lần lượt 1,2,3,4\n    print(paste(pha_che[i],qua[j],sep=\" \")) # in ra màn hình pha chế và quả\n  } # kết thúc vòng lặp của j với mỗi i\n} # kết thúc vòng lặp của i## [1] \"Nước ép chuối\"\n## [1] \"Nước ép táo\"\n## [1] \"Nước ép cam\"\n## [1] \"Nước ép chanh\"\n## [1] \"Sinh tố chuối\"\n## [1] \"Sinh tố táo\"\n## [1] \"Sinh tố cam\"\n## [1] \"Sinh tố chanh\""},{"path":"kiến-thức-r-cơ-bản.html","id":"vòng-lặp-while","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.4.2.2 Vòng lặp while","text":"Vòng lặp được gọi là vòng lặp xác định vì nếu không có thêm các câu lệnh đặc biệt, người viết câu lệnh sẽ biết trước được số lần vòng lặp thực hiện. Một cách khác để thực hiện vòng lặp là sử dụng vòng lặp . Đây là kiểu vòng lặp không xác định, nghĩa là trong nhiều trường hợp người viết câu lệnh sẽ không biết trước được sẽ vòng lặp sẽ được thực hiện bao nhiêu lần. Trước khi nói kỹ hơn về khái niệm không xác định, bạn đọc hãy làm quen với cấu trúc của vòng lặp trước. Cách viết một vòng lặp như sauNguyên tắc hoạt động của vòng lặp là tiếp tục thực hiện Đoạn câu lệnh nằm giữa dấu ngoặc {} nếu giá trị của y là TRUE và bỏ qua vòng lặp nếu giá trị của y là FALSE. Nếu y nhận giá trị là TRUE và trong Đoạn câu lệnh không có các dòng lệnh tác động làm thay đổi giá trị của y, thì y sẽ luôn luôn nhận giá trị là TRUE và khi đó vòng lặp sẽ lặp vô hạn, nghĩa là không bao giờ dừng lại được.Vòng lặp dưới đây sẽ ra tên các phần tử của véc-tơ qua bằng cách sử dụng một chỉ số tăng dần và chỉ thoát ra khỏi vòng lặp nếu chỉ số đó vượt qua độ dài của véc-tơ:Trong ví dụ ở trên chúng ta đã biết chính xác khi nào chúng ta sẽ dừng lại vòng lặp nên việc sử dụng vòng lặp sẽ phức tạp hơn vòng lặp . Vòng lặp sẽ phát huy hiệu quả khi bạn đọc không biết chính xác khi nào chúng ta nên dừng việc thực hiện lặp các câu lệnh.Hãy lấy ví dụ khi bạn đọc muốn kiểm tra xem một số tự nhiên \\(n\\) bất kỳ có phải là số nguyên tố hay không. Xin được nhắc lại rằng số nguyên tố là các số tự nhiên chỉ có hai ước số là số 1 và chính nó. Để kiểm tra xem số \\(n\\) có phải là số nguyên tố hay không, bạn đọc cần kiểm tra xem \\(n\\) có chia hết cho số nguyên dương nào từ 2 đến số tự nhiên là phần nguyên của \\(\\sqrt{n}\\) hay không. Phần nguyên của \\(\\sqrt{n}\\) được ký hiệu là \\([\\sqrt{n}]\\). Nếu \\(n\\) chia hết cho một số bất kỳ từ 2 đến \\([\\sqrt{n}]\\), \\(n\\) không phải là số nguyên tố. Theo nguyên tắc này bạn đọc có thể viết một vòng lặp bắt đầu từ \\(2\\) đến \\([\\sqrt{n}]\\) và kiểm tra xem \\(n\\) có chia hết cho số nào trong dãy này không. Tuy nhiên vòng lặp như vậy sẽ luôn luôn phải lặp lại chính xác \\([\\sqrt{n}] - 1\\) lần. Viết vòng lặp trong trường hợp này sẽ hiệu quả hơn rất nhiều bởi chỉ cần \\(n\\) chia hết cho 1 số nào đó chúng ta có thể kết thúc ngay vòng lặp và kết luận \\(n\\) không phải là số nguyên tố.Hãy thử áp dụng vòng lặp trên một ví dụ khác liên quan đến dữ liệu trump_tweet. Chẳng hạn như bạn đọc muốn tìm ra thời điểm đầu tiên mà một câu đăng trạng thái được yêu thích nhiều hơn 10.000 lượt. Câu hỏi này khá dễ nếu chúng ta sử dụng đối tượng véc-tơ. Tuy nhiên chúng tôi muốn bạn đọc suy nghĩ theo hướng sử dụng vòng lặp. Chúng ta sẽ sử dụng một chỉ số tăng dần từ 1 và kiểm tra xem câu đăng trạng thái đó có nhiều hơn 10.000 lượt yêu thích hay không và chỉ dừng lại việc kiểm tra nếu gặp câu có nhiều hơn 10.000 yêu thích. Chúng ta không biết chính xác khi nào sẽ dừng lại, đó sử dụng vòng lặp sẽ hợp lý trong trường hợp nàyMặc dù phần này của cuốn sách đang viết về vòng lặp nhưng chúng tôi muốn nhắc lại rằng bạn đọc hãy cố gắng sử dụng véc-tơ để tìm lời giải thay vì sử dụng vòng lặp khi có thể. Cùng câu hỏi như trên, chúng ta có thể cho lời giải đơn giản hơn bằng cách sử dụng hàm match().Khi làm việc với vòng lặp những người mới làm quen với lập trình rất dễ rơi vào trạng thái vòng lặp vô hạn. Dưới đây là một ví dụ về một vòng lặp như vậy. Biến kiem_tra nhận giá trị ban đầu là TRUE và trong các câu lệnh nằm trong vòng lặp không có câu lệnh nào tác động đến giá trị của biến đó. Bạn đọc sẽ thấy giá trị được ra tăng dần và không bao giờ dừng lại. Bạn đọc chỉ có thể dừng chương trình chạy bằng cách nhấn vào biểu tượng STOP màu đỏ phía trên - bên phải cửa sổ Console.Kinh nghiệm của chúng tôi khi sử dụng vòng lặp không xác định là luôn luôn sử dụng một biến, tạm gọi là , không liên quan đến chương trình chạy và được gán cho giá trị tăng dần trong vòng lặp. Trong biển thức điều kiện luôn luôn kèm thêm một điều kiện là nhỏ hơn số lần lặp tối đa mà người lập trình quy định. Bạn đọc có thể quan sát đoạn lệnh sau:Các đoạn câu lệnh kiểu trên sẽ lặp tối đa là 10.000 lần chúng ta sử dụng thêm điều kiện (<= loop_max)","code":"\n# y là một biến kiểu logic\nwhile (y){\n  \"Đoạn câu lệnh\"\n}\nqua = c(\"chuối\", \"táo\", \"cam\", \"chanh\") # Véc-tơ chứa tên các loại quả\ni<-1\nwhile (i <= length(qua)){ # TRUE cho đến khi i = 5\n  print(qua[i]) # In ra màn hình phần tử thứ i\n  i<-i+1 # Tăng i lên dần để thoát ra khỏi vòng lặp\n} # Kết thúc vòng lặp while## [1] \"chuối\"\n## [1] \"táo\"\n## [1] \"cam\"\n## [1] \"chanh\"\nprint(i) # Kiểm tra giá trị của i khi thoát ra khỏi vòng lặp## [1] 5\n# Nhập số n để kiểm tra\nn<-123454321\n\n# Biến điều kiện ket_qua\nket_qua<-TRUE # ket_qua sẽ đổi thành FALSE khi n chia hết cho 1 số\nuoc_so<-2 # Ước số đầu tiên cần kiểm tra\n\n# Vòng lặp ko xác định, lặp lại nếu ket_qua = TRUE VÀ ước số < n^0.5\nwhile( ket_qua & (uoc_so < n^0.5) ){\n  if(n %% uoc_so == 0){\n    ket_qua<-FALSE # Thay đổi ket_qua nếu n chia hết cho uoc_so\n  }\n  uoc_so<-uoc_so + 1 # Tăng ước số thêm 1\n}\n\n# In ra kết quả cuối cùng\nket_qua # TRUE nến n nguyên tố## [1] FALSE\n# Biến điều kiện của vòng lặp while\nkiem_tra<-TRUE\n\n# Chỉ số dòng\ni<-0\n\n# Thực hiện vòng lặp, dừng lại khi kiem_tra là FALSE\nwhile(kiem_tra){\n  i<-i+1 # tăng chỉ số i\n  kiem_tra<-trump_tweets$favorite_count[i] <= 10^4\n}\n\n# In ra kết quả\ntrump_tweets$favorite_count[i]## [1] 15457\ntrump_tweets$created_at[i]## [1] \"2011-12-21 15:36:36 EST\"\n# Sử dụng hàm match trên véc-tơ logic\n# vitri là chỉ số nhỏ nhất mà số like nhiều hơn 10.000\nvitri<-match(TRUE,trump_tweets$favorite_count>10^4)\n\n# In ra kết quả\ntrump_tweets$favorite_count[i]## [1] 15457\ntrump_tweets$created_at[vitri]## [1] \"2011-12-21 15:36:36 EST\"\n# HÃY CẨN THẬN VÌ ĐÂY LÀ VÒNG LẶP VÔ HẠN\n\n# Biến điều kiện trong vòng lặp không xác định\nkiem_tra<-TRUE\n\n# Bắt đầu lặp\nwhile (kiem_tra){\n  # In ra màn hình phần tử thứ i\n  print(paste0(\"Giá trị của i hiện tại: \", i))\n}\n# Quy định số lần lặp tối đa, biến i tăng dần sau mỗi lần lặp\nloop_max<-10^4\ni<-1\n\n# Biến điều kiện trong vòng lặp\nkiem_tra<-TRUE\n\n# Thực thi vòng lặp\nwhile (kiem_tra & (i<= loop_max)){\n  i<-i+1 # luôn luôn tăng i\n  print(paste0(\"Giá trị của i hiện tại: \", i))\n}"},{"path":"kiến-thức-r-cơ-bản.html","id":"điều-khiển-vòng-lặp","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.4.2.3 Điều khiển vòng lặp","text":"Khi bạn đọc viết các vòng lặp hoặc , R cung cấp các từ khóa để bạn đọc có thể điều khiển vòng lặp. Các từ khóa đó bao gồm break và next. Ý nghĩa của các từ khóa này như sau\nBảng 2.16: Các từ khóa điều khiển vòng lặp\nBạn đọc quan sát giá trị trả ra màn hình của đoạn câu lệnh sau đề hiểu cách sử dụng next trong vòng lặp dưới đâyCó thể thấy rằng trong các loại quả được ra màn hình không có giá trị cam bởi vì khi biến ten bằng giá trị này từ khóa next đã kết thúc vòng lặp hiện tại, bỏ qua dòng lệnh print() và đi đến vòng lặp tiếp theo. Vẫn các câu lệnh như trên nhưng thay next bằng break, chúng ta có thể quan sát R trả ra kết quả như sau:R chỉ trả ra tên hai loại quả là chuối và táo bởi vì khi gặp giá trị cam từ khóa break đã kết thúc vòng lặp .Trong R còn có một kiểu viết vòng lặp không xác định khác với vòng lặp đó là viết vòng lặp sử dụng câu lệnh repeat. Khi sử dụng vòng lặp repeat bạn đọc luôn luôn phải sử dụng từ khóa break để kết thúc vòng lặp và tránh bị lặp vô hạn. Cách sử dụng repeat trong R như sauTrong vòng lặp repeat ở trên, chúng tôi sử dụng điều kiện là bằng độ dài của véc-tơ để kết thúc vòng lặp. Những bạn đọc mới làm quen với lập trình sẽ dễ bị nhầm lẫn về cách kết thúc vòng lặp của và repeat. Cách hoạt động của hai vòng lặp này là tương đương nhau nên chúng tôi cho rằng những bạn đọc chưa quen với lập trình nên chỉ chọn một trong hai cách viết trong quá trình viết câu lệnh.","code":"\nqua = c(\"chuối\", \"táo\", \"cam\", \"chanh\") # Vec-tơ chứa tên các loại quả\nfor (ten in qua){ # cho biến ten nhận lần lượt các giá trị trong vec-tơ qua\n  if (ten == \"cam\"){\n    next # nếu ten là \"cam\" thì chuyển qua vòng lặp tiếp theo\n  }\n  print(ten) # in ten ra màn hình\n} # kết thúc vòng lặp for## [1] \"chuối\"\n## [1] \"táo\"\n## [1] \"chanh\"\nqua = c(\"chuối\", \"táo\", \"cam\", \"chanh\") # Vec-tơ chứa tên các loại quả\nfor (ten in qua){ # cho biến ten nhận lần lượt các giá trị trong vec-tơ qua\n  if (ten == \"cam\"){\n    break # nếu ten là \"cam\" thì kết thúc vòng lặp ngay lập tức\n  }\n  print(ten) # in ten ra màn hình\n} # kết thúc vòng lặp for## [1] \"chuối\"\n## [1] \"táo\"\nqua = c(\"chuối\", \"táo\", \"cam\", \"chanh\") # Vec-tơ chứa tên các loại quả\ni<-0\nrepeat{\n  i<-i+1 # luôn luôn tăng i\n  print(qua[i]) # in tên ra màn hình\n  if (i== length(qua)){break}\n} # kết thúc vòng lặp repeat## [1] \"chuối\"\n## [1] \"táo\"\n## [1] \"cam\"\n## [1] \"chanh\""},{"path":"kiến-thức-r-cơ-bản.html","id":"hàm-số","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.4.3 Hàm số","text":"Hàm số có vai trò quan trọng trong bất kỳ ngôn ngữ lập trình nào. Trước hết, hàm số công cụ hữu hiệu đảm bảo sự chính xác và tiện lợi khi lập trình. Thứ hai hàm số là phương pháp chuyển giao kiến thức và kinh nghiệm từ người dùng này đến người dùng khác một cách vô cùng hiệu quả.Hàm số đặc biệt có ý nghĩa khi bạn phải thực hiện một đoạn câu lệnh một cách lặp đi lặp lại và sự thay đổi của một số yếu tố đầu vào. Thay vì phải làm đi làm lại công việc đó một cách thủ công, bạn hãy viết quy trình đó thành một hàm số.Hàm số đặc biệt có ý nghĩa khi bạn phải thực hiện một đoạn câu lệnh một cách lặp đi lặp lại và sự thay đổi của một số yếu tố đầu vào. Thay vì phải làm đi làm lại công việc đó một cách thủ công, bạn hãy viết quy trình đó thành một hàm số.Khi chúng ta muốn chuyển giao kinh nghiệm, kiến thức của mình cho một người khác, hãy viết chương trình của bạn dưới dạng hàm số và chuyển giao. Người dùng có thể không hiểu được ý nghĩa của chương trình của bạn ngay thì ít nhất cũng có thể sử dụng được kiến thức của bạn. Nếu bạn đọc để ý, các thư viện cài đặt thêm trên R đều là tập hợp của các hàm số.Khi chúng ta muốn chuyển giao kinh nghiệm, kiến thức của mình cho một người khác, hãy viết chương trình của bạn dưới dạng hàm số và chuyển giao. Người dùng có thể không hiểu được ý nghĩa của chương trình của bạn ngay thì ít nhất cũng có thể sử dụng được kiến thức của bạn. Nếu bạn đọc để ý, các thư viện cài đặt thêm trên R đều là tập hợp của các hàm số.Hàm số trên R ngoài các hàm sẵn có còn có các hàm số nằm trong các thư viện mà bạn đọc cài đặt bổ sung và các hàm số mà bạn đọc tự định nghĩa.","code":""},{"path":"kiến-thức-r-cơ-bản.html","id":"hàm-số-do-người-dùng-tự-định-nghĩa.","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.4.3.1 Hàm số do người dùng tự định nghĩa.","text":"Từ khóa để khai báo một hàm số là function(). Để tự tạo một hàm số tên là f nhận giá trị bằng \\(x^2\\) thì bạn đọc sử dụng đoạn câu lệnh như sau:Thay vì sử dụng từ khóa return, bạn đọc cũng có thể sử dụng tên hàm số đển gán cho giá trị trả lại:Đôi khi bạn đọc sẽ gặp các đoạn lệnh khai báo hàm số không có từ khóa return và cũng không có phần gán giá trị cho hàm số. Khi đó R sẽ luôn luôn lấy giá trị được trả ra cuối cùng để gán giá trị cho hàm số đó.Cách viết này chỉ phù hợp cho các hàm số ngắn gọn và chúng tôi khuyên bạn đọc hãy luôn sử dụng từ khóa return khi trả lại giá trị cho hàm số để tránh sự nhầm lẫn.Sau khi đã chạy các đoạn lệnh khai báo hàm số \\(f(x) = x^2\\), R sẽ lưu đối tượng có tên f là kiểu hàm số lên môi trường làm việc chung. Để gọi hàm số và thực hiện tính toán, bạn đọc cần viết đúng tên hàm và cho tham số x giá trị phù hợp.Từ khóa return được sử dụng để trả lại giá trị cho hàm số f và R sẽ gán giá trị cho hàm số f ngay lập tức khi gặp hàm câu lệnh return. Nếu trong đoạn câu lệnh của hàm số f có nhiều từ khóa return, giá trị của f sẽ được gán bằng từ khóa return đầu tiên. Hãy quan sát ví dụ sau:Cách đặt tên hàm số cũng giống như đặt tên biến trong R, bạn đọc cần lựa chọn tên hợp lệ và tránh các từ khóa. Biến x trong phần khai báo hàm số ở trên được gọi là tham số. Hàm số trong R có thể không có tham số nào hoặc có thể có rất nhiều tham số, mỗi tham số là một kiểu đối tượng khác nhau, việc này hoàn toàn tùy thuộc vào người lập trình. Bên trong dấu ngoặc {} của từ khóa function() được gọi là môi trường cục bộ, R sẽ luôn ưu tiên biến nằm trong môi trường này trước tất cả các môi trường khác. Vấn đề sẽ được thảo luận ở phần tiếp theo. Một điểu cần lưu ý là khi viết hàm số hãy luôn luôn có tài liệu hoặc mô tả đi kèm rõ ràng để người sử dụng khác, hoặc chính mình khi sử dụng có thể hiểu hay nhớ được hàm số được sử dụng như thế nào và với mục đích gì.Tham số hay biến số là phần thiết yếu của các hàm trong R. Trong phần tiếp theo, chúng ta sẽ xem xét cách tham số trong hàm số hoạt động như thế nào, chẳng hạn như cách tạo giá trị mặc định cho tham số, cách xử lý các giá trị tham số bị thiếu, cách bổ sung vào tham số bằng cách sử dụng dấu ba chấm (…)Để tạo giá trị mặc định cho tham số bạn đọc cần gán giá trị phù hợp khi khai báo hàm số. Tạo giá trị mặc định cho tham số là quan trọng khi bạn đọc viết các hàm số có nhiều tham số bởi vì khi bạn gọi hàm số và quên gán giá trị cho một vài tham số nào đó, R sẽ sử dụng giá trị mặc định để tính toán và không báo lỗi. Hãy xem xét ví dụ sau: bạn muốn viết một hàm số để tính giá trị hiện tại (present value) của một dòng tiền được quan sát theo năm và được lưu trong một véc-tơ tên là CF. Lãi suất tính theo kiểu lãi gộp là biến . Chúng ta sẽ sử dụng giá trị mặc định 5% để gán cho iGiả sử dòng tiền có giá trị là 1 nghìn USD tại thời điểm cuối năm thứ nhất và tăng thêm 1 nghìn USD mỗi năm và lên đến 10 nghìn USD tại cuối năm thứ 10. Mức lãi suất gộp = 10%/năm. Giá trị hiện tại của dòng tiền được tính bằng hàm PV như sauKhi chúng ta quên không gán giá trị cho tham số khi gọi hàm PV, R sẽ cho nhận giá trị mặc định là 5%Sử dụng dấu ba chấm (…) khi khai báo tham số của một hàm số là phương pháp để người lập trình sử dụng tham số có sẵn của một hàm số khác. Nguyên tắc hoạt động của cách khai báo tham số này thể hiện qua ví dụ sau: hàm PV được xây dựng ở trên chỉ tính được dòng tiền tại các thời điểm cuối các năm. Bạn đọc muốn hàm PV có thể tính được giá trị hiện tại của dòng tiền trong cả hai trường hợp: dòng tiền bắt đầu từ thời điểm đầu năm hoặc dòng tiền bắt đầu từ cuối năm. Chúng ta thực hiện việc đó bằng cách thêm vào một tham số tên là bat_dau: khi bat_dau nhận giá trị bằng 0 thì thời điểm bắt đầu là đầu năm thứ nhất và khi bat_dau nhận giá trị bằng 1 thì thời điểm bắt đầu là cuối năm thứ nhất. Thay vì sửa lại hàm số PV chúng ta có thể viết một hàm mới, tạm gọi là PV1, và sử dụng tham số của hàm PV:Khi gọi hàm PV1 chúng ta cần gọi đầy đủ tham số:Bạn đọc cũng có thể sử dụng cách mượn tham số này để sử dụng các hàm số có sẵn trong R. Trong ví dụ dưới đây, chúng tôi tự xây dựng một hàm có tên là myplot() để vẽ đồ thị phân tán của một véc-tơ kiểu số x theo chỉ số của véc-tơ đó đồng thời và mượn các tham số main, xlab, ylab, của hàm plot():Chúng ta sẽ sử dụng hàm myplot() để vẽ đồ thị phân tán của véc-tơ x nhận giá trị bằng véc-tơ kiểu chuỗi thời gian Airpassengers.Bạn đọc có thể tham khảo cách sử dụng hàm plot() trong phần đồ thị cơ bản trong cuốn sách này.","code":"\nf<-function(x){ # Là một hàm số của biến x\n  return(x^2) # Trả lại giá trị của hàm số là x^2\n}\nf<-function(x){ # Là một hàm số của biến x\n  f<-x^2 # Trả lại giá trị của hàm số là x^2\n}\nf<-function(x) x^2\nclass(f) # Kiểu của đối tượng f là function## [1] \"function\"\nf(10) # Cho tham số x giá trị bằng 10## [1] 100\nf<-function(x){ # là một hàm số của biến x\n  return(x^2) # Trả lại giá trị của hàm số là x^2 khi gặp return\n  return(x^3) # R sẽ không chạy câu lệnh này\n}\nf(10) # trả lại gái trị là 100\nPV<-function(i = 0.05, CF){  # Hàm PV có hai tham số là i và CF\n  n<-length(CF)\n  discount_factor<-(1+i)^(-(1:n))\n  return (sum(discount_factor * CF))\n}\nMyCF<-seq(1000,10000,length=10)\nPV(i = 0.1, MyCF) # Giá trị hiện tại của MyCF tại i = 10%## [1] 29035.91\nPV(CF = MyCF) # Giá trị hiện tại của MyCF tại i = 5%## [1] 39373.78\nPV1<-function(bat_dau,i,...){ # chúng ta chỉ sử dụng tham số i của PV, các tham số khác khai báo bằng ...\n  if (bat_dau==1) {\n    return (PV(i,...)) # PV1 sử dụng các tham số còn lại của PV\n  } else {\n    return ((1+i)*PV(i,...)) # PV1 sử dụng các tham số còn lại của PV\n  }\n}\nPV1(bat_dau = 0,i = 0.1, CF = MyCF) # dòng tiền bắt đầu từ đầu năm thứ 1## [1] 31939.5\nPV1(bat_dau = 1,i = 0.1, CF = MyCF) # dòng tiền bắt đầu từ cuối năm thứ 1## [1] 29035.91\nmyplot<-function(x,...){ # hàm myplot vẽ đồ thị phân tán\n  n<-length(x) # độ dài của véc-tơ x\n  plot(1:n,x,...)\n}\nmyplot(AirPassengers,main=\"Số lượng hành khách các tháng\",\n       ylab = \"Số lượng hành khách\", # tham số ylab của hàm plot()\n       xlab = \"\", # tham số xlab của hàm plot()\n       type = \"l\", color = \"red\") # tham số type và color của hàm plot"},{"path":"kiến-thức-r-cơ-bản.html","id":"hàm-số-được-xây-dựng-sẵn","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.4.3.2 Hàm số được xây dựng sẵn","text":"Hàm số được xây dựng sẵn là các hàm số được phát triển sẵn trong R và các hàm số trong các thư viện mà bạn đọc cài đặt thêm. Để biết R hiện đang có các thư viện nào đang sẵn sàng để sử dụng, bạn đọc sử dụng câu lệnhNgoài việc liệt kê danh sách các đối tượng, thư viện đang sẵn trên môi trường đang làm việc, bạn đọc còn biết được thứ tự ưu tiên của các thư viện này. Chúng tôi sẽ giải thích về thứ tự ưu tiên ở phía dưới. Đa số các phiên bản R đều có sẵn các thư viện như stats, graphics, utils, … Để biết cụ thể hơn trong một thư viện cụ thể có những đối tượng (hàm số, nhóm các hàm số) nào khác, chúng ta sử dụng câu lệnhBạn đọc sẽ thấy cửa sổ Script liệt kê ra danh sách các hàm số hoặc tên các đối tượng lưu chứa nhóm các hàm số đã được phát triển sẵn trong thư viện stats. Một vài đối tượng được liệt kê ra trong danh sách là các hàm số: hàm AIC(), hàm ARMAacf(),… Một số đối tượng là nhóm các hàm số, chẳng hạn như Beta hay Binomal. Khi bạn đọc gọi Beta trên cửa sổ Console sẽ gặp lỗi vì đó không phải là tên chính xác của hàm số. Thay vì thế hãy chạy câu lệnh ? Beta để thấy rằng trong đối tượng Beta của thư viện stats có một nhóm các hàm số liên quan đến phân phối xác suất \\(Beta\\): hàm dbeta(), hàm pbeta(), hàm qbeta(), và hàm rbeta().Chúng tôi không bàn đến việc làm thế nào để biết sử dụng hàm số nào trong một trường hợp cụ thể bởi vì đương nhiên không có câu trả lời chung cho câu hỏi này. Việc này tùy thuộc vào chuyên môn, hiểu biết, khả năng tìm kiếm của bạn đọc. Chúng tôi muốn tập trung vào việc đảm bảo bạn đọc gọi đúng hàm số mà bạn mong muốn. Sẽ không có vấn đề lớn nếu tên hàm số bạn cần gọi là duy nhất trên cửa số R bạn đang làm việc. Tuy nhiên, khi có một vài đối tượng khác có tên giống như tên hàm số bạn đang sử dụng, bạn sẽ gặp vấn đề.Để làm được việc này bạn đọc nên hiểu một chút về môi trường làm việc và thứ tự ưu tiên khi gọi tên một đối tượng trong R. Khi bạn làm việc trên R, có ba môi trường mà R sử dụng để lưu trữ các đối tượng. Môi trường thứ nhất tạm gọi là môi trường chung (thuật ngữ công nghệ thông tin gọi là toàn cục), thứ hai là môi trường các thư viện, và cuối cùng là môi trường trong một hàm số cụ thể (thuật ngữ CNTT gọi là cục bộ). Khi bạn gọi tên một đối hay một hàm số, R sẽ luôn luôn ưu tiên theo thứ tự là: môi trường cục bộ \\(\\rightarrow\\) môi trường chung (toàn cục) \\(\\rightarrow\\) môi trường các thư viện. có nhiều thư viện cùng mở trên R nên để biết thứ tự ưu tiên của các thư viện bạn đọc sử dụng hàm search(). Các thư viện được ưu tiên hơn sẽ có chỉ số nhỏ hơn trong danh sánh được liệt kê bằng hàm search().Nhìn chung các thư viện cài đặt thêm sẽ thường được ưu tiên hơn các thư viện có sẵn. Nếu một hàm trong thư viện cài đặt thêm trùng tên với một hàm trong thư viện có sẵn, R ưu tiên thư viện cài đặt thêm. Thật vậy, hàm số tên filter() là một hàm được xây dựng sẵn trong thư viện stats. Tuy nhiên trong thư viện dplyr cũng có một hàm tên là filter(). Trước khi gọi thư viện dplyr, mỗi khi bạn đọc gọi hàm filter(), R sẽ luôn hiểu đây là hàm filter() của thư viện stats.Sau khi chúng ta gọi thư viện dplyr, chúng ta sẽ thấy thư viện này xuất hiện trước thư viện stats theo thứ tự ưu tiên.Trong thư viện dplyr cũng có một hàm tên là filter(). Theo thứ tự ưu tiên nếu bạn đọc gọi hàm filter() thì R sẽ hiểu đây là hàm của thư viện dplyr. Lúc này muốn sử dụng hàm filter() của thư viện stats bạn đọc cần phải sử dụng tên thư viện viết trước hàm này stats::filter().Như đã nói ở phần trước, môi trường chung cũng là môi trường được ưu tiên trước môi trường các thư viện. Bạn đọc có thể thấy từ kết quả hàm search(), môi trường chung, ký hiệu .GlobalEnv, luôn xuất hiện trước tiên. Môi trường chung chính là nơi lưu trữ tất cả các hàm số hay đối tượng mà bạn đọc tự định nghĩa. Môi trường chung luôn được ưu tiên trước môi trường thư viện. Điều này có nghĩa là nếu bạn đọc tự định nghĩa một biến, một véc-tơ, hay hàm số có tên là filter, R sẽ ưu tiên tên filter cho đối tượng mà bạn đọc tự định nghĩa. Như vậy, nếu bạn đọc sử dụng tên filter cho một hàm bạn tự định nghĩa, bạn sẽ cần phải sử dụng thêm tên thư viện để gọi hàm filter() từ các thư viện như dplyr hoặc stats.Còn một môi trường khác, tạm gọi là môi trường cục bộ, sẽ được ưu tiên hơn môi trường chung. Môi trường cục bộ mô tả môi trường bên trong một hàm số mà bạn đọc tự định nghĩa. Giả sử sau khi bạn đọc tự định nghĩa một hàm filter() trên môi trường chung và sau đó tự định nghĩa một hàm số f có sử dụng một tham số, có thể là biến hoặc hàm số, có tên là filter thì mỗi khi bạn đọc gọi hàm số f, đối tượng tên filter sẽ luôn được hiểu là tham số của hàm số f. Môi trường bên trong hàm f được gọi là môi trường cục bộ. Bạn đọc hãy quan sát ví dụ dưới đây để hiểu hơn về môi trường chung và môi trường cục bộTrước hết chúng ta định nghĩa một hàm tên là filter() trong môi trường chung luôn nhận giá trị bằng hằng số \\(\\pi\\). Lúc này khi chúng ta gọi filter(), R sẽ hiểu rằng đây là hàm filter() chúng ta tự định nghĩa. Sau đó chúng ta định nghĩa một hàm số tên f đồng thời bên trong hàm f chúng ta định nghĩa một hàm filter() khác nhận giá trị là 10. Hàm filter() bên trong hàm f() được gọi là hàm số trong môi trường cục bộ.Khi chúng ta gọi hàm số f, hàm số này lại gọi một hàm số tên là filter() được định nghĩa bên trong hàm số nó. Bởi vì R ưu tiên môi trường cục bộ trước nên hàm filter() bên trong f() có giá trị bằng 10. Bên ngoài hàm số f(), chúng ta lại gọi filter() thì giá trị trả lại là \\(\\pi\\) vì đây là môi trường chung.Tất cả các hàm số mà bạn đọc thường xuyên sử dụng hãy lưu trong các file và mỗi khi cần sử dụng bạn đọc chỉ cần gọi tên file đó thay vì copy toàn bộ các câu lệnh của các hàm số vào cửa sổ Script. Hàm số để gọi một file lên cửa sổ R bạn đang sử dụng là hàm source(). Chẳng hạn như tất cả các hàm số bạn đọc tự định nghía được lưu ở một file có tên myfunction.R, bạn chỉ cần sử dụng câu lệnh sau để gọi tất cả các hàm số lên cửa sổ đang làm việc:","code":"\nsearch()##  [1] \".GlobalEnv\"         \"package:dslabs\"     \"package:stringr\"   \n##  [4] \"package:ggrepel\"    \"package:pryr\"       \"package:gridExtra\" \n##  [7] \"package:grid\"       \"package:forcats\"    \"package:ggplot2\"   \n## [10] \"package:kableExtra\" \"package:knitr\"      \"package:dplyr\"     \n## [13] \"package:readxl\"     \"package:stats\"      \"package:graphics\"  \n## [16] \"package:grDevices\"  \"package:utils\"      \"package:datasets\"  \n## [19] \"package:methods\"    \"Autoloads\"          \"package:base\"\nlibrary(help = \"stats\") # liệt kê các đối tượng trong thư viện stats\n? filter # nếu chưa gọi thư viện dplyr, filter là hàm của thư viện stats\nlibrary(dplyr) # gọi thư viện dplyr\nsearch() # sau khi gọi thư viện dplyr, thư viện này được ưu tiên trước stats\nfilter<-function(){return(pi)} #Tự định nghĩa hàm filter trong môi trường chung\nfilter() # hàm filter trong .GlobalEnv luôn bằng pi## [1] 3.141593\nf<-function(){\n  filter<-function(){return(10)}\n  # bên trong hàm f, định nghĩa lại hàm filter bằng 10\n\n  return(filter())\n}\nf() # trả lại giá trị là 10 vì hàm filter bên trong f nhận giá trị 10## [1] 10\nfilter() # trả lại giá trị pi## [1] 3.141593\nsource(\"Đường dẫn đến file/myfunction.R\")"},{"path":"kiến-thức-r-cơ-bản.html","id":"đồ-thị-cơ-bản","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.5 Đồ thị cơ bản","text":"Có nhiều hàm trong R để tạo ra các đồ thị từ cơ bản đến phức tạp. Trong phần này chúng tôi sẽ giới thiệu về các hàm cơ bản để tạo đồ thị trong R. Mục đích là để bạn đọc làm quen với các phương pháp vẽ đồ thị phổ biến và hiểu cách tùy chỉnh tham số đồ thị cơ bản. Hiểu về cách vẽ các đồ thị cơ bản sẽ giúp ích rất nhiều khi bạn đọc tìm hiểu về các kỹ thuật trực quan hóa dữ liệu được giới thiệu trong các chương tiếp theo.","code":""},{"path":"kiến-thức-r-cơ-bản.html","id":"đồ-thị-phân-tán","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.5.1 Đồ thị phân tán","text":"Đồ thị phân tán, được gọi là Scatter plot, là đồ thị được sử dụng để mô tả sự phân tán của các điểm trên một mặt phẳng. Đồ thị phân tán có thể sử dụng để mô tả mối liên hệ của một véc-tơ kiểu số theo chỉ số của nó, hoặc để mô tả mối liên hệ giữa hai véc-tơ kiểu số. Hàm số dùng để vẽ đồ thị phân tán là hàm plot(). Một số tham số thường được sử dụng trong hàm này làTham số type cho biết hình dạng sẽ xuất hiện, chẳng hạn như type = ‘p’ cho biết sẽ sử dụng các điểm, type = ‘l’ cho biết sẽ sử dụng các đường.Tham số type cho biết hình dạng sẽ xuất hiện, chẳng hạn như type = ‘p’ cho biết sẽ sử dụng các điểm, type = ‘l’ cho biết sẽ sử dụng các đường.Tham số main được sử dụng để viết tiêu đề của đồ thị, xlab là tiêu đề của trục x, ylab là tiêu đề của trục y.Tham số main được sử dụng để viết tiêu đề của đồ thị, xlab là tiêu đề của trục x, ylab là tiêu đề của trục y.Tham số col cho biết màu sắc của các điểm, đường sử dụng trong đồ thị, chẳng hạn như col = ‘red’ cho biết sẽ sử dụng màu đỏ để vẽ hình.Tham số col cho biết màu sắc của các điểm, đường sử dụng trong đồ thị, chẳng hạn như col = ‘red’ cho biết sẽ sử dụng màu đỏ để vẽ hình.Khi đối tượng trong hàm plot() là một véc-tơ duy nhất, R sẽ vẽ đồ thị phân tán với trục x là chỉ số của các phần tử trong véc-tơ và trục y là giá trị của số trong véc-tơ. Câu lệnh dưới đây sử dụng hàm plot() để vẽ véc-tơ cột Temp từ dữ liệu airquality:\nHình 2.3: Vẽ đồ thị phân tán sử dụng hàm plot()\nNgoài vẽ đồ thị một véc-tơ, đồ thị phân tán còn được sử dụng để mô tả mối liên hệ giữa hai biến liên tục. Đồ thị dưới đây mô tả mối liên hệ giữa hai cột Temp và Ozone trong của dữ liệu airquality:\nHình 2.4: Mô tả mối liên hệ giữa hai biến liên tục sử dụng hàm plot()\nHàm plot() còn có thể được sử dụng để mô tả sự biến động của một véc-tơ theo thời gian. Bạn đọc chỉ cần sử dụng tham số type = ‘l’ trong hàm plot(). Hình vẽ dưới đây mô tả sự biến động của véc-tơ dữ liệu AirPassengers theo thời gian:\nHình 2.5: Mô tả một biến liên tục theo thời gian sử dụng hàm plot()\nHàm lines() được sử dụng để vẽ thêm các đường vào trong một đồ thị có sẵn. Bạn đọc quan sát các sử dụng hàm lines() trong đoạn câu lệnh dưới đây. Lưu ý rằng khi chúng ta mô tả nhiều biến trên cùng một đồ thị thì cần có thêm chú giải và điều chỉnh cá giá trị giới hạn trên trục y để đồ thị hiển thị đầy đủ:\nHình 2.6: Mô tả nhiều biến liên tục theo thời gian sử dụng hàm plot() và lines()\nBạn đọc có thể nhận thấy rằng chúng tôi sử dụng tham số ylim = c(1500,8500) để cho biết giới hạn trên và giới hạn dưới của giá trị trục y trong đồ thị. Hàm lines() được sử dụng để vẽ (thêm) chỉ số chứng khoán SMI vào trong đồ thị đã được tạo bàng hàm plot() trước đó. Sau cùng chúng ta sử dụng hàm legend() để thêm chú giải cho biết đâu là chỉ số chứng khoáng DAX, đâu là chỉ số chứng khoán SMI.","code":"\nplot(airquality$Temp,\n     type = \"p\",\n     main = \"Biến nhiệt độ (temp) - dữ liệu airquality\",\n     xlab = \"Chỉ số véc-tơ\",\n     ylab = \"Nhiệt độ\",\n     col = \"#640514\")\nplot(airquality$Ozone,airquality$Temp,\n     type = \"p\",\n     main = \"Mối liên hệ giữa Ozone và Temp trong dữ liệu airquality\",\n     xlab = \"Chỉ số Ozone\",\n     ylab = \"Nhiệt độ\",\n     col = \"#640514\")\nplot(AirPassengers,\n     type = \"l\",\n     main = \"Số lượng hành khách trung bình theo tháng\",\n     xlab = \"Thời gian\",\n     ylab = \"Số lượng hành khách\",\n     col = \"#640514\")\n# Vẽ đồ thị chỉ số chứng khoán DAX bằng plot()\nplot(EuStockMarkets[,1],type = \"l\",\n     main = \"Chỉ số chứng khoán DAX và SMI\",\n     col = \"#640514\",\n     ylab = (\"\"), xlab = (\"Năm\"),\n     ylim = c(1500,8500))\n\n# Vẽ (thêm) chỉ số chứng khoán SMI bằng lines()\nlines(EuStockMarkets[,2], col = \"#005478\")\n\n# Dùng hàm legend để thêm chú giải vào vị trí\n# (x,y) == (1992,8000)\nlegend(1992, 8000, legend=c(\"Chỉ số DAX\", \"Chỉ số SMI\"),\n       fill = c(\"#005478\",\"#640514\")\n)"},{"path":"kiến-thức-r-cơ-bản.html","id":"đồ-thị-cột","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.5.2 Đồ thị cột","text":"Đồ thị cột hay còn gọi là biểu đồ tần số được sử dụng để mô tả phân phối của một véc-tơ. Hàm số để vẽ đồ thị cột là hàm hist(). Chúng ta sử dụng đồ thị dạng cột để mô tả véc-tơ lợi suất của chỉ số DAX như sau\nHình 2.7: Mô tả phân phối của một biến bằng hàm hist()\nNgoài các tham số thường được sử dụng như main, xlab, ylab, hay col, hàm hist() có một tham số quan trọng là breaks. Tham số này cho biết vị trí các điểm mà ở đó chúng ta sẽ tính toán các cột tần suất. Véc-tơ có độ dài càng lớn thì cần càng nhiều điểm được sử dụng để mô tả phân phối dữ liệu. Bạn đọc có thể thấy rằng đồ thị tần xuất mô tả lợi suất của chỉ số DAX ở trên không có nhiều thông tin các điểm breaks quá nhỏ với độ dài véc-tơ. Chúng ta điều chỉnh lại đồ thị tần suất và sử dụng 50 điểm breaks cách đều từ -0.1 đến 0.1 để có hiển thị tốt hơn\nHình 2.8: Sử dụng tham số break trong hàm hist()\nBiểu đồ tần suất thường được chuẩn hóa về đồ thị xác suất và sử dụng với đồ thị hàm mật độ (density) để mô tả tốt hơn phân phối xác suất của véc-tơ kiểu số. Để chuyển đồ thị tần số thành đồ thị xác suất, bạn đọc sử dụng tham số freq và cho giá trị bằng FALSE. Đoạn câu lệnh dưới đây mô tả cách sử dụng biểu đồ xác suất kết hợp với đồ thị hàm mật độ của lợi suất của chỉ số DAX\nHình 2.9: Sử dụng đồng thời đồ thị tần suất và hàm mật độ để mô tả phân phối xác suất\n","code":"\n# Tính return trên chỉ số DAX\nDAX<-EuStockMarkets[,1]\nn<-length(DAX)\nr_DAX<-log(DAX[2:n]/DAX[1:(n-1)])\n\n# Dùng hàm hist để vẽ đồ thị tần số\nhist(r_DAX, main = \"Tần suất lợi suất của chỉ số DAX\",\n     xlab = \"\", ylab = \"\",\n     border = \"#640514\", col = \"white\")\n# Dùng hàm hist để vẽ đồ thị tần số\nhist(r_DAX, main = \"Tần suất lợi suất của chỉ số DAX\",\n     xlab = \"\", ylab = \"\",\n     breaks = seq(-0.1,0.1,length=100),\n     border = \"#640514\", col = \"white\")\n# Dùng hàm hist để vẽ đồ thị tần số\nhist(r_DAX, main = \"Phân phối xác suất lợi suất của chỉ số DAX\",\n     xlab = \"\", ylab = \"\", freq = FALSE,\n     breaks = seq(-0.1,0.1,length=50),\n     border = \"#640514\", col = \"white\")\n\n# Kết hợp thêm với đồ thị hàm mật độ\nlines(density(r_DAX), col = \"darkblue\")"},{"path":"kiến-thức-r-cơ-bản.html","id":"đồ-thị-hình-hộp","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.5.3 Đồ thị hình hộp","text":"Đồ thị hình hộp, hay còn được gọi là box--whisker, hoặc boxplot, dùng để mô tả phân phối xác suất của một biến liên tục hoặc để mô tả mối liên hệ giữa một biến liên tục với một biến rời rạc. Đồ thị hình hộp sử dụng 5 giá trị đặc trưng của một véc-tơ để mô tả hình dạng phân phối xác suất và các điểm có nhiều khả năng là giá trị ngoại lai trong một véc-tơ. Chúng tôi sẽ thảo luận kỹ hơn về cách sử dụng boxplot trong chương Trực quan hóa dữ liệu. Trong phần này, chúng tôi chỉ mô tả cách vẽ một đồ thị hình hộp cơ bản.Hàm boxplot() được sử dụng để vẽ đồ thị hình hộp. Đồ thị dưới đây mô tả phân phối xác suất của véc-tơ nhiệt độ (biến Temp) trong dữ liệu airquality bằng đồ thị kiểu hình hộp:\nHình 2.10: Đồ thị dạng hộp mô tả phân phối của biến Temp\nĐể mô tả phân phối xác suất của nhiệt độ theo tháng (cột Month) trong dữ liệu airquality chúng ta sử dụng đồ thị hình hộp như sau\nHình 2.11: Đồ thị dạng hộp mô tả phân phối của biến Temp theo tháng (Month)\nCòn nhiều hàm vẽ đồ thị hữu ích trong R bạn đọc có thể tự tìm hiểu như barplot(), dotchart(), hay coplot(). Như chúng tôi đã đề cập, trọng tâm của phần vẽ đồ thị sẽ ở trong chương Trực quan hóa dữ liệu, đó các đồ thị được liệt kê trong phần này chỉ mang tính tham khảo.","code":"\nboxplot(airquality$Temp,\n        border = \"#640514\",col = \"white\")\nboxplot(Temp~Month, data = airquality, border = \"#640514\",col = \"white\")"},{"path":"kiến-thức-r-cơ-bản.html","id":"phụ-lục","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.6 Phụ lục","text":"","code":""},{"path":"kiến-thức-r-cơ-bản.html","id":"biểu-thức-chính-quy-và-thư-viện-stringr","chapter":"Chương 2 Kiến thức R cơ bản","heading":"2.6.1 Biểu thức chính quy và thư viện stringr","text":"Biểu thức chính quy (Regular Expression hay Regex) là công cụ hiệu quả khi chúng phải xử lý một đoạn văn bản dài hoặc một véc-tơ kiểu chuỗi ký tự. Sử dụng biểu thức chính quy giúp cho các câu lệnh phân tích cú pháp, tìm kiếm, và thay thế trong các chuỗi ký tự hay đoạn văn bản trở nên đơn giản hơn rất nhiều. Khái niệm biểu thức chính quy xuất hiện trong hầu hết các ngôn ngữ lập trình nhưng mỗi ngôn ngữ lập trình lại có thể có một cách viết biểu thức chính quy khác nhau. Trong phần này, chúng tôi chỉ thảo luận về biểu thức chính quy trong R và cách sử dụng các biểu thức này trong thư viện chuyên xử lý biến kiểu chuỗi ký tự là thư viện stringr.Biểu thức chính quy là nhóm các quy tắc và cú pháp viết hoặc miêu tả các chuỗi ký tự khác, thường là phức tạp và tổng quát hơn, bằng cách sử dụng các chuỗi ký tự đơn giản. Ví dụ, biểu thức chính quy đơn giản nhất là . đại diện cho tất cả các ký tự có thể xuất hiện trong một chuỗi ký tự. Giả sử chúng ta có biến kiểu chuỗi ký tự là câu trạng thái thứ 20.000 của cựu tổng thống Donald Trump và chúng ta muốn xem trong chuỗi ký tự đó, có những đoạn ký tự nào được bắt đầu bằng chữ “” và theo sau đó là một ký tự bất kỳ, chúng ta sử dụng biểu thức chính quy \".\". Hàm số sử dụng để hiển thị tất cả đoạn ký tự là hàm str_view_all() của thư viện stringrCó thể thấy rằng có sáu đoạn ký tự trong biến str0 được bắt đầu bằng “” và theo sau là một ký tự bất kỳ. Để miêu tả ký tự . trong chuỗi ký tự và phân biệt với biểu thức chính quy, chúng ta sử dụng \\\\. để mô tả dấu .. Thật vậy, hãy quan sát ví dụ sau:","code":"\nstr0<-trump_tweets$text[20000]\nstr_view_all(str0,\"A.\")## [1] │ M<AK>E <AM>ERIC<A >GRE<AT> <AG><AI>N!\nstr0<-\"I am an actuary. What is your profession?\"\nstr_view_all(str0,\"\\\\.\")## [1] │ I am an actuary<.> What is your profession?"},{"path":"kiến-thức-r-cơ-bản-1.html","id":"kiến-thức-r-cơ-bản-1","chapter":"Chương 3 Kiến thức R cơ bản","heading":"Chương 3 Kiến thức R cơ bản","text":"","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"kiến-thức-r-nâng-cao","chapter":"Chương 4 Kiến thức R nâng cao","heading":"Chương 4 Kiến thức R nâng cao","text":"Trong cuốn sách này chúng tôi cố gắng tránh nhắc đến các khái niệm toán học phức tạp bởi đối tượng chúng tôi hướng đến là những người làm việc với dữ liệu nhưng không có một nền tảng chuyên sâu về toán học. Tuy nhiên để làm việc được với dữ liệu thì các kiến thức về ma trận nói riêng và kiến thức về đại số tuyến tính nói chung là bắt buộc phải nắm vững. Điều đáng tiếc là tại thời điểm chúng tôi viết cuốn sách này, đa số các chương trình đào tạo dành cho sinh viên các ngành kinh tế đang cắt giảm dần kiến thức về toán học và đặc biệt là kiến thức đại số tuyến tính.","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"ma-trận","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.1 Ma trận","text":"Ma trận có ý nghĩa đặc biệt quan trọng trong phân tích dữ liệu bởi đa số các dữ liệu đều được chuyển thành kiểu ma trận để dễ dàng phân tích và tính toán. Cũng giống như véc-tơ, ma trận là một đối tượng dùng để lưu các biến có cùng kiểu. Khác với véc-tơ, ma trận lưu phần tử theo hàng và cột, nghĩa là trong không gian hai chiều trong khi véc-tơ lưu phần tử trong không gian một chiều. Bạn đọc cũng có thể hiểu véc-tơ là một cột trong khi ma trận là tập hợp của các cột có cùng độ dài. Kích thước của một véc-tơ là chiều dài của véc-tơ đó trong khi kích thước của một ma trận là số hàng và số cột của ma trận đó.","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"khởi-tạo-ma-trận","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.1.1 Khởi tạo ma trận","text":"Hàm số dùng để tạo ra ma trận trong R là hàm matrix(). Khi tạo ma trận, bạn đọc sẽ luôn luôn phải khởi tạo giá trị cho ma trận đó. Đoạn lệnh sau sẽ khởi tạo một ma trận có tên M, có 3 hàng, 4 cột, và giá trị trong ma trận là các số tự nhiên từ 1 đến 12 được sắp xếp theo thứ tựCác giá trị dùng để khởi tạo cho ma trận là các số từ 1 đến 12 và được điền vào ma trận M theo nguyên tắc từ trên xuống dưới rồi từ trái sang phải, nghĩa làCột thứ nhất sẽ được ưu tiên cho giá trị trước; phần tử hàng thứ nhất của cột thứ nhất sẽ được điền giá trị trước tiên, sau đó đến phần tử ở hàng thứ hai của cột thứ nhất, …Sau khi điền hết cột thứ nhất R sẽ tiếp tục điền vào giá trị ở hàng thứ nhất của cột thứ hai, rồi phần tử hàng hai ở cột thứ hai,… cho đến hết cột thứ hai.Quá trình điền số vào ma trận sẽ tiếp tục như thế sau khi tất cả các phần tử trong ma trận đều có giá trị. Véc-tơ dùng để khởi tạo giá trị cho ma trận có độ dài 12 vừa đúng với số phần tử trong ma trận nên câu lệnh tạo ma trận M ở trên hoạt động bình thường. Trong trường hợp bạn đọc sử dụng véc-tơ có độ dài khác 12 để khởi tạo giá trị cho ma trận, câu lệnh vẫn sẽ chạy nhưng có kèm theo cảnh báo:Bạn đọc có thể thấy rằng:Nếu véc-tơ dùng để khởi tạo giá trị cho ma trận M có độ dài lớn hơn 12, R sẽ dùng 12 giá trị đầu tiên để khởi tạo giá trị cho ma trận.Nếu véc-tơ dùng để khởi tạo giá trị cho ma trận M có độ dài nhỏ hơn 12, R sẽ lặp lại véc-tơ đó cho đến khi có độ dài lớn hơn hoặc bằng 12 rồi sau đó dùng 12 giá trị đầu tiên để khởi tạo giá trị cho ma trận.Khi khởi tạo ma trận, bạn đọc có thể yêu cầu giá trị được khởi tạo theo hàng thay vì theo cột bằng tham số byrow = TRUE trong hàm matrix().Để biết kích cỡ của ma trận, chúng ta sử dụng hàm dim(). Hàm dim() trả lại giá trị là một véc-tơ kiểu số có độ dài là hai, phần tử thứ nhất là số hàng, phần tử thứ hai là số cột của ma trận:Ma trận cũng có thể được khởi tạo bằng cách ghép các véc-tơ hoặc các ma trận khác theo hàng hay theo cột bằng các hàm cbind() hoặc rbind():Hàm cbind() nối các ma trận có cùng số hàng hoặc ma trận với véc-tơ có độ dài bằng số hàng của ma trận.Tương tự, rbind() nối các ma trận có cùng số cột hoặc ma trận với véc-tơ có độ dài bằng số cột của ma trận.Các phép tính toán thông thường trên ma trận cũng có nguyên tắc giống như đối với véc-tơ. Các phép toán như cộng, trừ, nhân, chia, lũy thừa, …, sẽ tác động lên tất cả các phần tử trong ma trận theo thứ tự của các phần tử xuất hiện trên ma trận. Ví dụ khi nhân ma trận M kích thước 3 \\(\\times\\) 4 với một số ta sẽ có kết quả như sau:Bạn đọc có thể thấy rằng kết quả nhận được là một ma trận có kích thước bằng với kích thước của ma trận M và mỗi phần tử bằng phần tử ở vị trí tương ứng của ma trận M nhân với 2.Khi thực hiện phép nhân thông thường ma trận M với một ma trận M1 có cùng kích thước thì kết quả nhận được là một ma trận mà mỗi phần tử bằng tích của 2 phần tử ở vị trí tương ứng của M và M1. R sẽ báo lỗi nếu thực hiện phép nhân thông thường giữa hai ma trận không có cùng kích thước:Phép nhân thông thường cũng có thể được thực hiện giữa ma trận M với một véc-tơ có độ dài nhỏ hơn hoặc bằng số phần tử của M. Trước khi thực hiệp phép nhân, R sẽ chuyển các phần tử trong véc-tơ vào một ma trận có kích thước tương ứng với M sau đó thực hiện phép nhân giống như nhân hai ma trận có cùng kích thước:Khi thực hiện tính toán như trên, R đã tự động lặp lại véc-tơ x cho đến khi số lượng phần tử bằng với số phần tử của M, điền các giá trị này vào một ma trận có kích thước bằng với kích thước của M rồi sau đó thực hiện phép nhân. Thật vậy, chúng ta có thể kiểm tra như sau:","code":"\nM<-matrix(1:12, nrow = 3, ncol = 4) # nrow: số hàng, ncol: số cột\nM # In M##      [,1] [,2] [,3] [,4]\n## [1,]    1    4    7   10\n## [2,]    2    5    8   11\n## [3,]    3    6    9   12\nM<-matrix(1:13, nrow = 3, ncol = 4) # Sẽ có cảnh báo;\nM<-matrix(1:5, nrow = 3, ncol = 4) # Sẽ có cảnh báo;\nM<-matrix(1:12, nrow = 3, ncol = 4, byrow = TRUE)\nM # in M ra của sổ console##      [,1] [,2] [,3] [,4]\n## [1,]    1    2    3    4\n## [2,]    5    6    7    8\n## [3,]    9   10   11   12\ndim(M) # ma trận 3 hàng 4 cột## [1] 3 4\ncbind(M,rep(1,3)) # ghép THEO CỘT, ma trận M (3 hàng, 4 cột) với véc-tơ độ dài 3##      [,1] [,2] [,3] [,4] [,5]\n## [1,]    1    2    3    4    1\n## [2,]    5    6    7    8    1\n## [3,]    9   10   11   12    1\nrbind(M,rep(1,4)) # ghép THEO HÀNG, ma trận M (3 hàng, 4 cột) với véc-tơ độ dài 4##      [,1] [,2] [,3] [,4]\n## [1,]    1    2    3    4\n## [2,]    5    6    7    8\n## [3,]    9   10   11   12\n## [4,]    1    1    1    1\nM<-matrix(1:12, nrow = 3, ncol = 4)\nM * 2 # in M*2 ra của sổ console##      [,1] [,2] [,3] [,4]\n## [1,]    2    8   14   20\n## [2,]    4   10   16   22\n## [3,]    6   12   18   24\nM<-matrix(1:12, nrow = 3, ncol = 4)\nM1<-matrix(rep(c(0,1),6), nrow = 3, ncol = 4)\nM * M1# in M * M1 ra của sổ console##      [,1] [,2] [,3] [,4]\n## [1,]    0    4    0   10\n## [2,]    2    0    8    0\n## [3,]    0    6    0   12\nM<-matrix(1:12, nrow = 3, ncol = 4)\nx<-c(-2,-1,0,1,2) # véc-tơ độ dài 5\nM * x # phép nhân được thực hiện mà không báo lỗi##      [,1] [,2] [,3] [,4]\n## [1,]   -2    4   -7   20\n## [2,]   -2   10    0  -22\n## [3,]    0  -12    9  -12\ny<-rep(x,3)\n# Lặp lại x cho đến khi số phần tử của véc-tơ thu được lớn hơn 12\n\nM1<-matrix(y[1:12],nrow = 3, ncol = 4)\n# Dùng 12 giá trị ban đầu để tạo thành ma trận có cùng kích thước 3*4\n\nM * M1 # Kết quả giống như M * x##      [,1] [,2] [,3] [,4]\n## [1,]   -2    4   -7   20\n## [2,]   -2   10    0  -22\n## [3,]    0  -12    9  -12"},{"path":"kiến-thức-r-nâng-cao.html","id":"lấy-phần-tử-con-và-ma-trận-con-của-ma-trận.","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.1.2 Lấy phần tử con và ma trận con của ma trận.","text":"Tương tự như với véc-tơ, chúng ta sử dụng dấu ngoặc vuông [] để lấy phần tử con trong ma trận. Khác với véc-tơ, ma trận có chỉ số hàng và chỉ số cột nên chúng ta cần cho biết phần tử được lấy ra ở hàng thứ bao nhiêu và cột thứ bao nhiêu:Chúng ta cũng có thể lấy ra véc-tơ hàng hoặc véc-tơ cột của ma trận bằng cách sauĐể lấy ra một ma trận con của một ma trận, chúng ta cũng tạo véc-tơ chỉ số giống như cách tạo chỉ số với véc-tơ. Thay vì chỉ tạo một véc-tơ chỉ số duy nhất như khi làm với véc-tơ, chúng ta cần tạo một véc-tơ chỉ số theo hàng và một véc-tơ chỉ số theo cột. Bạn đọc có thể tạo chỉ số bằng một véc-tơ kiểu số hoặc véc-tơ kiểu logical hoặc kết hợp cả hai phương pháp này","code":"\nM[2,3] # Phần tử ở hàng thứ hai, cột thứ ba của ma trận M## [1] 8\nM[,3] # Lấy ra véc-tơ cột thứ 3 của ma trận M## [1] 7 8 9\nM[2,] # Lấy ra véc-tơ hàng thứ 2 của ma trận M## [1]  2  5  8 11\nchi_so_hang<-c(TRUE,FALSE,TRUE) # Chỉ số theo hàng kiểu logical\nchi_so_cot<-c(2,4) # Chỉ số cột theo kiểu số\nM[chi_so_hang,chi_so_cot] # Ma trận con của ma trận M##      [,1] [,2]\n## [1,]    4   10\n## [2,]    6   12"},{"path":"kiến-thức-r-nâng-cao.html","id":"các-phép-toán-trên-ma-trận","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.1.3 Các phép toán trên ma trận","text":"Các phép toán trên ma trận có ý nghĩa đặc biệt quan trọng trong phân tích dữ liệu. Ở các chương tiếp theo bạn đọc sẽ thấy rằng tất cả các tính toán nhằm biến đổi dữ liệu, hoặc ước lượng tham số cho các mô hình trên dữ liệu đều dựa trên các phép tính toán trên ma trận. Chúng tôi sẽ giải thích các phép toán này một cách đơn giản nhất để những bạn đọc không có nền tảng chuyên sâu về toán cũng có thể hiểu được. Tuy nhiên, để có kỹ năng thành thạo trong biến đổi dữ liệu, phân tích dữ liệu, và xây dựng các mô hình trên dữ liệu, chúng tôi khuyên bạn đọc nên tự trang bị cho mình các kiến thức về ma trận nói riêng và đại số tuyến tính nói chung.","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"phép-chuyển-vị","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.1.3.1 Phép chuyển vị","text":"Phép toán chuyển vị (transpose) là một phép toán biến đổi một ma trận \\(M\\) kích thước \\(n \\times p\\) thành một ma trận mới, ký hiệu là \\(M^T\\), có kích thước \\(p \\times n\\). Phần tử hàng thứ \\(j\\) và cột thứ \\(\\) của ma trận \\(M^T\\) bằng phần tử ở hàng thứ \\(\\) và cột thứ \\(j\\) của ma trận \\(M\\).\\[\\begin{align}\n\\begin{bmatrix}\nm_{11} & m_{12} & m_{13}\\\\\nm_{21} & m_{22} & m_{23}\n\\end{bmatrix}\n\n\\xrightarrow[\\text{(transpose)}]{\\text{chuyển vị}}\n\n\\begin{bmatrix}\nm_{11} & m_{21} \\\\\nm_{12} & m_{22} \\\\\nm_{13} & m_{23}\n\\end{bmatrix}\n\\tag{4.1}\n\\end{align}\\]Hàm số để thực hiện phép chuyển vị ma trận trong R là hàm t()Bạn đọc có thể thấy rằng nếu thực hiện phép chuyển vị hai lần liên tiếp ta sẽ thu được ma trận ban đầu","code":"\nM<-matrix(1:12, nrow = 3, ncol = 4, byrow = TRUE) # nrow: số hàng, ncol: số cột\nM # in M ra của sổ console##      [,1] [,2] [,3] [,4]\n## [1,]    1    2    3    4\n## [2,]    5    6    7    8\n## [3,]    9   10   11   12\nt(M) # ma trận chuyển vị của ma trận##      [,1] [,2] [,3]\n## [1,]    1    5    9\n## [2,]    2    6   10\n## [3,]    3    7   11\n## [4,]    4    8   12\nt(t(M)) # ma trận chuyển vị của ma trận chuyển vị là ma trận ban đầu##      [,1] [,2] [,3] [,4]\n## [1,]    1    2    3    4\n## [2,]    5    6    7    8\n## [3,]    9   10   11   12"},{"path":"kiến-thức-r-nâng-cao.html","id":"phép-nhân-ma-trận","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.1.4 Phép nhân ma trận","text":"Phép nhân ma trận (matrix multiplication) của ma trận \\(\\) với ma trận \\(B\\) chỉ thực hiện được nếu số cột của ma trận \\(\\) bằng với số hàng của ma trận \\(B\\). Giả sử rằng \\(\\) có kích thước là \\(n \\times p\\) và \\(B\\) có kích thước là \\(p \\times k\\) thì kết quả của phép nhân ma trận của ma trận \\(\\) với ma trận \\(B\\) là một ma trận \\(M\\) có kích thước \\(n \\times k\\), phần tử ở hàng thứ \\(\\) và cột thứ \\(j\\) của ma trận \\(M\\) là tích vô hướng giữa véc-tơ hàng \\(\\) của ma trận \\(\\) và véc-tơ cột \\(j\\) của ma trận \\(B\\). Nhắc lại với bạn đọc rằng tích vô hướng của hai véc-tơ \\(x\\) và \\(y\\) (phải) có cùng độ dài \\(n\\) được ký hiệu là \\(<x,y>\\) và được tính như sau\\[\\begin{align}\n<x,y> = \\sum\\limits_{= 1}^n \\ x_i y_i\n\\end{align}\\]trong đó \\(x_i\\), \\(y_i\\) lần lượt là phần tử thứ \\(\\) của véc-tơ \\(x\\) và véc-tơ \\(y\\).Để phân biệt phép nhân ma trận với phép nhân thông thường, chúng tôi sử dụng ký hiệu * cho phép nhân ma trận mà chỉ đơn giản ký hiệu phép nhân ma trận giữa ma trận \\(\\) và ma trận \\(B\\) là \\(AB\\). Công thức dưới đây mô tả phép nhân ma trận giữa một ma trận có 2 hàng và 3 cột với một ma trận có 3 hàng và 4 cột để được một ma trận có kích thước là 2 hàng và 4 cột\\[\\begin{align}\n& AB = M \\\\\n\n& \\begin{bmatrix}\na_{11} & a_{12} & a_{13}\\\\\na_{21} & a_{22} & a_{23}\n\\end{bmatrix}\n\n\\% * \\%\n\n\\begin{bmatrix}\nb_{11} & b_{12} & b_{13} & b_{14} \\\\\nb_{21} & b_{22} & b_{23} & b_{24} \\\\\nb_{31} & b_{32} & b_{33} & b_{34}\n\\end{bmatrix}\n\n=\n\n\\begin{bmatrix}\nm_{11} & m_{12} & m_{13} & m_{14} \\\\\nm_{21} & m_{22} & m_{23} & m_{24} \\\\\n\\end{bmatrix} \\\\\n\n& m_{ij} = <[,],B[,j]>\n\\tag{4.2}\n\\end{align}\\]trong đó \\([,]\\) là véc-tơ hàng \\(\\) của ma trận \\(\\) và \\(B[,j]\\) là véc-tơ cột \\(j\\) của ma trận \\(B\\).Toán tử dùng để thực hiện phép nhân ma trận trong R là %*%. Bạn đọc có thể thực hiện phép nhân hai ma trận và B như sauChúng ta có thể kiểm tra giá trị của phần tử ở hàng thứ 2 và cột thứ 3 của ma trận kết quả (số 100) chính là tích vô hướng giữa véc-tơ hàng thứ hai của ma trận và véc-tơ cột thứ ba của ma trận B.\\[\\begin{align}\n<(2,4,6),(7,8,9)> = 2 \\times 7 + 4 \\times 8 + 6 \\times 9 = 100\n\\end{align}\\]Bạn đọc cần phân biệt giữa phép nhân ma trận (ký hiệu %*%) và phép nhân thông thường (ký hiệu *) như đã trình bày ở trên. Để tránh gây nhầm lẫn, chúng tôi luôn sử dụng cụm từ nhân ma trận cho phép nhân %*%.","code":"\nA<-matrix(1:6, nrow = 2, ncol = 3) # ma trận kích thước 2 * 3\nprint(A)##      [,1] [,2] [,3]\n## [1,]    1    3    5\n## [2,]    2    4    6\nB<-matrix(1:12, nrow = 3, ncol = 4) # ma trận kích thước 3 * 4\nprint(B)##      [,1] [,2] [,3] [,4]\n## [1,]    1    4    7   10\n## [2,]    2    5    8   11\n## [3,]    3    6    9   12\nM <- A %*% B # kết quả là ma trận M có kich thước 2 * 4\nprint(M)##      [,1] [,2] [,3] [,4]\n## [1,]   22   49   76  103\n## [2,]   28   64  100  136"},{"path":"kiến-thức-r-nâng-cao.html","id":"ma-trận-đường-chéo-và-ma-trận-đơn-vị","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.1.5 Ma trận đường chéo và ma trận đơn vị","text":"Các khái niệm và phép toán trên ma trận được trình bày bắt đầu từ phần này sẽ chỉ áp dụng trên ma trận vuông, nghĩa là ma trận có số hàng bằng với số cột. Trong một ma trận vuông, các phần tử nằm trên đường chéo chính là các phần tử có chỉ số hàng bằng với chỉ số cột, các phần tử nằm trên đường chéo phụ là các phần tử có chỉ số hàng cộng với chỉ số cột bằng \\(n+1\\) trong đó \\(n\\) là số hàng (hay cột) của ma trận vuông. Với ma trận vuông M có kích thước \\(n \\times n\\) đường chéo chính của ma trận được ký hiệu là diag(M) xác định như sau\\[\\begin{align}\n& M\n=\n\\begin{bmatrix}\nm_{11} & m_{12} & m_{13} & m_{14} \\\\\nm_{21} & m_{22} & m_{23} & m_{24} \\\\\nm_{31} & m_{32} & m_{33} & m_{34}\\\\\nm_{41} & m_{42} & m_{43} & m_{44}\n\\end{bmatrix} \\\\\n& \\\\\n& diag(M) = (m_{11}, m_{22}, m_{33},  m_{44})\n\\tag{4.3}\n\\end{align}\\]Ma trận có tất cả các phần tử nằm ngoài đường chéo chính bằng 0 được gọi là ma trận đường chéo. Hàm diag() trong R được sử dụng để lấy ra véc-tơ đường chéo chính của một ma trận vuông, hoặc để tạo ra một ma trận đường chéo, hoặc cũng có thể dùng để khai báo một ma trận đường chéo:Ma trận đơn vị kích thước \\(n \\times n\\), thường được ký hiệu \\(I_n\\), là một ma trận đường chéo mà tất cả các phần tử trên đường chéo chính bằng 1. Ma trận đơn vị \\(I_n\\) có tính chất quan trọng là mọi ma trận M kích thước \\(k \\times n\\) khi thực hiện phép nhân ma trận với ma trận \\(I_n\\) sẽ có kết quả đúng bằng ma trận M. Bạn đọc có thể quan sát ví dụ sau:","code":"\nM<-matrix(1:9, nrow = 3, ncol = 3)\ndiag(M) # Lấy ra véc-tơ đường chéo chính của M## [1] 1 5 9\n# Tạo ra ma trận đường chéo có đường chéo chính là (1,10,100)\nM1<-diag(c(1,10,100))\nprint(M1)##      [,1] [,2] [,3]\n## [1,]    1    0    0\n## [2,]    0   10    0\n## [3,]    0    0  100\nIn<-diag(rep(1,4)) # ma trận đơn vị kích thước 4*4\nprint(In)##      [,1] [,2] [,3] [,4]\n## [1,]    1    0    0    0\n## [2,]    0    1    0    0\n## [3,]    0    0    1    0\n## [4,]    0    0    0    1\nM<-matrix(1:20, nrow = 5, ncol = 4) # ma trận vuông 5 * 4\nprint(M %*% In) # kết quả vẫn là ma trận M##      [,1] [,2] [,3] [,4]\n## [1,]    1    6   11   16\n## [2,]    2    7   12   17\n## [3,]    3    8   13   18\n## [4,]    4    9   14   19\n## [5,]    5   10   15   20"},{"path":"kiến-thức-r-nâng-cao.html","id":"định-thức-của-ma-trận","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.1.6 Định thức của ma trận","text":"Định thức của ma trận là một khái niệm toán học phức tạp. Phần lớn bạn đọc khi làm quen với khái niệm định thức trong môn học đại số tuyến tính sẽ được giới thiệu về công thức tính định thức của một ma trận, hoặc sử dụng định thức của ma trận để thực hiện tính toán như giải hệ phương trình thay vì thực sự hiểu khái niệm định thức được bắt đầu từ đâu. Định thức là một giá trị số thực đặc trưng của một ma trận vuông. Định thức cho biết nhiều tính chất quan trọng của ma trận đó, đồng thời định thức xuất hiện trong rất nhiều tính toán liên quan đến ma trận.Hãy bắt đầu với một ma trận vuông \\(M\\) kích thước \\(2 \\times 2\\) như sau:\n\\[\\begin{align}\nM\n=\n\\begin{bmatrix}\nm_{11} & m_{12}\\\\\nm_{21} & m_{22}\n\\end{bmatrix}\n\\end{align}\\]Định thức của ma trận \\(M\\) được ký hiệu là \\(|M|\\) hoặc \\(det(M)\\) được xác định bởi công thức\n\\[\\begin{align}\ndet(M) = m_{11} \\times m_{22} - m_{12} \\times m_{21}\n\\tag{4.4}\n\\end{align}\\]Định thức của ma trận M có thể biểu diễn dưới dạng diện tích của hình bình hành tạo thành từ 4 điểm có tọa độ \\((0,0)\\), \\((m_{11},m_{12})\\), \\((m_{21},m_{22})\\), và \\((m_{11}+m_{21}, m_{12}+m_{22})\\). Thật vậy, giả sử hai ma trận \\(M\\) và \\(M_1\\) có kích thước \\(2 \\times 2\\); ma trận \\(M_1\\) nhận được bằng cách đổi vị trí 2 dòng của ma trận \\(M\\),\\[\\begin{align}\n& M\n=\n\\begin{bmatrix}\n2 & 1 \\\\\n1 & 3\n\\end{bmatrix}  \\text{  và  } M_1\n=\n\\begin{bmatrix}\n1 & 3 \\\\\n2 & 1\n\\end{bmatrix} \\\\\n& \\\\\n\n& det(M) = 5  \\text{  và  } det(M_1) = -5\n\n\\end{align}\\]Hiểu một cách đơn giản, chúng ta có thể coi định thức của \\(M\\) và \\(M_1\\) qua diện tích của các hình bình hành tạo bởi hai véc-tơ (2,1) và véc-tơ (1,3) giống như hình ??. Sự khác nhau của hai định thức chỉ ở thứ tự véc-tơ: đối với định thức của \\(M\\) thì véc-tơ \\((2,1)\\) được đặt trước trong khi đối với định thức của \\(M_1\\) thì véc-tơ \\((1,3)\\) được tính đến trước.\n(#fig:fgadvr01 )Định thức của ma trận kích thước 2 * 2 có thể được biểu diễn dưới dạng diện tích. Hình bên trái: Định thức là số dương vì véc-tơ hàng thứ nhất (2,1) nằm phía bên phải véc-tơ hàng thứ hai (1,3). Hình bên phải: Định thức là số âm vì véc-tơ hàng thứ nhất (1,3) nằm phía bên trái véc-tơ hàng thứ hai (2,1)\nGiá trị của định thức sẽ cho ta biết thông tin về các véc-tơ tạo nên ma trận:Định thức bằng 0 chỉ xảy ra khi hai véc-tơ (hai mũi tên màu xanh và màu cam xuất phát từ điểm \\((0,0)\\)) trùng nhau hoặc đối đỉnh nhau. Điều này chỉ xảy ra khi véc-tơ thứ nhất bằng véc-tơ thứ hai nhân với một số. Trong trường hợp tổng quát với ma trận vuông kích thước \\(n \\times n\\), định thức bằng 0 khi một véc-tơ nào đó là tổ hợp tuyến tính của các véc-tơ còn lại.Định thức gần bằng 0 nghĩa là góc tạo bởi 2 véc-tơ rất gần 0 hoặc tạo với nhau một góc xấp xỉ 180 độ. Ma trận vuông kích thước \\(n \\times n\\) có định thức xấp xỉ bằng 0 nghĩa là mối liên hệ tuyến tính giữa các véc-tơ của ma trận là rất chặt chẽ.Dấu của định thức cho ta biết vị trí của các véc-tơ. Véc-tơ hàng thứ nhất tương ứng với màu xanh trong khi véc-tơ hàng thứ hai tương ứng với màu cam. Dấu của định thức dương chỉ khi véc-tơ màu xanh nằm phía trên (bên trái) véc-tơ màu cam, và dấu của định thức là âm chỉ khi véc-tơ màu xanh nằm phía dưới (bên phải) véc-tơ màu cam.Với các ma trận vuông kích thước \\(n \\times n\\); \\(n \\geq 3\\) định thức của ma trận được tính bằng cách lựa chọn một dòng (hoặc cột) thứ \\(\\) bất kỳ và sau đó thực hiện phép khai triển\n\\[\\begin{align}\ndet(M) = \\sum\\limits_{j = 1}^n (-1)^{+j} \\times m_{ij} \\times det(M_{-,-j})\n\\tag{4.5}\n\\end{align}\\]\ntrong đó \\(M_{\\{-,-j\\}}\\) mà ma trận vuông kích thước \\((n-1) \\times (n-1)\\) nhận được sau khi bỏ đi hàng thứ \\(\\) và cột thứ \\(j\\) của ma trận \\(M\\).Định thức của ma trận \\(M\\) kích thước \\(3 \\times 3\\) có thể tính toán dựa trên định thức của các ma trận con và lựa chọn hàng \\(=2\\) như sau\\[\\begin{align}\n& M\n=\n\\begin{bmatrix}\nm_{11} & m_{12} & m_{13}  \\\\\nm_{21} & m_{22} & m_{23} \\\\\nm_{31} & m_{32} & m_{33}\n\\end{bmatrix} \\\\\n& \\\\\n& det(M) = - m_{21} \\times \\begin{vmatrix}\nm_{12} & m_{13}  \\\\\nm_{32} & m_{33}\n\\end{vmatrix} + m_{22} \\times \\begin{vmatrix}\nm_{11} & m_{13}  \\\\\nm_{31} & m_{33}\n\\end{vmatrix} - m_{23} \\times \\begin{vmatrix}\nm_{11} & m_{12}  \\\\\nm_{31} & m_{32}\n\\end{vmatrix}\n\\tag{4.6}\n\\end{align}\\]Hàm det() trong R được sử dụng để tính định thức của ma trận.Một vài tính chất quan trọng của định thức:Định thức của một ma trận đường chéo bằng tích các phần tử nằm trên đường chéo chính của ma trận đó. Ma trận đường chéo là một trường hợp đặc biệt của ma trận tam giác. Ma trận tam giác trên là ma trận có tất cả các phần tử nằm phía dưới đường chéo chính nhận giá trị bằng 0. Tương tự, ma trận tam giác dưới là ma trận có tất cả các phần tử nằm phía trên đường chéo chính nhận giá trị bằng 0. Các ma trận tam giác có tính chất như đã phát biểu ở trên: định thức của các ma trận này bằng tích các phần tử nằm trên đường chéo chính.Định thức của ma trận chuyển vị của một ma trận bằng định thức của ma trận đó. Bạn đọc có thể kiểm tra bằng câu lệnh trên R như sau\n\\[\\begin{align}\ndet(M) = det(M^T)\n\\end{align}\\]Định thức của tích hai ma trận bằng tích của các định thức. Lưu ý rằng phép nhân hai ma trận vuông chỉ có ý nghĩa khi đây là hai ma trận vuông có cùng kích thước:\n\\[\\begin{align}\ndet(\\% * \\% B) = det() \\times det(B)\n\\end{align}\\]","code":"\nM<-matrix(c(2,1,1,3),nrow = 2,ncol = 2,byrow = TRUE)\ndet(M)## [1] 5\nM<-matrix(1:16,nrow = 4,ncol = 4)\nM[lower.tri(M)]<-0 # cho các phần tử phía dưới đường chéo chính bằng 0\nprint(M) # ma trận M là ma trận tam giác trên##      [,1] [,2] [,3] [,4]\n## [1,]    1    5    9   13\n## [2,]    0    6   10   14\n## [3,]    0    0   11   15\n## [4,]    0    0    0   16\nprint(c(det(M), prod(diag(M)))) # định thức của M bằng tích các số trên đường chéo chính## [1] 1056 1056\nM<-matrix(rnorm(16),nrow = 4,ncol = 4)\nprint(c(det(M),det(t(M))))## [1] 6.084931 6.084931\nM<-matrix(rnorm(16),nrow = 4,ncol = 4)\nM1<-matrix(rnorm(16),nrow = 4,ncol = 4)\nprint(c(det(M%*%M1),det(M)*det(M1)))## [1] 0.08111256 0.08111256"},{"path":"kiến-thức-r-nâng-cao.html","id":"ma-trận-nghịch-đảo","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.1.7 Ma trận nghịch đảo","text":"Ma trận nghịch đảo của một ma trận vuông \\(M\\), thường được ký hiệu \\(M^{-1}\\), là ma trận vuông có cùng kích thước với ma trận \\(M\\) và thỏa mãn tính chất: phép nhân ma trận giữa ma trận \\(M\\) với ma trận nghịch đảo \\(M^{-1}\\) sẽ cho kết quả là một ma trận đơn vị. Không phải ma trận vuông nào cũng có ma trận nghịch đảo; chỉ có các ma trận có định thức khác 0 là có ma trận nghịch đảo. Các ma trận có ma trận nghịch đảo được còn được gọi là các ma trận khả nghịch. Các ma trận khả nghịch luôn có một ma trận nghịch đảo duy nhất.\\[\\begin{align}\nM \\ \\% * \\% \\ M^{-1} = I_n\n\\tag{4.7}\n\\end{align}\\]Hai lần lấy nghịch đảo liên tiếp với một ma trận khả nghịch sẽ quay trở lại ma trận ban đầu, hay nói một cách khác ma trận nghịch đảo của ma trận \\(M^{-1}\\) chính là ma trận \\(M\\)\n\\[\\begin{align}\nM^{-1} \\ \\% * \\% \\ M = I_n\n\\end{align}\\]Phương pháp chung để tính toán ma trận nghịch đảo là dựa trên các ma trận liên hợp (adjugate matrix). Ma trận liên hợp của ma trận \\(M\\) được ký hiệu là \\(adj(M)\\) là ma trận vuông kích thước \\(n \\times n\\) mà phần tử ở hàng thứ \\(\\), cột thứ \\(j\\) được tính bằng\n\\[\\begin{align}\nadj(M)_{ij} = (-1)^{j+} det(M_{\\{-j,-\\}})\n\\tag{4.8}\n\\end{align}\\]Khi tính toán định thức của ma trận \\(M\\), chúng tôi đã sử dụng ký hiệu \\(M_{\\{-j,-\\}}\\) cho ma trận vuông kích thước \\((n-1) \\times (n-1)\\) nhận được sau khi bỏ đi hàng thứ \\(j\\) và cột thứ \\(\\) của ma trận \\(M\\). Bạn đọc lưu ý rằng có sự thay đổi vị trí của \\(\\) và \\(j\\) trong vế phải của phương trình (4.8). Ma trận nghịch đảo \\(M^{-1}\\) được tính từ ma trận liên hợp như sau\n\\[\\begin{align}\nM^{-1} = \\cfrac{1}{det(M)} adj(M)_{ij}\n\\tag{4.9}\n\\end{align}\\]Nhìn chung, để tính toán ma trận nghịch đảo của một ma trận kích thước \\(n \\times n\\), chúng ta sẽ phải tính toán định thức của ma trận ban đầu và định thức của \\(n^2\\) ma trận vuông có kích thước \\((n-1) \\times (n-1)\\). Với các ma trận vuông có kích thước lớn, việc tính toán sử dụng công thức như trên sẽ tốn nhiều thời gian và bộ nhớ. Có nhiều thuật toán để tính xấp xỉ ma trận nghịch đảo của một ma trận. Nội dung của các thuật toán này vượt quá phạm vi của cuốn sách. Bạn đọc có thể sử dụng hàm solve() có sẵn trong để tính toán ma trận nghịch đảo như sauCác tính toán liên quan đến định thức cần nhớĐịnh thức của ma trận sau khi nhân tất cả các phần tử với một số\n\\[\\begin{align}\ndet(\\lambda M) = \\lambda^n \\times det(M)\n\\tag{4.10}\n\\end{align}\\]Định thức của ma trận sau khi nhân tất cả các phần tử với một số\n\\[\\begin{align}\ndet(\\lambda M) = \\lambda^n \\times det(M)\n\\tag{4.10}\n\\end{align}\\]Định thức của ma trận chuyển vị \\(M^{-T}\\) bằng định thức của ma trận \\(M\\)\n\\[\\begin{align}\ndet(M^T) = det(M)\n\\tag{4.11}\n\\end{align}\\]Định thức của ma trận chuyển vị \\(M^{-T}\\) bằng định thức của ma trận \\(M\\)\n\\[\\begin{align}\ndet(M^T) = det(M)\n\\tag{4.11}\n\\end{align}\\]Tích của định thức của ma trận \\(M^{-1}\\) với định thức của ma trận \\(M\\) bằng 1.\n\\[\\begin{align}\ndet(M^{-1}) \\times det(M) = det(I_n) = 1\n\\tag{4.12}\n\\end{align}\\]Tích của định thức của ma trận \\(M^{-1}\\) với định thức của ma trận \\(M\\) bằng 1.\n\\[\\begin{align}\ndet(M^{-1}) \\times det(M) = det(I_n) = 1\n\\tag{4.12}\n\\end{align}\\]","code":"\nset.seed(10)\n\n# Tạo ma trận gồm toàn các số ngẫu nhiên\nM<-matrix(rnorm(16),nrow = 4,ncol = 4)\nM1<-solve(M) # Ma trận M1 là ma trận nghịch đảo của ma trận M\n\n# Kiểm tra:\nM1 %*% M # Tích của M1 với M là ma trận đơn vị##               [,1]         [,2]          [,3]          [,4]\n## [1,]  1.000000e+00 1.371264e-16 -2.640509e-16 -2.563393e-16\n## [2,]  2.593928e-18 1.000000e+00  4.325543e-17  2.018082e-16\n## [3,] -1.526477e-17 2.711603e-17  1.000000e+00  3.759516e-17\n## [4,]  2.101255e-16 1.072900e-16 -6.432270e-17  1.000000e+00\nM %*% M1 # Tích của M với M1 là ma trận đơn vị##               [,1]          [,2]         [,3]          [,4]\n## [1,]  1.000000e+00 -2.732291e-17 2.528256e-17 -1.023377e-16\n## [2,] -8.333103e-17  1.000000e+00 6.305725e-17 -3.129494e-16\n## [3,] -4.952797e-17 -5.792706e-18 1.000000e+00  1.667626e-17\n## [4,]  3.116926e-18  1.904906e-17 8.713393e-17  1.000000e+00"},{"path":"kiến-thức-r-nâng-cao.html","id":"mảng-nhiều-chiều","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.2 Mảng nhiều chiều","text":"Ma trận lưu phần tử trong hai chiều mà chúng ta gọi là hàng và cột. Đa số dữ liệu kiểu bảng biểu truyền thống đều có thể biểu diễn dưới dạng ma trận. Tuy nhiên có những kiểu dữ liệu mà khi biểu diễn dưới dạng ma trận hai chiều là không dễ dàng và có thể gây nhầm lẫn cho người sử dụng. Có thể kể đến dữ liệu kiểu hình ảnh. Khi bạn đọc lưu một bức ảnh màu lên trên máy tính điện tử, bức ảnh sẽ được số hóa thành một mảng ba chiều, bao gồm có chiều cao, chiều rộng của ảnh và một chiều thứ ba là màu sắc của điểm ảnh. Phức tạp hơn nữa nếu dữ liệu là một đoạn phim, hay một hình động, bạn đọc sẽ cần phải sử dụng thêm chiều thứ tư để mô tả thời gian xuất hiện của mỗi hình ảnh trong đoạn phim.Thông thường thì người làm việc với dữ liệu sẽ đổi các mảng nhiều chiều về mảng hai chiều hoặc một chiều (véc-tơ) để dễ dàng xử lý. Tuy nhiên, bạn đọc cũng cần nằm được các thao tác cơ bản khi làm việc với mảng nhiều chiều để xử lý được các dữ liệu như đề cập ở trên.","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"khởi-tạo-mảng-nhiều-chiều","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.2.1 Khởi tạo mảng nhiều chiều","text":"Để tạo mảng nhiều chiều bạn đọc sử dụng hàm array().Bạn đọc có thể thấy R hiển thị mảng ba chiều Ar kích thước \\(2 \\times 3 \\times 4\\) như là sự kết hợp của 4 ma trận kích thước \\(2 \\times 3\\). Tương tự như khi khởi tạo giá trị cho ma trận, số lượng phần tử đưa vào trong mảng phải bằng với số phần tử của mảng, trong trường hợp mảng Ar ở trên là véc-tơ có độ dài 24 tương ứng với \\(2 \\times 3 \\times 4 = 24\\) phần tử của mảng.Để lấy ra các phần tử con (một biến, một ma trận, hay 1 mảng nhiều chiều) từ một nhiều mảng, bạn đọc sử dụng dấu ngoặc vuông [] giống như khi làm với ma trận. Lưu ý rằng khi lấy phần tử con từ một mảng, bạn đọc cần phải sử dụng chỉ số cho tất cả các chiều.Thứ tự các phần tử khi điền vào mảng khi sử dụng hàm trong hàm array() sẽ là ưu tiên ma trận kích thước \\(2 \\times 3\\) tương ứng với chỉ số [,,1] trước, rồi đến ma trận kích thước \\(2 \\times 3\\) tương ứng với chỉ số [,,2], …, và tiếp tục như thế cho đến khi tất cả các phần tử của mảng được gán giá trị.","code":"\nAr<-array(1:24,dim=c(2,3,4)) # mảng 3 chiều\nAr # hiển thị mảng 3 chiều Ar## , , 1\n## \n##      [,1] [,2] [,3]\n## [1,]    1    3    5\n## [2,]    2    4    6\n## \n## , , 2\n## \n##      [,1] [,2] [,3]\n## [1,]    7    9   11\n## [2,]    8   10   12\n## \n## , , 3\n## \n##      [,1] [,2] [,3]\n## [1,]   13   15   17\n## [2,]   14   16   18\n## \n## , , 4\n## \n##      [,1] [,2] [,3]\n## [1,]   19   21   23\n## [2,]   20   22   24\nAr[1,2,1] # phần tử có các chỉ số 1 - 2 - 1## [1] 3\nAr[,,1] # ma trận 2 * 3##      [,1] [,2] [,3]\n## [1,]    1    3    5\n## [2,]    2    4    6\nAr[,c(1,3),c(1,4)] # mảng trận 2 * 2 * 2## , , 1\n## \n##      [,1] [,2]\n## [1,]    1    5\n## [2,]    2    6\n## \n## , , 2\n## \n##      [,1] [,2]\n## [1,]   19   23\n## [2,]   20   24"},{"path":"kiến-thức-r-nâng-cao.html","id":"sử-dụng-mảng-nhiều-chiều-để-biến-đổi-dữ-liệu-kiểu-hình-ảnh","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.2.2 Sử dụng mảng nhiều chiều để biến đổi dữ liệu kiểu hình ảnh","text":"Để bạn đọc có cái nhìn trực quan hơn về mảng nhiều chiều, chúng ta sẽ thực hiện các phép biến đổi, tính toán trên một dữ liệu cụ thể. Như chúng tôi đã nói ở trên, mảng nhiều chiều là một đối tượng thích hợp dùng để lưu dữ liệu kiểu hình ảnh. Thư viện imager có thể được cài đặt bổ sung vào R có các hàm thích hợp để làm việc với dữ liệu kiểu hình ảnh. Chúng ta sẽ sử dụng một mảng nhiều chiều để lưu một bức ảnh và thực hiện các phép biến đổi bức ảnh đó sử dụng tính toán trên mảng nhiều chiều.Hàm load.image() trong thư viện imager có thể đọc các file hình ảnh có định dạng .png, .jpeg, hoặc .bmp. Bạn đọc có thể đọc một hình ảnh có một trong các định dạng kể trênĐể biết img được đọc bằng hàm load.image() là kiểu đối tượng nào, bạn đọc dùng hàm class()R cho biết đây là một đối tượng kiểu cimg. Kiểu đối tượng này về bản chất là một mảng bốn chiều. Chiều thứ nhất là cho biết chiều rộng của bức ảnh, chiều thứ hai cho biết chiều cao của bức ảnh, chiều thứ ba là chiều thời gian nên luôn bằng 1 đối với dữ liệu kiểu ảnh, và chiều thứ tư bằng 3 nếu bức ảnh là ảnh màu.Đối tượng kiểu cimg cho phép bạn đọc thực hiện các biến đổi, tính toán giống như trên một mảng nhiều chiều mà không cần phải chuyển đổi sang kiểu mảng. Chẳng hạn như để biết bức ảnh được lưu bởi đối tượng tên img có bao nhiêu chiều, chúng ta sử dụng hàm dim() giống như với mảngBức ảnh được lưu bởi đối tượng img ở trên là một bức ảnh màu có chiều rộng 535 và chiều cao 595. Chiều thứ ba bằng 1 nghĩa là đây là một bức ảnh (chiều thứ ba lớn hơn 1 khi đối tượng là hình ảnh động hoặc video). Chiều thứ tư bằng 3 đại diện cho 3 sắc màu: màu đỏ (Red), màu xanh lá cây (Green), và màu xanh da trời (Blue). Bạn đọc có thể hình dung một bức ảnh màu ở trên như là sự kết hợp của ba ma trận cùng kích thước 535 \\(\\times\\) 595, ma trận thứ nhất đại diện cho màu đỏ, ma trận thứ hai đại diện cho màu xanh lá cây và ma trận thứ ba đại diện cho màu xanh da trời. Mỗi giá trị trong ma trận là một số trong khoảng từ 0 đến 1. Giá trị 0 tương ứng với màu đen và giá trị càng gần 1 thì màu sắc của điểm đó càng gần màu mà ma trận đại diện. Để quan sát ma trận tương ứng với mỗi màu, bạn đọc cần gán giá trị của 2 ma trận còn lại bằng 0 trước khi hiển thị.Hàm .cimg() được dùng để đổi một mảng bốn chiều sang kiểu cimg để có thể hiển thị khi sử dụng hàm plot(). Lưu ý rằng hãy luôn sử dụng chiều thứ ba bằng 1 và chiều thứ tư bằng 3 nếu bạn muốn tạo ảnh màu. Các câu lệnh dưới đây tạo ra các bức ảnh mà các giá trị trong các ma trận màu sắc hoàn toàn là các giá trị ngẫu nhiên phân phối đều (uniform) trong khoảng (0,1).Tham số interpolate nhận giá trị bằng FALSE có nghĩa là các điểm ảnh giữ nguyên giá trị. Tham số này có giá trị là mặc định là TRUE. Khi interpolate nhận giá trị bằng mặc định, hình ảnh hiển thị sẽ có sự giao thoa về màu sắc tại viền các điểm ảnh và làm cho ảnh nhìn mượt mà hơn.Về bản chất, xử lý ảnh trên máy tính điện tử chính là xử lý các con số nằm trong mảng nhiều chiều. Chúng tôi sẽ giới thiệu một vài kỹ thuật xử lý đơn giản trên ảnh để bạn đọc có thể hiểu hơn về xử lý mảng nhiều chiều.Trước hết là thao tác cắt ảnh. Cắt ảnh chính là một phép lấy mảng con từ một mảng ban đầu. Thật vậy, trong ví dụ dưới đây chúng tôi cắt bức ảnh được lưu trong đối tượng tên là img thành hai nửa, bức ảnh được chia theo chiều rộng:Tiếp theo, chúng ta sẽ thực hiện tăng hoặc giảm độ sáng của ảnh. Tăng hoặc giảm độ sáng của ảnh tương đương với việc điều chỉnh đồng thời các số trong mảng nhiều chiều gần hơn đến giá trị 1 hoặc gần hơn đến giá trị 0 theo cùng một tỷ lệ. Chúng ta thực hiện như sauMột kỹ thuật xử lý ảnh khác là giảm kích thước của ảnh. Giả sử bạn đọc muốn giảm kích thước ảnh mỗi chiều 50%. Để làm được việc này, mỗi ma trận kích thước \\(n \\times m\\) sẽ được đổi thành ma trận kích thước \\([n/2] \\times [m/2]\\) trong đó \\([n/2]\\) là phần nguyên của số \\(n/2\\). Nguyên tắc chuyển từ ma trận ban đầu sang ma trận có kích thước nhỏ hơn là mỗi ô \\(2 \\times 2\\) của ma trận ban đầu được chuyển thành 1 số (ô) trong ma trận mới. Giá trị mới này thường là giá trị trung bình, hoặc max, min của 4 phần tử của ma trận ban \\(2 \\times 2\\)Bạn đọc có thể thấy rằng giảm kích thước của ảnh cũng là giảm kích thước của các mảng nhiều chiều. Khi kích thước ảnh giảm, khả năng hiển thị của ảnh cũng bị ảnh hưởng. Chúng ta sẽ quay trở lại với dữ liệu kiểu hình ảnh khi thảo luận về Mô hình mạng nơ-ron tích chập.","code":"\n#install.packages(\"imager\")\nlibrary(imager)\nsetwd(\"../KHDL_KTKD Final/Image\")\nimg<-load.image(\"cat.jpg\") # đọc hình ảnh tên \"cat\" vào\nplot(img)\nclass(img)## [1] \"cimg\"         \"imager_array\" \"numeric\"\ndim(img) # mảng bốn chiều: chiều rộng * chiều cao * chiều thời gian * chiều màu sắc## [1] 535 595   1   3\nimg_red<-img\nimg_red[,,1,2:3]<-0 # cho 2 ma trận màu xanh lá và xanh dương bằng 0\n\nimg_green<-img\nimg_green[,,1,c(1,3)]<-0 # cho 2 ma trận màu đỏ và xanh dương bằng 0\n\nimg_blue<-img\nimg_blue[,,1,1:2]<-0 # cho 2 ma trận màu xanh lá và đỏ bằng 0\n\npar(mfrow = c(1,3))\nplot(img_red, main = \"Chỉ còn lại màu đỏ\")\nplot(img_green, main = \"Chỉ còn lại màu xanh lá\")\nplot(img_blue, main = \"Chỉ còn lại màu xanh dương\")\nimg1<-array(runif(5*5*1*3),dim=c(5,5,1,3)) # bức ảnh màu kích thước 5*5\nimg1<-as.cimg(img1)\n\nimg2<-array(runif(1000*1000*1*3),dim=c(1000,1000,1,3)) # bức ảnh màu kích thước 1000*1000\nimg2<-as.cimg(img2)\n\npar(mfrow = c(1,2))\nplot(img1, interpolate = FALSE, main = \"Ảnh nhiễu 5 * 5\")\nplot(img2, interpolate = FALSE, main = \"Ảnh nhiễu 1000 * 1000\")\nn<-dim(img)[1] # Chiều rộng của ảnh\nk<-round(n/2) # Điểm giữa để chia ảnh làm hai nửa\nimg1<-img[1:k,,,] # img1 là nửa bên trái của ảnh\nimg2<-img[(k+1):n,,,] # img2 là nửa bên phải của ảnh\npar(mfrow = c(1,2))\nplot(as.cimg(img1), main = \"Nửa bên trái\")\nplot(as.cimg(img2), main = \"Nửa bên phải\")\nimg1<-img + (1 - img) * 0.3 # img1 là bức ảnh sau khi tăng độ sáng lên 30%\nimg2<-img - img * 0.5 # img2 là bức ảnh sau khi giảm độ sáng đi 50%\npar(mfrow = c(1,3))\nplot(img, rescale = FALSE, main= \"Ảnh ban đầu\")\nplot(as.cimg(img1), rescale = FALSE, main = \"Tăng độ sáng\")\nplot(as.cimg(img2),rescale = FALSE, main = \"Giảm độ sáng\")\ngiamchieu<-function(M,k){\n  n<-dim(M)[1]; m<-dim(M)[2]\n  n1<-round(n/k)-1; m1<-round(m/k)-1\n  M1<-matrix(0,n1,m1)\n  for (i in 1:n1){\n    for (j in 1:m1){\n      i1<-(k*(i-1)+1):(k*i)\n      j1<-(k*(j-1)+1):(k*j)\n      M1[i,j]<-mean(M[i1,j1],na.rm=TRUE)\n    }\n  }\n  return(M1)\n}\n\nn<-dim(img)[1]; m<-dim(img)[2]\nk1<-10; k2<-20\nn1<-round(n/k1)-1; m1<-round(m/k1)-1\nn2<-round(n/k2)-1; m2<-round(m/k2)-1\n\nimg1<-array(0,dim=c(n1,m1,1,3));\nimg2<-array(0,dim=c(n2,m2,1,3));\n\nfor (i in 1:3){\n  img1[,,1,i]<-giamchieu(img[,,1,i],k1)\n  img2[,,1,i]<-giamchieu(img[,,1,i],k2)\n}\n\npar(mfrow = c(1,3))\nplot(img, interpolate = FALSE, main= \"Ảnh ban đầu\")\nplot(as.cimg(img1), interpolate = FALSE, main = \"Giảm kích thước 1:10\")\nplot(as.cimg(img2), interpolate = FALSE, main = \"Giảm kích thước 1:20\")"},{"path":"kiến-thức-r-nâng-cao.html","id":"list-trong-r","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.3 List trong R","text":"Không giống như véc-tơ, ma trận, hay mảng nhiều chiều, list là một cấu trúc trong R mà có thể chứa nhiều kiểu đối tượng khác nhau bao gồm biến, véc-tơ, ma trận, và cả các list khác. Với những bạn đọc đã học qua Python, list cũng giống như một dictionary. Đối với các bạn đọc đã học qua ngôn ngữ lập trình C++, list tương tự như một struct. list đóng vai trò quan trọng trong R, đặc biệt là trong viết hàm số và lập trình hướng đối tượng.Trong phần này của cuốn sách, chúng ta sẽ tìm hiểu cách tạo ra list và ứng dụng cấu trúc của list để phục vụ công việc phân tích dữ liệu một cách hiệu quả nhất.","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"khởi-tạo-list-và-chỉ-số-của-list.","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.3.1 Khởi tạo list và chỉ số của list.","text":"Hàm số để tạo ra một list trong R là hàm list(). Giả sử chúng ta muốn tạo thành một đối tượng có tên Sv1 chứa các thông tin về một sinh viênTên của sinh viên: được lưu trong một biến kiểu chuỗi ký tự.\nTên của sinh viên: được lưu trong một biến kiểu chuỗi ký tự.Ngày sinh của sinh viên: được lưu trong một biến kiểu thời gian.\nNgày sinh của sinh viên: được lưu trong một biến kiểu thời gian.Giới tính của sinh viên: được lưu trong một biến kiểu logic, giá trị TRUE tương ứng với giới tính Nam, và FALSE tương ứng với giới tính nữ.\nGiới tính của sinh viên: được lưu trong một biến kiểu logic, giá trị TRUE tương ứng với giới tính Nam, và FALSE tương ứng với giới tính nữ.Bảng điểm của sinh viên: là một data.frame có 2 cột, 1 cột là tên môn học và một cột là điểm của môn học tương ứng.\nBảng điểm của sinh viên: là một data.frame có 2 cột, 1 cột là tên môn học và một cột là điểm của môn học tương ứng.Chúng ta sử dụng hàm list() để tạo ra một list có tên SV1 như sauBạn đọc có thể thấy SV1 có bốn đối tượng con có tên là Ten, Ngay_sinh, Gioi_tinh, và Bang_diem. Mỗi đối tượng con có một kiểu giá trị khác nhau, riêng đối tượng con Bang_diem là một dữ liệu hay còn được gọi là một data.frame.Để lấy ra một đối tượng con của list bạn đọc sử dụng ký hiệu $. Ví dụ bạn muốn hiển thị bảng điểm của sinh viên có thông tin được lưu trong SV1, hãy sử dụng câu lệnh sau:Để biết tên các đối tượng trong một list bạn đọc sử dụng hàm names():Một cách khác để lấy ra một đối tượng con của list là sử dụng chỉ số của đối tượng. bảng điểm nằm ở vị trí thứ 4 trong list nên bạn đọc sử dụng câu lệnh sauBạn đọc có thể thấy rằng để lấy ra phần tử con, chúng ta cần phải sử dụng hai lần dấu ngoặc vuông [[]]. Nếu chỉ sử dụng một dấu ngoặc vuông [], phần tử được lấy ra sẽ là một list có 1 phần tử và phần tử duy nhất đó là bảng điểm.Để thêm một đối tượng vào list, chúng ta có thể đặt tên trực tiếp cho đối tượng mới và gán giá trị cho đối tượng. Ví dụ như chúng ta muốn thêm thông tin về quê quán của sinh viên vào một đối tượng có tên là \\(que\\_quan\\)Để xóa đi một đối tượng khỏi list, chúng ta gán cho đối tượng đó giá trị bằng NULLNhư chúng ta đã thảo luận trong phần giới thiệu, list là một cấu trúc nhiều lớp, nghĩa là một list có thể chứa các đối tượng có kiểu list. Thật vậy, giả sử chúng ta có list có tên là SV2 chứa các thông tin tương ứng của một sinh viên khácChúng ta có thể tạo một list có tên là DS chứa thông tin của cả 2 sinh viênĐể xem bảng điểm của sinh viên thứ hai, chúng ta cần sử dụng 2 lần ký hiệu $:","code":"\nSV1<-list(Ten = \"Nguyễn Đức Nam\",\n          Ngay_sinh = as.Date(\"2000-06-20\"),\n          Gioi_tinh = TRUE,\n          Bang_diem = data.frame(Mon_hoc = c(\"Giải tích\", \"Đại số\", \"Xác suất\"),\n                                 Diem = c(6.5, 8.5, 7.0)))\nstr(SV1) # xem cấu trúc của list SV1## List of 4\n##  $ Ten      : chr \"Nguyễn Đức Nam\"\n##  $ Ngay_sinh: Date[1:1], format: \"2000-06-20\"\n##  $ Gioi_tinh: logi TRUE\n##  $ Bang_diem:'data.frame':   3 obs. of  2 variables:\n##   ..$ Mon_hoc: chr [1:3] \"Giải tích\" \"Đại số\" \"Xác suất\"\n##   ..$ Diem   : num [1:3] 6.5 8.5 7\nSV1$Bang_diem # Hiển thị bảng điểm##     Mon_hoc Diem\n## 1 Giải tích  6.5\n## 2    Đại số  8.5\n## 3  Xác suất  7.0\nnames(SV1)## [1] \"Ten\"       \"Ngay_sinh\" \"Gioi_tinh\" \"Bang_diem\"\nSV1[[4]] # Sử dụng 2 lần dấu ngoặc vuông##     Mon_hoc Diem\n## 1 Giải tích  6.5\n## 2    Đại số  8.5\n## 3  Xác suất  7.0\nSV1[4] # Là một list có 1 phần tử## $Bang_diem\n##     Mon_hoc Diem\n## 1 Giải tích  6.5\n## 2    Đại số  8.5\n## 3  Xác suất  7.0\nSV1$que_quan<-\"Hà Nội\" # Thêm vào một phần tử có tên que_quan là một biến\nstr(SV1) # list SV1 đã có thêm phần tử thứ năm## List of 5\n##  $ Ten      : chr \"Nguyễn Đức Nam\"\n##  $ Ngay_sinh: Date[1:1], format: \"2000-06-20\"\n##  $ Gioi_tinh: logi TRUE\n##  $ Bang_diem:'data.frame':   3 obs. of  2 variables:\n##   ..$ Mon_hoc: chr [1:3] \"Giải tích\" \"Đại số\" \"Xác suất\"\n##   ..$ Diem   : num [1:3] 6.5 8.5 7\n##  $ que_quan : chr \"Hà Nội\"\nSV1$que_quan<-NULL # xóa phần tử có tên que_quan khỏi SV1\nstr(SV1) # list SV1 chỉ còn 4 phần tử## List of 4\n##  $ Ten      : chr \"Nguyễn Đức Nam\"\n##  $ Ngay_sinh: Date[1:1], format: \"2000-06-20\"\n##  $ Gioi_tinh: logi TRUE\n##  $ Bang_diem:'data.frame':   3 obs. of  2 variables:\n##   ..$ Mon_hoc: chr [1:3] \"Giải tích\" \"Đại số\" \"Xác suất\"\n##   ..$ Diem   : num [1:3] 6.5 8.5 7\nSV2<-list(Ten = \"Nguyễn Thị Loan\",\n          Ngay_sinh = as.Date(\"2000-05-13\"),\n          Gioi_tinh = FALSE,\n          Bang_diem = data.frame(Mon_hoc = c(\"Xác suất\", \"Thống kê\", \"Học máy\",\"AI\"),\n                                 Diem = c(7.0, 9.5, 10.0, 9.0)),\n          Que_quan = \"Hà Nội\")\nDS<-list(SV1 = SV1,SV2 = SV2) # DS là một list có 2 phần tử, mỗi phần tử là 1 list\nstr(DS) # xem cấu trúc của list DS## List of 2\n##  $ SV1:List of 4\n##   ..$ Ten      : chr \"Nguyễn Đức Nam\"\n##   ..$ Ngay_sinh: Date[1:1], format: \"2000-06-20\"\n##   ..$ Gioi_tinh: logi TRUE\n##   ..$ Bang_diem:'data.frame':    3 obs. of  2 variables:\n##   .. ..$ Mon_hoc: chr [1:3] \"Giải tích\" \"Đại số\" \"Xác suất\"\n##   .. ..$ Diem   : num [1:3] 6.5 8.5 7\n##  $ SV2:List of 5\n##   ..$ Ten      : chr \"Nguyễn Thị Loan\"\n##   ..$ Ngay_sinh: Date[1:1], format: \"2000-05-13\"\n##   ..$ Gioi_tinh: logi FALSE\n##   ..$ Bang_diem:'data.frame':    4 obs. of  2 variables:\n##   .. ..$ Mon_hoc: chr [1:4] \"Xác suất\" \"Thống kê\" \"Học máy\" \"AI\"\n##   .. ..$ Diem   : num [1:4] 7 9.5 10 9\n##   ..$ Que_quan : chr \"Hà Nội\"\nDS$SV2$Bang_diem # Xem bảng điểm của sinh viên thứ hai##    Mon_hoc Diem\n## 1 Xác suất  7.0\n## 2 Thống kê  9.5\n## 3  Học máy 10.0\n## 4       AI  9.0"},{"path":"kiến-thức-r-nâng-cao.html","id":"sử-dụng-list-trong-viết-hàm-số","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.3.2 Sử dụng list trong viết hàm số","text":"Hầu như tất cả các hàm số được xây dựng sẵn trong R đều cho kết quả đầu ra dưới dạng list. Ví dụ, bạn đọc quan sát giá trị đầu ra của hàm có tên là uniroot() như sauHàm uniroot() được sử dụng để tìm nghiệm duy nhất của một hàm số trên một khoảng. Đoạn câu lệnh ở trên sử dụng hàm uniroot() để tìm nghiệm duy nhất của phương trình \\(x^2 - 1/4 = 0\\) trên khoảng \\((0,1)\\). Kết quả của hàm uniroot() là một list có 5 phần tử đều là các biến kiểu số với tên tương ứng là root, f.root, iter, init., và estim.prec. Các hàm số phức tạp hơn sẽ có kết quả đầu ra phức tạp hơn rất nhiều. Bạn đọc cần đọc kỹ hướng dẫn của các hàm để hiểu mỗi đối tượng con của kết quả đầu ra có ý nghĩa như thế nào.Bạn đọc cũng nên sử dụng đối tượng list để làm đầu ra cho các hàm số tự xây dựng. Chúng ta sẽ quay trở lại ví dụ về xây dựng hàm số PV() để tính giá trị hiện tại của một dòng tiền. Đối với một dòng tiền tương lai, ngoài giá trị hiện tại, bạn đọc có thể quan tâm đến các giá trị khác như Macaulay Duration, Modified Duration, Dollar Duration. Ý nghĩa và cách tính các giá trị này ở trong phần phụ lục @ref(#advrappen3).Chúng ta có thể sử dụng hàm summary_CF() để tính toán các đặc trưng của một trái phiếu với các thông số như sau:\nBảng 4.1: Bảng 4.2: Các thông số của một trái phiếu\nChúng ta tạo ra dòng tiền tương lai của trái phiếu với các thông số như trên và sau đó sử dụng hàm summary_CF()Chúng ta chuyển sang một ví dụ khác khi sử dụng list làm đầu ra cho một hàm số tự xây dựng. Khi bạn đọc tìm hiểu về giá trị của một véc-tơ kiểu số, chúng ta thường tính toán các giá trị đặc trưng như giá trị trung bình, giá trị lớn nhất, nhỏ nhất, các phân vị, và muốn xem phân phối các giá trị trong véc-tơ đó như thế nào. Chúng ta có thể tự viết một hàm số để thực hiện việc này với đầu ra là một list:Chúng ta có thể sử dụng hàm summary_vec() để tổng hợp thông tin về lợi suất tính theo ngày của chỉ số FTSE (chỉ số cổ phiếu của 100 công ty có giá trị vốn hóa thị trường lớn nhất niêm yết trên Sở giao dịch chứng khoán London) trong năm 1991 đến năm 1999. Chỉ số này được lưu trong dữ liệu EuStockMarkets có sẵn trong R.Một lợi thế khác của đối tượng kiểu list là có thể đẩy nhanh tốc độ tính toán khi dùng các hàm họ apply(). Chúng ta sẽ thảo luận vấn đề này trong phần tiếp theo của cuốn sách.","code":"\nf<-function(x) x^2 - 1/4\nresult<-uniroot(f,c(0,1))\nclass(result) # Đối tượng result có kiểu list## [1] \"list\"\nstr(result) # Xem cấu trúc của đối tượng result## List of 5\n##  $ root      : num 0.5\n##  $ f.root    : num -2.85e-05\n##  $ iter      : int 6\n##  $ init.it   : int NA\n##  $ estim.prec: num 6.1e-05\nsummaryCF<-function(i,CF){\n  n<-length(CF)\n  PV<-sum(CF/((1+i)^(1:n)))\n  Mac_D<-sum(CF*(1:n)/((1+i)^(1:n)))/PV\n  Mod_D<-Mac_D/(1+i)\n  Dollar_D<-PV*Mod_D*0.01\n  ket_qua<-list(PV = PV, Mac_D = Mac_D, Mod_D = Mod_D,\n               Dollar_D = Dollar_D)\n  return(ket_qua)\n}\n# Nhập liệu\nF<-10 # Mệnh giá trái phiếu, đơn vị tỷ đồng\nT<-12 # 12 năm cho đến ngày đáo hạn\nc<-9.25/100 # Lãi suất coupon\ni<-5/100 # Lãi suất dùng để chiết khấu\nCF<-c(rep(c*F,(T-2)),c*F+F) # Dòng tiền tương lai của trái phiếu\nsummaryCF(i,CF)## $PV\n## [1] 13.53023\n## \n## $Mac_D\n## [1] 7.884908\n## \n## $Mod_D\n## [1] 7.509436\n## \n## $Dollar_D\n## [1] 1.016044\nsummary_vec<-function(x){\n  do_dai<-length(x) # Độ dài của véc-tơ\n  ty_le_na<-paste(round(sum(is.na(x))/do_dai*100,2),\"%\")\n  # % giá trị không quan sát được\n  gioi_han<-c(min(x,na.rm=TRUE),max(x,na.rm=TRUE))\n  trung_binh<-mean(x,na.rm=TRUE)\n  do_lech_chuan<-sd(x,na.rm=TRUE)\n  phan_vi<-quantile(x,c(0.01,0.1,0.25,0.5,0.75,0.9,0.99),na.rm=TRUE)\n  do_thi<-ggplot(data=data.frame(x=x), aes(x=x))+\n    geom_histogram(color = \"#640514\",\n                   fill = \"white\",alpha = 0.3)+\n    xlab(\"\")+ylab(\"\")+theme_minimal()\n  result<-list(do_dai = do_dai, ty_le_na = ty_le_na, gioi_han = gioi_han,\n               trung_binh = trung_binh, do_lech_chuan = do_lech_chuan,\n               phan_vi = phan_vi, do_thi = do_thi)\n  return(result)\n}\nchi_so<-EuStockMarkets[,4] # lấy chỉ số FTSE ra từ cột thứ 4 của EuStockMarkets\nn<-length(chi_so) # độ dài của chuỗi chỉ số chứng khoán\nloi_suat<-log(chi_so[2:n]/chi_so[1:(n-1)]) # lợi suất của chỉ số\nsummary_vec(loi_suat)## $do_dai\n## [1] 1859\n## \n## $ty_le_na\n## [1] \"0 %\"\n## \n## $gioi_han\n## [1] -0.04139903  0.05439552\n## \n## $trung_binh\n## [1] 0.0004319851\n## \n## $do_lech_chuan\n## [1] 0.007957728\n## \n## $phan_vi\n##            1%           10%           25%           50%           75% \n## -2.060655e-02 -9.139666e-03 -4.318778e-03  8.021069e-05  5.253592e-03 \n##           90%           99% \n##  9.714781e-03  1.931723e-02 \n## \n## $do_thi"},{"path":"kiến-thức-r-nâng-cao.html","id":"các-hàm-họ-apply","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.4 Các hàm họ apply()","text":"Nhóm hàm apply() là nhóm hàm có sẵn trong R cho phép bạn đọc thực hiện lặp đi lặp lại một hàm số trên nhiều đối tượng. Về cơ bản nhóm hàm này hoạt động giống như một vòng lặp nhưng câu lệnh viết bằng nhóm hàm này sẽ chạy nhanh hơn và đơn giản hơn viết vòng lặp rất nhiểu.Các hàm mà chúng tôi sẽ giới thiệu đến bạn đọc trong phần này bao gồm apply(), lapply() và sapply(). Còn nhiều hàm khác thuộc nhóm hàm này như vapply(), tapply(), mapply(), …, nhưng về nguyên tắc hoạt động của các hàm này là tương tự và chỉ khác ở chỗ chúng áp dụng trên các loại đối tượng khác nhau nên bạn đọc có thể tự tìm hiểu mà không gặp khó khăn nào.","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"hàm-apply","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.4.1 Hàm apply()","text":"Cho một véc-tơ \\(x\\) kiểu số và một hàm \\(f\\), chẳng hạn như \\(f(x) = x^2\\). Khi bạn đọc viết f(x), R sẽ hiểu rằng bạn đang thực hiện hàm số \\(f\\) cho từng phần tử của véc-tơ \\(x\\) và sẽ trả lại giá trị là một véc-tơ mà từng phần tử tương ứng là bình phương của các phần tử trong \\(x\\). Việc thực hiện hàm \\(f\\) trên véc-tơ \\(x\\) diễn ra một cách đồng thời và hiệu quả hơn với việc viết một vòng lặp để tính hàm \\(f\\) trên từng phần tử của \\(x\\).Điều gì xảy ra khi x không phải là một véc-tơ đồng các phần tử con của x không phải là một biến, chẳng hạn nhưx là một ma trận và bạn muốn tính toán một hàm \\(f\\) trên các phần tử con của x là một véc-tơ hàng hoặc một véc-tơ cột.\nx là một ma trận và bạn muốn tính toán một hàm \\(f\\) trên các phần tử con của x là một véc-tơ hàng hoặc một véc-tơ cột.x là một dữ liệu và bạn muốn thực hiện một hàm \\(f\\) trên tất cả các cột dữ liệu.\nx là một dữ liệu và bạn muốn thực hiện một hàm \\(f\\) trên tất cả các cột dữ liệu.x là một list và bạn muốn thực hiện một hàm \\(f\\) trên tất cả các đối tượng con của x.\nx là một list và bạn muốn thực hiện một hàm \\(f\\) trên tất cả các đối tượng con của x.Các hàm thuộc họ apply() sẽ giúp bạn đọc thực hiện tác tính toán như vậy. Cách viết hàm apply() như sau:trong đó x là một ma trận, một mảng nhiều chiều, hoặc một dữ liệu; tham số MARGIN là một số, hoặc véc-tơ chỉ số cho biết hàm sẽ áp dụng trên chiều (hoặc các chiều) nào, và FUN là hàm số mà bạn muốn thực hiện. Ví dụ như bạn đọc muốn tính giá trị trung bình của mỗi cột của một ma trận M, hãy sử dụng câu lệnh như sauDo ma trận M có 5 cột nên giá trị trả lại là một véc-tơ kiểu số có độ dài bằng 5. Véc-tơ này chứa giá trị là trung bình của các cột thứ 1, 2, 3, 4, và 5 của ma trận M.Về nguyên tắc đối tượng sử dụng trong hàm apply() là ma trận hoặc mảng nhiều chiều. Bạn đọc cũng có thể sử dụng hàm apply() trên đối tượng là dữ liệu kiểu bảng. Khi đối tượng của hàm apply() có từ 3 chiều trở lên, giá trị của tham số MARGIN có thể là một số hoặc một véc-tơ. Thật vậy,Giá trị trả lại sẽ là một véc-tơ có độ dài là 2, phần tử thứ nhất là giá trị trung bình của các phần tử thuộc ma trận kích thước \\(5 \\times 2\\) thứ nhất, nghĩa là ma trận Ar[,,1], và phần tử thứ hai là giá trị trung bình của các phần tử thuộc ma trận kích thước \\(5 \\times 2\\) thứ hai (ma trận Ar[,,2]). Chúng ta có thể kiểm tra kết quả như sau:Chúng ta có thể áp dụng đồng thời hàm mean() theo chiều thứ 2 và chiều thứ 3 trên mảng \\(Ar\\) như sauKết quả thu được sẽ là một ma trận kích thước \\(2 \\times 2\\) mà các phần tử sẽ tương ứng với giá trị trung bình:Phần tử ở vị trí [1,1] của ma trận kết quả là giá trị trung bình của véc-tơ Ar[,1,1]Phần tử ở vị trí [1,1] của ma trận kết quả là giá trị trung bình của véc-tơ Ar[,1,1]Phần tử ở vị trí [1,2] của ma trận kết quả là giá trị trung bình của véc-tơ Ar[,1,2]Phần tử ở vị trí [1,2] của ma trận kết quả là giá trị trung bình của véc-tơ Ar[,1,2]Phần tử ở vị trí [2,1] của ma trận kết quả là giá trị trung bình của véc-tơ Ar[,2,1]Phần tử ở vị trí [2,1] của ma trận kết quả là giá trị trung bình của véc-tơ Ar[,2,1]Phần tử ở vị trí [2,2] của ma trận kết quả là giá trị trung bình của véc-tơ Ar[,2,2]Phần tử ở vị trí [2,2] của ma trận kết quả là giá trị trung bình của véc-tơ Ar[,2,2]Chúng ta có thể sánh giá trị trung bình của các véc-tơ với ma trận kết quả của hàm apply():Hàm số sử dụng với tham số FUN có thể là hàm số có sẵn trong R, hoặc trong các thư viện cài đặt bổ sung, hoặc cũng có thể là một hàm số mà bạn đọc tự xây dựng. Khi các câu lệnh của hàm số tự xây dựng ngắn gọn, bạn đọc có thể định nghĩa hàm số đó bên trong hàm apply(). Giá trị đầu ra của hàm số được tự định nghĩa cũng có thể là một véc-tơ, thậm chí là một ma trận hay là một mảng nhiều chiều, thậm chí là một list. Nếu kết quả đầu ra của hàm sử dụng trong apply() là một ma trận hoặc mảng nhiều chiều, R sẽ chuyển ma trận hoặc mảng nhiều chiều về dạng véc-tơ. Trong trường hợp đầu ra của hàm tự định nghĩa là một list, giá trị đầu ra sẽ là một ma trận hoặc mảng nhiều chiều mà mỗi phần tử con là một list. Dưới đây là một ví dụ mà giá trị đầu ra là một véc-tơ ba chiều.Kết quả nhận được sẽ là một ma trận kích thước \\(3 \\times 5\\). Cột thứ nhất của ma trận kết quả nhận giá trị (1, 10.5, 20) tương ứng với các giá trị min, mean, và max của véc-tơ M[,1].Bạn đọc cũng có thể tự xây dựng hàm số trên môi trường chung sau đó gọi tên hàm số này trong hàm apply(). Nếu hàm số tự xây dựng là hàm số có tham số khác ngoài x, bạn đọc cần phải khai báo giá trị cho tham số đó trong môi trường cục bộ của hàm apply():Khi tham số của hàm số mà bạn đọc muốn áp dụng trên ma trận là không cố định mà thay đổi theo một chiều của x thì không nên khai báo giá trị của tham số theo dạng véc-tơ trong hàm apply(). Thật vậy, giả sử bạn đọc muốn tính các giá trị phân vị ở mức xác suất 10% và 90% lần lượt của véc-tơ hàng thứ nhất và véc-tơ hàng thứ hai của một ma trận M kích thước \\(2 \\times 10\\). Hàm số quantile(x, probs = p) là hàm số có sẵn trong R được sử dụng để tính giá trị phân vị tại mức xác suất \\(p\\) của véc-tơ số x. Hãy quan sát kết quả của hàm apply() khi sử dụng tham số probs của hàm quantile() dưới dạng véc-tơ:Bạn đọc có thể thấy rằng kết quả của hàm apply() khi tham số probs là một véc-tơ là một ma trận, trong đó cột thứ nhất là giá trị phân vị tại các mức xác suất 10% và 90% của véc-tơ M[1,] và cột thứ hai giá trị phân vị tại các mức xác suất 10% và 90% của véc-tơ M[2,]. Giá trị chúng ta mong muốn lấy ra chính là các số nằm trên đường chéo chính của ma trận kết quả. Sẽ không có khó khăn gì nếu số lượng hàng của ma trận M nhỏ. Bạn đọc sẽ gặp vấn đề khi số lượng véc-tơ được áp dụng là lớn bởi kích thước của ma trận kết quả sẽ tăng lên theo cấp số nhân. Thật vậy, nếu M có \\(n\\) hàng và hàm số được áp dụng có 1 tham số, ma trận kết quả sẽ có kích thước sẽ là \\(n \\times n\\) nếu bạn đọc sử dụng trực tiếp hàm apply(). Chẳng hạn như bạn muốn tính giá trị phân vị ở các mức xác suất 10%, 30%, 50%, 70%, và 90% của lần lượt các véc-tơ hàng thứ 1, 2, 3, 4, và 5 của một ma trận M kích thước \\(5 \\times 10\\).Điều gì xảy ra khi ma trận M có \\(10^4\\) véc-tơ hàng? Ma trận kết quả sẽ có kích thước là \\(10^4 \\times 10^4\\). Khi ma trận M có \\(10^5\\) véc-tơ hàng? Ma trận kết quả sẽ có kích thước là \\(10^5 \\times 10^5\\) và R sẽ báo lỗi vì bộ nhớ không đủ để lưu một ma trận có kích thước như vậy.Một cách đơn giản để tiết kiệm thời gian và bộ nhớ khi áp dụng hàm số có tham số là hãy thêm tham số vào như là một phần của ma trận M và điều chỉnh lại hàm quantile() trước khi sử dụng hàm apply()","code":"\nx<-1:5; f<-function(x) x^2\nf(x) # f được áp dụng trên từng phần tử của x## [1]  1  4  9 16 25\napply(x, MARGIN, FUN, ...)\nM<-matrix(1:100,20,5) # Ma trận kích thước 20 * 5\napply(M, MARGIN = 2, FUN = mean)## [1] 10.5 30.5 50.5 70.5 90.5\n# MARGIN = 2 nghĩa là tính theo cột (1 theo hàng)\nAr<-array(1:20,dim=c(5,2,2)) # Mảng kích thước 5 * 2 * 2\napply(Ar, MARGIN = 3, FUN = mean)## [1]  5.5 15.5\n# MARGIN = 3 nghĩa là áp dụng hàm mean theo chiều thứ 3\nmean(Ar[,,1]) # bằng phần tử thứ nhất khi dùng apply## [1] 5.5\nmean(Ar[,,2]) # bằng phần tử thứ hai khi dùng apply## [1] 15.5\napply(Ar, MARGIN = c(2,3), mean) # MARGIN = c(2,3) nghĩa là áp dụng hàm mean theo chiều thứ 2 và 3##      [,1] [,2]\n## [1,]    3   13\n## [2,]    8   18\nmean(Ar[,1,1]) # bằng phần tử ở vị trí [1,1] của ma trận kết quả## [1] 3\nmean(Ar[,1,2]) # bằng phần tử ở vị trí [1,2] của ma trận kết quả## [1] 13\nmean(Ar[,2,1]) # bằng phần tử ở vị trí [1,2] của ma trận kết quả## [1] 8\nmean(Ar[,2,2]) # bằng phần tử ở vị trí [1,2] của ma trận kết quả## [1] 18\napply(M, 2, function(x) c(min(x),mean(x),max(x)))##      [,1] [,2] [,3] [,4]  [,5]\n## [1,]  1.0 21.0 41.0 61.0  81.0\n## [2,] 10.5 30.5 50.5 70.5  90.5\n## [3,] 20.0 40.0 60.0 80.0 100.0\nM[,1]##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\nc(min(M[,1]), mean(M[,1]), max(M[,1]))## [1]  1.0 10.5 20.0\nmy_range<-function(x, a) (max(x^a) - min(x^a)) # hàm số có tham số khác là a\napply(M, 2, my_range, a = 2)## [1]  399 1159 1919 2679 3439\n# Cần khai báo giá trị tham số a của my_range trong hàm apply\nM<-matrix(1:20,2,10) # ma trận 2 * 10\napply(M, 1, quantile, probs = c(0.1,0.9))##     [,1] [,2]\n## 10%  2.8  3.8\n## 90% 17.2 18.2\nquantile(M[1,],0.1) # giá trị mong muốn## 10% \n## 2.8\nquantile(M[2,],0.9) # giá trị mong muốn##  90% \n## 18.2\nM<-matrix(1:50,5,10) # ma trận 5 * 10\napply(M, 1, quantile, probs = c(0.1,0.3,0.5,0.7,0.9)) # ma trận kết quả kích thước 5 * 5##     [,1] [,2] [,3] [,4] [,5]\n## 10%  5.5  6.5  7.5  8.5  9.5\n## 30% 14.5 15.5 16.5 17.5 18.5\n## 50% 23.5 24.5 25.5 26.5 27.5\n## 70% 32.5 33.5 34.5 35.5 36.5\n## 90% 41.5 42.5 43.5 44.5 45.5\ndiag(apply(M, 1, quantile, probs = c(0.1,0.3,0.5,0.7,0.9))) # lấy ra đường chéo chính## [1]  5.5 15.5 25.5 35.5 45.5\nM1<-cbind(M,c(0.1,0.3,0.5,0.7,0.9)) # Thêm tham số vào cột cuối của ma trận M\nmy_quantile<-function(x){\n  # Định nghĩa lại hàm quantile có tham số p là giá trị cuối của véc-tơ\n  n<-length(x)\n  quantile(x[1:(n-1)], x[n])\n}\napply(M1, 1, my_quantile)## [1]  5.5 15.5 25.5 35.5 45.5"},{"path":"kiến-thức-r-nâng-cao.html","id":"hàm-lapply-và-sapply.","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.4.2 Hàm lapply() và sapply().","text":"Cơ chế hoạt động của lapply() tương tự như apply() và chỉ khác ở đối tượng áp dụng và cấu trúc của kết quả đầu ra. lapply() thường áp dụng trên các đối tượng kiểu list hoặc các kiểu đối tượng mà có thể sử dụng ký hiệu $ để gọi phần tử con như data.frame và tibble. Chúng ta sẽ thảo luận về các đối tượng này ở phần sau của cuốn sách. Khi bạn đọc sử dụng hàm lapply(), bạn không cần phải sử dụng tham số MARGIN bởi vì lapply() sẽ luôn luôn hiểu các đối tượng được tác động đến là tất cả các đối tượng con của list.Kết quả của lapply() là một list có số lượng phần tử và tên các phần tử con giống với véc-tơ x. Trong trường hợp áp dụng hàm mean(), mỗi giá trị nằm trong list kết quả là giá trị trung bình của phần tử có tên tương ứng nằm trong list ban đầu. hàm mean() không thể sử dụng với đối tượng là một list nên phần tử x4 của kết quả có giá trị NA.Hàm sapply() có cơ chế hoạt động hoàn toàn tương tự như lapply() và chỉ khác ở chỗ kết quả đầu ra là dưới dạng véc-tơ, ma trận, hoặc mảng. Thật vậy, vẫn với đối tượng x kiểu list ở trên, chúng ta sử dụng sapply() thay vì lapply() sẽ cho kết quả dưới dạng véc-tơ thay vì dưới dạng listCác hàm lapply() và sapply() thường xuyên được sử dụng khi làm việc với dữ liệu vì R lưu dữ liệu dưới dạng các data.frame hoặc tibbles. Khi sử dụng các hàm lapply() và sapply() với dữ liệu, các đối tượng được tác động đến sẽ luôn luôn là các véc-tơ cột. Hãy quan sát ví dụ dưới đây khi sử dụng sapply() để tính tỷ lệ giá trị không quan sát được của mỗi véc-tơ cột của một dữ liệu có tên là gapminder nằm trong thư viện dslabs.","code":"\nx <- list(x1 = 1:10,\n          x2 = c(TRUE,FALSE,TRUE,TRUE),\n          x3 = matrix(1:6,2,3),\n          x4 = list(x41 = c(1,2), x42 = c(3,4)) )\nlapply(x, mean) # áp dụng hàm mean trên tất cả các phần tử con của x## $x1\n## [1] 5.5\n## \n## $x2\n## [1] 0.75\n## \n## $x3\n## [1] 3.5\n## \n## $x4\n## [1] NA\nsapply(x, mean) # áp dụng hàm mean trên tất cả các phần tử con của x##   x1   x2   x3   x4 \n## 5.50 0.75 3.50   NA\ns1<-sapply(gapminder, function(x) sum(is.na(x))/length(x))\n# s1 là tỷ lệ không quan sát được của mỗi cột trong dữ liệu\ns1<-sort(s1) # sắp xếp s1 theo thứ tự tăng dần\nprint(s1) # hiển thị s1##          country             year  life_expectancy        continent \n##       0.00000000       0.00000000       0.00000000       0.00000000 \n##           region       population        fertility infant_mortality \n##       0.00000000       0.01754386       0.01773352       0.13779042 \n##              gdp \n##       0.28183973\nbarplot(s1,border = \"#640514\", col = \"white\",\n        ylab = \"Tỷ lệ\",\n        xlab = \"Tên biến/cột\",\n        main = \"Tỷ lệ giá trị không quan sát được của các cột dữ liệu Gapminder\")"},{"path":"kiến-thức-r-nâng-cao.html","id":"phụ-lục-1","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.5 Phụ lục","text":"","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"advrappen1","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.5.1 Kiến thức nâng cao liên quan đến ma trận","text":"Các kiến thức liên quan đến ma trận trong phần này đòi hỏi bạn đọc cần có kiến thức nâng cao hơn. Nếu bạn đọc cảm thấy không cần thiết có thể bỏ qua.","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"giá-trị-riêng-và-véc-tơ-riêng-của-ma-trận","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.5.1.1 Giá trị riêng và véc-tơ riêng của ma trận","text":"Cho là một ma trận kích thước \\(n \\times n\\). Nếu \\(\\lambda\\) và véc-tơ \\(\\textbf{v}\\) thỏa mãn\n\\[\\begin{align}\n\\ \\textbf{v} = \\lambda \\ \\textbf{v}\n\\end{align}\\]\nthì \\(\\lambda\\) là một giá trị riêng và \\(\\textbf{v}\\) là một véc-tơ riêng của ma trận vuông . Giá trị riêng \\(\\lambda\\) là nghiệm của phương trình\n\\[\\begin{align}\ndet(- \\lambda I_n) = 0\n\\end{align}\\]\ntrong đó \\(det\\) là định thức của ma trận và \\(I_n\\) là ma trận đơn vị kích thước \\(n \\times n\\). Vế bên trái của phương trình ở trên là một đa thức bậc \\(n\\) và giá trị riêng \\(\\lambda\\) là nghiệm của đa thức đó. Véc-tơ \\(\\textbf{v}\\) là véc-tơ riêng tương ứng với giá trị riêng \\(\\lambda\\).Nếu ma trận \\(\\) là một ma trận đối xứng thì tất cả các giá trị riêng của ma trận đều là số thực và ma trận đó có \\(n\\) véc-tơ riêng tương ứng với \\(n\\) giá trị riêng. Giả sử \\(\\lambda_1\\), \\(\\lambda_2\\), \\(\\cdots\\), \\(\\lambda_n\\) là \\(n\\) giá trị riêng của ma trận . Các véc-tơ riêng tương ứng là \\(\\textbf{v}_1\\), \\(\\textbf{v}_2\\), \\(\\cdots\\), \\(\\textbf{v}_n\\) và chúng ta giả sử rằng các véc-tơ \\(\\textbf{v}_i\\) đều đã được chuẩn hóa sao cho\n\\[\\begin{align}\n& \\textbf{v}_i^T \\textbf{v}_j = 0 \\ \\ \\forall \\neq j, 1 \\leq ,j \\leq n \\\\\n& \\textbf{v}_i^T \\textbf{v}_i = 1 \\ \\ \\forall , 1 \\leq \\leq n\n\\end{align}\\]\nKhi đó, ma trận có thể được khai triển dưới dạng\n\\[\\begin{align}\n= V \\Gamma V^T\n\\end{align}\\]\ntrong đó V là ma trận có các cột là các véc-tơ riêng của ma trận và \\(\\Gamma\\) là ma trận đường chéo có các phần tử nằm trên đường chéo chính là các giá trị riêng của ma trận \n\\[\\begin{align}\n& V[,] = \\textbf{v}_i \\forall , 1 \\leq \\leq n \\\\\n& \\Gamma = diag(\\lambda_1, \\lambda_2, \\cdots, \\lambda_n)\n\\end{align}\\]\nKhai triển trên của ma trận vuông được gọi là spectral decomposition.Hàm eigen() được sử dụng để tính toán các giá trị riêng và véc-tơ riêng của ma trận. Bạn đọc quan sát ví dụ dưới đây: hàm eigen() được sử dụng để tính toán các giá trị riêng và véc-tơ riêng của ma trận tương quan của ba biến medv, lstat, và rm (ma trận \\(3 \\times 3\\)) trong dữ liệu Boston của thư viện MASS.","code":"\ndat<-dplyr::select(Boston, medv, lstat, rm) # Lựa chọn 3 cột\nM<-cor(dat) # Tính ma trận tương quan\nresult<-eigen(M) # Hàm eigen tính giá trị riêng và véc-tơ riêng\nresult$values # Giá trị riêng## [1] 2.3658220 0.3900962 0.2440818\nresult$vectors # Véc-tơ riêng theo cột##            [,1]       [,2]       [,3]\n## [1,]  0.5959303 -0.1286943  0.7926568\n## [2,] -0.5741638  0.6218127  0.5326207\n## [3,]  0.5614294  0.7725197 -0.2966654"},{"path":"kiến-thức-r-nâng-cao.html","id":"khai-triển-trực-giao-của-ma-trận","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.5.1.2 Khai triển trực giao của ma trận","text":"Mọi ma trận kích thước \\(m \\times n\\) đều có thể viết dưới dạng\n\\[\\begin{align}\n= Q U\n\\end{align}\\]\ntrong đó \\(Q\\) là một ma trận trực giao kích thước, nghĩa là \\(Q^T Q = \\) và \\(U\\) là một ma trận đường tam giác trên. Nếu \\(m \\geq n\\) thì có hai cách để chọn kích thước cho các ma trậnCách thứ nhất: \\(Q\\) là một ma trận kích thước \\(m \\times n\\) và \\(R\\) là một ma trận kích thước \\(n \\times n\\).Cách thứ nhất: \\(Q\\) là một ma trận kích thước \\(m \\times n\\) và \\(R\\) là một ma trận kích thước \\(n \\times n\\).Cách thứ hai: \\(Q\\) là một ma trận kích thước \\(m \\times m\\) và \\(R\\) là một ma trận kích thước \\(n \\times n\\).Cách thứ hai: \\(Q\\) là một ma trận kích thước \\(m \\times m\\) và \\(R\\) là một ma trận kích thước \\(n \\times n\\).","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"ma-trận-xác-định-dương","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.5.1.3 Ma trận xác định dương","text":"Ma trận đối xứng được gọi là xác định dương khi và chỉ khi\n\\[\\begin{align}\n\\textbf{x}^T \\ \\ \\textbf{x} > 0\n\\end{align}\\]\nvới mọi véc-tơ \\(\\textbf{x}\\) khác véc-tơ \\(\\textbf{0}\\). Định nghĩa này của ma trận xác định dương rất khó được xác thực, đó có các định nghĩa tương đương khác sẽ có ý nghĩa thực tiễn hơn. Chẳng hạn như nếu một ma trận đối xứng có tất cả các giá trị riêng là số dương thì đó là một ma trận xác định dương.Tương tự như khai niệm ma trận xác định dương, ta có các khái niệmMa trận xác định không âm là ma trận đối xứng thỏa mãn \\(\\textbf{x}^T \\ \\ \\textbf{x} \\geq 0\\) với mọi véc-tơ \\(\\textbf{x}\\) khác véc-tơ \\(\\textbf{0}\\). Ma trận xác định không âm là ma trận có tất cả các giá trị riêng không âm.Ma trận xác định không âm là ma trận đối xứng thỏa mãn \\(\\textbf{x}^T \\ \\ \\textbf{x} \\geq 0\\) với mọi véc-tơ \\(\\textbf{x}\\) khác véc-tơ \\(\\textbf{0}\\). Ma trận xác định không âm là ma trận có tất cả các giá trị riêng không âm.Ma trận xác định âm là ma trận đối xứng thỏa mãn \\(\\textbf{x}^T \\ \\ \\textbf{x} < 0\\) với mọi véc-tơ \\(\\textbf{x}\\) khác véc-tơ \\(\\textbf{0}\\). Ma trận xác định âm là ma trận có tất cả các giá trị riêng là số âm.Ma trận xác định âm là ma trận đối xứng thỏa mãn \\(\\textbf{x}^T \\ \\ \\textbf{x} < 0\\) với mọi véc-tơ \\(\\textbf{x}\\) khác véc-tơ \\(\\textbf{0}\\). Ma trận xác định âm là ma trận có tất cả các giá trị riêng là số âm.Ma trận xác định không dương là ma trận đối xứng thỏa mãn \\(\\textbf{x}^T \\ \\ \\textbf{x} \\leq 0\\) với mọi véc-tơ \\(\\textbf{x}\\) khác véc-tơ \\(\\textbf{0}\\). Ma trận xác định không dương là ma trận có tất cả các giá trị riêng không dương.Ma trận xác định không dương là ma trận đối xứng thỏa mãn \\(\\textbf{x}^T \\ \\ \\textbf{x} \\leq 0\\) với mọi véc-tơ \\(\\textbf{x}\\) khác véc-tơ \\(\\textbf{0}\\). Ma trận xác định không dương là ma trận có tất cả các giá trị riêng không dương.Ma trận xác định dương kích thước \\(n \\times n\\) có thể được viết dưới dạng\n\\[\\begin{align}\n= L D L^T\n\\end{align}\\]\nvới \\(L\\) là ma trận tam giác dưới có tất cả các phần tử nằm trên đường chéo chính bằng 1, ma trận \\(D\\) là ma trận đường chéo có tất cả các phần tử nằm trên đường chéo chính là số dương.\\(D\\) là ma trận có tất cả các phần tử nằm trên đường chéo chính là số dương nên \\(D\\) có thể được viết dưới dạng\n\\[\\begin{align}\nD = \\hat{D} \\ \\hat{D}\n\\end{align}\\]\ntrong đó \\(\\hat{D}\\) là ma trận đường chéo có phần tử thứ \\(\\) trên đường chéo chính bằng căn bậc 2 của phần \\(D_{,}\\).Khi đó, ma trận \\(\\) có thể được viết dưới dạng\n\\[\\begin{align}\n= L D L^T = L \\hat{D} \\ \\hat{D} L^T = \\hat{L} \\ \\hat{L}^T\n\\end{align}\\]\ntrong đó \\(\\hat{L}\\) là ma trận tam giác dưới. Khai triển này thường được gọi là Cholesky decomposion của một ma trận xác định dương.","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"advrappen2","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.5.2 Gradient, Hessian và Jacobian","text":"Trong tính toán và tối ưu hàm nhiều biến, grandient, hessian và jacobian là các khái niệm vô cùng quan trọng.","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"định-nghĩa","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.5.2.1 Định nghĩa","text":"Cho hàm số \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\)\n\\[\\begin{align}\nf(\\textbf{x}) = f(x_1, x_2, \\cdots, x_n)\n\\end{align}\\]Véc-tơ của các đạo hàm bậc nhất của hàm \\(f\\) theo các thành phần của véc-tơ \\(\\textbf{x}\\) được gọi là \\(gradien\\) của hàm số \\(f\\) tại điểm \\(\\textbf{x}\\). Gradient của hàm \\(f\\) được ký hiệu như sau\\[\\begin{align}\n\\nabla f(\\textbf{x}) = \\left(\\cfrac{\\partial f(\\textbf{x})}{\\partial x_1}, \\cfrac{\\partial f(\\textbf{x})}{\\partial x_2}, \\cdots, \\cfrac{\\partial f(\\textbf{x})}{\\partial x_n}\\right)\n\\end{align}\\]Ma trận chứa đạo hàm bậc hai của hàm \\(f\\) theo các thành phần của véc-tơ \\(\\textbf{x}\\), mà phần tử ở hàng thứ \\(\\) cột \\(j\\) là đạo hàm của hàm \\(f\\) lần lượt theo \\(x_i\\), \\(x_j\\), được gọi là ma trận \\(hessian\\) của hàm \\(f\\) tại điểm \\(\\textbf{x}\\). Ma trận hessian thường được ký hiệu là \\(\\nabla^2 f(\\textbf{x})\\). Phần tử ở hàng thứ \\(\\) và cột \\(j\\) của ma trận hessian được xác định như sau\n\\[\\begin{align}\n\\left[\\nabla^2 f(\\textbf{x})\\right]_{,j} = \\cfrac{\\partial^2 f(\\textbf{x})}{\\partial x_i \\partial x_j}\n\\end{align}\\]Lưu ý rằng hessian là ma trận đối xứng bởi vì\n\\[\\begin{align}\n\\cfrac{\\partial^2 f(\\textbf{x})}{\\partial x_i \\partial x_j} = \\cfrac{\\partial^2 f(\\textbf{x})}{\\partial x_j \\partial x_i}\n\\end{align}\\]Khái niệm Jacobian được dùng thay thế cho gradient khi hàm số \\(f\\) nhận giá trị trong không gian \\(\\mathbb{R}^m\\), với\n\\[\\begin{align}\nf(\\textbf{x}) = f(x_1, x_2, \\cdots, x_n) =\n\\begin{bmatrix}\nf_1(x_1, x_2, \\cdots, x_n) \\\\\nf_2(x_1, x_2, \\cdots, x_n) \\\\\n\\cdots \\\\\nf_m(x_1, x_2, \\cdots, x_n) \\\\\n\\end{bmatrix}\n\\end{align}\\]\nta có ma trận Jacobian của hàm \\(f\\) tại điểm \\(x\\) là ma trận kích thước \\(n \\times m\\), ký hiệu \\([\\nabla f(\\textbf{x})]^T\\) trong đó cột thứ \\(j\\) của ma trận Jacobian là gradient của hàm \\(f_j\\) tại điểm \\(\\textbf{x}\\). Trong nhiều trường hợp, khái niệm \\(grandient\\) và \\(Jacobian\\) có thể được sử dụng thay thế cho nhau.Ví dụ, với \\(\\textbf{x}\\) là véc-tơ có độ dài \\(n\\). Nếu \\(\\textbf{}\\) là véc-tơ độ dài \\(n\\) và \\(\\) là ma trận kích thước \\(m \\times n\\) thì chúng ta có\n\\[\\begin{align}\n\\nabla \\textbf{}^T \\textbf{x}) = \\textbf{} \\\\\n\\nabla \\textbf{x} = ^T\n\\end{align}\\]","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"gradient-và-hessian-của-dạng-toàn-phương","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.5.2.2 Gradient và hessian của dạng toàn phương","text":"Cho\n\\[\\begin{align}\nf(\\textbf{x}) = \\cfrac{1}{2} \\ \\textbf{x}^T \\textbf{x} + \\textbf{}^T \\textbf{x}\n\\end{align}\\]\nvới \\(\\) là một ma trận đối xứng và \\(\\textbf{}\\) là véc-tơ độ dài \\(n\\) thì ta có\n\\[\\begin{align}\n& \\nabla f(\\textbf{x}) = \\textbf{x} + \\textbf{} \\\\\n& \\nabla^2 f(\\textbf{x}) = \n\\end{align}\\]","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"gradient-và-hessian-của-tích-các-hàm-số","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.5.2.3 Gradient và hessian của tích các hàm số","text":"Cho hàm \\(f\\) là tích của hai hàm \\(g\\) và \\(h\\) đều là các hàm số có đạo hàm có tập xác định trên tập \\(\\mathbb{R}^n\\) và nhận giá trị trên tập các số thực\n\\[\\begin{align}\nf(\\textbf{x}) = h(\\textbf{x}) g(\\textbf{x})\n\\end{align}\\]Gradient và hessian của hàm số \\(f\\) được tính toán thông qua gradient và hessian của các hàm \\(g\\) và \\(h\\) như sau\n\\[\\begin{align}\n& \\nabla f(\\textbf{x}) = \\nabla h(\\textbf{x}) \\ g(\\textbf{x}) + h(\\textbf{x}) \\  \\nabla g(\\textbf{x}) \\\\\n& \\nabla^2 f(\\textbf{x}) = \\left[\\nabla^2 h(\\textbf{x})\\right] g(\\textbf{x}) + \\left[\\nabla^2 g(\\textbf{x})\\right] h(\\textbf{x}) + \\nabla h(\\textbf{x}) \\nabla g(\\textbf{x})^T + \\nabla g(\\textbf{x}) \\nabla h(\\textbf{x})^T\n\\end{align}\\]","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"quy-tắc-chain-rule","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.5.2.4 Quy tắc Chain rule","text":"chain rule là quy tắc tính toán đạo hàm của một hàm số trên một hàm số khác. Cho \\(g\\) là hàm số \\(\\mathbb{R}^m \\rightarrow \\mathbb{R}\\) và với mỗi \\(\\), \\(1 \\leq \\leq m\\), ta có hàm \\(f_i\\) nhận có tập xác định trên \\(\\mathbb{R}^n\\) và nhận giá trị trên tập các số thực:\n\\[\\begin{align}\nf_i(\\textbf{x}) = f_i(x_1, x_2, \\cdots, x_n)\n\\end{align}\\]Hàm số \\(f\\) được xác định bởi\n\\[\\begin{align}\nf(\\textbf{x}) = g(f_1(\\textbf{x}), f_2(\\textbf{x}), \\cdots, f_m(\\textbf{x}))\n\\end{align}\\]\nsẽ có gradient được xác định theo chain rule như sau\n\\[\\begin{align}\n\\nabla f(\\textbf{x}) = \\left[ \\nabla f_1, \\nabla f_2, \\cdots, \\nabla f_m \\right] \\cdot \\nabla g(f_1(\\textbf{x}), f_2(\\textbf{x}), \\cdots, f_m(\\textbf{x}))\n\\end{align}\\]Trong công thức tính gradient ở trên, thành phần thứ nhất là một ma trận kích thước \\(n \\times m\\) trong đó cột thứ \\(j\\) là gradient của hàm \\(f_j\\) theo \\(\\textbf{x}\\), thành phần thứ hai là gradient (véc-tơ) của hàm \\(g\\) tính tại điểm \\(\\left(f_1(\\textbf{x}), f_2(\\textbf{x}), \\cdots, f_m(\\textbf{x})\\right)\\).","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"sgd","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.5.3 Thuật toán gradient descent","text":"Gradient descent là một phương pháp giải số các bài toán tối ưu không bị ràng buộc. Đây là thuật toán sử dụng vòng lặp để tìm kiếm điểm cực tiểu địa phương của một hàm nhiều biến khả vi. Ý tưởng của thuật toán là từ một điểm ban đầu chúng ta sẽ thực hiện các vòng lặp để thay đổi giá trị đó theo hướng ngược lại với độ dốc (gradient) của hàm số tính tại điểm hiện tại. Gradient descent là phương pháp chủ yếu trong quá trình ước lượng tham số của các mô hình học máy phức tạp.Giả sử hàm số chúng ta muốn tối thiểu hóa là hàm \\(f\\) và điểm khởi đầu là điểm \\(x_0\\), chúng ta sẽ di chuyển đến điểm \\(x_1\\) được tính toán bởi công thức sau\n\\[\\begin{align}\nx_1 = x_0 - \\lambda \\cdot \\nabla f(x_0)\n\\end{align}\\]Một cách tổng quát, chúng ta có thể viết công thức để di chuyển từ điểm \\(x_n\\) đến \\(x_{n+1}\\) như sau\n\\[\\begin{align}\nx_{n+1} = x_n - \\lambda \\cdot \\nabla f(x_n)\n\\end{align}\\]\nvới \\(\\lambda\\) là một số dương nhỏ. Thuật toán gradient descent sẽ dừng lại cho đến khi đạt được tiêu chí là hàm \\(f\\) không còn giảm một cách đáng kể sau mỗi lần thay đổi \\(x\\). Một vài lưu ý khi thực hiện thuật toán này làThuật toán gradient descent luôn hiểu với mục tiêu là tìm cực tiểu của hàm \\(f\\), đó trong bài toán tìm cực đại, chúng ta áp dụng gradient descent trên hàm \\(-f\\).Thuật toán gradient descent luôn hiểu với mục tiêu là tìm cực tiểu của hàm \\(f\\), đó trong bài toán tìm cực đại, chúng ta áp dụng gradient descent trên hàm \\(-f\\).Gradient descent chỉ hội tụ đến một điểm cực tiểu địa phương chứ không hội tụ đến điểm cực tiểu tổng thể, đó lựa chọn điểm \\(x_0\\) bạn đầu là khá quan trọng nếu hàm \\(f\\) có một (vài) điểm cực tiểu địa phương khác với điểm cực tiểu tổng thể.Gradient descent chỉ hội tụ đến một điểm cực tiểu địa phương chứ không hội tụ đến điểm cực tiểu tổng thể, đó lựa chọn điểm \\(x_0\\) bạn đầu là khá quan trọng nếu hàm \\(f\\) có một (vài) điểm cực tiểu địa phương khác với điểm cực tiểu tổng thể.Lựa chọn giá trị của \\(\\lambda\\) cũng là rất quan trọng. Nếu \\(\\lambda\\) quá nhỏ, thuật toán sẽ hội tụ chậm, nghĩa là cần rất nhiều bước để tìm được điểm tối ưu. Nếu \\(\\lambda\\) lớn, thuật toán sẽ không tìm được điểm cực tiểu. Lưu ý rằng, tại mỗi bước lựa chọn giá trị của \\(\\lambda\\) không nhất thiết phải là hằng số. Kinh nghiệm lựa chọn \\(\\lambda\\) là cho \\(\\lambda\\) giảm dần sau một số bước.Lựa chọn giá trị của \\(\\lambda\\) cũng là rất quan trọng. Nếu \\(\\lambda\\) quá nhỏ, thuật toán sẽ hội tụ chậm, nghĩa là cần rất nhiều bước để tìm được điểm tối ưu. Nếu \\(\\lambda\\) lớn, thuật toán sẽ không tìm được điểm cực tiểu. Lưu ý rằng, tại mỗi bước lựa chọn giá trị của \\(\\lambda\\) không nhất thiết phải là hằng số. Kinh nghiệm lựa chọn \\(\\lambda\\) là cho \\(\\lambda\\) giảm dần sau một số bước.Ví dụ 1: Hàm số \\(f(x) = (x-2)^2\\) có điểm cực tiểu là 2. Chúng ta có thể kiểm tra sự hội tụ của thuật toán gradient descent như sau: có thể dễ dàng thấy rằng đạo hàm của hàm \\(f\\) là \\(2 \\times (x-2)\\); giá trị \\(x_0\\) được lựa chọn ngẫu nhiên trong khoảng từ -100 đến 100; \\(\\lambda\\) được cho cố định là 0.1; thuật toán sẽ dừng lại khi giá trị hàm \\(f\\) tại 2 bước kế tiếp nhau nhỏ hơn \\(10^{-8}\\).Bạn đọc có thể thấy rằng sau khoảng 20 đến 30 vòng lặp thuật toán đã hội tụ. Hình 4.1 mô tả quá trình hội tụ của 50 điểm ngẫu nhiên trong hình vuông \\([-50,50] \\times [-50,50]\\) hội tụ về điểm tối ưu \\((x_1 = 5, x_2 = 10)\\) của hàm \\(f(x_1, x_2) = (x_1 - 5)^2 + (x_2 - 10)^2\\).\nHình 4.1: Quá trình hội tụ các điểm ngẫu nhiên đến điểm cực tiểu của hàm f sử dụng thuật toán gradient descent\n","code":"\nlambda<-0.1\nvong_lap_toi_da = 40\nsai_so_nho_nhat<-10^(-8)\n\n# Hàm số cần tìm cực tiểu\nf<-function(x) (x-2)^2\n\n# Gradient tại điểm x\ngrad.f<-function(x) 2*(x-2)\n\n# Cho x0 bat ky\nset.seed(20)\nv_x0<-runif(20,-100,100)\n\n# dat: du lieu luu ket qua\ndat<-data.frame(so_vong_lap = 1:vong_lap_toi_da)\n\nfor (j in 1:length(v_x0)){\n  x0<-v_x0[j]\n  # Bước 1\n  x<-rep(0,vong_lap_toi_da)\n  x[1]<- x0 - lambda * grad.f(x0)\n  sai_so<-abs(f(x[i])-f(x0))\n\n  # Từ bước 2 trở đi\n  i <- 2\n  while (i< vong_lap_toi_da & sai_so > sai_so_nho_nhat){\n    x[i]<-x[i-1] - lambda * grad.f(x[i-1])\n    sai_so = abs(f(x[i])-f(x[i-1]))\n    i<-i+1\n  }\n  x[i:vong_lap_toi_da]<-x[i-1]\n  dat<-mutate(dat,x)\n  names(dat)[j+1]<-paste(\"Vong_lap\",j)\n}\n\ndat%>%gather(\"loop\", \"value\", -so_vong_lap)%>%\n  ggplot(aes(so_vong_lap, value, col = loop))+\n  geom_line(alpha = 0.5)+theme_minimal()+\n  ylab(\"Giá trị hàm f\")+xlab(\"Số vòng lặp\")+\n  geom_hline(yintercept = 2, color = \"red\")+\n  theme(legend.position = \"none\")"},{"path":"kiến-thức-r-nâng-cao.html","id":"advrappen3","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.5.4 Các giá trị đặc trưng của một dòng tiền tương lai","text":"","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"giá-trị-hiện-tại-và-tỷ-suất-sinh-lời-nội-bộ","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.5.4.1 Giá trị hiện tại và tỷ suất sinh lời nội bộ","text":"Một dòng tiền \\(CF_{t_1}\\), \\(CF_{t_2}\\), \\(\\cdots\\), \\(CF_{t_n}\\) xảy ra tại các thời điểm \\(t_k\\) với \\(1 \\leq k \\leq n\\). Giá trị hiện tại của dòng tiền với lãi suất \\(\\) được tính theo phương pháp lãi gộp như sau:\n\\[\\begin{align}\nPV = \\sum\\limits_{k=1}^n \\cfrac{CF_{t_k}}{(1+)^{t_k}}\n\\end{align}\\]\nGiá trị hiện tại của một dòng tiền là một thước đo cho giá trị của tài sản tạo ra dòng tiền đó. Nhìn chung, tài sản nào có giá trị hiện tại lớn hơn thì có giá trị cao hơn.Tỷ suất sinh lời nội bộ (Internal rate return hay IRR) là mức lãi suất \\(i_0\\) mà tính theo mức lãi suất này giá trị hiện tại của một dòng tiền bằng 0. Tỷ suất sinh lời nội bộ không tồn tại nếu dòng tiền tương lai của một tài sản chỉ có giá trị dương (hoặc âm).","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"durations","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.5.4.2 Durations","text":"Duration không phải là thước đo thời gian từ lúc bắt đầu đến lúc đáo hạn của dòng tiền mà là một thước đo cho sự nhạy cảm của giá trị hiện tại của dòng tiền theo sự thay đổi của lãi suất.Macaulay Duration là thước đo, tính bằng đơn vị thời gian, là giá trị trung bình có trọng số của khoảng thời gian tính từ lúc bắt đầu đến thời điểm mà các dòng tiền xuất hiện. Macaulay Duration được ký hiệu là \\(Mac\\_D\\) được tính bằng công thức sau:\n\\[\\begin{align}\nMac_D = w_1 \\times t_1 + w_2 \\times t_2 + \\cdots + w_n \\times t_n\n\\end{align}\\]\nvới tỷ trọng \\(w_k\\) được tính bằng tỷ trọng của giá trị hiện tại của \\(CF_{t_k}\\) trong giá trị hiện tại của toàn bộ dòng tiền\n\\[\\begin{align}\nw_k = \\cfrac{1}{PV} \\times \\cfrac{CF_{t_k}}{(1+)^{t_k}}\n\\end{align}\\]Macaulay Duration là thước đo, tính bằng đơn vị thời gian, là giá trị trung bình có trọng số của khoảng thời gian tính từ lúc bắt đầu đến thời điểm mà các dòng tiền xuất hiện. Macaulay Duration được ký hiệu là \\(Mac\\_D\\) được tính bằng công thức sau:\n\\[\\begin{align}\nMac_D = w_1 \\times t_1 + w_2 \\times t_2 + \\cdots + w_n \\times t_n\n\\end{align}\\]\nvới tỷ trọng \\(w_k\\) được tính bằng tỷ trọng của giá trị hiện tại của \\(CF_{t_k}\\) trong giá trị hiện tại của toàn bộ dòng tiền\n\\[\\begin{align}\nw_k = \\cfrac{1}{PV} \\times \\cfrac{CF_{t_k}}{(1+)^{t_k}}\n\\end{align}\\]Modified duration đo lường sự thay đổi (theo %) sự thay đổi của giá trị hiện tại của dòng tiền khi có sự thay đổi nhỏ trong lãi suất:\n\\[\\begin{align}\nMod_D & = - \\lim\\limits_{\\rightarrow 0} \\cfrac{1}{PV} \\ \\cfrac{\\Delta PV}{\\Delta } \\\\\n& = \\cfrac{1}{PV} \\ \\sum\\limits_{k=1}^n \\cfrac{t_k CF_{t_k}}{(1+)^{t_k+1}} \\\\\n& = \\cfrac{1}{1+} \\ \\cfrac{1}{PV} \\ \\cfrac{t_k CF_{t_k}}{(1+)^{t_k}}\n\\end{align}\\]\nBạn đọc có thể thấy rằng mặc dù ý nghĩa khác nhau, nhưng \\(Mod_D\\) có thể được tính từ \\(Mac_D\\) như sau\n\\[\\begin{align}\nMod_D = \\cfrac{1}{1+} \\times Mac_D\n\\end{align}\\]Modified duration đo lường sự thay đổi (theo %) sự thay đổi của giá trị hiện tại của dòng tiền khi có sự thay đổi nhỏ trong lãi suất:\n\\[\\begin{align}\nMod_D & = - \\lim\\limits_{\\rightarrow 0} \\cfrac{1}{PV} \\ \\cfrac{\\Delta PV}{\\Delta } \\\\\n& = \\cfrac{1}{PV} \\ \\sum\\limits_{k=1}^n \\cfrac{t_k CF_{t_k}}{(1+)^{t_k+1}} \\\\\n& = \\cfrac{1}{1+} \\ \\cfrac{1}{PV} \\ \\cfrac{t_k CF_{t_k}}{(1+)^{t_k}}\n\\end{align}\\]\nBạn đọc có thể thấy rằng mặc dù ý nghĩa khác nhau, nhưng \\(Mod_D\\) có thể được tính từ \\(Mac_D\\) như sau\n\\[\\begin{align}\nMod_D = \\cfrac{1}{1+} \\times Mac_D\n\\end{align}\\]Dollar duration là khoản tăng lên (theo số tiền tuyệt đối) của giá trị hiện tại của một dòng tiền khi lãi suất giảm 1% trong lãi suất\n\\[\\begin{align}\nDollar_D = Mod_D \\times PV \\times 0.01\n\\end{align}\\]Dollar duration là khoản tăng lên (theo số tiền tuyệt đối) của giá trị hiện tại của một dòng tiền khi lãi suất giảm 1% trong lãi suất\n\\[\\begin{align}\nDollar_D = Mod_D \\times PV \\times 0.01\n\\end{align}\\]","code":""},{"path":"kiến-thức-r-nâng-cao.html","id":"bài-tập","chapter":"Chương 4 Kiến thức R nâng cao","heading":"4.6 Bài tập","text":"\\(\\textbf{Câu hỏi }\\) Bạn cố gắng xấp xỉ hàm \\(sin(x)\\) trên khoảng \\([0,2*\\pi]\\) bằng một đa thức bậc 5\n\\[\\begin{align}\nP(x) = a_0 + a_1 \\cdot x + a_2 \\cdot x^2 + a_3 \\cdot x^3 + a_4 \\cdot x^4 + a_5 \\cdot x^5\n\\end{align}\\]\nbằng cách tìm các hệ số \\(\\textbf{} = (a_0, a_1, a_2, a_3, a_4, a_5)\\) sao cho hàm số \\(g(\\textbf{})\\) được xác định bằng\n\\[\\begin{align}\ng(\\textbf{}) = \\int\\limits_0^{2 \\pi} (P(x) - sin(x))^2 \\ dx\n\\end{align}\\]\nđạt giá trị nhỏ nhất. Hãy sử dụng thuật toán gradient descent để tìm \\(\\textbf{}\\).","code":"## \n## Attaching package: 'dplyr'## The following object is masked from 'package:pryr':\n## \n##     where## The following object is masked from 'package:gridExtra':\n## \n##     combine## The following object is masked from 'package:kableExtra':\n## \n##     group_rows## The following objects are masked from 'package:stats':\n## \n##     filter, lag## The following objects are masked from 'package:base':\n## \n##     intersect, setdiff, setequal, union## \n## Attaching package: 'lubridate'## The following objects are masked from 'package:base':\n## \n##     date, intersect, setdiff, union"},{"path":"nhập-dữ-liệu-vào-r.html","id":"nhập-dữ-liệu-vào-r","chapter":"Chương 5 Nhập dữ liệu vào R","heading":"Chương 5 Nhập dữ liệu vào R","text":"","code":""},{"path":"nhập-dữ-liệu-vào-r.html","id":"giới-thiệu-chung","chapter":"Chương 5 Nhập dữ liệu vào R","heading":"5.1 Giới thiệu chung","text":"Trong phần này của cuốn sách, bạn đọc sẽ được tìm hiểu về các kỹ thuật phân tích dữ liệu, bao gồm tiền xử lý dữ liệu, sắp xếp dữ liệu và trực quan hóa dữ liệu.Tiền xử lý dữ liệu bao gồm tất cả các kỹ thuật biến đổi dữ liệu thô thành định dạng để có thể thực hiện phân tích. Dữ liệu thô bao gồm dữ liệu nhận được từ người khác hoặc dữ liệu mà người phân tích tự tìm kiếm từ các nguồn khác nhau.Sắp xếp và tổ chức dữ liệu bao gồm các bước biến đổi, chuyển hóa dữ liệu thành định dạng để có thể trực quan hóa, thực hiện phân tích tính toán và xây dựng mô hình trên dữ liệu.Trực quan hóa dữ liệu là một nghệ thuật biến đổi dữ liệu vốn được hiển thị dưới dạng các con số, chuỗi ký tự, thành các biểu đồ, đồ thị, hình ảnh; sử dụng màu sắc, hình dạng, khoảng cách để mô tả giúp con người dễ dàng nhận thức và hiểu về dữ liệu. Trực quan hóa dữ liệu còn có thể giúp người phân tích dữ liệu và người tiếp nhận dữ liệu dễ dàng tìm ra những giá trị ẩn chứa trong dữ liệu.Trước khi có thể bắt đầu bước tiền xử lý và phân tích dữ liệu, bước đầu tiên là nhập dữ liệu vào R. Trong một vài trường hợp, nhập dữ liệu cần nhập chỉ đơn giản là một bảng Excel có sẵn. Trong một số trường hợp khác, quá trình nhập dữ liệu có thể phức tạp hơn, chẳng hạn như từ một (vài) phần nào đó trong một hoặc nhiều bảng Excel, hoặc từ một cơ sở dữ liệu được lưu trữ trong các máy tính server, hoặc đôi khi cần viết các vòng lặp để lấy dữ liệu từ các trình duyệt web. Đây là chủ đề mà chúng ta sẽ thảo luận trong chương đầu của phần phân tích dữ liệu.","code":""},{"path":"nhập-dữ-liệu-vào-r.html","id":"đối-tượng-lưu-dữ-liệu-trong-r","chapter":"Chương 5 Nhập dữ liệu vào R","heading":"5.2 Đối tượng lưu dữ liệu trong R","text":"Hai kiểu đối tượng thường được dùng để lưu dữ liệu trong R là data.frame và tibble. Chúng ta sẽ thảo luận về data.frame trước vì đây là kiểu lưu dữ liệu phổ biến và xuất hiện trước. Đối tượng kiểu tibble, với một vài ưu điểm hơn data.frame, sẽ được thảo luận trong phần tiếp theo.","code":""},{"path":"nhập-dữ-liệu-vào-r.html","id":"data.frame","chapter":"Chương 5 Nhập dữ liệu vào R","heading":"5.2.1 Data.frame","text":"Data.frame là đối tượng phổ biến nhất để lưu trữ dữ liệu trên môi trường làm việc của R. Hiểu một cách đơn giản, một data.frame giống như một bảng excel mà mỗi cột tương ứng với một véc-tơ và mỗi dòng tương ứng với một quan sát. Ngay khi cài đặt R, đã có nhiều đối tượng là dữ liệu kiểu data.frame đã được lưu trữ trong R và đã sẵn sàng được sử dụng. Bạn đọc sử dụng câu lệnh data() để biết trên môi trường đang sử dụng có những dữ liệu nào,Sau khi thực thi câu lệnh, bạn đọc có thể thấy trên cửa sổ script xuất hiện một cửa sổ mới với danh sách tất cả các dữ liệu sẵn có trong R và những dữ liệu có trong các thư viện đang được gọi lên trên môi trường đang làm việc. Để biết trong một thư viện cụ thể có những dữ liệu nào, bạn đọc có thể sử dụng lệnh data() kèm với tùy chọn package như sau:Trong danh sách dữ liệu của thư viện dslabs, bạn đọc có thể thấy rất nhiều đối tượng kiểu data.frame. Một trong số đó có một dữ liệu có tên là murders. Bạn đọc có thể kiểm tra kiểu của đối tượng này bằng hàm class():Thông thường để có hiểu biết ban đầu về một đối tượng kiểu data.frame, chúng ta nên bắt đầu bằng đọc mô tả về dữ liệu (nếu có):Có một nhóm các câu lệnh thường được sử dụng để có cái nhìn tổng thể về cấu trúc của dữ liệu. Các câu lệnh này được liệt kê ở dưới:Hàm head() cho kết quả là các dòng đầu tiên của dữ liệu và giúp bạn đọc cái nhìn trực quan về tên các cột hoặc kiểu dữ liệu trong các cột. Tuy nhiên hàm head() không hiệu quả khi dữ liệu có nhiều cột. Hàm head() có tham số n đi kèm cho biết số lượng dòng dữ liệu bạn đọc muốn hiển thị. n nhận giá trị mặc định bằng 6.Hàm View() hiển thị về dữ liệu một cách trực quan và dễ nhìn nhất. Sau khi thực thi, kết quả của hàm View() sẽ xuất hiện trên cửa sổ Script. Ngoài ý nghĩa hiển thị dữ liệu, kết quả của hàm View() còn là một bảng tương tác mà bạn đọc có thể thực hiện thao tác như sắp xếp dữ liệu trong các cột. Hàm View() có hạn chế khi dữ liệu có quá nhiều dòng hoặc nhiều cột và thời gian hiển thị lâu hơn với head().Hàm str() là cách hiển thị dữ liệu một cách tổng quát và hiệu quả hơn với head(). Sau thi thực thi hàm str() trên dữ liệu murders, bạn đọc có thể có cái nhìn tổng thể về dữ liệu này:\nmurders là một data.frame có 5 cột (còn gọi là các variables) và 51 dòng (còn gọi là các observations).\nTên của 5 cột lần lượt là state, abb, region, population, và total.\nHàm str() cho chúng ta thấy thấy được kiểu dữ liệu của từng cột: cột state và cột abb chứa dữ liệu kiểu character; cột region chứa dữ liệu kiểu factor, các cột population, và total chứa dữ liệu kiểu numeric.\nmurders là một data.frame có 5 cột (còn gọi là các variables) và 51 dòng (còn gọi là các observations).Tên của 5 cột lần lượt là state, abb, region, population, và total.Hàm str() cho chúng ta thấy thấy được kiểu dữ liệu của từng cột: cột state và cột abb chứa dữ liệu kiểu character; cột region chứa dữ liệu kiểu factor, các cột population, và total chứa dữ liệu kiểu numeric.Hàm glimpse() là một hàm số trong thư viện dplyr cũng thường được sử dụng để tìm hiểu về dữ liệu. Kết quả của hàm glimpse() tương tự như hàm str().Một hàm số khác cũng thường được sử dụng để người phân tích có cái nhìn tổng quan về dữ liệu là hàm summary(). Hàm số này có thể được áp dụng trên các đối tượng kiểu khác nhau, không nhất thiết phải là kiểu data.frame. Khi sử dụng trên data.frame, hàm summary() cho chúng ta nhiều thông tin hữu ích về dữ liệu. Thật vậy, bạn đọc có thể quan sát kết quả của hàm summary() trên dữ liệu murders:Có thể thấy rằng hàm summary() cho biết thông chi tiết hơn với str() về giá trị trong các cột dữ liệu:Ngoài kiểu dữ liệu của từng biến, summary() còn cung cấp các giá trị thống kê cho phép người phân tích dữ liệu có hình dung ban đầu về phân phối xác suất của các biến liên tục và tần suất xuất hiện của các giá trị trong biến rời rạc.Trong trường hợp cột dữ liệu có giá trị không quan sát được, hàm summary() cũng sẽ cho biết có bao nhiêu giá trị không quan sát được trong mỗi cột.Bạn đọc hãy sử dụng các hàm liệt kê ở trên để tìm hiểu về dữ liệu có tên gapminder trong thư viện dslabsXét về cấu trúc, có thể hiểu một data.frame là một trường hợp đặc biệt của đối tượng kiểu list trong R. Các phần tử con của một data.frame là các véc-tơ (cột) dữ liệu. Để lấy ra một cột dữ liệu của một data.frame chúng ta sử dụng ký tự $ để kết nối tên data.frame và tên cột dữ liệu. Ví dụ, để lấy giá trị của cột có tên là population từ dữ liệu murders, chúng ta viết câu lệnh như sau:Hoặc lấy ra cột có tên là region:Kiểu dữ liệu của cột region là kiểu factor. Về bản chất, một véc-tơ kiểu factor là một véc-tơ kiểu chuỗi ký tự nhưng được lưu trong R theo một cách hiệu quả hơn, tiết kiệm bộ nhớ, và thuận lợi cho người sử dụng khi phân tích dữ liệu. Trước hết, mỗi giá trị trong véc-tơ chuỗi ký tự sẽ được cho tương ứng với một số tự nhiên, bắt đầu từ 1 đến số lượng chuỗi ký tự khác nhau trong véc-tơ đó. Thay vì lưu chính xác giá trị của các chuỗi ký tự, véc-tơ kiểu factor lưu dữ liệu dưới dạng các số tự nhiên. Mỗi khi cần hiển thị giá trị của một chuỗi ký tự, véc-tơ kiểu factor sẽ tìm kiếm số tự nhiên tương ứng với giá trị của chuỗi ký tự đó. Cách lưu dữ liệu như vậy hiệu quả hơn về mặt bộ nhớ đặc biệt là khi trong véc-tơ chuỗi ký tự có nhiều giá trị bị lặp lại.Các hàm số summary() và table() có thể được sử dụng để tổng hợp thông tin về một véc-tơ kiểu factor:Từ kết quả của hàm table() trên véc-tơ region có thể thấy rằng:Biến region có 4 giá trị riêng biệt và quy tắc cho tương ứng mỗi giá trị đến các số tự nhiên là: Northeast:1; South:2; North Central:3, và West:4.Tần suất xuất hiện của các giá trị trong véc-tơ region\nNortheast xuất hiện 9 lần;\nSouth xuất hiện 17 lần;\nNorth Central xuất hiện có 12 lần;\nWest xuất hiện 13 lần.\nNortheast xuất hiện 9 lần;South xuất hiện 17 lần;North Central xuất hiện có 12 lần;West xuất hiện 13 lần.Trong hầu hết các trường hợp, dữ liệu cần xử lý và phân tích là dữ liệu được nhập từ các nguồn bên ngoài. Dữ liệu sau khi được nhập vào R sẽ được lưu dưới dạng data.frame để dễ dàng xử lý. Trong một vài trường hợp, bạn đọc sẽ cần tự tạo data.frame trực tiếp từ các câu lệnh R. Hàm số để tạo một data.frame là data.frame(). Các véc-tơ khai báo cho giá trị của các cột cần có độ dài bằng nhau nếu không R sẽ báo lỗi. Ví dụ, để tạo một data.frame có tên df với các cột lần lượt là id, names, grades, và result, chúng ta viết câu lệnh như sau:Khi lưu dữ liệu kiểu data.frame sẽ có một số nhược điểm khiến cho việc lấy dữ liệu từ nguồn bên ngoài vào bị hạn chế, chẳng hạn như tên cột dữ liệu bị tự động thay đổi nếu không phù hợp, hoặc kiểu dữ liệu bị tự động thay đổi. Để khắc phục các nhược điểm này, một kiểu đối tượng mới được phát triển để lưu dữ liệu trên môi trường làm việc của R, đó là kiểu tibble. Trong phần tiếp theo chúng ta sẽ thảo luận về đối tượng lưu dữ liệu này.","code":"\ndata()\nlibrary(dslabs) # Gọi thư viện dslabs\ndata(package = \"dslabs\") # Liệt kê những data trong dslabs\nclass(murders) # Trả lại kết quả là một data frame## [1] \"data.frame\"\n? murders # Cửa sổ help sẽ hiển thị mô tả về murders\nView(murders) # Hiển thị data.frame dưới dạng bảng\nhead(murders,k = 5) # Hiển thị k dòng đầu tiên của data.frame\nstr(murders) # Hiển thị cấu trúc của data.frame\nglimpse(murders) # Hiển thị cấu trúc của data.frame\nsummary(murders)##     state               abb                      region     population      \n##  Length:51          Length:51          Northeast    : 9   Min.   :  563626  \n##  Class :character   Class :character   South        :17   1st Qu.: 1696962  \n##  Mode  :character   Mode  :character   North Central:12   Median : 4339367  \n##                                        West         :13   Mean   : 6075769  \n##                                                           3rd Qu.: 6636084  \n##                                                           Max.   :37253956  \n##      total       \n##  Min.   :   2.0  \n##  1st Qu.:  24.5  \n##  Median :  97.0  \n##  Mean   : 184.4  \n##  3rd Qu.: 268.0  \n##  Max.   :1257.0\nmurders$population # in ra màn hình cột population của data.frame murders\nmurders$region # in ra màn hình cột region của data.frame murders\nsummary(murders$region) # Tổng hợp thông tin của vec-tơ dạng factor##     Northeast         South North Central          West \n##             9            17            12            13\ntable(murders$region) # cho kết quả tương tự như summary## \n##     Northeast         South North Central          West \n##             9            17            12            13\ndf<-data.frame( # Hàm data.frame() dùng để tạo data.frame tên df\n      id = paste(\"SV\",1:5), # Cột có tên là ID nhận giá trị \"SV1\",...,\"SV5\"\n      names = c(\"You\", \"Me\", \"Him\", \"Her\", \"John\"), # Cột names\n      grades = c(5.5, 1.5, 10.0, 9.0, 7.6), # Cột grades\n      result = c(TRUE, FALSE,TRUE, TRUE, TRUE)) # Cột result\ndf # hiển thị data.frame có tên df##     id names grades result\n## 1 SV 1   You    5.5   TRUE\n## 2 SV 2    Me    1.5  FALSE\n## 3 SV 3   Him   10.0   TRUE\n## 4 SV 4   Her    9.0   TRUE\n## 5 SV 5  John    7.6   TRUE"},{"path":"nhập-dữ-liệu-vào-r.html","id":"tibble","chapter":"Chương 5 Nhập dữ liệu vào R","heading":"5.2.2 Tibble","text":"Về cơ bản một tibble là cũng có thể hiểu là một data.frame với một vài điều chỉnh để giúp việc lấy dữ liệu từ nguồn bên ngoài vào và thực hiện phân tích trở nên dễ dàng hơn. Theo kinh nghiệm của chúng tôi, ở mức độ phân tích dữ liệu thông thường, sự khác khác nhau giữa tibble và data.frame là không đáng kể. Sự khác nhau cơ bản giữu hai đối tượng này có thể liệt kê như sau:Thứ nhất, khi một tibble ra màn hình sẽ chỉ có 10 dòng đầu được hiển thị và số lượng cột được sẽ luôn khớp với kích thước cửa sổ Console hiện tại. Việc này giúp cho cửa sổ Console không bị tràn dòng giống như khi chúng ta data.frame có kích thước lớn. Ngoài ra, khi hiển thị trên cửa sổ Console, thông tin về kiểu dữ liệu của cột cũng sẽ xuất hiện ngay dưới tên cột. Thư viện để làm việc trên đối tượng tibble là thư viện có cùng tên. Bạn đọc có thể sử dụng hàm as_tibble() để đổi một data.frame sang kiểu tibble và dùng hàm .data.frame() để thực hiện phép đổi ngược lại. Bạn đọc có thể thực hiện một tibble trực tiếp lên màn hình Console mà không gặp phải vấn đề về tràn dòng như ví dụ dưới đây:Thứ hai, khi lấy dữ liệu từ nguồn ngoài, tibble không đổi tên cột dù tên cột không phải là kiểu tên cho phép trong R. Đồng thời, khi tạo một tibble, bạn đọc có thể đặt tên biến (cột) là một tên không được phép sử dụng với tên biến thông thường trong R.Thứ ba, khi dữ liệu từ nguồn bên ngoài được lưu vào một tibble, kiểu dữ liệu sẽ không thay đổi.Hàm tibble() được sử dụng để tạo ra một tibble trong R. Trong ví dụ dưới đây, chúng tôi tạo ra một dữ liệu có 3 cột với tên biến đều không được sử dụng làm tên biến trong R, tuy nhiên R vẫn không báo lỗi và dữ liệu được tạo ra có các cột có tên không thay đổi:Nếu thay thế hàm tibble() trong đoạn câu lệnh trên bằng hàm data.frame() thì data.frame được tạo thành sẽ tự động thay đổi tên cộtBạn đọc có thể thấy rằng dữ liệu có tên df khi được lưu dưới dạng data.frame có tên các cột đã tự động thay đổi. Việc tự động thay đổi tên cột sẽ khiến cho người phân tích dữ liệu gặp khó khăn khi kiểm soát tên biến mỗi khi lấy dữ liệu từ nguồn ngoài, đặc biệt đối với những dữ liệu lớn và phức tạp.Những điểm khác nhau giữa tibble và data.frame sẽ được tiếp tục đề cập ở các phần tiếp theo của chương khi chúng tôi thảo luận về các hàm dùng để nhập dữ liệu vào R.","code":"\nlibrary(tibble)\ntrump_tweets # in một data.frame sẽ bị tràn dòng\nas_tibble(trump_tweets) # Hiển thị 1 tibble hiệu quả hơn.\ntib<-tibble( # hàm tibble dùng để tạo tibble\n  \":D\" = c(1,2,3), # có thể dùng tên cột là \":D\"\n  \":p\" = c(\"X\",\"Y\",\"Z\"), # có thể dùng tên cột là \":p\"\n  \"1\" = 2 # có thể dùng tên cột là \"1\"\n)\ntib## # A tibble: 3 × 3\n##    `:D` `:p`    `1`\n##   <dbl> <chr> <dbl>\n## 1     1 X         2\n## 2     2 Y         2\n## 3     3 Z         2\ndf<-data.frame( # tạo data.frame thay vì tibble\n  \":D\" = c(1,2,3), # data.frame sẽ đổi tên cột cho phù hợp\n  \":p\" = c(\"X\",\"Y\",\"Z\"), # data.frame sẽ đổi tên cột cho phù hợp\n  \"1\" = 2 # data.frame sẽ đổi tên cột cho phù hợp\n)\ndf # hãy quan sát xem tên cột của df thay đổi như thế nào##   X.D X.p X1\n## 1   1   X  2\n## 2   2   Y  2\n## 3   3   Z  2"},{"path":"nhập-dữ-liệu-vào-r.html","id":"nhập-dữ-liệu-bằng-hàm-có-sẵn","chapter":"Chương 5 Nhập dữ liệu vào R","heading":"5.3 Nhập dữ liệu bằng hàm có sẵn","text":"Dữ liệu từ các nguồn ngoài tồn tại ở nhiều định dạng khác nhau được lưu và trích xuất từ các phần mềm/hệ thống khác nhau. Một trong những điểm mạnh của phần mềm R là khả năng đọc được hầu hết các định dạng khác nhau của dữ liệu. Ngay trong các thư viện sẵn có khi chúng ta cài đặt R, đã có một danh sách các hàm cho phép chúng ta đọc dữ liệu từ nhiều định dạng. Một số hàm điển hình và định dạng dữ liệu tương ứng được liệt kê trong các Bảng 5.1\nBảng 5.1: Danh sách hàm có sẵn để lấy dữ liệu từ nguồn bên ngoài\nĐể đọc dữ liệu từ nguồn ngoài bằng một trong các hàm được liệt kê trong Bảng 5.1, cấu trúc câu lệnh sẽ như sau:trong đó TenHamSo là tên của hàm đọc dữ liệu; Duong_dan là đường dẫn đến folder chứa dữ liệu; và Ten_file là tên file chứa dữ liệu bao gồm cả phần định dạng.Khi lấy dữ liệu từ các nguồn bên ngoài vào bằng các câu lệnh có sẵn, tên của các cột dữ liệu có thể bị thay đổi một số tên cột không thể được dùng để đặt tên của data.frame. đó, bạn đọc hãy luôn kiểm tra lại tên các cột dữ liệu sau khi đọc. Hàm names() cho biết tên các cột của một data.frame.Để đổi tên của các biến trong data.frame có tên df ở trên, bạn đọc sử dụng hàm cần gán names() để gọi tên các biến sau đó gán giá trị của hàm này bằng một véc-tơ kiểu chuỗi ký tự chứa tên các cột. Hãy đảm bảo rằng độ dài của vec-tơ chứa tên cột bằng số cột của df nếu không sẽ có cảnh báo từ R.Thực hành:Bạn đọc hãy tìm trên máy tính của mình các file dữ liệu có định dạng như trong Bảng 5.1 sau đó hãy sử dụng hàm số tương ứng để đọc dữ liệu vào R.Mặc dù R đã hỗ trợ việc đọc dữ liệu từ hầu hết các định dạng khác nhau, tuy nhiên khi dữ liệu ngày càng lớn và phức tạp thì các hàm đọc dữ liệu sẵn có sẽ không còn đáp ứng được nhu cầu. Chính vì thế có các thư viện được thiết kế riêng cho việc đọc dữ liệu. Trong các phần tiếp theo chúng ta sẽ thảo luận về các thư viện như vậy và các ưu thế khi sử dụng các thư viện này với việc sử dụng các hàm sẵn có.","code":"\nTenHamSo(Duong_dan/Ten_file)\ndf<-read.csv(header = TRUE,\n              text = \"@1,@2\n                      1,2\n                      3,4\") # sử dụng read.csv để đọc đoạn text\nnames(df) # hiển thị tên của các cột## [1] \"X.1\" \"X.2\"\nnames(df)<-c(\"c1\",\"c2\") # đổi tên 2 cột của data.frame df\ndf # in data.frame df##   c1 c2\n## 1  1  2\n## 2  3  4"},{"path":"nhập-dữ-liệu-vào-r.html","id":"nhập-dữ-liệu-bằng-thư-viện-readr.","chapter":"Chương 5 Nhập dữ liệu vào R","heading":"5.4 Nhập dữ liệu bằng thư viện readr.","text":"Thư viện readr là một (1) trong tám (8) thư viện được tích hợp sẵn trong thư viện tổng hợp tidyverse chuyên dành cho việc phân tích dữ liệu. Thư viện readr có các câu lệnh để đọc dữ liệu tương tự như các câu lệnh sẵn có trong R nhưng đặc biệt hiệu quả hơn về tốc độ (thời gian) đọc dữ liệu. Chẳng hạn như hàm số dùng để đọc các file định dạng .csv trong thư viện readr là hàm read_csv() thường được dùng thay thế cho hàm có sẵn read.csv() khi chúng ta cần đọc các file có dung lượng lớn.Chúng ta thực hiện một ví dụ như sau để sánh thời gian đọc dữ liệu của hàm read_csv() và hàm read.csv(): chúng ta sẽ tạo hai file dữ liệu bao gồm test1.csv và test2.csv là các file chứa các số được sinh ngẫu nhiên. Dữ liệu test1.csv có \\(10^2\\) hàng và \\(10^4\\) cột, trong khi dữ liệu test2.csv có \\(10^2\\) hàng và \\(10^5\\) cột. Chúng ta sẽ dùng hàm sẵn có và hàm read_csv() cùng đọc hai dữ liệu này sau đó sánh thời gian đọc dữ liệu. Các câu lệnh dưới đây dùng để tạo và lưu các dữ liệu:Bạn đọc có thể kiểm tra kích thước của các file test1.csv và test2.csv trên máy tính để thấy rằng dung lượng của các file lần lượt là 18 Mega byte và 180 Mega byte. Chúng ta sẽ kiểm tra thời gian mà các hàm read.csv() và read_csv() nhập dữ liệu đối với dữ liệu test1.csv trước:Đối với dữ liệu test1.csv thì thời gian nhập dữ liệu của read_csv() có nhanh hơn nhưng không có sự khác biệt đáng kể. Tuy nhiên sự khác biệt sẽ rõ ràng khi nhập dữ liệu test2.csv. Bạn đọc cân nhắc khi dùng hàm read.csv() đọc dữ liệu bởi thời gian nhập dữ liệu với những file có dung lượng hơn 100 Mega bytes có thể lên đến hơn 20 phút.Trên máy tính của chúng tôi, hàm read_csv() sẽ mất khoảng 2 phút để đọc dữ liệu test2.csv, nghĩa là thời gian có thể nhanh hơn đến 10 lần. Điều này đặc biệt quan trọng mỗi khi chúng ta cần đọc các dữ liệu có kích thước lớn. Một lưu ý khác đối với read_csv() là dữ liệu sẽ được lưu dưới dạng một tibble, nghĩa là dữ liệu sẽ không bị thay đổi tên biến và kiểu giá trị của biến.Ngoài hàm read_csv(), thư viện readr còn có các hàm số khác để đọc các kiểu định dạng file khác nhau. Danh sách các hàm thường hay dùng được liệt kê trong bảng 5.2\nBảng 5.2: Danh sách hàm đọc dữ liệu của thư viện readr\nNgoài việc các hàm trong thư viện readr luôn lưu dữ liệu vào một tibble, một số lưu ý khác khi bạn đọc sử dụng các hàm số này là:Thứ nhất: các hàm số đọc dữ liệu của readr luôn hiểu hàng đầu tiên của dữ liệu là tên của các biến. đó, nếu thực sự hàng đầu tiên không phải là tên của biên, bạn đọc cần sử dụng tham số col_names và gán giá trị cho tham số này bằng FALSE. Thật vậy, hãy quan sát sự khác nhau giữa việc có sử dụng và không sử dụng col_names = FALSE trong ví dụ dưới đây:Bạn đọc có thể thấy rằng khi không sử dụng col_names = FALSE như trong đoạn câu lệnh thứ nhất, hàm read_csv() sẽ hiểu hàng đầu tiên, tương ứng với các số 1, 2, và 3, là tên các cột và dữ liệu chỉ được tính bắt đầu từ hàng thứ hai. Điều này giải thích tại sao kết quả nhận được là một tibble chỉ có 1 quan sát. Trong đoạn câu lệnh thứ hai, Khi chúng ta sử dụng col_names = FALSE, hàm read_csv() sẽ tự động đặt tên các cột là X1, X2, X3 và kết quả nhận được là một tibble có 2 quan sát.Khi dữ liệu được trích xuất từ nhiều nguồn khác nhau, trong một số trường hợp các dòng đầu tiên của dữ liệu là các đoạn văn bản được viết để mô tả về dữ liệu. đó khi sử dụng các hàm đọc dữ liệu, bạn đọc cần có thể sử dụng tham số skip = k để loại bỏ k dòng đầu tiên của file dữ liệu. Ví dụ, dữ liệu dưới đây có hai dòng đầu tiên là các đoạn văn bản không thuộc về dữ liệu, chúng ta loại bỏ đi hai dòng đó trong câu lệnh đọc dữ liệu như sau:Bạn đọc cũng có thể gán một véc-tơ chuỗi ký tự cho tham số col_names tạo tên cho các biến ngay khi gọi hàm read_csv(). Tuy nhiên để tránh sự phức tạp, chúng tôi khuyên bạn đọc hãy đặt tên cho các cột bằng các gọi hàm names() như chúng tôi đã đề cập ở trên.Cách sử dụng các hàm khác ngoài read_csv() được liệt kê trong Bảng 5.2 hoàn toàn tương tự và bạn đọc có thể tham khảo trong hướng dẫn của thư viện readr.Bạn đọc hãy thử kiểm tra xem các câu lệnh đọc dữ liệu dưới đây có vấn đề gì không và nếu có thể, bạn đọc hãy thử lựa chọn hàm hoặc thêm tham số phù hợp để đọc dữ liệu.","code":"\nx<-matrix(rnorm(10^6),10^2,10^4) # Ma trận 100 hàng, 10^4 cột\nwrite.csv(x,\"test1.csv\") # Ma tran thanh file .csv\nx<-matrix(rnorm(10^7),10^2,10^5) # Ma trận 100 hàng, 10^5 cột\nwrite.csv(x,\"test2.csv\") # Ma tran thanh file .csv\nstart<-proc.time() # lưu lại thời điểm trước khi chạy read.csv\ndat<-read.csv(\"test1.csv\") # dùng hàm read.csv để load dữ liệu\nproc.time() - start # tính thời gian hàm read.csv chạy\n\nstart<-proc.time() # lưu lại thời điểm trước khi chạy read_csv\ndat<-read_csv(\"test1.csv\") # dùng hàm read_csv để load dữ liệu\nproc.time() - start # tính thời gian hàm read_csv chạy\nstart<-proc.time() # lưu lại thời điểm trước khi chạy read.csv\ndat<-read.csv(\"test2.csv\") # !!! THỜI GIAN CHẠY CÓ THỂ LÊN ĐẾN 20-25 phút\nproc.time() - start # tính thời gian hàm read.csv chạy\n\nstart<-proc.time() # lưu lại thời điểm trước khi chạy read_csv\ndat<-read_csv(\"test2.csv\") # dùng hàm read_csv để load dữ liệu\nproc.time() - start # tính thời gian hàm read_csv chạy\nlibrary(readr)\n# Kết quả sẽ là một Tibble 1 hàng và 3 cột\nread_csv(\"1,2,3\n         4,5,6\") # Tên các cột là \"1\", \"2\", và \"3\"## # A tibble: 1 × 3\n##     `1`   `2`   `3`\n##   <dbl> <dbl> <dbl>\n## 1     4     5     6\n# Kết quả sẽ là một Tibble 2 hàng và 3 cột\nread_csv(\"1,2,3\n         4,5,6\", col_names = FALSE)## # A tibble: 2 × 3\n##      X1    X2    X3\n##   <dbl> <dbl> <dbl>\n## 1     1     2     3\n## 2     4     5     6\n# readr tự động đặt tên các cột X1, X2, X3\n# Kết quả sẽ là một Tibble 2 hàng và 3 cột\nread_csv(\"Trường Công nghệ\n        Khoa toán Kinh tế\n         1,2,3\n         4,5,6\", col_names = FALSE, skip = 2) # readr sẽ không đọc 2 dòng đầu## Rows: 2 Columns: 3\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## dbl (3): X1, X2, X3\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.## # A tibble: 2 × 3\n##      X1    X2    X3\n##   <dbl> <dbl> <dbl>\n## 1     1     2     3\n## 2     4     5     6\nread_csv(\"x,y\\n1,2,3\\n4,5,6\") # \\n thay cho xuống dòng\nread_csv(\"x,y,z\\n1,2\\n1,2,3,4\")\nread_csv(\"x,y\\n\\\",1,\\n,a,b\",col_names = FALSE)\nread_csv(\"x;y\\n1;2\\nx;y\") # Thử hàm số khác\nread_csv(\"x|y\\n1|2\") # Thử hàm số khác"},{"path":"nhập-dữ-liệu-vào-r.html","id":"tương-tác-giữa-r-với-microsoft-excel","chapter":"Chương 5 Nhập dữ liệu vào R","heading":"5.5 Tương tác giữa R với Microsoft Excel","text":"Speardsheet trong Microsoft Excel là công cụ rất phổ biến trong các môi trường làm việc liên quan đến lĩnh vực kinh tế và kinh doanh. Ngoài chức năng tính toán, phân tích, vẽ đồ thị rất phong phú và trực quan, Speardsheet cũng là một công cụ có thể dùng để lưu trữ dữ liệu khi cần. Thực tế là người phân tích dữ liệu trong môi trường kinh doanh sẽ thường xuyên nhận được dữ liệu từ các phòng ban, đơn vị khác trong các file có định dạng của Microsoft Excel như .xls, .xlsx, .xlsb, hoặc .xlsm.Bạn đọc có thể sử dụng trực tiếp Speardsheet để thực hiện những phân tích và tính toán đơn giản. Tuy nhiên để thực hiện các yêu cầu phức tạp hơn, chẳng hạn như khi làm việc trên các bảng có kích thước lớn, khi làm việc với nhiều bảng cùng lúc, hoặc khi thực hiện xây dựng các mô hình phức tạp trên dữ liệu, bạn cần phải sử dụng các công cụ phân tích dữ liệu cao cấp hơn, như R là một ví dụ.Ngoài hỗ trợ việc đọc dữ liệu từ các file được lưu dưới các định dạng của Microsoft Excel, R còn có thể truy cập và làm việc trực tiếp trên các Speardsheet mà không cần sử dụng Microsoft Excel. Các thư viện bổ sung mà chúng thôi thường sử dụng để có thể thực thi câu lệnh từ R, đọc dữ liệu và kết nối với Microsoft Excel là các thư viện readxl và openxlsx. Thư viện readxl bao gồm các hàm đọc dữ liệu từ nhiều định dạng khác nhau từ Excel trong khi thư viện openxlsx có tính năng cho phép sử dụng các câu lệnh của R để điều khiển, tính toán, và định dạng các Spreadsheet mà không cần mở Microsoft Excel. Cách sử dụng các hàm cơ bản trong hai thư viện này được trình bày trong các phần dưới đây.","code":""},{"path":"nhập-dữ-liệu-vào-r.html","id":"đọc-dữ-liệu-được-lưu-bằng-microsoft-excel","chapter":"Chương 5 Nhập dữ liệu vào R","heading":"5.5.1 Đọc dữ liệu được lưu bằng Microsoft Excel","text":"Hàm read_excel() được sử dụng để đọc các file được lưu bằng Microsoft Excel. Hàm số sẽ hỗ trợ đọc các file có định dạng .xlsx, .xlsm, và .xls. Hai biến thể khác của hàm read_excel() là read_xlsx() và read_xls() được sử dụng khi chúng ta biết chính xác định dạng của file cần đọc. Các tham số thường được sử dụng trong các hàm này được liệt kê như sau:Tham số sheet cho biết tên của sheet của trong file mà bạn muốn đọc dữ liệu từ đó. Tham số này có ý nghĩa khi file chúng ta cần lấy dữ liệu có nhiều sheet. Nếu không sử dụng tham số này trong hàm read_excel(), giá trị mặc định sẽ là sheet thứ nhất của file.Tham số range được sử dụng nếu bạn đọc chỉ muốn lấy dữ liệu từ một phần chứ không phải toàn bộ sheet. Chẳng hạn như khi khai báo range = ‘A1:E100’, hàm read_excel() sẽ chỉ lấy dữ liệu từ cell A1 đến cell E100 của sheet tương ứng.Tham số col_names nhận một trong hai giá trị là TRUE hoặc FALSE. Giá trị TRUE cho biết có sử dụng hàng đầu tiên làm tên các biến, trong khi giá trị FALSE cho biết không lấy hàng đầu tiên làm tên cột.Tham số skip cho biết số lượng dòng sẽ bỏ qua trước khi bắt đầu đọc dữ liệu. Nếu bạn sử dụng đồng thời hai tham số range và skip thì hàm read_excel() sẽ ưu tiên tham số range và bỏ qua tham số skipNgoài ra hàm read_excel() còn có các tham số khác có thể hữu ích trong nhiều trường hợp như col_types hay n_max. Bạn đọc cần đọc mô tả của hàm số read_excel() để hiểu chính xác hơn về các tham số này.Tóm lại, để đọc dữ liệu được lưu bằng Microsoft Excel, bạn đọc cần lựa chọn hàm tương ứng với định dạng của file, sau đó sử dụng các tham số được liệt kê ở trên để điều chỉnh việc đọc dữ liệu. Các câu lệnh dưới đây được sử dụng để đọc dữ liệu nằm trong range được giới hạn từ cell A1 đến cell E100, trong sheet có tên ‘ws1’, và file có tên ‘wb1.xlsx’Thực hành: bạn đọc hãy tìm các file dữ liệu có định dạng khác nhau được lưu bằng Microsoft Excel trên máy tính của mình và sử dụng các hàm tương ứng trong thư viện readxl để đọc dữ liệu.","code":"\nsetwd(path) # Đặt đường dẫn đến folder chứa file\ndat<-read_xlsx(\"wb1.xlsx\",\n               sheet = \"ws1\",\n               range = \"A1:E100\",\n               col_names = TRUE)"},{"path":"nhập-dữ-liệu-vào-r.html","id":"tương-tác-r-với-spreadsheet","chapter":"Chương 5 Nhập dữ liệu vào R","heading":"5.5.2 Tương tác R với Spreadsheet","text":"Ngoài việc lấy dữ liệu từ các file được lưu bằng Microsoft Excel, bạn đọc cũng có thể sử dụng R để thực hiện tính toán trên các spreardsheet và lưu lại kết quả dưới định dạng của Microsoft Excel mà không cần phải mở file trực tiếp . Các hàm số: loadWorkbook(), addWorksheet(), writeData(), và saveWorkbook() trong thư viện openxlsx có thể giúp chúng ta thực hiện được các yêu cầu này.Hàm loadWorkbook() đượpc sử dụng để mở một excel workbook và lưu thành một đối tượng kiểu workbook trên R. Câu lệnh dưới đây dùng để lấy thông tin từ file có tên là ‘mau bd.xlsx’ trong đường dẫn tương ứng và sau đó lưu thông tin vào một đối tượng kiểu workbook với tên wb1:Hàm str() có thể sử dụng để xem cấu trúc của đối tượng wb1. Bạn đọc cần lưu ý là các workbook lớn có thể khiến cho kết quả của hàm str() khi hiển thị trở nên khó hiểu.Bạn đọc có thể hiểu đối tượng kiểu workbook sẽ hoạt động giống như một đối tượng kiểu list mà mỗi list con tương ứng với một sheet của workbook đó. Bạn đọc có thể sử dụng hàm names() để biết wb1 có những đối tượng con nào:Hàm addWorksheet() được sử dụng để thêm một worksheet vào trong một đối tượng workbook. Cấu trúc câu lệnh của hàm addWworksheet() khá đơn giản và các tham số được sử dụng chủ yếu là để thiết kế định dạng cho worksheet mới. Ví dụ, câu lệnh sau được sử dụng để thêm vào workbook wb1 một worksheet có tên là Sheet 2Hàm writeData() có thể được sử dụng để thay đổi và sửa thông tin trên đối tượng kiểu workbook. Các tham số thường được sử dụng với hàm writeData() bao gồm có:Tham số startCol: chỉ số của cột trên cùng của worksheet mà chúng ta bắt đầu ghi thông tin lên. Nếu không sử dụng tham số này, chỉ số cột đầu tiên sẽ luôn là 1, nghĩa là cột của workssheet mà chúng ta muốn thay đổi thông tin.Tham số statRow: chỉ số của hàng trên worksheet mà chúng ta bắt đầu ghi thông tin lên. Nếu không sử dụng tham số này, chỉ số hàng đầu tiên sẽ luôn là hàng 1 của workssheet mà chúng ta muốn thay đổi thông tin.Tham số colNames: nhận giá trị bằng TRUE hoặc FALSE. Giá trị colNames = TRUE cho biết có ghi nhận thông tin tên cột của dữ liệu (hoặc véc-tơ) vào hàng đầu tiên. Giá trị colNames = FALSE nghĩa là không ghi nhận tên cột của dữ liệu hay véc-tơ vào hàng đầu tiên.Tham số rowNames: : nhận giá trị bằng TRUE hoặc FALSE. Giá trị TRUE cho biết có ghi nhận thông tin tên hàng của dữ liệu (hoặc véc-tơ) vào cột đầu tiên của worksheet. Giá trị FALSE nghĩa là không ghi nhận tên hàng của dữ liệu hay véc-tơ vào hàng đầu tiên của worksheet.Đoạn câu lệnh dưới đây sẽ lưu thông tin của một đối tượng kiểu data.frame có tên là women là một data.frame có sẵn vào worksheet có tên Sheet 2 của wb1. Dữ liệu sẽ được ghi vào bắt đầu từ hàng thứ nhất và cột thứ nhất, với tên của các biến trong dữ liệu ở trên hàng thứ nhất:Hàm số saveWorkbook() được sử dụng để lưu một đối tượng workbook thành một excel workbook có định dạng phù hợp:Bạn đọc có thể sử dụng Microsoft Excel để mở Workbook có tên ‘mau bd1.xlsx’ và xem thông tin về dữ liệu women ở trong worksheet có tên là “Sheet 2” của Workbook này. Trong hàm saveWorkbook(), tham số overwrite nhận giá trị TRUE có nghĩa là nếu trong đường dẫn tương ứng đã có file có tên trùng với tên Workbook mới thì sẽ lưu Workbook mới thay thế cho Workbook cũ có trùng tên.","code":"\nwb1<-loadWorkbook(\"../KHDL_KTKD Final/Dataset/mau bd.xlsx\")\nstr(wb1)\nclass(wb1)## [1] \"Workbook\"\n## attr(,\"package\")\n## [1] \"openxlsx\"\nnames(wb1)## [1] \"Sheet\"  \"Sheet1\"\naddWorksheet(wb1, \"Sheet 2\")\nwriteData(wb1, \"Sheet 2\", women,\n          startCol = 1, startRow = 1,\n          colNames = TRUE, rowNames = FALSE)\nsaveWorkbook(wb1, \"mau bd1.xlsx\", overwrite = TRUE)"},{"path":"nhập-dữ-liệu-vào-r.html","id":"kết-nối-r-với-cơ-sở-dữ-liệu","chapter":"Chương 5 Nhập dữ liệu vào R","heading":"5.6 Kết nối R với cơ sở dữ liệu","text":"Có thể sử dụng R như một công cụ để kết nối vào các cơ sở dữ liệu (database) và viết các câu lệnh truy vấn từ R vào các cơ sở dữ liệu. Để thực hiện được việc này, trước tiên, bạn đọc cần phải cài đặt một Open Database Connectivity (ODBC), được gọi là kết nối cơ sở dữ liệu mở. Kết nối này giúp cho hệ điều hành máy tính mà chúng ta cài đặt phần mềm R tương thích với hệ quản lý cơ sở dữ liệu mà chúng ta cần sử dụng. Chúng tôi sử dụng hệ điều hành Windows và hệ quản trị cơ sở dữ liệu MySQL nên chúng tôi sẽ lựa chọn ODBC cho Windows và MySQL. Bạn đọc tham khảo các ODBC cho MySQL với các hệ điều hành khác (Linux, MacOS) tại địa chỉhttps://dev.mysql.com/downloads/connector/odbc/Tại thời điểm nhóm tác giả viết cuốn sách này, ODBC cho hệ điều hành Windows đang là phiên bản 8.0. Sau khi cài đặt ODBC lên hệ điều hành, bạn đọc đã có thể sử dụng R để truy cập vào một cơ sở dữ liệu và thực hiện các câu lệnh truy vấn dữ liệu trên cơ sở dữ liệu đó trên R với sự trợ giúp của thư viện DBI. Sau khi cài đặt thư viện DBI, bạn đọc cần tạo một kết nối giữa R và cơ sở dữ liệu bằng hàm dbConnect()Trong câu lệnh ở trên,Biến con là biến lưu kết nối mà chúng ta sẽ gọi ra mỗi khi truy cập vào cơ sở dữ liệu.Giá trị gán cho tham số Server của hàm dbConnect() là ten_server là địa chỉ của máy tính lưu trữ cơ sở dữ liệu. Nếu cơ sở dữ liệu nằm trên máy tính cá nhân, ten_server thường được gán bằng ‘localhost’. Nếu cơ sở dữ liệu được lưu trên một máy tính server, ten_server được gán bằng địa chỉ của máy tính server đó.Tham số Database cần được gán cho giá trị là tên của cơ sở dữ liệu.Các tham số UID và PWD lần lượt là tên người sử dụng và mật mã được cấp để truy cập vào cơ sở dữ liệu.Sau khi đã tạo được kết nối, bạn đọc có thể thực hiện các câu lệnh truy vấn dữ liệu từ R với hàm DBI::dbGetQuery(). Quy tắc viết câu lệnh truy vấn từ R như sautrong đó Cau_lenh_truy_van là câu lệnh truy vấn được lưu dưới dạng biến chuỗi ký tự. Ví dụ, bạn đọc muốn lấy ra thông tin của tất cả những khách hàng có ngày sinh là ngày 01 tháng 01 năm 2000 từ một bảng có tên Life_Insured từ một cơ sở dữ liệu có tên tktdb, bạn đọc viết câu lệnh như sauCác hệ quản trị cơ sở dữ liệu cho phép tìm kiếm, truy vấn, và sắp xếp dữ liệu hiệu quả và tiết kiệm thời gian hơn với các phần mềm phân tích dữ liệu như R hay Python. đó, nếu cần thiết có các phép tìm kiếm, lọc, sắp xếp dữ liệu trước khi phân tích bạn đọc nên thực hiện các phép biến đổi trên các câu lệnh SQL trước khi nhập liệu vào R.","code":"\nlibrary(DBI)\ncon <- dbConnect(odbc::odbc(), .connection_string = \"Driver={MySQL ODBC 8.0 Unicode Driver};\",\n    Server = \"ten_serve\", Database = \"db_name\", UID = \"ID\", PWD = \"password\")\nDBI::dbGetQuery(\"Cau_lenh_truy_van\")\nsql <- \"select * from tktdb.Life_Insured\n      where DOB = '2000-01-01'\" # Viết chính xác câu lệnh truy vấn trên MySQL\ndf <- DBI::dbGetQuery(sql) # df sẽ lưu kết quả của câu lệnh truy vấn"},{"path":"tiền-xử-lý-dữ-liệu.html","id":"tiền-xử-lý-dữ-liệu","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"Chương 6 Tiền xử lý dữ liệu","text":"","code":""},{"path":"tiền-xử-lý-dữ-liệu.html","id":"tiền-xử-lý-dữ-liệu-là-gì","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.1 Tiền xử lý dữ liệu là gì?","text":"Tiền xử lý dữ liệu là một công việc đòi hỏi sự tỉ mỉ cẩn thận và là một trong những bước quan trọng nhất trong một quy trình làm việc trên dữ liệu. Tiền xử lý dữ liệu là tập hợp tất cả các bước kỹ thuật nhằm đảm bảo cho dữ liệu bạn sử dụng phân tích hoặc xây dựng mô hình được đảm bảo về định dạng, giá trị, và ý nghĩa. Hiểu một cách đơn giản, tiền xử lý dữ liệu là quá trình biến dữ liệu thô thành dữ liệu có thể sử dụng được để phân tích và đưa ra kết quả.Khi làm việc với dữ liệu, thực tế là đến hơn 50% các trường hợp bạn đọc sẽ nhận được những dữ liệu ở dạng thô chưa qua tiền xử lý. Thông thường thì đối với những dữ liệu được nhập và xuất ra qua một hệ thống được phát triển đầy đủ, công việc tiền xử lý chỉ cần một vài bước cơ bản để đi đến kết quả. Tuy nhiên, trong trường hợp dữ liệu bạn nhận được là dữ liệu được nhập một cách thủ công, qua tay nhiều người nhập, hoặc là dữ liệu thu thập tự động từ các website, thì đây thực sự sẽ là một vấn đề lớn. Tiền xử lý dữ liệu trong tình huống như vậy có thể chiếm từ 80% đến 90% thời gian công việc của bạn!Các vấn đề thường gặp phải khi làm việc với một dữ liệu thô thường xuất phát từ hai nguyên nhân:Thứ nhất là dữ liệu sai định dạng, nghĩa là trong cùng một cột dữ liệu có các biến kiểu khác nhau hoặc kiểu của biến không đúng như quy ước.Thứ nhất là dữ liệu sai định dạng, nghĩa là trong cùng một cột dữ liệu có các biến kiểu khác nhau hoặc kiểu của biến không đúng như quy ước.Thứ hai là dữ liệu chứa giá trị không quan sát được hoặc chứa các giá trị ngoại lai. Các giá trị ngoại lai thường được gọi là các outliers.Thứ hai là dữ liệu chứa giá trị không quan sát được hoặc chứa các giá trị ngoại lai. Các giá trị ngoại lai thường được gọi là các outliers.Hãy quan sát một ví dụ như sau: bạn nhận được dữ liệu về 3 ứng cử viên từ bộ phận nhân sự và bạn muốn xem xét độ tuổi trung bình của những ứng cử viên và tỷ lệ Nam/Nữ trong danh sách ứng tuyển\nBảng 6.1: Dữ liệu thô từ nguồn ngoài\nĐây là một dữ liệu không thể sử dụng để phân tích bởi vì giá trị trong các cột ngày sinh là không đúng định dạng ngày tháng và có các giá trị không quan sát được ở cột giới tính. Nếu sử dụng dữ liệu này để phân tích mà bỏ qua việc tiền xử lý dữ liệu thì kết quả sẽ sai lệch hoàn toàn với bản chất của dữ liệu:Giả sử bộ phận nhân sự muốn biết độ tuổi trung bình của các ứng cử viên. Không thể trả lời câu hỏi này nếu bỏ qua việc tiền xử lý vì cột ngày sinh đang có dạng chuỗi ký tự và định dạng ngày tháng là không thống nhất.Bộ phận nhân sự muốn biết tỷ lệ Nam/Nữ tham gia ứng tuyển. Cũng không thể trả lời câu hỏi này vì có nhiều giá trị không quan sát được trong cột giới tính. Nếu bỏ qua những giá trị không có quan sát, tỷ lệ giới tính Nam là 100%. Nhưng con số này rõ ràng không chính xác!Tiền xử lý dữ liệu không chỉ bao gồm các công cụ kỹ thuật mà còn yêu cầu cả kiến thức phổ thông và kiến thức chuyên môn nghiệp vụ của người xử lý dữ liệu. Khi có vấn đề gây khó hiểu về dữ liệu nhận được, điều trước hết cần làm đó là liên hệ với người chủ dữ liệu để kiểm tra lại thông tin. Khi việc này là không thể thực hiện được, người xử lý dữ liệu sẽ phải đưa ra các phán đoán về dữ liệu đó dựa trên hiểu biết của mình.Giả sử không thể có thêm thông tin nào từ nơi cung cấp dữ liệu, chúng ta cần phải đưa ra phán đoán với dữ liệu kể trên. Trước hết, với cột ngày sinh của các nhân viên:Giá trị 01/02/98 có khả năng cao là ngày 01 tháng 02 năm 1998 quy ước phổ biến ở Việt Nam là viết theo thứ tự ngày -> tháng -> năm.Giá trị 12/17/1999 có khả năng cao là ngày 17 tháng 12 năm 1999. Khi gặp các trường hợp này nhiều khả năng người nhập dữ liệu sử dụng format ngày tháng của Microsoft Excel.Giá trị 1-1-1992 có khả năng cao là ngày 01 tháng 01 năm 1992.Như vậy với mỗi giá trị trong cột ngày sinh, bạn đọc cần một phép biến đổi khác nhau để đưa dữ liệu về đúng với định dạng. Chúng ta sẽ sử dụng hàm .Date() với tham số format để chỉnh định dạng của các biến ngày tháng và lưu vào một véc-tơ có tên là DOB như sauVéc-tơ DOB được tính toán trong các câu lệnh ở trên chứa giá trị ngày sinh kiểu dạng ngày tháng đúng định dạng của các ứng cử viên và bạn đọc có thể sử dụng làm đầu vào để tính tuổi của các ứng cử viên.Đối với cột giới tính của nhân viên:Giới tính của ứng cử viên có tên Trần Văn Cường là không quan sát được tuy nhiên theo tên của ứng cử viên thì nhiều khả năng đây là Nam.Giới tính của ứng cử viên Lê Thị Loan là không quan sát được tuy nhiên theo tên của ứng cử viên thì nhiều khả năng đây là Nữ.Sau những bước xử lý như trên, chúng ta đã có một dữ liệu được định dạng chính xác như ở dưới. Đây là một dữ liệu đã được làm sạch và sẵn sàng để trả lời cho các câu hỏi như độ tuổi trung bình hay tỷ lệ Nam/Nữ của các ứng cử viên.\nBảng 6.2: Dữ liệu thô sau tiền xử lý\nCác bước xử lý dữ liệu như trên mặc dù đơn giản nhưng lại là điển hình của tiền xử lý dữ liệu. Dữ liệu chúng ta nhận được sẽ ít khi được định dạng chuẩn và sẵn sàng cho mục đích phân tích. Để xử lý những giá trị sai định dạng, hoặc thay thế cho các giá trị không quan sát, hoặc loại bỏ đi các giá trị ngoại lai, người làm dữ liệu phải sử dụng kiến thức phổ thông, kiến thức nghiệp vụ để làm sạch và đưa ra những dự đoán tốt nhất có thể.","code":"\nDOB<-rep(as.Date(\"1900-01-01\"),3)\nDOB[1]<-as.Date(\"01/02/98\", format = \"%d/%m/%y\")\nDOB[2]<-as.Date(\"12/17/1999\", format = \"%m/%d/%Y\")\nDOB[3]<-as.Date(\"1-1-1992\", format = \"%d-%m-%Y\")"},{"path":"tiền-xử-lý-dữ-liệu.html","id":"định-dạng-cột-dữ-liệu-sử-dụng-thư-viện-readr","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.2 Định dạng cột dữ liệu sử dụng thư viện readr","text":"","code":""},{"path":"tiền-xử-lý-dữ-liệu.html","id":"quy-tắc-định-dạng-tự-động-của-readr","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.2.1 Quy tắc định dạng tự động của readr","text":"Trong phần trước, chúng tôi đã giới thiệu đến bạn đọc các hàm số trong thư viện readr dùng để đọc dữ liệu từ nguồn ngoài. Bên cạnh hỗ trợ đọc dữ liệu, readr còn có các hàm số để hỗ trợ tiền xử lý dữ liệu. Trước hết, mỗi khi đọc dữ liệu từ các nguồn ngoài vào R, thư viện readr có các quy tắc chung về định dạng kiểu dữ liệu cho các biến. Các quy tắc chung đó được tổng hợp trong Bảng 6.3. Để đảm bảo thời gian đọc dữ liệu không bị kéo dài, mỗi khi đọc dữ liệu readr sử dụng 1000 hàng dữ đầu tiên của dữ liệu để dự đoán kiểu dữ liệu của từng biến bằng:\nBảng 6.3: Nguyên tắc định tự động định dạng kiểu dữ liệu của readr\nLưu ý rằng các giá trị không quan sát được không ảnh hưởng đến việc readr dự đoán kiểu dữ liệu của một cột, nghĩa là các hàm đọc dữ liệu sẽ bỏ qua các giá trị NA trong 1000 hàng đầu tiên để đưa ra phán đoán về kiểu dữ liệu của biến. Từ Bảng 6.3 có thể thấy rằng trong nhiều trường hợp, nhất là khi dữ liệu không được định dạng trước khi đưa vào R, readr sẽ lưu dữ liệu dưới dạng chuỗi ký tự.Khi đọc dữ liệu kiểu số, sự khác nhau trong cách sử dụng dấu thập phân là ‘.’ và ‘,’ có thể làm cho giá trị của biến kiểu số thay đổi về giá trị thật. Nếu bạn đọc không sử dụng thêm tham số trong hàm đọc dữ liệu, read_csv() luôn mặc định dấu thập phân là ‘.’ và trong khi hàm read_csv2() mặc định dấu thập phân là ‘,’. Hãy quan sát ví dụ dưới đây khi sử dụng hàm read_csv2() để đọc một dữ liệu kiểu số được định dạng không thống nhất:Lưu ý rằng hàm read_csv2() là hàm dùng để đọc dữ liệu mà các cột được phân tách bằng dấu ; và cho đầu ra là một tibble giống như các hàm đọc dữ liệu khác từ readr. Từ kết quả ở trên, có thể đưa ra nhận xét như sau:Trong cột C1 có các số đặc biệt như 1e-10 hay Inf và read_csv2() vẫn hiểu đây là các kiểu số thông thường.Trong cột C2 chứa các giá trị Trong cột 2.2 và Trong cột 3,2 và khi được đọc bằng hàm read_csv2() đã cho kết quả là véc-tơ kiểu số có hai phần tử lần lượt là 22 và 3.2. Điều này có nghĩa là read_csv2() bỏ qua dấu ‘.’ trong 2.2 và cho kết quả đầu ra là 22, trong khi giá trị 3,2 có dấu ‘,’ được hiểu là số thập phân.Tương tự, trong cột thứ ba (C3) giá trị 1.0 được hiểu là giá trị 10, trong khi 1.000 được hiểu là giá trị 1 vì ‘,’ được hiểu là dấu của số thập phân.Hàm read_csv2() không phân tích được kiểu dữ liệu trong các cột C4 và C5 nên kiểu dữ liệu của hai cột này trong tibble kết quả là kiểu chuỗi ký tự.Chúng ta tiếp tục xem xét quy tắc tự động định dạng véc-tơ kiểu logical qua ví dụ dưới đây:Như chúng tôi đã đề cập ở trên, hàm read_csv() được sử dụng để đọc dữ liệu từ nguồn ngoài có các cột ngăn cách nhau bằng dấu ‘,’. Có thể thấy rằng các giá trị tương ứng với biến logic được liệt kê trong Bảng 6.3 đều được hàm read_csv() hiểu đúng là kiểu logical.Chúng ta sẽ thảo luận về biến kiểu ngày tháng khi được định dạng tự động bằng readr. Như chúng tôi đã trình bày trong Bảng 6.3, readr chỉ có thể tự động định dạng đúng véc-tơ kiểu ngày tháng nếu giá trị từ nguồn bên ngoài vào được viết theo định dạng “yyyy-mm-dd” hoặc “yyyy/mm/dd”. Bạn đọc hãy quan sát ví dụ dưới đây:Từ kết quả có thể phân tích cách thức thư viện readr tự động định dạng dữ liệu kiểu ngày tháng như sau:Giá trị trong các cột được viết theo một trong hai kiểu định dạng là “yyyy-mm-dd” hoặc “yyyy/mm/dd” đều được hiểu là kiểu ngày tháng. Có thể thấy rằng các cột C1 và C2 đều được định nghĩa đúng kiểu ngày tháng.Cột C3 mặc dù giá trị hàng thứ hai bị viết ngược giá trị ngày với giá trị tháng nhưng readr vẫn ghi nhận đúng cột này là kiểu ngày tháng và ghi nhận đúng giá trị.Cột C4 và cột C5 không được hiểu là kiểu ngày tháng dữ liệu không được viết theo một trong hai định dạng trong Bảng 6.3Để tìm hiểu chi tiết hơn cách thư viện readr tự động định dạng kiểu giá trị của dữ liệu đọc từ nguồn bên ngoài, bạn đọc tham khảo hướng dẫn của hàm guess_parse(). Đây là hàm được mặc định sử dụng trong các hàm đọc dữ liệu với mục đích dự đoán kiểu giá trị của các biến.Khi thư viện readr không thể phân tích được định dạng của các biến, kiểu biến mặc định sẽ là kiểu chuỗi ký tự. Trong các phần tiếp theo, chúng ta sẽ thảo luận về các hàm được sử dụng để chuyển đổi các véc-tơ kiểu chuỗi ký tự như vậy thành kiểu dữ liệu đúng của véc-tơ đó.","code":"\nfile<-\"C1;C2;C3;C4;C5\n       1e-10;2.2;1.0;TRUE; 1.0.0.0\n       Inf;3,2;1,000.0;1;10%\"\n# Dữ liệu có 5 cột và 2 hàng\nread_csv2(file)## # A tibble: 2 × 5\n##        C1    C2    C3 C4    C5     \n##     <dbl> <dbl> <dbl> <chr> <chr>  \n## 1   1e-10  22      10 TRUE  1.0.0.0\n## 2 Inf       3.2     1 1     10%\nfile<-\"C1,C2,C3,C4,C5,C6\n        TRUE,t,True,false,F,true\n        F,F,FALSE,T,f,True\"\nread_csv(file)## # A tibble: 2 × 6\n##   C1    C2    C3    C4    C5    C6   \n##   <lgl> <lgl> <lgl> <lgl> <lgl> <lgl>\n## 1 TRUE  TRUE  TRUE  FALSE FALSE TRUE \n## 2 FALSE FALSE FALSE TRUE  FALSE TRUE\nfile<-\"C1,C2,C3,C4,C5\n        2020/01/12,2020-01-12,2020/01/12,2020/1/1,2020|1|1\n        2021-12-31,2021/12/31,2021/31/12,2021-12-31,2021-12-31\"\nread_csv(file)## # A tibble: 2 × 5\n##   C1         C2         C3         C4         C5        \n##   <date>     <date>     <date>     <chr>      <chr>     \n## 1 2020-01-12 2020-01-12 2020-01-12 2020/1/1   2020|1|1  \n## 2 2021-12-31 2021-12-31 NA         2021-12-31 2021-12-31"},{"path":"tiền-xử-lý-dữ-liệu.html","id":"định-dạng-véc-tơ-bằng-các-hàm-parse_","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.2.2 Định dạng véc-tơ bằng các hàm parse_()","text":"Với các cột dữ liệu mà không thể xác định được kiểu biến, thư viện readr sẽ lưu dưới dạng véc-tơ kiểu chuỗi ký tự. Để đưa biến về đúng với giá trị thật, bạn đọc cần định dạng lại các cột cho đúng với mong muốn. Các hàm parse_() trong thư viện readr hỗ trợ bạn đọc thực hiện các yêu cầu như vậy. Nhóm hàm parse_() có đầu vào là một véc-tơ kiểu chuỗi ký tự và đầu ra sẽ là kiểu dữ liệu mà bạn đọc mong muốn, bao gồm dữ liệu kiểu số, kiểu logic, kiểu thời gian, và kiểu chuỗi ký tự. Với mỗi định dạng khác nhau, nhóm hàm parse_() sẽ có hàm số tương ứng và có các tham số phù hợp để đáp ứng được yêu cầu về định dạng.","code":""},{"path":"tiền-xử-lý-dữ-liệu.html","id":"định-dạng-véc-tơ-kiểu-logic","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.2.2.1 Định dạng véc-tơ kiểu logic","text":"Định dạng lại một véc-tơ kiểu chuỗi ký tự thành kiểu logical là đơn giản nhất bởi các giá trị có thể nhận của biến logic chỉ bao gồm TRUE hoặc FALSE. Hàm số sử dụng trong trường hợp này là parse_logical(). Bạn đọc hãy quan sát ví dụ sau:Bạn đọc có thể thấy rằng tất cả các giá trị nằm trong véc-tơ x, ngoại trừ các giá trị ‘.’, ‘@’, ‘2’, đều được chuyển sang đúng với định dạng của biến logic. Có thể thấy rằng parse_logical() tự động đổi giá trị \"1\" thành TRUE và giá trị \"0\" thành FALSE. Tham số na trong hàm parse_logical() được sử dụng để khai báo các giá trị mà người phân tích dữ liệu cho rằng tương đương với giá trị không quan sát được khi chuyển đổi định dạng sang kiểu logic. Trong câu lệnh ở trên, sử dụng hay không sử dụng tham số na không làm thay đổi véc-tơ kết quả đầu ra. Tuy nhiên, trong một số trường hợp, giá trị NA lại được lưu bằng một chuỗi ký tự có ý nghĩa trong chuyển đổi định đạng, chẳng hạn như khi người lưu trữ dữ liệu ngầm định ký tự ‘0’ tương đương với không quan sát được. Ngoài ra, việc sử dụng tham số na sẽ ảnh hưởng đến kết quả của hàm problem() được sử dụng để liệt kê các giá trị mà không thể chuyển đổi sang dạng logic.Khi véc-tơ x có kích thước lớn, các phần tử không thể đổi sang kiểu logic sẽ được lưu vào một tibble để người phân tích dữ liệu có thể dễ dàng truy cập. Bạn đọc hãy quan sát ví dụ sau:. Bạn đọc sử dụng hàm problems() để xem danh sách các các giá trị này:Trong kết quả của hàm problem(), cột row cho biết vị trí của các phần tử trong véc-tơ x1 không thể đổi sang biến kiểu logic. Giá trị thực của các phần tử này nằm trong cột actual. Bạn đọc có thể quan sát các giá trị trong cột actual để tìm hiểu nguyên nhân tại sao hàm parse_logical() không thể hoạt động trên các giá trị này.","code":"\nx<-c(\"TRUE\",\"True\",\"1\",\"0\",\"2\",\".\",\"@\",\n     \"FALSE\",\"false\",\"f\",\"F\",\"T\",\"t\",\"true\",\"false\")\nparse_logical(x, na = c(\".\", \"@\"))##  [1]  TRUE  TRUE  TRUE FALSE    NA    NA    NA FALSE FALSE FALSE FALSE  TRUE\n## [13]  TRUE  TRUE FALSE\n## attr(,\"problems\")\n## # A tibble: 1 × 4\n##     row   col expected           actual\n##   <int> <int> <chr>              <chr> \n## 1     5    NA 1/0/T/F/TRUE/FALSE 2\nx1<-sample(x, 10^3, replace = TRUE)\ny<-parse_logical(x1)\nproblems(y)## # A tibble: 199 × 4\n##      row   col expected           actual\n##    <int> <int> <chr>              <chr> \n##  1     1    NA 1/0/T/F/TRUE/FALSE @     \n##  2     6    NA 1/0/T/F/TRUE/FALSE .     \n##  3    11    NA 1/0/T/F/TRUE/FALSE @     \n##  4    17    NA 1/0/T/F/TRUE/FALSE @     \n##  5    18    NA 1/0/T/F/TRUE/FALSE 2     \n##  6    28    NA 1/0/T/F/TRUE/FALSE @     \n##  7    29    NA 1/0/T/F/TRUE/FALSE .     \n##  8    34    NA 1/0/T/F/TRUE/FALSE 2     \n##  9    39    NA 1/0/T/F/TRUE/FALSE @     \n## 10    43    NA 1/0/T/F/TRUE/FALSE @     \n## # ℹ 189 more rows"},{"path":"tiền-xử-lý-dữ-liệu.html","id":"định-dạng-véc-tơ-kiểu-số","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.2.2.2 Định dạng véc-tơ kiểu số","text":"Các nguyên nhân thường dẫn đến việc các hàm đọc dữ liệu trong thư viện readr không thể tự động định dạng một véc-tơ có kiểu số là:Cách đánh số thập phân của các số trong véc-tơ. Chẳng hạn như tại Việt Nam số thập phân được sử dụng là dấu phẩy (,) trong khi R hiểu số thập phân là dấu chấm (.). Một số quốc gia khác trên thế giới như Pháp cũng sử dụng dấu thập phân là dấu phẩy.Cách viết các số sử dụng cùng với các ký tự chấm hoặc phẩy để người đọc dễ dàng đọc số đó. Chẳng hạn như tại Việt Nam, chúng ta viết số 1 tỷ với dấu chấm phân tách các số không như sau: 1.000.000.000. Tại Thụy Sỹ cách phân tách số lại được viết theo cách khác; số 1 tỷ được viết thành 1’000’000’000. Khi gặp các trường hợp này, chúng ta cần cung cấp cho R định dạng đúng của các số đó.Khi các con số đi kèm theo đơn vị, chẳng hạn như đi kèm với ký hiệu tiền tệ: “100.000 đồng”, “100.000 vnd”, hoặc đi kèm với ký hiệu % như 50%, các hàm đọc dữ liệu của thư viện readr cũng sẽ không thể tự động chuyển đổi các giá trị này sang kiểu số nếu không có gợi ý thích hợp.Bạn đọc có thể sử dụng parse_double() hoặc parse_number() khi gặp phải các vấn đề ở trên. Chẳng hạn như khi gặp vấn đề về dấu phẩy (,) đối với dấu thập phân, nghĩa là dữ liệu từ nguồn bên ngoài viết số thập phân sử dụng dấu phẩy (,), bạn đọc sử dụng parse_number() với tham số locale = locale(decimal_mark = ‘,’) để hàm đọc dữ liệu hiểu rằng phần thập phân được ngăn cách với phần nguyên bằng dấu phẩy (,) và có thể đổi định dạng véc-tơ kiểu chuỗi ký tự sang véc-tơ kiểu số thành công:Khi gặp phải vấn đề về việc sử dụng các ký tự không đúng định dạng để phân tách các giá trị đơn vị hàng nghìn, hàng triệu, hàng tỷ; chúng ta sử tham số grouping_mark trong hàm locate(). Ví dụ dưới đây sử dụng đồng thời hai tham số decimal_mark và grouping_mark của hàm locate() để biến đổi cách viết số thập phân theo kiểu viết của Việt Nam sang kiểu số và giữ đúng giá trị :Khi gặp phải chuỗi ký tự chứa biến kiểu số đi kèm với đơn vị tiền tệ, hoặc đơn vị %, hàm parse_number() vẫn cho phép chuyển đổi chuỗi ký tự sang kiểu số mà không cần sử dụng thêm tham số nào cả. Bạn đọc hãy quan sát ví dụ dưới đây:Bạn đọc cần thận trọng khi véc-tơ kiểu số có % ở phía sau. Hàm parse_number() loại bỏ ký tự % theo sau và giữa nguyên giá trị số đó. Áp dụng parse_number() trên giá trị 2.000,5 % cho kết quả là số 2000.5 chứ không phải là 20.005. Để có giá trị đúng kiểu số, chúng ta cần chia kết quả cho 100.","code":"\nx<-c(\"0,5\",\"1,5\") # Dấu thập phân là dấu phẩy\nparse_number(x, locale = locale(decimal_mark = \",\"))## [1] 0.5 1.5\nx<-c(\"1.000,5\",\"1.000.000,5\")\n# véc-tơ chứa các số\n# 1000,5: một nghìn phẩy năm\n# 1000000,5: một triệu phẩy năm\n# dấu thập phân là dấu \",\"\n# phân tách hàng nghìn, hàng triệu là dấu .\nparse_number(x, locale = locale(decimal_mark = \",\",\n                                grouping_mark = \".\"))## [1]    1000.5 1000000.5\nx<-c(\"1.000,5 đồng\",\"1.000.000,5 vnd\", \"2.000,5 %\")\n# số kiểu Việt Nam\n# có đơn vị tiền phía sau\n# có ký hiệu % phía sau\nparse_number(x, locale = locale(decimal_mark = \",\",\n                                grouping_mark = \".\"))## [1]    1000.5 1000000.5    2000.5"},{"path":"tiền-xử-lý-dữ-liệu.html","id":"định-dạng-véc-tơ-kiểu-thời-gian","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.2.2.3 Định dạng véc-tơ kiểu thời gian","text":"Hàm số parse_datetime() có thể sử dụng để chuyển đổi các véc-tơ kiểu chuỗi ký tự sang véc-tơ kiểu thời gian và véc-tơ kiểu ngày tháng.Hai tham số của hàm parse_datetime() mà bạn đọc cần lưu ý là tham số na và tham số format.Tham số na là một véc-tơ chứa các giá trị mà bạn đọc mặc định là các giá trị không quan sát được. Trong véc-tơ x ở trên, giá trị 01/01/1900 được gán cho tham số na mặc dù giá trị này là ngày tháng có ý nghĩa. Điều này khiến cho giá trị thứ ba trong véc-tơ kết quả có giá trị là NA. Nếu không sử dụng tham số na, giá trị thứ ba của véc-tơ kết quả sẽ là ngày 01 tháng 01 năm 1990. Đối với một vài hệ thống lưu dữ liệu, có thể xảy ra trường hợp các giá trị không được ghi nhận nhưng vẫn được gán một giá trị mặc định nào đó. Các giá trị mặc định này nếu giữ nguyên giá trị sẽ làm sai lệch phân tích. Giả sử với véc-tơ ở trên, nếu chúng ta biết giá trị mặc định gán cho các giá trị không quan sát được của hệ thống là 01/01/1900, việc gán giá trị này cho tham số na là cần thiết.Tham số na là một véc-tơ chứa các giá trị mà bạn đọc mặc định là các giá trị không quan sát được. Trong véc-tơ x ở trên, giá trị 01/01/1900 được gán cho tham số na mặc dù giá trị này là ngày tháng có ý nghĩa. Điều này khiến cho giá trị thứ ba trong véc-tơ kết quả có giá trị là NA. Nếu không sử dụng tham số na, giá trị thứ ba của véc-tơ kết quả sẽ là ngày 01 tháng 01 năm 1990. Đối với một vài hệ thống lưu dữ liệu, có thể xảy ra trường hợp các giá trị không được ghi nhận nhưng vẫn được gán một giá trị mặc định nào đó. Các giá trị mặc định này nếu giữ nguyên giá trị sẽ làm sai lệch phân tích. Giả sử với véc-tơ ở trên, nếu chúng ta biết giá trị mặc định gán cho các giá trị không quan sát được của hệ thống là 01/01/1900, việc gán giá trị này cho tham số na là cần thiết.Tham số format sử dụng trong hàm parse_datetime() là gợi ý cho R về định dạng của biến kiểu ngày tháng. Khi gán giá trị cho tham số format, bạn đọc cần lưu ý:\nMỗi thành phần của biến thời gian (ngày, tháng, năm, giờ, phút, giây,…) được định nghĩa bắt đầu bằng % và theo sau 1 chữ cái, chẳng hạn như bạn đọc sử dụng %Y khi muốn gợi ý rằng biến kiểu thời gian nằm trong chuỗi ký tự được sử dụng 4 chữ số để chỉ định giá trị năm. –>\nCác ký tự không liên quan đến các thành phần của thời gian, ngoại trừ các khoảng trắng phía trước và sau biến thời gian, cần phải được khai báo chính xác. Hãy quan sát ví dụ dưới đây\nTham số format sử dụng trong hàm parse_datetime() là gợi ý cho R về định dạng của biến kiểu ngày tháng. Khi gán giá trị cho tham số format, bạn đọc cần lưu ý:Mỗi thành phần của biến thời gian (ngày, tháng, năm, giờ, phút, giây,…) được định nghĩa bắt đầu bằng % và theo sau 1 chữ cái, chẳng hạn như bạn đọc sử dụng %Y khi muốn gợi ý rằng biến kiểu thời gian nằm trong chuỗi ký tự được sử dụng 4 chữ số để chỉ định giá trị năm. –>Các ký tự không liên quan đến các thành phần của thời gian, ngoại trừ các khoảng trắng phía trước và sau biến thời gian, cần phải được khai báo chính xác. Hãy quan sát ví dụ dưới đâyTừ ví dụ trên bạn đọc có thể thấy rằngCần khai báo chính xác các ký tự nằm giữa các biến thời gian. Ký tự @ nằm giữa các giá trị ngày, tháng, năm; phân tách giữa ngày tháng với giờ, phút, giây là ký tự %; phân tách giữa các thành phần của thời gian trong ngày là ký tự #. Tất cả đều cần phải được khai báo chính xác trong tham số format. Điều này giải thích tại sao hai giá trị đầu trong véc-tơ x được chuyển đổi sang dạng biến thời gian. Giá trị thứ ba trong véc-tơ x gặp vấn đề vì phân tách giữa các thành phần của thời gian trong ngày sử dụng dấu :.Các khoảng trắng nằm trước và sau các chuỗi ký tự được bỏ qua và không ảnh hưởng đến kết quả. Các giá trị thứ nhất và thứ hai trong véc-tơ x có khoảng trắng phía trước và phía sau nhưng hàm parse_datetime() bỏ qua các khoảng trắng đo khi chuyển đổi ký tự sang ngày tháng.Để biết một cách chính xác cách gán giá trị cho tham số format, bạn đọc nên tham khảo hướng dẫn sử dụng hàm parse_datetime(). Chúng tôi tóm tắt cách định dạng các thành phần của một biến thời gian trong bảng 6.4\nBảng 6.4: Định nghĩa các thành phần của biến thời gian của thư viện readr\nLưu ý rằng khi bạn đọc sử dụng %y để định nghĩa cho giá trị năm, các ký tự từ 00 đến 69 sẽ được chuyển thành năm 2000 đến năm 2069. Trong khi đó, các ký tự từ 70 đến 99 sẽ được chuyển thành năm 1970 đến 1999. Ngoài ra, thành phần tháng của biến thời gian trong nhiều dữ liệu thường được viết dưới dạng chuỗi ký tự thay vì sử dụng số. đó bạn đọc cần các lựa chọn %b hoặc %B để gợi ý cho R. Hãy quan sát ví dụ sau:Khi ngày tháng được viết bằng chuỗi ký tự viết tắt, bằng chữ hoa hoặc chữ thường, như sep hay JAN, gợi ý cần sử dụng là %b. Điều này giải thích tại sao kết quả của hàm parse_datetime() sử dụng %b cho kết quả đúng định dạng ngày tháng đối với ba giá trị đầu của véc-tơ, và cho kết quả là NA với phân tử thứ tư tháng của phần tử này được viết đầy đủ là april. Ngược lại, hàm parse_datetime() thứ hai cho kết quả ba giá trị đầu của véc-tơ là NA và phần tử thứ tư là giá trị ngày tháng được định dạng đúng là chúng ta sử dụng tham số format với gợi ý cho cách viết tháng là %B.","code":"\nx<-c(\"1/2/2023\", \"23/10/2023 \", \"01/01/1900\")\nparse_datetime(x, format = \"%d/%m/%Y\",\n               na = c(\"01/01/1900\"))## [1] \"2023-02-01 UTC\" \"2023-10-23 UTC\" NA\nx<-c(\" 1@2@2023-23#25#01  \", \"  23@10@2023-01#06#59 \", \"01@01@2023-00:00:00\")\nparse_datetime(x, format = \"%d@%m@%Y-%H#%M#%S\")## [1] \"2023-02-01 23:25:01 UTC\" \"2023-10-23 01:06:59 UTC\"\n## [3] NA\n# Gợi ý cho R là ngày, tháng, năm cách nhau bởi @\n# và giờ phút, giây cách nhau bởi #\nx<-c(\"sep 21, 23 \", \"  JAN 1, 69 \", \"Dec 25, 70\", \"april 3, 99\")\nparse_datetime(x, format = \"%b %d, %y\")## [1] \"2023-09-21 UTC\" \"1969-01-01 UTC\" \"1970-12-25 UTC\" NA\nparse_datetime(x, format = \"%B %d, %y\")## [1] NA               NA               NA               \"1999-04-03 UTC\""},{"path":"tiền-xử-lý-dữ-liệu.html","id":"định-dạng-cột-kiểu-chuỗi-ký-tự","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.2.3 Định dạng cột kiểu chuỗi ký tự","text":"Khi bạn đọc dùng thư viện readr để đọc dữ liệu từ nguồn bên ngoài, các biến trong dữ liệu không phân tích được định dạng sẽ lưu dưới dạng các véc-tơ chuỗi ký tự. Vậy tại sao cần định dạng lại các véc-tơ đó thành véc-tơ kiểu chuỗi ký tự? Nghe có vẻ vô lý nhưng đây lại là vấn đề phức tạp nhất trong định dạng cột dữ liệu! Để hiểu vấn đề này bạn đọc cần tìm hiểu một chút về cách máy tính điện tử lưu và mở một chuỗi ký tự.Giả sử một người muốn gửi một dữ liệu chứa ký tự “” đến một người nhận dữ liệu khác. Sau khi viết ký tự “” lên một phần mềm soạn thảo văn bản, người gửi dữ liệu sẽ cần lưu ký tự đó lên máy tính của mình. Tất nhiên máy tính điện tử sẽ không thể ghi nhớ chữ “” một cách tượng hình mà sẽ mã hóa, hay thuật ngữ chuyên ngành gọi là encode, chữ “” thành một đoạn mã nhị phân bao gồm 0 và 1 mà máy tính điện tử có thể lưu được. Khi dữ liệu được gửi sang một máy tính khác, đoạn mã bao gồm các chữ số 0 và 1 đó sẽ được gửi đi. Khi máy tính điện tử khác mở dữ liệu, đoạn mã nhị phân sẽ được giải mã, hay thuật ngữ chuyên ngành gọi là decode, để hiển thị. Sẽ không có vấn đề gì xảy ra nếu quy tắc mã hóa và giải mã được thống nhất và chữ “” sẽ được hiển thị chính xác trên máy tính thứ hai.Thực tế là trước khi có bộ mã hóa và quy tắc mã hóa chung được công nhận rộng rãi như Unicode và UTF-8, rất khó để có sự thống nhất quy tắc mã hóa ký tự. May mắn là đến thời điểm chúng tôi viết cuốn sách này đa số các hệ điều hành, hệ soạn thảo văn bản, đều sử dụng bảng mã Unicode và bộ mã hóa UTF-8. Giải thích chi tiết về bộ mã hóa hay quy tắc mã hóa là rất phức tạp và vượt quá nội dung của cuốn sách này. Chúng tôi chỉ cần bạn đọc hiểu về Unicode và UTF-8 như sau:Unicode là một bảng mã chuẩn được công nhận rộng rãi cho biết quy tắc cho tương ứng hầu hết các ký tự từ đơn giản đến phức tạp, kể cả các ngôn ngữ sử dụng ký tự tượng hình phức tạp như chữ Hán của tiếng Trung Quốc, tiếng Nhật, chữ Nôm của tiếng Việt, với một số nằm giữa số 0 đến số 10FFFF khi viết theo hệ 16. Một số khi viết trong hệ 16 có thể sử dụng, bao gồm 0, 1, …, 9, , B, C, D, E, F, để biểu diễn, đó số các ký tự mà bảng mã Unicode có thể đưa vào là \\(16^4 + 16^5 = 1.114.112\\) ký tự, bao gồm \\(16^5\\) số từ 0 đến FFFFF và \\(16^4\\) số từ 100000 đến 10FFFF. Ví dụ, bạn đọc có thể dễ dàng tìm thấy được qua các công cụ tìm kiếm rằng ký tự “” có mã Unicode là “0041” và “” có mã Unicode là “0061”.UTF-8 là quy tắc lưu các số viết trong hệ 16 của bảng mã Unicode thành các chuỗi nhị phân 0 và 1 để máy tính có thể nhận biết được. Số 8 ở đây có nghĩa là 8-bits hay là một byte - là 8 giá trị 0 và 1 đứng liền nhau. Một ký tự bất kỳ trong bảng mã Unicode đều có thể được mã hóa thành 1, 2, 3 hoặc nhiều byte theo quy tắc mã hóa UTF-8. Chữ “” với mã Unicode “0041” sẽ được lưu trong máy tính điện tử dưới dạng một byte là “01000001”, hay “” có mã Unicode “0061” được máy tính điện tử lưu bằng 1 byte có giá trị “01100001”.Quay trở lại vấn đề định dạng lại dữ liệu kiểu chuỗi ký tự, sẽ không có vấn đề xảy ra nếu người nhập liệu sử dụng bộ mã hóa UTF-8 bởi readr luôn sử dụng UTF-8 để giải mã. Trong thực tế thì vẫn còn một số hệ thống, hoặc hệ soạn thảo văn bản sử dụng cách mã hóa khác với UTF-8. Điều này làm cho dữ liệu khi được nhập vào R sẽ hiển thị không đúng như mong muốn. Ví dụ, khi đọc một dữ liệu từ nguồn ngoài vào bằng read_csv() và cho kết quả như sauCột của dữ liệu đã không được lưu bằng bộ mã hóa UTF-8 nên thư viện readr không hiển thị được các chuỗi ký tự có ý nghĩa. Để định dạng lại cột dữ liệu, bạn đọc sử dụng hàm parse_character() với tham số encoding. Không dễ để biết được hay dự đoán dữ liệu đã được mã hóa bằng bộ mã hóa nào. Thư viện readr cung cấp hàm guess_encoding() hỗ trợ bạn đọc dự đoán một biến kiểu chuỗi ký tự đã được mã hóa bẳng bộ mã hóa nào. Tuy nhiên trải nghiệm của chúng tôi với hàm số này là không tốt! Lời khuyên của chúng tôi là bạn đọc khi có thể hãy tìm hiểu nguồn gốc của dữ liệu: dữ liệu được sinh ra từ đâu, hoặc từ hệ thống nào,…, để đưa ra phán đoán. Nếu không thể tìm kiếm nguồn gốc của dữ liệu, giải pháp duy nhất là thử giải mã đoạn văn bản bằng một số bộ mã hóa thường gặp cho đến khi gặp được kết quả mong muốn! Trong trường hợp dữ liệu ở trên nguồn là tiếng Việt nên chúng ta có thể thử các bộ mã hóa như Latin1 hay Latin2. Cách sử dụng hàm parse_character() để giải mã các chuỗi ký tự như sau:Kết quả khi sử dụng bộ mã Latin2 đã cho một vài giá trị có ý nghĩa, chúng ta tiếp tục thử với Latin1:May mắn là cột dữ liệu đều đã có thể đọc được với người Việt. Chúng ta có thể suy đoán đây là một dữ liệu về giá của các loại quả, đó cột B của dữ liệu cần được định dạng lại kiểu số. Bạn đọc có thể sử dụng parse_numbder() như đã trình bày ở trên. Dữ liệu sau khi được định dạng lại các cột đã dễ hiểu hơn rất nhiều:","code":"\nx<-read_csv(\"../KHDL_KTKD Final/Dataset/Book1.csv\")\nx## # A tibble: 5 × 2\n##   A              B         \n##   <chr>          <chr>     \n## 1 \"l\\xea\"        20.000 vnd\n## 2 \"t\\xe1o\"       35.000 vnd\n## 3 \"qu\\xfdt\"      30.000 vnd\n## 4 \"c\\xe0 t\\xedm\" 5.500 vnd \n## 5 \"m\\xedt\"       10.000 vnd\nparse_character(x$A, locale = locale(encoding = \"Latin2\"))## [1] \"lę\"     \"táo\"    \"quýt\"   \"cŕ tím\" \"mít\"\nparse_character(x$A, locale = locale(encoding = \"Latin1\"))## [1] \"lê\"     \"táo\"    \"quýt\"   \"cà tím\" \"mít\"\ntibble(Name = parse_character(x$A, locale = locale(encoding = \"Latin1\")),\n      Price = parse_number(x$B, locale = locale(grouping_mark = \".\")))## # A tibble: 5 × 2\n##   Name   Price\n##   <chr>  <dbl>\n## 1 lê     20000\n## 2 táo    35000\n## 3 quýt   30000\n## 4 cà tím  5500\n## 5 mít    10000"},{"path":"tiền-xử-lý-dữ-liệu.html","id":"giá-trị-không-quan-sát-được","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.3 Giá trị không quan sát được","text":"Giá trị không quan sát được là các giá trị NA xuất hiện trong dữ liệu khi nhập vào R. Có nhiều lý khác nhau dẫn đến việc dữ liệu không quan sát được. Chẳng hạn như thông tin người làm dữ liệu cung cấp không đầy đủ, hoặc người cung cấp dữ liệu từ chối chia sẻ thông tin, hoặc hệ thống quản lý dữ liệu bị lỗi, hoặc cũng có thể người quản lý dữ liệu chủ động xóa dữ liệu vì lý bảo mật. Giá trị không quan sát được ngoài các giá trị NA xuất hiện trong dữ liệu còn có thể là các giá trị không phù hợp với kiểu dữ liệu hoặc miền giá trị của cột dữ liệu. Đối với một vài hệ thống, khi dữ liệu được xuất ra giá trị không quan sát được vẫn được ghi nhận bằng một giá trị nào đó. Bạn đọc cần cẩn trọng khi làm việc với những dữ liệu như vậy.","code":""},{"path":"tiền-xử-lý-dữ-liệu.html","id":"xác-định-giá-trị-không-quan-sát-được","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.3.1 Xác định giá trị không quan sát được","text":"Khi không được xử lý một cách thích hợp, giá trị không quan sát được sẽ làm sai lệch kết quả của các phân tích về dữ liệu, khiến người ra quyết định dựa trên dữ liệu mắc phải sai lầm. Ví dụ, một yêu cầu về phân tích độ tuổi và giới tính của sinh viên được gửi kèm với dữ liệu như sau:Trong dữ liệu ở trên, mặc dù chỉ có một giá trị là NA trong cột Gender, nhưng nếu quan sát kỹ trong dữ liệu ở trên, bạn đọc sẽ nhận ra rằng:Trong cột Name, giá trị 12345 không thể là tên của một sinh viên, đó đây cũng là một giá trị không quan sát được.Trong cột Age, giá trị ở hàng thứ hai là kiểu chuỗi ký tự Nhập sai ngày sinh không phù hợp với giá trị trong dữ liệu. Thứ hai, tuổi của một sinh viên không thể là số âm, nên giá trị -1 ở hàng thứ ba cũng không phù hợp với miền giá trị của cột này. Như vậy, cột Age có hai giá trị không quan sát được.Cột Gender: có giá trị là ký tự N không rõ là thể hiện cho giới tính Nam hay Nữ, giá trị này cũng là không quan sát được.Cột MSV: giả sử từ thông tin bên ngoài, bạn đọc biết rằng mã sinh viên phải là một đoạn ký tự có độ dài là 8, bắt đầu bằng đoạn ký tự “MSV” và theo sau là 5 chữ số. Như vậy giá trị MS34 ở hàng thứ tư cũng là một giá trị không quan sát được trong cột MSV.Để xác định dữ liệu có giá trị ngoại lai hay không cần sử dụng các kiến thức tổng hợp, kiến thức chuyên môn và kiến thức về xác suất - thống kê toán:Cột Height có giá trị chiều cao ở hàng thứ nhất là 1.76 cm. Giá trị đo lường này quá nhỏ để làm chiều cao của một người bình thường. Nhiều khả năng khi đo chiều cao của sinh viên, người nhập dữ liệu đã ghi lại theo đơn vị mét.Cột Weight có giá trị cân nặng của hàng thứ tư là 150 kg. Mặc dù dữ liệu có rất ít quan sát để đưa ra kết luận phân phối xác suất của cân nặng của sinh viên, tuy nhiên với kiến thức thực tế chúng ta có thể kết luận rằng 150 kg là một cân nặng lớn bất thường với các giá trị cân nặng còn lại. Đây nhiều khả năng là một giá trị ngoại lai.Để xác định các giá trị không quan sát được và giá trị ngoại lai tùy thuộc vào từng dữ liệu cụ thể và kiến thức tổng hợp và kiến thức chuyên môn của người xử lý dữ liệu và nằm ngoài phạm vi thảo luận của cuốn sách này. Dữ liệu ở trên chỉ là một dữ liệu nhỏ và không yêu cầu kiến thức chuyên môn hoặc các kiến thức về xác suất thống kê nên việc xác định các giá trị không quan sát được và giá trị ngoại lai là không quá khó khăn.Nguyên tắc xử lý giá trị không quan sát được là luôn cố gắng tìm cách thay thế các giá trị đó bằng một giá trị dự đoán dựa trên kinh nghiệm và kiến thức của người phân tích. Nếu việc tìm kiếm giá trị thay thế là không thể thực hiện được, hoặc không mang lại giá trị cho phân tích dữ liệu, thì giải pháp mới là xóa quan sát hoặc biến có chứa NA.Đối với dữ liệu trong ví dụ ở trên, chúng ta biến đổi các giá trị không quan sát được thành NA bằng các câu lệnh như sau:Đối với các giá trị ngoại lai về chiều cao, chúng ta sẽ đổi giá trị bị ghi nhận sai đơn vị về đúng đơn vị. Với giá trị cân nặng 150 kg, dữ liệu nhỏ, nên các phân tích thống kê sẽ không có ý nghĩa. Có hai cách để xử lý giá trị ngoại lai, đó là giữ nguyên giá trị ban đầu hoặc thay thế giá trị này bằng giá trị lớn nhất của những giá trị thông thường.Dữ liệu sau khi xử lý giá trị ngoại lai và định nghĩa lại các giá trị không quan sát được sẽ có dạng như sau:Với những dữ liệu nhỏ thì hiển thị trực tiếp dữ liệu cũng cho phép người phân tích xác định vị trí của giá trị không quan sát được trong từng biến. Khi dữ liệu có kích thước lớn thì hiển thị dữ liệu không phải là cách xác định vị trí của NA hiệu quả. Hàm số .na() thường được sử dụng để xác định vị trí của giá trị không quan sát được trong các trường họp như vậy. Ngoài ra, hàm summary() cũng có thể được sử dụng cùng với .na() để quản lý giá trị các giá trị không quan sát được:Hàm summary() cho kết quả là các giá trị thống kê mô tả của các biến trong dữ liệu, bao gồm cả số lượng giá trị không quan sát được của các biến dạng số và dạng factor. Bạn đọc có thể thấy rằng sử dụng hàm số summary() trên dữ liệu summary() cho chúng ta biết trong mỗi cột Age và Gender có hai giá trị không quan sát được, trong khi trong các cột Height và Weight không có giá trị không quan sát được. Hạn chế của hàm summary() là không cho chúng ta biết số lượng giá trị không quan sát được trong các biến kiểu chuỗi ký tự.Hàm số .na() thường được sử dụng để xác định vị trí của giá trị không quan sát được trong dữ liệu. Hàm .na() có thể áp dụng trên một véc-tơ, một ma trận, một dữ liệu, hay một mảng nhiều chiều và trả lại kết quả tương ứng là một véc-tơ, một ma trận, hay một mảng nhiều chiều chứa các biến kiểu logical có kích thước bằng với kích thước dữ liệu đầu vào, đồng thời tại vị trí tương ứng của giá trị không quan sát được sẽ có giá trị TRUE, và có giá trị FALSE tại các vị trí còn lại. Ví dụ, chúng ta áp dụng hàm .na() trên dữ liệu df sẽ cho kết quả là một ma trận kiểu logical kích thước \\(4 \\times 6\\) tương ứng với 4 hàng và 6 cột của dữ liệu:Bạn đọc có thể nhận thấy các vị trí nhận giá trị TRUE trong ma trận kết quả tương ứng với giá trị không quan sát được trong các cột MSV, Name, Age và Gender của dữ liệu df.Khi dữ liệu lớn thì việc hiển thị trực tiếp kết quả của hàm .na() là không hiệu quả. Chúng ta cần kết hợp .na() với các hàm số khác hoặc với các kỹ thuật trực quan hóa để đánh giá được tỷ lệ không quan sát được của các biến trong dữ liệu. Thật vậy, khi thực hiện phân tích trên dữ liệu có tên gapminder là một dữ liệu trong thư viện dslabs có kích thước \\(\\text{10545 (dòng) } \\times \\text{ 9 (cột) }\\), chúng ta có thể kết hợp .na() với đồ thị dạng cột để mô tả tỷ lệ số giá trị không quan sát được trong mỗi cột như sau:\nHình 6.1: Mô tả tỷ lệ giá trị không quan sát được của các biến trong dữ liệu gapminder bằng đồ thị dạng cột\nCó thể dễ dàng nhận thấy rằng biến gdp có tỷ lệ giá trị không quan sát được cao nhất, lên đến khoảng 28%, sau đó là biến infant_mortality với tỷ lệ giá trị không quan sát được khoảng 14%. Các biến population và fertility có tỷ lệ giá trị không quan sát được là khoảng 2%. Các biến còn lại gần như không có giá trị không quan sát được.Chúng ta có thể sử dụng các kỹ thuật trực quan hóa dữ liệu để mô tả tỷ lệ giá trị không quan sát được của các biến một cách chi tiết hơn. các hàm số phục vụ cho trực quan hóa dữ liệu được giới thiệu trong phần sau của cuốn sách nên chúng tôi không giới thiệu chi tiết ở phần này. Chúng tôi sẽ mô tả cách xác định giá trị không quan sát được bằng một hàm số Visual_Na() mà chúng tôi tự phát triển. Hàm số Visual_Na() có đầu vào là một dữ liệu và tên một biến rời rạc. Kết quả của hàm Visual_Na() sẽ cho bạn đọc thông tin về tỷ lệ giá trị không quan sát được của từng phần khi chia dữ liệu thành các nhóm nhỏ theo từng giá trị của biến rời rạc. Ví dụ, bạn đọc muốn tìm hiểu về tỷ lệ giá trị không quan sát được của các biến trong dữ liệu gapminder theo từ năm, nghĩa là theo biến year, bạn đọc chỉ cần thực thi câu lệnh của hàm Visual_Na() như dưới đây sau đó hàm số thêm tham số cho hàm số này:\nHình 6.2: Tỷ lệ giá trị không quan sát được của các biến trong dữ liệu gapminder theo năm bắt đầu từ 1960 đến 2016\nHình 6.2 cho biết chi tiết hơn về tỷ lệ giá trị NA xuất hiện trong các biến với hình 6.1. Có thể thấy rằng biến gdp có tỷ lệ NA cao nhất là trong giai đoạn 2012 đến 2016 tỷ lệ giá trị NA là gần 100%. Biến infant_mortality ngoài năm 2016 có tỷ lệ giá trị NA là 100% còn có tỷ lệ giá trị không quan sát được khá cao trong các năm trước năm 1980. Hai biến population và fertility có tỷ lệ giá trị NA là 100% vào 2016, trong khi các năm khác tỷ lệ giá trị NA là bằng 0%.","code":"## # A tibble: 4 × 6\n##   MSV      Name            Age                Gender `Height (cm)` `Weight (kg)`\n##   <chr>    <chr>           <chr>              <chr>          <dbl>         <dbl>\n## 1 MSV00001 12345           30                 Nam             1.76            68\n## 2 MSV43241 Nguyễn Văn An   Nhập sai ngày sinh N             169               72\n## 3 MSV65432 Lê Thị Loan     -1                 Nữ            155               48\n## 4 MSV34    Trần Mạnh Cường 15                 <NA>          175              150\ndf$MSV[(nchar(df$MSV)!=8)]<-NA # mã sinh viên không có 8 ký tự là không quan sát được\ndf$Name[df$Name==\"12345\"]<-NA\ndf$Age<-parse_number(df$Age, na = c(\"-1\")) # tuổi có giá trị (-1) là không quan sát được\ndf$Gender[df$Gender == \"N\"]<-NA\ndf$Gender<-as.factor(df$Gender)\ndf$`Height (cm)`[1]<-df$`Height (cm)`[1] * 100 # đổi đơn vị đo từ mét sang cm\ndf## # A tibble: 4 × 6\n##   MSV      Name              Age Gender `Height (cm)` `Weight (kg)`\n##   <chr>    <chr>           <dbl> <fct>          <dbl>         <dbl>\n## 1 MSV00001 <NA>               30 Nam              176            68\n## 2 MSV43241 Nguyễn Văn An      NA <NA>             169            72\n## 3 MSV65432 Lê Thị Loan        NA Nữ               155            48\n## 4 <NA>     Trần Mạnh Cường    15 <NA>             175           150\nsummary(df)##      MSV                Name                Age         Gender   Height (cm)   \n##  Length:4           Length:4           Min.   :15.00   Nam :1   Min.   :155.0  \n##  Class :character   Class :character   1st Qu.:18.75   Nữ  :1   1st Qu.:165.5  \n##  Mode  :character   Mode  :character   Median :22.50   NA's:2   Median :172.0  \n##                                        Mean   :22.50            Mean   :168.8  \n##                                        3rd Qu.:26.25            3rd Qu.:175.2  \n##                                        Max.   :30.00            Max.   :176.0  \n##                                        NA's   :2                               \n##   Weight (kg)   \n##  Min.   : 48.0  \n##  1st Qu.: 63.0  \n##  Median : 70.0  \n##  Mean   : 84.5  \n##  3rd Qu.: 91.5  \n##  Max.   :150.0  \n## \nis.na(df)##        MSV  Name   Age Gender Height (cm) Weight (kg)\n## [1,] FALSE  TRUE FALSE  FALSE       FALSE       FALSE\n## [2,] FALSE FALSE  TRUE   TRUE       FALSE       FALSE\n## [3,] FALSE FALSE  TRUE  FALSE       FALSE       FALSE\n## [4,]  TRUE FALSE FALSE   TRUE       FALSE       FALSE\n# Véc-tơ y chứa tỷ lệ giá trị NA trong mỗi cột\ny<-sapply(gapminder,\n          function(x) sum(is.na(x))/length(x))\n\n# Dùng đồ thị dạng cột để mô tả tỷ lệ NA\ndf<-data.frame(variable = names(y), NA_rate = y, row.names = NULL)\ndf%>%ggplot(aes(y = variable, x = NA_rate))+\n  geom_bar(stat = \"identity\",alpha = 0.5, color = \"darkblue\", fill = \"#640514\")+\n  theme_minimal()+scale_x_continuous(labels = scales::percent)+\n  ylab(\"\")+\n  xlab(\"Tỷ lệ NA\")\nVisual_Na<-function(df,variable){\n  # Tìm chỉ số của biến variable\n  ind<-names(df)==variable\n\n  # Tính tỷ lệ NA của từng biến theo từng nhóm\n  # Nhóm đươc xác định theo giá trị của variable\n  df1<-df%>%group_by(df[,ind])%>%\n    group_modify(~summarize(.x, across(everything(), function(x) sum(is.na(x))/length(x) ))) %>%\n    as.data.frame()%>%gather(variables,na_rate,-1)\n\n  # Đặt lại tên biến nhóm theo\n  names(df1)[1]<-\"variable\"\n\n  # Biểu diễn đồ thị\n  p<-df1%>%ggplot(aes(x = variable, y = variables, fill = na_rate))+\n    geom_tile(color = \"grey30\", height = 1, width = 1)+\n    scale_fill_gradient(low=\"white\", high = \"#640514\",\n                        labels = scales::label_percent())+\n    theme_minimal()+ylab(\"\")+xlab(\"\")\n  return(p)\n}\nVisual_Na(gapminder,\"year\")"},{"path":"tiền-xử-lý-dữ-liệu.html","id":"xử-lý-giá-trị-không-quan-sát-được.","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.3.2 Xử lý giá trị không quan sát được.","text":"Khi dữ liệu có giá trị không quan sát được, cách tiếp cận hợp lý nhất là tìm các giá trị thay thế cho các giá trị này dựa trên kinh nghiệm và suy đoán của người xử lý dữ liệu. Chỉ khi việc tìm kiếm dữ liệu thay thế là không thể thực hiện được, hoặc không đem lại giá trị cho các bước phân tích tiếp theo, chúng ta mới áp dụng cách đơn giản hơn là xóa các quan sát hoặc xóa các biến chứa các giá trị đó. Sự xuất hiện của giá trị không quan sát được trong dữ liệu thường được chia làm hai trường hợp, đó là dữ liệu không quan sát được xuất hiện một cách không ngẫu nhiên và dữ liệu không quan sát được xuất hiện một cách ngẫu nhiên.Giá trị không quan sát được xuất hiện một cách không ngẫu nhiên là trường hợp mà có một số quan sát (hoặc biến) có tỷ lệ giá trị NA rất cao, trong khi tất cả các quan sát (hoặc biến) còn lại có tỷ lệ NA nhỏ. Nguyên nhân dẫn đến việc giá trị không quan sát được xuất hiện một cách không ngẫu nhiên thường đến từ nguyên nhân chủ quan, khi người cung cấp dữ liệu không muốn cung cấp thông tin, hoặc lỗi của hệ thống cung cấp dữ liệu. Khi gặp vấn đề như vậy thì xóa quan sát (hoặc biến) có tỷ lệ giá trị NA cao là giải pháp hợp lý.Ví dụ, chúng ta có dữ liệu về thông tin sinh viên của một lớp như trong Bảng 6.5\nBảng 6.5: Dữ liệu có giá trị không quan sát được tập trung vào một quan sát\nCó thể thấy rằng, quan sát tương ứng với mã sinh viên MSV33789 ngoài thông tin về mã sinh viên và tên sinh viên, các thông tin khác đều không quan sát được. Ngoài sinh viên này, các sinh viên còn lại đều có đầy đủ thông tin. Trong trường hợp này phương pháp xử lý hiệu quả nhất là xóa sinh viên có mã MSV33789 khỏi dữ liệu trước khi tiến hành phân tích.Dữ liệu không quan sát được xuất hiện một cách không ngẫu nhiên có thể tập trung ở một số biến như ví dụ dưới đây\nBảng 6.6: Dữ liệu có giá trị không quan sát được tập trung vào một quan sát\nCó thể thấy rằng trong Bảng 6.5 có biến GPA có đa số các giá trị là không quan sát được. Ngoài ra, không thể đưa ra phán đoán cho các giá trị của biến này dựa trên các biến còn lại. Nếu không có thêm thông tin, mọi phân tích liên quan đến giá trị của biến GPA sẽ không có ý nghĩa, đó cách xử lý tốt nhất là xóa biến này ra khỏi dữ liệu.Có nhiều cách để xóa quan sát và biến khỏi dữ liệu, hai cách phổ biến thường được sử dụng là:Để xóa các quan sát có chứa giá trị không quan sát được ra khỏi dữ liệu, bạn đọc có thể sử dụng hàm drop_na() của thư viện tidyr. Cấu trúc câu lệnh của drop_na() như sau:Để xóa một biến khỏi dữ liệu, bạn đọc có thể coi dữ liệu như là một list và gán giá trị của biến đó bằng giá trị NULL:Dữ liệu không quan sát được xuất hiện một cách ngẫu nhiên là trường hợp mà các giá trị không quan sát được nằm rải rác ở các cột và các quan sát không theo một quy tắc nào. Khi gặp trường hợp, này nếu xóa đi các quan sát hoặc biến có chứa giá trị NA thì tỷ lệ dữ liệu bị xóa đi sẽ là rất đáng kể. Thật vậy, chúng tôi sẽ sử dụng dữ liệu cự thể để để minh họa cho vấn đề này. Dữ liệu được sử dụng là mpg của thư viện ggplot2. Đây là một data.frame có kích thước 234 (quan sát) \\(\\times\\) 11 (biến) mô tả mức độ tiêu hao nhiên liệu của các loại xe ô tô thương mại đang bán trên thị trường trong hai năm 1999 và 2008. Dữ liệu không có giá trị NA nhưng chúng tôi sẽ thêm các giá trị không quan sát được vào dữ liệu một các ngẫu nhiên. Sau đó dữ liệu chính xác sẽ được sử dụng để minh họa và đánh giá phương pháp xử lý giá trị không quan sát được trong phần sau.Bạn đọc sử dụng đoạn câu lệnh dưới đây để thêm giá trị không quan sát được vào trong dữ liệu một cách ngẫu nhiên. Dữ liệu mới sau khi thêm NA vào sẽ được gọi tên là na.mpg để phân biệt với dữ liệu ban đầu.Chúng ta thấy rằng có 8 trên tổng số 11 biến có giá trị NA, mỗi cột có 5 giá trị NA xuất hiện một cách ngẫu nhiên trên tổng số 234 giá trị (tỷ lệ khoảng 2%). Tuy nhiên số quan sát có chứa NA lại lớn hơn 2% rất nhiều. Nếu sử dụng hàm drop_na() của thư viện tidyr để xóa các quan sát có giá trị không quan sát được ra khỏi dữ liệu, chúng ta có thể tính được tỷ lệ dữ liệu còn giữ lại là bao nhiêu như sau:Có thể thấy nếu 2% dữ liệu không quan sát được xuất hiện ngẫn nhiên ở mỗi biến thì tỷ lệ dữ liệu còn lại là khoảng 85% nếu chúng ta áp dụng phương pháp xóa các quan sát có chứa NA, nghĩa là 15% dữ liệu đã bị xóa. Chúng tôi thử tăng tỷ lệ giá trị không quan sát được trên mỗi cột lên thành 3%, 5%, 10%, 20%, 30% và quan sát tỷ lệ dữ liệu còn lại sau khi xóa và cho kết quả như Bảng 6.7\nBảng 6.7: Tỷ lệ dữ liệu mpg bị xóa nếu loại bỏ quan sát có giá trị không quan sát được\nBảng 6.7 cho thấy nếu xử lý giá trị không quan sát được bằng cách xóa quan sát thì tỷ lệ dữ liệu còn lại giảm đi rất nhanh. Khi tỷ lệ NA xuất hiện một cách ngẫu nhiên trong mỗi biến từ 5% trở lên chúng ta phải xóa đi hơn 35% số quan sát. Tỷ lệ dữ liệu xóa như vậy sẽ ảnh hưởng lớn đến kết quả của phân tích dữ liệu. Rõ ràng đây không phải là một giải pháp hiệu quả khi giá trị NA xuất hiện một cách ngẫu nhiên.Phương pháp xử lý giá trị không quan sát được thường được áp dụng trong trường hợp này là thay thế giá trị không quan sát được bằng các giá trị thích hợp. Cách tiếp cận đơn giản nhất đó là giả thiết các biến chứa giá trị không quan sát được độc lập với các biến còn lại và sử dụng các giá trị đặc trưng của biến đó để thay thế cho giá trị không quan sát được. Cách tiếp cận phức tạp hơn nhưng cũng cho hiệu quả cao hơn là cân nhắc mối liên hệ giữa các biến trong dữ liệu và xây dựng các thuật toán để dự đoán giá trị thích hợp thay thế cho các giá trị không quan sát được. Mỗi phương pháp đều có ưu nhược điểm riêng và chúng tôi thường thử cả hai hướng tiếp cận sau đó đánh giá hiệu quả của kết quả phân tích. Các phương pháp thay thế giá trị không quan sát được bằng một giá trị thích hợp được trình bày trong các phần tiếp theo.","code":"\n# Dữ liệu có tên là dat\ndat<-drop_na(dat) # Xóa các quan sát có giá trị NA ra khỏi dữ liệu\ndat$ten_cot<-NULL # Xóa cột có tên là ten_cot ra khoi du lieu\n# Tạo dữ liệu mới giống như dữ liệu mpg\nna.mpg<-mpg\n\n# Định dạng các cột kiểu biến rời rạc thành kiểu factor\nchiso<- !(names(na.mpg) %in% c(\"displ\", \"cty\", \"hwy\"))\nna.mpg[,chiso]<-lapply(na.mpg[,chiso], as.factor)%>%\n  as.data.frame()\n\n# Viết hàm số để thêm giá trị NA vào một véc-tơ\n## Hàm số thêm vào véc-tơ x các giá trị NA một cách ngẫu nhiên\n## Tỷ lệ giá trị NA được thêm vào là na.rate\nrd.add<-function(x, na.rate){\n  n<-length(x)\n  k<-round(n*na.rate)\n  ind<-sample(1:n,k,replace=FALSE)\n  x[ind]<-NA\n  return(x)\n}\n\n# Thêm giá trị NA vào các cột NGOẠI TRỪ ba cột\n## Cột nhà sản xuất: manufacturer\n## Cột loại xe: model\n## Cột năm sản xuất\n## tỷ lệ thêm NA một cách ngẫu nhiên vào các cột là 2%\nchiso<- !(names(na.mpg) %in% c(\"manufacturer\", \"model\", \"year\"))\nset.seed(12)\nna.mpg[,chiso]<-as.data.frame(lapply(na.mpg[,chiso],\n                                     rd.add,\n                                      na.rate = 0.02))\n\n# Xem mỗi cột có bao nhiêu giá trị NA\nsapply(na.mpg, f<-function(x) sum(is.na(x)))## manufacturer        model        displ         year          cyl        trans \n##            0            0            5            0            5            5 \n##          drv          cty          hwy           fl        class \n##            5            5            5            5            5\nnrow(drop_na(na.mpg))/nrow(na.mpg)## [1] 0.8461538"},{"path":"tiền-xử-lý-dữ-liệu.html","id":"thay-thế-giá-trị-không-quan-sát-được-bằng-các-đại-lượng-đặc-trưng-của-biến","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.3.2.1 Thay thế giá trị không quan sát được bằng các đại lượng đặc trưng của biến","text":"Phương pháp thay thế này dựa trên giả thiết rằng biến chứa giá trị không quan sát được không có mối liên hệ đến các biến còn lại, và chúng ta sẽ sử dụng một trong các giá trị đặc trưng của các giá trị quan sát được của cột đó như trung bình (mean), trung vị (median), hoặc mode để thay thế cho các giá trị không quan sát được.Giá trị trung bình thường được sử dụng để thay thế cho các giá trị không quan sát được cho véc-tơ kiểu số liên tục và phân phối của các giá trị không có đuôi dài và không có giá trị bất thường.Giá trị trung vị, là giá trị tại ngưỡng xác suất 50%, thường được sử dụng để thay thế cho các giá trị không quan sát được trong véc-tơ kiểu số liên tục và véc-tơ có đuôi dài. Giá trị trung vị có ưu điểm là ít bị ảnh hưởng bởi các giá trị ngoại lai và không bị thay đổi sau các bước biến đổi dữ liệu bằng các hàm đơn điệu.Giá trị mode, là giá trị mà hàm mật độ có xác suất cao nhất, có thể dùng cho cả véc-tơ kiểu số liên tục hoặc véc-tơ kiểu biến rời rạc. Trong trường hợp véc-tơ kiểu số liên tục, bạn đọc cần phải ước lượng hàm mật độ nên giá trị mode sẽ còn phụ thuộc vào phương pháp tiếp cận của người phân tích.Để thay thế giá trị không quan sát được bằng một giá trị khác, bạn đọc có thể sử dụng một trong các hàm có sẵn như sau:Hàm số na_if() của thư viện dplyrHàm số replace_na() của thư viện tidyrCác hàm số người dùng tự định nghĩaĐể đơn giản hóa, chúng ta giả sử rằng sẽ luôn luôn sử dụng giá trị thay thế là giá trị trung vị khi đối với véc-tơ kiểu số liên tục và giá trị mode đối với véc-tơ kiểu biến rời rạc.Giá trị thực tế của các biến kiểu số liên tục, bao gồm các biến có tên là displ, hwy, và cty, và giá trị được dùng để thay thế bằng giá trị trung vị được tổng kết lại trong Bảng 6.8\nBảng 6.8: sánh giá trị đúng và giá trị thay thế bằng trung vị của các biến liên tục trong dữ liệu mpg\nGiá trị thực tế của các biến rời rạc và giá trị dùng để thay thế bằng giá trị mode được tổng kết trong Bảng 6.9.\nBảng 6.9: sánh giá trị đúng và giá trị thay thế của các biến rời rạc trong dữ liệu mpg\nKhông dễ dàng để đưa ra kết luận là thay thế các giá trị không quan sát được của véc-tơ kiểu số liên tục bằng giá trị trung vị như trong Bảng 6.8 là hiệu quả hay không. Chúng ta chỉ có thể thấy rằng giá trị thay thế là giá trị trung vị nên luôn nằm giữa các giá trị thực và khoảng cách từ giá trị thay thế đến các giá trị thực không quá lớn. Về lý thuyết, khi thay thế giá trị không quan sát được bằng giá trị trung vị, chúng ta đang cố gắng đưa ra các dự đoán cho giá trị không quan sát được sao cho giá trị trung bình của sai số tuyệt đối, còn gọi là Mean Absoluted Error hay MAE là nhỏ nhất. Trong trường hợp chúng ta sử dụng giá trung bình để thay thế cho các giá trị không quan sát được, chúng ta tối thiểu hóa trung bình của bình phương sai số dự đoán, còn gọi là Mean Squared Error hay MSE.Thay thế các giá trị không quan sát được trong các véc-tơ kiểu biến rời rạc bằng giá trị mode là nguyên tắc làm giảm thiểu tối đa xác suất dự đoán sai đối với giá trị không quan sát được. Tuy nhiên, giá trị thay thế cho giá trị rời rạc trong bảng 6.9 chỉ cho một vài lần dự đoán đúng cho mỗi biến. Nguyên nhân là giá trị mode trong các biến rời rạc không chiếm ưu thế với các giá trị khác. Chẳng hạn như biến drv bị dự đoán sai 4 trên 5 kết quả thực sự biến này có đến 2 giá trị mode.","code":"\nmy_mode<-function(x){ # Tự định nghĩa hàm mode\n  names(which.max(table(x)))\n}\nmy_fillna_1<-function(x){ # Tự định nghĩa cách thay thế giá trị NA\n  if(is.numeric(x)){\n    # Nếu x là biến liên tục thì dùng median\n    x[is.na(x)]<-median(x,na.rm=TRUE)\n  } else {\n    # Nếu x là biến rời rạc thì dùng mode\n    x[is.na(x)]<-my_mode(x)\n  }\n  return(x)\n}\n# Áp dụng hàm my_fill_na1 vò dữ liệu na.m\nmpg_1<-lapply(na.mpg, my_fillna_1)%>%as.data.frame()"},{"path":"tiền-xử-lý-dữ-liệu.html","id":"thay-thế-giá-trị-không-quan-sát-được-bằng-một-mẫu-ngẫu-nhiên.","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.3.2.2 Thay thế giá trị không quan sát được bằng một mẫu ngẫu nhiên.","text":"Phương pháp thay thế giá trị NA bằng mẫu ngẫu nhiên vẫn giữ nguyên giả thiết rằng biến chứa giá trị không quan sát được không có mối liên hệ đến các cột còn lại. Cácgiá trị được sử dụng để thay thế cho các giá trị không quan sát được là một mẫu được lấy ngẫu nhiên từ phân phối xác suất của các giá trị quan sát được. Hàm sample() là hàm số được sử dụng để lấy mẫu ngẫu nhiên từ một dữ liệu cho trước. Để lấy ra k giá trị ngẫu nhiên từ một véc-tơ x, chúng ta sử dụng câu lệnh như sau:Tham số replace trong hàm sample() nhận giá trị bằng TRUE có ý nghĩa là giá trị ngẫu nhiên được lấy ra từ véc-tơ x có thể được lấy lặp lại. Chúng ta định nghĩa hàm fill_na_2() dùng để thay thế giá trị không quan sát được trong một véc-tơ x bằng phương pháp lấy mẫu ngẫu nhiên như sauGiá trị thực tế của các biến kiểu số liên tục và giá trị dùng để thay thế bằng phương pháp lấy mẫu ngẫu nhiên được tổng kết trong Bảng 6.10\nBảng 6.10: Biến liên tục, thay thế NA bằng lấy mẫu ngẫu nhiên\nGiá trị thực tế của các biến rời rạc và giá trị dùng để thay thế bằng phương pháp lấy mẫu ngẫu nhiên được tổng kết trong Bảng 6.11\nBảng 6.11: Biến rời rạc, thay thế giá trị không quán sát được bằng lấy mẫu ngẫu nhiên\nHiệu quả của phương pháp lấy mẫu ngẫu nhiên với phương pháp sử dụng các giá trị trung vị hoặc mode là không rõ ràng. Phương pháp thay thế giá trị không quan sát được bằng một mẫu ngẫu nhiên chỉ cho hiệu quả khi dữ liệu đủ lớn và phân phối xác suất của các biến quan sát được ổn định. Nhược điểm lớn nhất của phương pháp này đó là giá trị được sử dụng để thay thế được sinh ngẫu nhiên nên có khả năng sẽ làm cho dữ liệu bị sai lệch, đồng thời mỗi lần thực hiện phương pháp sẽ cho các kết quả khác nhau tùy theo hàm sinh ngẫu nhiên.","code":"\nsample(x, size = k, replace = TRUE)\nmy_fillna_2<-function(x){ # Hàm thay thế giá trị NA, phương pháp thứ 2\n  ind<-is.na(x) # véc-tơ kiểu logic, nhận giá trị TRUE tại các vị trí NA\n  k<-sum(ind)\n  x[ind]<-sample(x[!ind],k,replace = TRUE)\n  return(x)\n}\nset.seed(12)\nmpg_1<-lapply(na.mpg, my_fillna_2)%>%as.data.frame()"},{"path":"tiền-xử-lý-dữ-liệu.html","id":"replaceNAbymodel","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.3.2.3 Thay thế giá trị không quan sát được bằng mô hình dự đoán","text":"Giả thiết rằng cột chứa giá trị không quan sát được không có mối liên hệ đến các cột còn lại là một giả thiết không thực tế. Bởi vì các biến trong dữ liệu thực tế luôn luôn có mối liên hệ với nhau dù ít hay nhiều. Nói theo nguyên lý của xác suất - thống kê thì các biến trong dữ liệu thực tế thường hiếm khi độc lập với nhau. Làm thế nào để biết hai biến dữ liệu bất kỳ là độc lập hay phụ thuộc ? Đây là một câu hỏi không dễ. Bạn đọc cần có kiến thức về xác suất và thống kê toán để có được câu trả lời chính xác. Có rất nhiều lý thuyết khác nhau nghiên cứu về sự phụ thuộc giữa các biến và đa số các lý thuyết đó vượt quá phạm vi của cuốn sách này. Chúng tôi chỉ trình bày các phương pháp được công nhận rộng rãi và có mức độ phức tạp vừa đủ để bạn đọc không cần có nền tảng nâng cao về toán học, xác suất, thống kê có thể hiểu được. Nhìn chung, để đưa ra kết luận hai cột dữ liệu có độc lập hay không, bạn đọc có thể sử dụng các kiểm định như sau:Kiểm định Khi-bình phương khi cả hai biến đều là biến rời rạc.Kiểm định hệ số tương quan Person, hoặc hệ số tương quan Spearman, hoặc hệ số tương quan Kendall khi cả hai biến đều là biến liên tục.Sử dụng phân tích phương sai (hay còn gọi là anova test) trong trường hợp một biến là rời rạc và một biến là liên tục.Chi tiết của các kiểm định này được trình bày ở phần Phụ lục 6.5.1. Chúng ta sẽ sử dụng các phương pháp này để kiểm tra mối liên hệ giữa các biến trong dữ liệu na.mpg.Để thực hiện kiểm định Khi-bình phương trong R, chúng ta sử dụng hàm chisq.test(). Ví dụ, để kiểm ra hai biến rời rạc là year và drv có mối liên hệ hay không, chúng ta thực hiện như sau:Giá trị p-value bằng 43% nghĩa là xác suất bác bỏ giả thiết hai biến year và drv độc lập là 1 - 43% = 57%. Thông thường, mức xác suất bác bỏ giả thiết độc lập thường được chọn ở mức 95% hoặc 99%. xác suất bác bỏ giả thiết độc lập là thấp nên trong trường hợp này có thể đưa ra kết luận rằng hai biến year và drv là không có mối liên hệ.Tương tự, để kiểm ra hai biến drv và cyl có mối liên hệ hay không, chúng ta cũng thực hiện kiểm định Khi-bình phươngTrong trường hợp này, xác suất bác bỏ giả thiết độc lập là xấp xỉ 100% nên chúng ta có thể đưa ra kết luận rằng hai biến drv và cyl là có mối liên hệ.Để kiểm định hệ số tương quan giữa hai biến liên tục chúng ta sử dụng hàm cor.test(). Tham số method nhận giá trị pearson, kendall, hoặc spearman tương ứng với kiểm định hệ số tương quan Pearson, hệ số tương quan Kendall, hoặc hệ số tương quan Spearman. Chúng ta kiểm định sự độc lập giữa hai biến displ và hwy như sauKiểm định đối với ba hệ số tương quan đều cho xác suất bác bỏ giả thiết độc lập là xấp xỉ 100%. Nói một cách khác có thể khẳng định rằng hai biến displ và hwy là có sự phụ thuộc.Sau cùng, để kiểm định sự phụ thuộc giữa một biến rời rạc và một biến liên tục, chúng ta sử dụng phân tích phương sai. Hàm số để thực hiện phân tích phương sai trong R là hàm aov(). Chúng ta kiểm định sự phụ thuộc giữa biến liên tục hwy và biến rời rạc cyl như sau:Xác suất bác bỏ giả thiết giá trị trung bình của biến hwy bằng nhau theo các nhóm của biến cyl là xấp xỉ 100% hay nói một cách khác hwy và cyl là có mối liên hệ.Để xem xét một cách tổng thể mối liên hệ giữa các biến trong dữ liệu na.mpg, bạn đọc có thể sử dụng kiểm định phù hợp với từng cặp biến và lưu xác suất bác bỏ giả thiết độc lập vào một ma trận. Hàm số ind_check() được chúng tôi tự xây dựng với tham số đầu vào là một dữ liệu, dưới dạng một tibble hoặc một data.frame, cho đầu ra là một ma trận cho biết xác suất bác bỏ giả thiết độc lập của từng cặp biến như thế nào.Ma trận thể hiện xác suất bác bỏ giả thiết độc lập giữa từng cặp biến trong dữ liệu na.mpg ở trong Hình 6.3\nHình 6.3: Ma trận mức xác suất bác bỏ giả thuyết độc lập giữa các cặp biến trong dữ liệu na.mpg\nCó thể thấy rằng ngoại trừ biến year ít có mối liên hệ đến các biến khác, còn lại đa số các biến là có mối liên hệ với nhau. Điều này được thể hiện qua xác suất bác bỏ giả thiết độc lập giữa các biến trong ma trận của hình đều xấp xỉ 100%. Khi xây dựng mô hình trên dữ liệu, sự xuất hiện của các biến ít có mối liên hệ đến các biến khác sẽ khiến mô hình bị nhiễu và làm giảm chất lượng dự đoán. đó, chúng tôi sẽ loại bỏ biến year khi dự đoán giá trị không quan sát được của các biến khác.Phương pháp để xây dựng mô hình dự đoán cho các giá trị không quan sát được là thuật toán rừng ngẫu nhiên. Đây là một thuật toán mở rộng của mô hình dạng cây quyết định sẽ được trình bày trong chương ??. Còn quá sớm để nói về mô hình này, bạn đọc cần hiểu rằng chúng ta sẽ dựa vào các giá trị quan sát được để xây dựng mô hình, hay tổng quát hơn là xây dựng một hàm số với giá trị của hàm là biến có chứa giá trị NA và biến số là các biến là các giá trị quan sát được. Thư viện missForest hỗ trợ chúng ta thực hiện việc này. Bạn đọc có thể cài thư viện sau đó sử dụng hàm missForest(). Quá trình thay thế giá trị không quan sát được của dữ liệu na.mpg bằng cách dự đoán dựa trên thuật toán rừng ngẫu nhiên được thực hiện mà chỉ cần một dòng lệnh:Sau khi có giá trị dự đoán cho các giá trị không quan sát được, chúng ta sẽ hiển thị giá trị thực của các biến kiểu số và các giá trị thay thế hàm missForest() như trong Bảng 6.12\nBảng 6.12: Các giá trị không quan sát được trong các biến liên tục trong na.mpg được thay thế bằng giá trị dự đoán bằng thuật toán rừng ngẫu nhiên\nTương tự, giá trị thực tế tại các vị trí không quan sát được của các biến rời rạc và giá trị dự đoán bằng thuật toán rừng ngẫu nhiên ở trong Bảng 6.13\nBảng 6.13: Các giá trị không quan sát được trong các biến rời rạc trong na.mpg được thay thế bằng giá trị dự đoán bằng thuật toán rừng ngẫu nhiên\nCó thể nhận thấy rằngĐối với các biến kiểu số, giá trị dùng để thay thế cho các giá trị không quan sát được không khác nhiều với giá trị thực tế. Phương pháp thay thế giá trị NA bằng cách sử dụng thuật toán rừng ngẫu nhiên là hiệu quả hơn hẳn với hai phương pháp trước đó.Đối với các biến kiểu rời rạc, ngoại trừ biến trans và biến fl, các biến còn lại đều được dự đoán chính xác 100% bằng thuật toán rừng ngẫu nhiên. Hiệu quả của việc sử dụng thuật toán rừng ngẫu nhiên rõ ràng là vượt trội hơn hai phương pháp còn lại.Nhìn chung, xây dựng mô hình để dự đoán giá trị không quan sát được của một biến dựa trên các biến khác là phương pháp cho hiệu quả tốt hơn, đặc biệt đối với dữ liệu có các biến có mối liên hệ chặt chẽ với nhau. Điểm bất lợi duy nhất của phương pháp này là sự phức tạp trong kỹ thuật xây dựng mô hình. Bạn đọc cần có các hiểu biết cơ bản về xây dựng mô hình, trong trường hợp này là mô hình cây quyết định, và các kỹ thuật thống kê hiện đại như kỹ thuật lấy mẫu lặp, để hiểu được nguyên tắc dự đoán giá trị không quan sát được. Tất nhiên, thực thi hàm missForest() của thư viện cùng tên không cần bạn phải có các kiến thức này. Để hiểu được chính xác cách xây dựng mô hình, bạn đọc tham khảo chương ??.","code":"\nchisq.test(na.mpg$year,na.mpg$drv)## \n##  Pearson's Chi-squared test\n## \n## data:  na.mpg$year and na.mpg$drv\n## X-squared = 1.689, df = 2, p-value = 0.4298\nchisq.test(na.mpg$drv, na.mpg$cyl)## \n##  Pearson's Chi-squared test\n## \n## data:  na.mpg$drv and na.mpg$cyl\n## X-squared = 90.288, df = 6, p-value < 2.2e-16\ncor.test(na.mpg$displ, na.mpg$hwy, method = \"pearson\")## \n##  Pearson's product-moment correlation\n## \n## data:  na.mpg$displ and na.mpg$hwy\n## t = -17.743, df = 223, p-value < 2.2e-16\n## alternative hypothesis: true correlation is not equal to 0\n## 95 percent confidence interval:\n##  -0.8143893 -0.7048317\n## sample estimates:\n##       cor \n## -0.765092\ncor.test(na.mpg$displ, na.mpg$hwy, method = \"kendall\")## \n##  Kendall's rank correlation tau\n## \n## data:  na.mpg$displ and na.mpg$hwy\n## z = -13.857, p-value < 2.2e-16\n## alternative hypothesis: true tau is not equal to 0\n## sample estimates:\n##        tau \n## -0.6534741\ncor.test(na.mpg$displ, na.mpg$hwy, method = \"spearman\")## \n##  Spearman's rank correlation rho\n## \n## data:  na.mpg$displ and na.mpg$hwy\n## S = 3467012, p-value < 2.2e-16\n## alternative hypothesis: true rho is not equal to 0\n## sample estimates:\n##        rho \n## -0.8262809\nsummary(aov(hwy~cyl,data=na.mpg))##              Df Sum Sq Mean Sq F value Pr(>F)    \n## cyl           3   4479  1492.9   101.6 <2e-16 ***\n## Residuals   220   3233    14.7                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## 10 observations deleted due to missingness\n### Hàm số ind_check()\nind_check<-function(dat){\n  dat<-as.data.frame(dat)\n  dat.name<-names(dat)\n  p<-dim(dat)[2]\n  M<-matrix(0,p,p)\n  for (i in 1:(p-1)){\n    for (j in (i+1):p){\n      x<-dat[,i]\n      y<-dat[,j]\n      if(is.character(x)|is.character(y)){\n        return(NA)\n      } else {\n        if (is.numeric(x)){\n          if (is.numeric(y)){\n            test<-cor.test(x, y, method = \"spearman\")\n            M[i,j]<-1 - test$p.value\n          } else {\n            test<-summary(aov(x ~ y))\n            M[i,j]<-1 - test[[1]][[5]][1]\n          }\n        } else {\n          if (is.numeric(y)){\n            test<-summary(aov(y ~ x))\n            M[i,j]<-1 - test[[1]][[5]][1]\n          } else {\n            test<-chisq.test(x,y)\n            M[i,j]<-1 - test$p.value\n          }\n        }\n      }\n      M[j,i]<-M[i,j]\n    }\n  }\n  colnames(M)<-dat.name\n  rownames(M)<-dat.name\n  diag(M)<-1\n  return((round(M,3)))\n}\nlibrary(missForest)\nna.mpg<-as.data.frame(na.mpg)\n\n### Thời gian chạy mất khoảng 1-2 phút\nmodel<-missForest(select(na.mpg,-year), maxiter = 200, ntree = 100)\nmpg_1<-model$ximp # Dữ liệu mpg_1 là dữ liệu sau khi thay thế NA"},{"path":"tiền-xử-lý-dữ-liệu.html","id":"xử-lý-giá-trị-ngoại-lai","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.4 Xử lý giá trị ngoại lai","text":"","code":""},{"path":"tiền-xử-lý-dữ-liệu.html","id":"ảnh-hưởng-của-giá-trị-ngoại-lai-lên-kết-quả-phân-tích","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.4.1 Ảnh hưởng của giá trị ngoại lai lên kết quả phân tích","text":"Giá trị ngoại lai hay còn được gọi là giá trị bất thường là một, hoặc một số điểm dữ liệu có giá trị sai khác đáng kể với đa số các quan sát khác. Một giá trị ngoại lai xuất hiện trong dữ liệu có thể là lỗi trong quản lý dữ liệu, sai số trong đo lường hoặc cũng có thể bản chất phân phối của dữ liệu. Tùy theo nguồn gốc của giá trị ngoại lai mà chúng ta có cách xử lý dữ liệu khác nhau. Khi không được xử lý thích hợp, các giá trị ngoại lai có thể làm sai lệch kết luận của các phân tích dựa trên dữ liệu.Giá trị ngoại lai được hiểu là những điểm dữ liệu khác xa tập hợp các điểm còn lại. Không có một định nghĩa chính xác nào cho khái niệm khác xa các giá trị còn lại. đó, tùy theo bản chất của dữ liệu, và tùy theo quan điểm của người phân tích dữ liệu, mà một (hay một số) giá trị có khả năng là giá trị ngoại lai hay không. Giá trị ngoại lai thường chỉ được nhắc đến với các dữ liệu có số quan sát đủ lớn để đưa ra kết luận có ý nghĩa thống kê.\nHình 6.4: Giá trị ngoại lai xuất hiện trong dữ liệu có ít (10) và có nhiều (100) quan sát. Hình bên trái: Các điểm và B nằm cách xa 8 điểm còn lại nhưng dữ liệu chưa đủ lớn để đưa ra kết luận. Hình bên phải: điểm và B nằm cách xa 98 điểm còn lại, có thể kết luận và B là các điểm ngoại lai.\nHình 6.4 mô tả trực quan các điểm và B có khả năng là giá trị ngoại lai trong hai trường hợp là có ít quan sát và có nhiều quan sát. Khi dữ liệu có 10 quan sát như hình bên trái, có 8 quan sát nằm gần nhau, điểm B nằm xa hơn tập hợp các điểm còn lại một chút, còn điểm nằm cách xa hơn. Khi gặp dữ liệu như vậy, chúng ta có thể khá chắc chắn với kết luận rằng điểm là giá trị ngoại lai vì điểm này nằm cách rất xa các điểm còn lại. Tuy nhiên, kết luận điểm B có phải ngoại lai hay không thì còn tùy thuộc vào cách tiếp cận của người phân tích dữ liệu. Hình bên phải với dữ liệu có 100 quan sát. Các điểm nằm gần nhau định hình khá rõ miền giá trị của trung tâm của dữ liệu. Chúng ta có thể kết luận một cách khá chắc chắn rằng điểm là một giá trị ngoại lai. Điểm B mặc dù nằm khá xa trung tâm của dữ liệu, và cũng có thể kết luận khá chắc chắn rằng đây là điểm ngoại lai.Nguồn gốc của giá trị ngoại lai là có thể đến từ nhiều nguyên nhân khác nhau, bao gồm cả nguyên nhân khách quan hoặc nguyên nhân chủ quan. Các nguyên nhân khách quan có thể nguồn sinh dữ liệu, hay hệ thống quản lý dữ liệu gặp sự cố, lỗi trong quá trình truyền hoặc sao chép dữ liệu. Nguyên nhân chủ quan bao gồm có các hành vi gian lận, lỗi nhập và sao chép dữ liệu của con người, hoặc các giá trị được cố tình đưa vào trong dữ liệu với mục đích lấy phản hồi từ người dùng dữ liệu.Nếu không xử lý giá trị ngoại lai, kết quả phân tích sẽ bị sai lệch đáng kể. Và dữ liệu có kích thước càng nhỏ thì ảnh hưởng của giá trị ngoại lai lại càng lớn. Trong ví dụ trong đồ thị bên trái của Hình 6.4, giả sử chúng ta cần phân tích sự tác động của biến X lên biến Y bằng một mối quan hệ tuyến tính. Chúng ta xây dựng mô hình tuyến tính trong ba trường hợpTrường hợp 1: Giữ nguyên 10 quan sát và xây dựng mô hình mô tả mối liên hệ tuyến tính.Trường hợp 2: Loại bỏ điểm trước khi xây dựng mô hình.Trường hợp 3: Loại bỏ điểm và điểm B trước khi xây dựng mô hình.Các đường tuyến tính mô tả mối liên hệ giữa biến X và Y được mô tả trong Hình 6.5\nHình 6.5: Xây dựng mô hình trên dữ liệu có chứa và không chứa giá trị ngoại lai. Hình bên trái: bao gồm cả hai điểm và B trong xây dựng mô hình. Hình ở giữa: loại điểm và giữ lại điểm B trong xây dựng mô hình. Hình bên phải: loại bỏ cả điểm và điểm B trước khi xây dựng mô hình.\nKhi giữ nguyên 10 điểm dữ liệu để xây dựng mối quan hệ tuyến tính, đường thẳng mô tả mối quan hệ giữa X và Y là nằm trong đồ thị phía bên trái của Hình 6.5. Đường thẳng này có hệ số góc dương, nghĩa là một đường dốc lên khi đi từ trái sang phải. Điều này có nghĩa là biến X có tác động cùng chiều lên biến Y, nghĩa là khi X tăng hoặc giảm thì nhiều khả năng Y cũng sẽ tăng hoặc giảm.Khi giữ nguyên 10 điểm dữ liệu để xây dựng mối quan hệ tuyến tính, đường thẳng mô tả mối quan hệ giữa X và Y là nằm trong đồ thị phía bên trái của Hình 6.5. Đường thẳng này có hệ số góc dương, nghĩa là một đường dốc lên khi đi từ trái sang phải. Điều này có nghĩa là biến X có tác động cùng chiều lên biến Y, nghĩa là khi X tăng hoặc giảm thì nhiều khả năng Y cũng sẽ tăng hoặc giảm.Sau khi loại bỏ điểm và tính toán lại, đường thẳng mô tả mối quan hệ tuyến tính giữa X và Y ở là đường thẳng trong đồ thị ở giữa của Hình 6.5. Đường thẳng gần như nằm ngang, cho thấy X không có tác động lên biến Y. Nghĩa là X có tăng hay giảm cũng không làm thay đổi Y.Sau khi loại bỏ điểm và tính toán lại, đường thẳng mô tả mối quan hệ tuyến tính giữa X và Y ở là đường thẳng trong đồ thị ở giữa của Hình 6.5. Đường thẳng gần như nằm ngang, cho thấy X không có tác động lên biến Y. Nghĩa là X có tăng hay giảm cũng không làm thay đổi Y.Sau cùng, trong đồ thị phía bên phải của Hình 6.5, sau khi loại bỏ các điểm X và điểm B, đường thẳng mô tả mối quan hệ tuyến tính giữa X và Y là đường dốc xuống, nghĩa là mối tác động của X lên Y là ngược chiều.Sau cùng, trong đồ thị phía bên phải của Hình 6.5, sau khi loại bỏ các điểm X và điểm B, đường thẳng mô tả mối quan hệ tuyến tính giữa X và Y là đường dốc xuống, nghĩa là mối tác động của X lên Y là ngược chiều.Bạn đọc có thể thấy rằng kết luận từ kết quả ước lượng mô hình thay đổi hoàn toàn khi chúng ta có các lựa chọn khác nhau về việc có loại bỏ hay không các giá trị được cho là ngoại lai ra khỏi dữ liệu. Sự tác động của X lên Y từ thuận chiều trong đồ thị bên trái đến không có mối liên hệ trong đồ thị ở giữa, và sau cùng là sự tác động ngược chiều của X lên Y trong đồ thị bên phải. Điều này cho thấy việc xác định và xử lý giá trị ngoại lai là vô cùng quan trọng trước khi xây dựng mô hình.Trong phần tiếp theo chúng ta sẽ thảo luận về các phương pháp dùng để xác định các giá trị ngoại lai trong dữ liệu.","code":""},{"path":"tiền-xử-lý-dữ-liệu.html","id":"phương-pháp-phát-hiện-giá-trị-ngoại-lai","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.4.2 Phương pháp phát hiện giá trị ngoại lai","text":"Không có một định nghĩa chính xác như thế nào là giá trị ngoại lai, chính vì thế không có phương pháp chung để phát hiện giá trị ngoại lai. Với mỗi dữ liệu, với mỗi cách nhìn nhận giá trị ngoại lại khác nhau, mà có phương pháp tiếp cận cụ thể để xác định các giá trị đó. Trong phần này, chúng tôi chỉ trình bày các phương pháp chung được chấp nhận rộng rãi. Đây là các phương pháp đơn giản, dễ hiểu và có thể thực hiện được mà không cần bổ sung thêm kiến thức. Các phương pháp phức tạp hơn, đòi hỏi kiến thức nâng cao về dữ liệu như phân nhóm, phân cụm, sẽ được thảo luận trong chương sách học máy không có giám sát.","code":""},{"path":"tiền-xử-lý-dữ-liệu.html","id":"phát-hiện-giá-trị-ngoại-lai-trong-một-véc-tơ","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.4.2.1 Phát hiện giá trị ngoại lai trong một véc-tơ","text":"Để xác định một giá trị là giá trị ngoại lai hay không thường bao gồm hai bước, bước thứ nhất là sử dụng các phương pháp xác suất thống kê để xác định các giá trị có khả năng cao là ngoại lai, sau đó bước thứ hai là sử dụng kiến thức chuyên môn hoặc hỏi ý kiến chuyên gia để khẳng định lại kết quả từ bước thứ nhất.Nếu véc-tơ là một véc-tơ kiểu chuỗi ký tự mà không phải kiểu factor thì không có quy tắc rõ ràng nào để xác định giá trị ngoại lai. Trước hết, việc một biến kiểu chuỗi ký tự có phải là một giá trị ngoại lai hay không phụ thuộc vào bản chất của véc-tơ chuỗi ký tự. Việc này hoàn toàn phụ thuộc vào hiểu biết của người phân tích dữ liệu với véc-tơ đó. Ví dụ, véc-tơ chuỗi ký tự là tên của người bằng tiếng Việt, một giá trị ngoại lai có thể là một tên người với nhiều hơn 6 hay 7 từ, bởi vì theo kiến thức chung, tên người bình thường bao gồm 2,3 hoặc 4 từ. Ngoài ra, một chuỗi ký tự có thể là ngoại lai nếu chuỗi ký tự có độ dài bất thường, có chứa nhiều ký tự bất thường, hay một chuỗi ký tự không có ý nghĩa trong một véc-tơ bao gồm các chuỗi ký tự có ý nghĩa. Nói một cách khác một giá trị có phải là ngoại lai hay không hoàn toàn phụ thuộc vào cách tiếp cận của người phân tích dữ liệu. Các phương pháp xử lý dữ liệu kiểu chuỗi ký tự hiện nay có khả năng biến đổi một chuỗi ký tự thành một véc-tơ kiểu số. Việc xác định chuỗi ký tự có phải là một giá trị bất thường hay không sẽ liên quan đến việc xác định một véc-tơ kiểu số có phải là một véc-tơ có giá trị bất thường trong một tập hợp các véc-tơ. Các kỹ thuật này vượt quá phạm vi của cuốn sách nên chúng tôi không đề cập ở đây.\nHình 6.6: Tần suất xuất hiện của các loại đồ uống được bán tại một siêu thị. Loại đồ uống có tần suất xuất hiện thấp có khả năng là giá trị ngoại lai\nKhi gặp trường hợp như đồ thị trong Hình 6.6, có khả năng đồ uống có tên Collagen là giá trị ngoại lai. Chúng ta chưa thể khẳng định bởi vì nếu siêu thị thực sự có bán loại đồ uống này và việc sản phẩm không được khách hàng ưa chuộng, thì sản phẩm xuất hiện với tần xuất thấp là bình thường. Tuy nhiên cũng có thể tên sản phẩm xuất hiện trong danh sách bán hàng dù siêu thị bán cũng có thể là lỗi gặp phải trong quản lý hệ thống bán hàng, hoặc người bán hàng đã ghi nhận tên Collagen cho một đồ uống khác.Đối với véc-tơ kiểu số, các giá trị có khả năng là ngoại lai thường là các giá trị nằm ở đuôi của phân phối xác suất. Các giá trị nằm ở đuôi là các giá trị nằm cách xa các giá trị trung bình, hoặc trung vị, về phía bên phải hoặc bên trái. Để biết một véc-tơ kiểu số có giá trị ngoại lai hay không, bạn đọc nên sử dụng đồ thị Boxplot. Các điểm nằm phía dưới điểm nhỏ nhất (\\(Q_0\\)) và nằm phía trên điểm lớn nhất (\\(Q_4\\)) của đồ thị boxplot có nhiều khả năng là các giá trị ngoại lai. Điểm nhỏ nhất và điểm lớn nhất của đồ thị Boxplot được xác định dựa trên mức tứ phân vị thứ nhất (\\(Q_1\\)) và mức tứ phân vị thứ ba (\\(Q_3\\)):\n\\[\\begin{align}\n&\\text{Inter Quartile Range (IQR)} = Q_3 - Q_1 \\\\\n&\\text{Điểm nhỏ nhất } (Q_0) = Q_1 - 1.5 \\times IQR \\\\\n&\\text{Điểm lớn nhất } (Q_4) = Q_3 + 1.5 \\times IQR\n\\end{align}\\]Các giá trị trong véc-tơ kiểu số nằm ngoài khoảng \\((Q_0, Q_4)\\) có nhiều khả năng là giá trị ngoại lai. Giá trị càng nhỏ hơn \\(Q_0\\) và càng cao hơn \\(Q_4\\) thì khả năng là giá trị ngoại lai lại càng cao.Chúng tôi sẽ lấy một ví dụ mô tả việc sử dụng đồ thị Boxplot để phát hiện giá trị ngoại lai trên một dữ liệu thực tế. Hình 6.7 mô tả phân phối xác suất của véc-tơ chứa khối lượng giao dịch, tính bằng triệu cổ phiếu/ngày, của cổ phiếu tập đoàn FLC. Cổ phiếu được niêm yết trên sàn giao dịch chứng khoán Thành phố Hồ Chí Minh từ ngày 6 tháng 10 năm 2011 đến ngày 8 tháng 9 năm 2022. Dữ liệu có 2719 quan sát.\nHình 6.7: Sử dụng đồ thị boxplot để mô tả lịch sử khối lượng giao dịch cổ phiếu FLC. Các giá trị có khả năng là giá trị ngoại lai nằm trên điểm Q4 của phân phối xác suất.\nChúng ta có thể thấy trên đồ thị Boxplot không có điểm nằm dưới \\(\\text{Q_0}\\) trong khi có 8 quan sát có giá trị lớn hơn \\(\\text{Q_4}\\). Và các giá trị này có khả năng là các giá trị ngoại lai. Có 3 quan sát với giá trị lớn hơn 100 triệu, nghĩa là có ba ngày mà có hơn 100 triệu cổ phiếu FLC được giao dịch. Nếu có một chút kinh nghiệm về giao dịch thị trường chứng khoán Việt Nam, bạn đọc có thể kiểm chứng được đây là số lượng cổ phiếu giao dịch lớn bất thường.Ba phiên giao dịch có khối lượng giao dịch lớn hơn 100 triệu cổ phiếu là các phiên giao dịch ngày 10 tháng 1 năm 2022, ngày 11 tháng 1 năm 2022 và phiên giao dịch ngày 1 tháng 4 năm 2022. Thực tế cho thấy đây là ba phiên giao dịch mà cổ phiếu FLC đã bị thao túng giá và dẫn đến việc cố phiếu FLC bị cấm giao dịch trên sàn giao dịch HOSE kể từ tháng 09 năm 2022.Từ khoảng tháng 10 năm 2021 giá cổ phiếu FCL bắt đầu tăng nhanh. Đến đầu tháng 01 năm 2022, giá cổ phiếu đã tăng lên gấp 2 lần. Ngày 10 và ngày 11 tháng 01 năm 2022, các cổ đông chính của FLC bán ra khối lượng rất lớn các cổ phiếu mà không đăng ký với Ủy ban chứng khoán theo quy định. Sau hai phiên giao dịch này giá cổ phiếu FLC giảm mạnh về đến mức trước đó vài tháng.Ngày 31 tháng 03 năm 2022 các thông tin giả mạo về nhu cầu mua cổ phiếu FLC với khối lượng lớn được đưa ra sau nhiều ngày giá cổ phiếu FLC giảm hết biên độ làm cho nhu cầu mua FLC trong ngày 01 tháng 04 năm 2022 cao đột biến.Việc thao túng giá và đưa thông tin giả mạo khiến cho số lượng cố phiếu FLC tăng lên đột biến đã bị các cơ quan chức năng phát hiện và đưa ra lệnh cấm giao dịch với cổ phiếu này. Đây là ví dụ điển hình về dữ liệu có giá trị ngoại lai có nguyên nhân chủ quan từ con người.Ngoài đồ thị Boxplot, bạn đọc có thể sử dụng các đồ thị mô tả phân phối của biến liên tục như đồ thị histogram hay đồ thị density để xác định giá trị ngoại lai trong véc-tơ kiểu số. Ví dụ, Hình 6.8 mô tả phân phối của chiều cao của 245 nam giới là nhân viên của một công ty. Đơn vị đo chiều cao là cm.\nHình 6.8: Kết hợp Boxplot và Histogram để xác định giá trị ngoại lai trong dữ liệu. Hình bên trái: đồ thị boxplot cho có điểm nằm phía dưới điểm Q0. Hình bên phải: đồ thị histogram cho thấy có giá trị bất thường nằm ở đuôi bên trái\nCả hai đồ thị Boxplot và Histogram trong Hình 6.8 đều cho thấy trong dữ liệu có các giá trị là chiều cao của nam giới xấp xỉ giá trị 0 và nhiều khả năng đây là các giá trị ngoại lai. Đồ thị Histogram còn cho thấy có nhiều hơn 1 giá trị có giá trị như vậy. Lọc các giá trị đó ra khỏi véc-tơ chúng ta sẽ thu được 5 giá trị là 1,52; 1,74; 1,70; 1,62; và 1,80. Đây không thể là chiều cao của nam giới đo bằng đơn vị cm. Có nhiều khả năng là khi ghi lại chiều cao của các nhân viên này, người nhập dữ liệu đã sử dụng đơn vị là mét thay vì cm. Chúng ta có thể sửa các giá trị ngoại lai này bằng cách đổi từ đơn vị mét sang cm. Phân phối xác suất của chiều cao sau khi sửa lại dữ liệu được mô tả như hình dưới đây:\nHình 6.9: Kết hợp Boxplot và Histogram để xác định giá trị ngoại lai trong dữ liệu. Hình bên trái: đồ thị Boxplot sau khi điều chỉnh lại chiều cao từ đơn vị mét sang cm. Hình bên phải: đồ thị Histogram sau khi điều chỉnh lại chiều cao từ đơn vị mét sang cm\nVéc-tơ kiểu số là đơn vị đo lường hay đơn vị tiền tệ rất thường xuyên gặp vấn đề như kể trên. Ngay khi gặp giá trị ngoại lai trong véc-tơ kiểu số như trên bạn đọc hãy nghĩ đến sai đơn vị đo lường là nguyên nhân đầu tiên.Ngoài việc sử dụng các tứ phân vị để phát hiện giá trị ngoại lai, một phương pháp định lượng khác cũng thường được đề cập đến trong nhiều tài liệu là sử dụng \\(\\text{Z-Score}\\). Đây là thước đo được tính bằng khoảng cách từ 1 điểm đến giá trị trung bình của dữ liệu sau đó chia cho độ lệch chuẩn của dữ liệu\n\\[\\begin{align}\n\\text{Z-Score}(x_i) = \\cfrac{|x_i - \\bar{x}|}{\\sigma(x)}\n\\end{align}\\]\nvới \\(x_i\\) là giá trị thứ \\(\\) trong véc-tơ \\(x\\), \\(\\bar{x}\\) là giá trị trung bình của véc-tơ \\(x\\), và \\(\\sigma(x)\\) là độ lệch chuẩn của các số trong véc-tơ \\(x\\). Z-Score được tính toán dựa trên giả thiết là dữ liệu có phân phối chuẩn, đó các điểm dữ liệu có Z-Score lớn, thường được lấy ngưỡng lớn hơn 3, được coi là các giá trị ngoại lai. Chẳng hạn như khi vẽ Z-Score của tất cả các điểm dữ liệu trong dữ liệu về chiều cao của nhân viên trong ví dụ được mô tả trong Hình 6.8, chúng ta sẽ có giá trị Z-Score của chiều cao của tất cả các nhân viên như trong Hình 6.10\nHình 6.10: Giá trị Z-Score chiều cao của tất cả các nhân viên. Các quan sát có Z-Score lớn hơn 3 có nhiều khả năng là giá trị ngoại lai\nCác điểm có Z-score lớn hơn ngưỡng 3 trong Hình 6.10 là các điểm bị ghi nhận sai đơn vị đo lường từ cm sang mét và có Z-Score lên đến hơn 6. Trong trường hợp này Z-Score cũng là phương pháp định lượng hiệu quả để xác định giá trị ngoại lai. Tuy nhiên, Z-Score có điểm bất lợi là giá trị này được tính toán dựa trên giá trị trung bình và độ lệch tiêu chuẩn của dữ liệu trong khi chính các giá trị đó lại bị tác động rất mạnh bởi các giá trị ngoại lai. Một cách để giảm thiểu tác động của giá trị ngoại lai đến tính toán \\(\\text{Z-Score}(x_i)\\) là không tính đến \\(x_i\\) khi tính toán trung bình \\(\\bar{x}\\) và \\(\\sigma(x)\\).Đa số các phương pháp xác định giá trị ngoại lai ở trên đều dựa trên giả thiết là véc-tơ dữ liệu có phân phối chuẩn. Tuy nhiên, không phải lúc nào phân phối chuẩn cũng phù hợp với véc-tơ kiểu số. Dữ liệu về bồi thường bảo hiểm là một điển hình của dữ liệu không có phân phối chuẩn. Hình 6.11 mô tả số liệu về tiền bồi thường bảo hiểm sức khỏe của hơn 1.000 khách hàng tại một công ty bảo hiểm:\nHình 6.11: Phân phối xác suất của tiền bồi thường bảo hiểm y tế tại của hơn 1.000 khách hàng tại một công ty bảo hiểm. Hình bên trái: đồ thị histogram cho thấy phân phối của số tiền bồi thường không phải là phân phối chuẩn. Hình bên phải: có nhiều điểm có Z-Score lớn hơn ngưỡng 3\nNhiều điểm dữ liệu được xác định là ngoại lai mặc dù thực tế thì đây vẫn là các giá trị thông thường. Nguyên nhân là phân phối của số tiền bảo hiểm y tế không phải là phân phối chuẩn. Trong trường hợp này, tính toán Z-score trên dữ liệu ban đầu sẽ không cho kết quả chính xác. Khi gặp dữ liệu không có phân phối chuẩn, trước hết cần biến đổi dữ liệu về phân phối chuẩn hoặc biến đổi về gần phân phối chuẩn nhất có thể trước khi thực hiện tính Z-Score. Phép biến đổi về dữ liệu phân phối chuẩn thường được sử dụng nhất là biến đổi Box-Cox được trình bày trong Phụ lục 6.5.2.\nHình 6.12: Dữ liệu bồi thường bảo hiểm sau khi đã được biến đổi về gần với phân phối chuẩn. Hình bên trái: đồ thị Histogram cho thấy phân phối của các điểm dữ liệu đã gần với phân phối chuẩn hơn với dữ liệu ban đầu. Hình bên phải: các điểm có nhiều khả năng là giá trị ngoại lai là các giá trị có Z-score trên ngưỡng 3\nHình 6.12 mô tả dữ liệu bồi thường bảo hiểm sau khi đã được biến đổi về phân phối chuẩn. Có thể thấy rằng sau phép biến đổi, các giá trị có Z-Score lớn hơn ngưỡng 3 đã giảm đi rất nhiều. Các điểm này nhiều khả năng là những khoản tiền bồi thường lớn bất thường và cần được kiểm tra lại. Ngoài biến đổi Box-Cox, một phương pháp khác để biến đổi véc-tơ về phân phối chuẩn là sử dụng hàm ngược của hàm phân phối chuẩn. Phương pháp này được trình bày trong Phụ lục ??.Trong thực tế trong rất nhiều trường hợp, chúng ta chỉ quan sát trên các biến dữ liệu riêng lẻ thì không thể xác định được giá trị ngoại lai. Giống như điểm B trong đồ thị bên phải của Hình 6.4, nếu chúng ta chỉ quan sát vị trí của điểm này trên trục \\(\\overrightarrow{Ox}\\) hoặc trục \\(\\overrightarrow{Oy}\\) một cách riêng biệt thì không thể xác định được đây là giá trị ngoại lai. Điều này có nghĩa là một quan sát có thể không phải là ngoại lai nếu như chỉ quan sát trên từng biến dữ liệu, nhưng lại là giá trị ngoại lai khi quan sát đồng thời các thành phần của quan sát đó. Các kỹ thuật xác định giá trị ngoại lai trong không gian nhiều chiều sẽ được thảo luận trong phần tiếp theo.","code":""},{"path":"tiền-xử-lý-dữ-liệu.html","id":"giá-trị-ngoại-lai-trong-không-gian-nhiều-chiều","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.4.2.2 Giá trị ngoại lai trong không gian nhiều chiều","text":"Xác định giá trị ngoại lai trong không gian nhiều chiều phức tạp hơn trong không gian một chiều. Thật vậy, trong không gian một chiều, chúng ta cần xác định những số nào là giá trị ngoại lai của một véc-tơ. Trong khi trong không gian nhiều chiều, chúng ta cần phải xác định các quan sát nào là giá trị ngoại lai trong một dữ liệu. Ngoài việc xem xét giá trị trong từng biến dữ liệu, chúng ta cần phải xem xét cả mối liên hệ giữa các biến.Các phương pháp để xác định giá giá trị ngoại lai trong không gian nhiều chiều về cơ bản vẫn dựa trên nguyên tắc cơ bản áp dụng trong không gian một chiều, đó là các quan sát càng xa điểm trung tâm của dữ liệu thì quan sát đó càng có khả năng cao là giá trị ngoại lai. Khái niệm xa hay gần trong một không gian nhiều chiều luôn gắn liền với một khái niệm về khoảng cách. Khoảng cách thường được sử dụng nhiều nhất trong không gian nhiều chiều là khoảng cách Euclid. Tuy nhiên khoảng cách Euclid có nhược điểm là không tính đến mối liên hệ giữa các biến dữ liệu. Khoảng cách thường được sử dụng hơn để xác định giá trị ngoại lai là khoảng cách Mahalanobis.Cho \\(\\textbf{x}_i = x_{i1}, x_{i2}, \\cdots, x_{ip}\\) là quan sát thứ \\(\\) và \\(\\boldsymbol{\\mu} = \\mu_{1}, \\mu_{2}, \\cdots, \\mu_{p}\\) là véc-tơ giá trị trung bình của các véc-tơ cột. Khoảng cách Euclid và khoảng cách Mahalanobis từ điểm \\(\\textbf{x}_i\\) đến \\(\\boldsymbol{\\mu}\\) được định nghĩa như sau:\n\\[\\begin{align}\nD^{Euc}(\\textbf{x}_i,\\boldsymbol{\\mu}) & = \\sqrt{(\\textbf{x}_i - \\boldsymbol{\\mu})^T (\\textbf{x}_i - \\boldsymbol{\\mu}}) \\\\\nD^{Mah}(\\textbf{x}_i,\\boldsymbol{\\mu})& = \\sqrt{(\\textbf{x}_i - \\boldsymbol{\\mu})^T \\ \\Sigma^{-1} \\  (\\textbf{x}_i - \\boldsymbol{\\mu})} \\\\\n\\end{align}\\]\ntrong đó \\(D^{Euc}(\\textbf{x}_i,\\boldsymbol{\\mu})\\) và \\(D^{Mah}(\\textbf{x}_i,\\boldsymbol{\\mu})\\) lần lượt là khoảng cách Euclid và khoảng cách Mahalanobis từ quan sát \\(\\textbf{x}_i\\) đến điểm trung bình \\(\\boldsymbol{\\mu}\\). Trong công thức tính khoảng cách Mahalanobis, \\(\\Sigma^{-1}\\) là ma trận nghịch đảo của ma trận hiệp phương sai của các biến trong dữ liệu. Có thể thấy rằng khoảng cách Euclid là trường hợp riêng của khoảng cách Mahalanobis khi các cột dữ liệu có phương sai bằng 1 và đôi một độc lập với nhau.Bạn đọc có thể tự viết các hàm số tính khoảng cách Euclid và hàm số tính khoảng cách Mahalanobis giữa 2 véc-tơ bất kỳ. Ví dụ, trong các câu lệnh dưới đây, các hàm có tên là Dis.Euc() và hàm Dis.Mah() được định nghĩa như sauChúng ta quay lại ví dụ về dữ liệu bao gồm 10 quan sát với hai giá trị ngoại lai là điểm và điểm B trong Hình 6.4. Chúng ta tính toán khoảng cách Euclid của mỗi điểm đến trung tâm của dữ liệu và sắp xếp các điểm theo thứ tự khoảng cách Euclid đến điểm trung tâm giảm dần. Kết quả được cho trong Bảng @ref(tag:tbptdl010)\nBảng 6.14: Khoảng cách Euclid của 10 điểm dữ liệu đến trung tâm được sắp xếp theo thứ tự giảm dần\nCó thế thấy rằng khi chỉ có 10 quan sát, khoảng cách Euclid có thể sử dụng để phát hiện được giá trị ngoại lai là điểm và điểm B vì hai điểm này có khoảng cách đến trung tâm xa hơn với các điểm còn lại. Khoảng cách Mahalanobis cho kết quả là điểm là giá trị ngoại lai, trong khi điểm B lại không cho kết quả rõ ràng.Sử dụng khoảng cách Euclid có thể gặp vấn đề khi số lượng quan sát nhiều hơn và mối liên hệ giữa X và Y rõ ràng hơn. Thật vậy, chúng ta thực hiện tính toán các khoảng cách Euclid và Mahalanobis từ 100 điểm trong đồ thị bên phải của Hình 6.4 đến trung tâm của dữ liệu đó, sau đó sắp xếp các điểm theo thứ tự khoảng cách Euclid giảm dần giống như khi có 10 quan sát. 10 điểm có khoảng cách Euclid đến trung tâm lớn nhất được liệt kê trong Bảng 6.15.\nBảng 6.15: 10 điểm dữ liệu có khoảng cách Euclid lớn nhất đến trung tâm của dữ liệu\nBạn đọc có thể thấy khoảng cách Euclid không cho kết quả tốt như khoảng cách Malahanobis khi dữ liệu nhiều quan sát và mối liên hệ giữa các biến là rõ ràng hơn.\n* Khi đo bằng khoảng cách Euclid, điểm vẫn là điểm xa trung tâm dữ liệu nhất. Tuy nhiên khoảng cách từ điểm B đến trung tâm dữ liệu là nhỏ hơn một số điểm khác, mặc dù các điểm đó không phải là các giá trị ngoại lai.\n* Khi tính bằng khoảng cách Mahalanobis, chúng ta có thể thấy rằng điểm là điểm có khoảng cách xa nhất, sau đó đến điểm B với khoảng cách Malahanobis là 4.675. Các điểm khác đều có khoảng cách Mahalanobis nhỏ hơn 2.5. Như vậy khoảng cách Mahalanobis xác định giá trị ngoại lai tốt hơn khoảng cách Euclid trong trường hợp này.Các kỹ thuật phát hiện giá trị ngoại lai phức tạp hơn dựa trên nguyên lý phân nhóm và phân cụm sẽ được trình bày trong chương học máy không có giám sát. Nguyên tắc xác định một quan sát ngoại lai là phân chia dữ liệu thành các cụm sao cho các quan sát trong cùng một cụm có tính chất tương tự nhau. Các quan sát không nằm trong cụm nào, hoặc trong các cụm có rất ít quan sát, là các điểm dữ liệu có nhiều khả năng là giá trị ngoại lai.","code":"\nDis.Euc<-function(x,y) sum((x-y)^2)^0.5\nDis.Mah<-function(x,y,Sigma) (t(x-y)%*% solve(Sigma) %*%(x-y))^0.5"},{"path":"tiền-xử-lý-dữ-liệu.html","id":"xử-lý-giá-trị-ngoại-lai.","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.4.3 Xử lý giá trị ngoại lai.","text":"Có nhiều phương pháp để xử lý giá trị ngoại lai trong dữ liệu. Tùy thuộc vào tình huống và dữ liệu cụ thể, phương pháp nào cũng có thể đúng hoặc sai. Điều quan trọng là bạn đọc phải phân tích các tình huống có thể liên quan đến giá trị ngoại lai. Đôi khi việc phân tích các giá trị ngoại lai này còn giúp bạn có những hiểu biết hơn về dữ liệu và tối ưu công việc phân tích của bạn.Phương pháp đơn giản nhất và nhưng kém hiệu quả nhất là loại bỏ các quan sát, hoặc biến có chứa giá trị ngoại lai. Phương pháp này chỉ có ý nghĩa khi bạn có số lượng quan sát đủ lớn và các giá trị bị coi là ngoại lai không có có ý nghĩa trong xác định phân phối xác suất của từng biến.Phương pháp thứ hai là thay thế giá trị ngoại lai bằng một giá trị khác: bạn đọc có thể thay thế giá trị ngoại lai bằng giá trị có ý nghĩa hơn, chẳng hạn như thay thế các giá trị nhỏ hơn giá trị \\(Q_0\\) bằng chính \\(Q_0\\) và thay thế các giá trị lớn hơn \\(Q_4\\) bằng chính \\(Q_4\\). Một cách tiếp cận khác cũng có thể sử dụng là thay thế giá trị ngoại lai bằng giá trị trung bình, trung vị, hoặc mode của phân phối. Đây là phương pháp đơn giản, dễ sử dụng và có thể cho hiệu quả tốt hơn với phương pháp xóa quan sát.Phương pháp sau cùng, và cũng là phương pháp đòi hỏi kỹ thuật phức tạp nhất, là coi giá trị ngoại lai như một giá trị không quan sát được, sau đó xây dựng mô hình để dự đoán cho giá trị ngoại lai. Các phương pháp thay thế giá trị ngoại lai bằng giá trị dự đoán dựa trên các mô hình tương tự như các phương pháp xử lý dữ liệu không quan sát được. Bạn đọc có thể tham khảo phần 6.3.2.3 của cuốn sách.","code":""},{"path":"tiền-xử-lý-dữ-liệu.html","id":"phụ-lục-2","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.5 Phụ lục","text":"","code":""},{"path":"tiền-xử-lý-dữ-liệu.html","id":"appenptdl01","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.5.1 Kiểm định sự độc lập của hai biến","text":"","code":""},{"path":"tiền-xử-lý-dữ-liệu.html","id":"pearsons-chi-squared-tests","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.5.1.1 Pearson’s Chi-squared tests","text":"","code":""},{"path":"tiền-xử-lý-dữ-liệu.html","id":"appenptdl02","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.5.2 Box-Cox transformation","text":"Biến đổi Box-Cox là một phương pháp biến đổi để đưa một véc-tơ có phân phối khác với phân phối chuẩn thành một véc-tơ có phân phối gần với phân phối chuẩn. Phép biến đổi Box-Cox chỉ có duy nhất một tham số \\(\\lambda\\).\n\\[\\begin{align}\nx(\\lambda) = \\begin{cases}\n\\cfrac{y^\\lambda-1}{\\lambda} \\text{ nếu } \\lambda \\neq 0 \\\\\nlog(y) \\text{ nếu } \\lambda = 0\n\\end{cases}\n\\end{align}\\]giá trị \\(\\lambda\\) thường được lựa chọn trong khoảng (-5,5) sao cho khoảng cách giữa dữ liệu sau khi biến đổi đến phân phối chuẩn là nhỏ nhất. Khoảng cách giữa hai phân phối được đo bằng khoảng cách Kolmogorov-Smirnov. Dữ liệu nào có khoảng cách Kolmogorov-Smirnov đến phân phối chuẩn nhỏ nhất là dữ liệu có phân phối gần với phân phối chuẩn nhất. Hình (@fig::fgoutlier11) mô tả quá trình tìm tham số \\(\\lambda\\) của biến đổi Box-Cox sao cho dữ liệu về bồi thường bảo hiểm y tế được mô tả trong Hình … được biến đổi về gần phân phối chuẩn.\nHình 6.13: Lựa chọn tham số để thực hiện biến đổi Box-Cox. Giá trị tham số lambda tối thiểu hóa khoảng cách của phân phối của dữ liệu đến phân phối chuẩn được lựa chọn\nTham số \\(\\lambda\\) tối thiểu hóa khoảng cách từ phân phối của dữ liệu đến phân phối chuẩn là 0.21, chúng ta có phân phối của dữ liệu sau khi biến đổi trong Hình 6.14\nHình 6.14: Biến đổi số tiền bồi thường thành phân phối chuẩn bằng cách sử dụng biến đổi Box-Cox với tham số 0.21\n","code":""},{"path":"tiền-xử-lý-dữ-liệu.html","id":"phương-pháp-chuẩn-hóa-véc-tơ-bằng-hàm-ngược","chapter":"Chương 6 Tiền xử lý dữ liệu","heading":"6.5.3 Phương pháp chuẩn hóa véc-tơ bằng hàm ngược","text":"Phương pháp biến đổi này dựa trên hai kết quả cơ bản như sau:Nếu \\(X\\) là một biến ngẫu nhiên liên tục có hàm phân phối \\(F\\) thì biến ngẫu nhiên \\(F(X)\\) sẽ có phân phối \\(\\text{Uniform}(0,1)\\)Nếu \\(X\\) là một biến ngẫu nhiên liên tục có hàm phân phối \\(F\\) thì biến ngẫu nhiên \\(F(X)\\) sẽ có phân phối \\(\\text{Uniform}(0,1)\\)Nếu \\(U\\) là một biến ngẫu nhiên phân phối \\(\\text{Uniform}(0,1)\\) thì biến ngẫu nhiên \\(\\Phi^{-1}(U)\\) sẽ có phân phối chuẩn với trung bình bằng 0 và phương sai bằng 1, trong đó \\(\\Phi^{-1}\\) là hàm ngược của hàm phân phối của biến ngẫu nhiên phân phối chuẩn với trung bình bằng 0 và phương sai bằng 1.Nếu \\(U\\) là một biến ngẫu nhiên phân phối \\(\\text{Uniform}(0,1)\\) thì biến ngẫu nhiên \\(\\Phi^{-1}(U)\\) sẽ có phân phối chuẩn với trung bình bằng 0 và phương sai bằng 1, trong đó \\(\\Phi^{-1}\\) là hàm ngược của hàm phân phối của biến ngẫu nhiên phân phối chuẩn với trung bình bằng 0 và phương sai bằng 1.Cả hai kết quả này đều có thể được chứng minh bằng kiến thức xác suất cơ bản. Thứ nhất, \\(F(X)\\) có phân phối \\(\\text{Uniform}(0,1)\\) vì \\(F(X)\\) nhận giá trị trên \\([0,1]\\), đồng thời\n\\[\\begin{align}\n\\mathbb{P}\\left(F(X) < x\\right) &= \\mathbb{P}\\left(X < F^{-1}(x)\\right) \\\\\n& = F(F^{-1}(x)) \\\\\n& = x\n\\end{align}\\]\nlà hàm phân phối xác suất của biến ngẫu nhiên \\(\\text{Uniform}(0,1)\\)Thứ hai, biến ngẫu nhiên \\(\\Phi^{-1}(U)\\) có phân phối chuẩn với trung bình bằng 0 và phương sai bằng 1 vì\n\\[\\begin{align}\n\\mathbb{P}\\left(\\Phi^{-1}(U) < x\\right) & = \\mathbb{P}\\left(U < \\Phi(x)\\right) \\\\\n& = \\Phi(x)\n\\end{align}\\]Như vậy, biến ngẫu nhiên \\(X\\) bất kỳ có thể được biến đổi thành biến ngẫu nhiên phân phối chuẩn với trung bình bằng 0 và phương sai bằng 1 bằng phép biến đổi \\(N = \\Phi^{-1}(F(X))\\) với \\(F\\) là hàm phân phối của \\(X\\).Khó khăn lớn nhất trong phép biến đổi này là tìm ra phân phối \\(F\\) của biến ngẫu nhiên \\(X\\) vì chúng ta chỉ có một véc-tơ quan sát được của \\(X\\). Việc này đòi hỏi các kiến thức liên quan đến thống kê toán.Quay trở lại với ví dụ về dữ liệu về số tiền bồi thường bảo hiểm trong hình 6.11, chúng ta có thể sử dụng phân phối \\(\\text{Pareto}(\\alpha,\\beta)\\) cho số tiền bảo hiểm. Các tham số của phân phối \\(\\text{Pareto}\\) ước lượng cho dữ liệu là \\(\\alpha = 2.17\\), và \\(\\beta = 3.34\\). Chúng ta biến đổi số tiền bồi thường thành phân phối chuẩn như sau:\n\\[\\begin{align}\n& N = \\Phi^{-1}(F(X))\n\\end{align}\\]\nvới \\(F(x)\\) được xác định bởi\n\\[\\begin{align}\nF(x) = 1 - \\left(\\cfrac{\\beta}{x+\\beta} \\right)^\\alpha\n\\end{align}\\]Hình 6.15 mô tả dữ liệu trước và sau khi biến đổi\nHình 6.15: Biến đổi số tiền bồi thường có phân phối Pareto thành phân phối chuẩn bằng cách sử dụng hàm ngược\nCó thể thấy dữ liệu sau khi biến đổi đã gần với phân phối chuẩn hơn với dữ liệu gốc.","code":""},{"path":"biến-đổi-và-sắp-xếp-dữ-liệu.html","id":"biến-đổi-và-sắp-xếp-dữ-liệu","chapter":"Chương 7 Biến đổi và sắp xếp dữ liệu","heading":"Chương 7 Biến đổi và sắp xếp dữ liệu","text":"","code":""},{"path":"biến-đổi-và-sắp-xếp-dữ-liệu.html","id":"biến-đổi-dữ-liệu-bằng-thư-viện-dplyr","chapter":"Chương 7 Biến đổi và sắp xếp dữ liệu","heading":"7.1 Biến đổi dữ liệu bằng thư viện dplyr","text":"Dữ liệu trước khi được đưa vào các bước phân tích, trực quan hóa, hoặc xây dựng mô hình, thường không có cấu trúc đúng như mong muốn. Thông thường, chúng ta sẽ cần thay đổi tên các biến, tạo thêm một số biến mới, sắp xếp lại các quan sát theo một trật tự, lọc dữ liệu theo một số tiêu chí, hoặc tổng hợp và nhóm dữ liệu vào các nhóm để dễ dàng hơn cho các bước tiếp theo. Các bước biến đổi dữ liệu như vậy sẽ được trình bày chi tiết trong phần này của cuốn sách. Đa số các hàm số được sử dụng để thực hiện các phép biến đổi dữ liệu như vậy sẽ nằm trong thư viện dplyr và thư viện tidyr. Đây là hai thư viện con của thư viện tổng hợp tidyverse. Để sử dụng hai thư viện này, bạn đọc có thể gọi thư viện tidyverse hoặc gọi tên hai thư viện dplyr và thư viện tidyr lên cửa sổ làm việc. Bạn đọc cũng cần lưu ý rằng trong thư viện dplyr có một số hàm trùng tên với các hàm có sẵn trong R, chẳng hạn như hàm filter(), hàm select(), hoặc hàm lag(). Bạn đọc cần kiểm tra thứ tự ưu tiên của các thư viện khi sử dụng các hàm kể trên, hoặc gọi tên thư viện đi kèm với tên hàm để tránh gặp lỗi khi thực thi các câu lệnh.Dữ liệu để minh họa cho các phép biến đổi trong chương này là dữ liệu gapminder nằm trong thư viện dslabs. Đây là dữ liệu mô tả sức khỏe và thu nhập của người dân thuộc tất cả các quốc gia trên thế giới được quan sát từ năm 1960 đến năm 2016. Chúng tôi lựa chọn dữ liệu này vì đây là dữ liệu dễ hiểu với đa số bạn đọc và có nhiều ý tưởng để phân tích. Mặc dù dữ liệu gapminder đã được đề cập trong phần tiền xử lý dữ liệu nhưng chúng tôi khuyên bạn đọc nên tham khảo mô tả về các biến trong dữ liệu một lần nữa trước khi đi đến các phần tiếp theo của cuốn sách.Để tránh việc hiển thị dữ liệu bị tràn dòng, chúng ta sẽ đổi dữ liệu về dạng tibble trước khi thực thi các hàm sốTrong các phần tiếp theo, chúng tôi sẽ lần lượt giới thiệu các hàm quan trọng trong thư viện dplyr dùng để thực hiện các biến đổi dữ liệu và các tham số quan trọng của các hàm số đó. Chúng tôi cũng sẽ giới thiệu với bạn đọc về cách kết hợp các hàm số đó với nhau thành một câu lệnh duy nhất bằng cách sử dụng toán tử pipe (%>%).","code":"\nmytib<-as.tibble(gapminder) # mytib là dữ liệu kiểu tibble"},{"path":"biến-đổi-và-sắp-xếp-dữ-liệu.html","id":"thêm-biến-bằng-hàm-mutate","chapter":"Chương 7 Biến đổi và sắp xếp dữ liệu","heading":"7.1.1 Thêm biến bằng hàm mutate()","text":"Khi muốn tính toán giá trị cho một biến mới dựa trên các biến hiện có và thêm biến đó vào dữ liệu, bạn đọc sử dụng hàm mutate(). Hàm mutate() luôn thêm biến vào vị trí phía sau biến cuối cùng theo thứ tự từ trái sang phải trong dữ liệu hiện có. Khi bạn muốn thêm biến vào một vị trí cụ thể trong dữ liệu, bạn có thể sử dụng các tham số sau trong hàm mutate().Tham số .sử dụng để gán giá trị cho tên biến hiện có sẽ nằm phía trước biến mà bạn đọc muốn thêm vào.Tham số .sử dụng để gán giá trị cho tên biến hiện có sẽ nằm phía sau biến mà bạn đọc muốn thêm vào.Ví dụ, chúng ta muốn thêm biến thu nhập bình quân đầu người của mỗi quốc gia, được tính bằng thu nhập quốc nội (biến gdp) chia cho dân số của quốc gia đó (biến population), chúng ta sử dụng mutate() như sau:Câu lệnh trên có ý nghĩa là thêm biến có tên là gdp_per_capita, được tính bằng tổng thu nhập quốc nội (gdp) chia cho dân số (population) của quốc gia đó. chúng ta không chỉ định vị trí cụ thể cho biến gdp_per_capita, biến này sẽ nằm ở vị trí cuối cùng theo thứ tự từ trái sang phải trong dữ liệu mới.Nếu bạn đọc muốn biến mới được thêm vào ngay sau biến infant_mortality, hãy sử dụng tham số .trong hàm mutate() như sau:Tương tự như tham số ., chúng ta sử dụng tham số .trong hàm mutate() để cho biết biến mới thêm vào sẽ nằm phía trước biến mà chúng ta chỉ định. Để thêm biến thu nhập bình quân đầu người vào phía trước biến infant_mortality, chúng ta sử dụng tham số .như sauMột hàm số khác được sử dụng với mục đích tương tự là thêm biến mới vào dữ liệu giống như hàm mutate() là hàm transmute(). Hàm transmute() khác hàm mutate() ở chỗ là trong dữ liệu mới được tạo thành chỉ bao gồm các biến mới được khai báo trong hàm số đó. Ví dụ, chúng ta có thể thêm biến thu nhập bình quân đầu người của các quốc gia vào dữ liệu ban đầu bằng hàm transmute():Có thể thấy rằng trong dữ liệu mới được tạo thành, chỉ có một biến duy nhất là biến thu nhập bình quân đầu người (gdp_per_capita) còn các biến khác đã không được giữ lại.","code":"\nmutate(mytib, gdp_per_capita = gdp/population) # Thêm cột có tên là gdp_per_capita## # A tibble: 10,545 × 10\n##    country   year infant_mortality life_expectancy fertility population      gdp\n##    <fct>    <int>            <dbl>           <dbl>     <dbl>      <dbl>    <dbl>\n##  1 Albania   1960            115.             62.9      6.19    1636054 NA      \n##  2 Algeria   1960            148.             47.5      7.65   11124892  1.38e10\n##  3 Angola    1960            208              36.0      7.32    5270844 NA      \n##  4 Antigua…  1960             NA              63.0      4.43      54681 NA      \n##  5 Argenti…  1960             59.9            65.4      3.11   20619075  1.08e11\n##  6 Armenia   1960             NA              66.9      4.55    1867396 NA      \n##  7 Aruba     1960             NA              65.7      4.82      54208 NA      \n##  8 Austral…  1960             20.3            70.9      3.45   10292328  9.67e10\n##  9 Austria   1960             37.3            68.8      2.7     7065525  5.24e10\n## 10 Azerbai…  1960             NA              61.3      5.57    3897889 NA      \n## # ℹ 10,535 more rows\n## # ℹ 3 more variables: continent <fct>, region <fct>, gdp_per_capita <dbl>\nmutate(mytib, gdp_per_capita = gdp/population, .after = infant_mortality)## # A tibble: 10,545 × 10\n##    country        year infant_mortality gdp_per_capita life_expectancy fertility\n##    <fct>         <int>            <dbl>          <dbl>           <dbl>     <dbl>\n##  1 Albania        1960            115.             NA             62.9      6.19\n##  2 Algeria        1960            148.           1243.            47.5      7.65\n##  3 Angola         1960            208              NA             36.0      7.32\n##  4 Antigua and …  1960             NA              NA             63.0      4.43\n##  5 Argentina      1960             59.9          5254.            65.4      3.11\n##  6 Armenia        1960             NA              NA             66.9      4.55\n##  7 Aruba          1960             NA              NA             65.7      4.82\n##  8 Australia      1960             20.3          9393.            70.9      3.45\n##  9 Austria        1960             37.3          7415.            68.8      2.7 \n## 10 Azerbaijan     1960             NA              NA             61.3      5.57\n## # ℹ 10,535 more rows\n## # ℹ 4 more variables: population <dbl>, gdp <dbl>, continent <fct>,\n## #   region <fct>\nmutate(mytib, gdp_per_capita = gdp/population, .before = infant_mortality)## # A tibble: 10,545 × 10\n##    country        year gdp_per_capita infant_mortality life_expectancy fertility\n##    <fct>         <int>          <dbl>            <dbl>           <dbl>     <dbl>\n##  1 Albania        1960            NA             115.             62.9      6.19\n##  2 Algeria        1960          1243.            148.             47.5      7.65\n##  3 Angola         1960            NA             208              36.0      7.32\n##  4 Antigua and …  1960            NA              NA              63.0      4.43\n##  5 Argentina      1960          5254.             59.9            65.4      3.11\n##  6 Armenia        1960            NA              NA              66.9      4.55\n##  7 Aruba          1960            NA              NA              65.7      4.82\n##  8 Australia      1960          9393.             20.3            70.9      3.45\n##  9 Austria        1960          7415.             37.3            68.8      2.7 \n## 10 Azerbaijan     1960            NA              NA              61.3      5.57\n## # ℹ 10,535 more rows\n## # ℹ 4 more variables: population <dbl>, gdp <dbl>, continent <fct>,\n## #   region <fct>\ntransmute(mytib, gdp_per_capita = gdp/population)## # A tibble: 10,545 × 1\n##    gdp_per_capita\n##             <dbl>\n##  1            NA \n##  2          1243.\n##  3            NA \n##  4            NA \n##  5          5254.\n##  6            NA \n##  7            NA \n##  8          9393.\n##  9          7415.\n## 10            NA \n## # ℹ 10,535 more rows"},{"path":"biến-đổi-và-sắp-xếp-dữ-liệu.html","id":"lựa-chọn-biến-bằng-hàm-select","chapter":"Chương 7 Biến đổi và sắp xếp dữ liệu","heading":"7.1.2 Lựa chọn biến bằng hàm select()","text":"Khi dữ liệu có quá nhiều biến trong khi chúng ta chỉ muốn sử dụng một số biến nhất định trong việc phân tích, chúng ta sử dụng hàm select() để lựa chọn các biến cần sử dụng trong các bước tiếp theo. Để biết chính xác tên các biến trong dữ liệu hiện có, chúng ta sử dụng hàm names():Lưu ý duy nhất khi sử dụng hàm select() là cần gọi đúng tên các biến mà chúng ta muốn lựa chọn. Ví dụ, trong số 9 biến hiện có trong mytib, chúng ta chỉ sử dụng ba biến có tên là year, gdp, và population, chúng ta sử dụng hàm select() như sau:Khi sử dụng hàm select() để lựa chọn biến, chúng ta cũng có thể thực hiện đổi tên biến trong cùng một câu lệnh. Ví dụ, bạn đọc muốn tên các biến mới tương ứng với các biến year, gdp, và population lần lượt là Year, Gdp và Population, chúng ta viết câu lệnh với hàm select() như sau:Dữ liệu mytib chỉ có 9 biến nên việc hiển thị và gọi đúng tên biến không gặp vấn đề. Tuy nhiên, khi dữ liệu có quá nhiều biến đồng thời tên các biến dài và khó nhớ thì việc gọi tên chính xác tất cả các biến trở nên khó khăn và câu lệnh select() sẽ trở nên phức tạp. Để hỗ trợ cho người dùng khi gặp những khó khăn như vậy, thư viện dplyr có các phương pháp lựa chọn biến mà không cần gọi chính xác tên biến. Ví dụ, chúng ta có thể sử dụng dấu : đứng giữa hai tên biến cụ thể để lựa chọn tất cả các biến nằm giữa hai biến mà chúng ta chỉ định.Câu lệnh trên có ý nghĩa là lựa chọn từ dữ liệu mytib biến year và tất cả các biến nằm giữa biến gdp và biến population.Ngoài ra, hàm select() còn cho phép bạn đọc lựa chọn các biến mà chúng ta không nhớ chính xác tên bằng cách sử dụng một trong các tham số được liệt kê dưới đây:Tham số starts_with() được sử dụng để lựa chọn các biến có tên bắt đầu bằng một chuỗi ký tự nào đó. Chúng ta chỉ cần viết đoạn ký tự đó trong hàm starts_with() đặt trong hàm select(). Ví dụ, chúng ta không nhớ chính xác tên của biến tỷ lệ tử vong của trẻ sơ sinh trong dữ liệu gapminder; chúng ta chỉ chắc chắn rằng tên biến được bắt đầu bằng infant. Tham số starts_with() được sử dụng trong trường hợp này như sau:Tương tự như tham số starts_with(), các tham số ends_with() hoặc contains() được sử dụng để lựa chọn các biến có tên kết thúc bằng một chuỗi ký tự hoặc có tên chứa một chuỗi ký tự nào đó.Tương tự như tham số starts_with(), các tham số ends_with() hoặc contains() được sử dụng để lựa chọn các biến có tên kết thúc bằng một chuỗi ký tự hoặc có tên chứa một chuỗi ký tự nào đó.Tham số matches() có thể được sử dụng trong trường hợp tổng quát hơn contains()khi các biến được lựa chọn có tên được biểu diễn qua các biểu thức chính quy.Tham số matches() có thể được sử dụng trong trường hợp tổng quát hơn contains()khi các biến được lựa chọn có tên được biểu diễn qua các biểu thức chính quy.Khi số lượng biến được lựa chọn nhiều hơn số biến không được lựa chọn, hoặc khi chúng ta muốn loại một số biến không sử dụng ra khỏi dữ liệu, hàm select() cũng cho phép chúng ta thực thi yêu cầu loại bỏ biến bằng cách thêm dấu - vào trước tên các biến mà chúng ta muốn loại ra khỏi dữ liệu. Ví dụ, khi chúng ta muốn lựa chọn tất cả các biến, ngoại trừ các biến có tên bắt đầu bằng chuỗi ký tự gdp, hàm select() được sử dụng như sau:","code":"\nnames(mytib) # Cho biết tên các biến trong mytib## [1] \"country\"          \"year\"             \"infant_mortality\" \"life_expectancy\" \n## [5] \"fertility\"        \"population\"       \"gdp\"              \"continent\"       \n## [9] \"region\"\nselect(mytib, year, gdp, population) # lựa chọn các cột year, gdp, population## # A tibble: 10,545 × 3\n##     year          gdp population\n##    <int>        <dbl>      <dbl>\n##  1  1960           NA    1636054\n##  2  1960  13828152297   11124892\n##  3  1960           NA    5270844\n##  4  1960           NA      54681\n##  5  1960 108322326649   20619075\n##  6  1960           NA    1867396\n##  7  1960           NA      54208\n##  8  1960  96677859364   10292328\n##  9  1960  52392699681    7065525\n## 10  1960           NA    3897889\n## # ℹ 10,535 more rows\nselect(mytib, Year = year, Gdp =  gdp,  Population = population)## # A tibble: 10,545 × 3\n##     Year          Gdp Population\n##    <int>        <dbl>      <dbl>\n##  1  1960           NA    1636054\n##  2  1960  13828152297   11124892\n##  3  1960           NA    5270844\n##  4  1960           NA      54681\n##  5  1960 108322326649   20619075\n##  6  1960           NA    1867396\n##  7  1960           NA      54208\n##  8  1960  96677859364   10292328\n##  9  1960  52392699681    7065525\n## 10  1960           NA    3897889\n## # ℹ 10,535 more rows\nselect(mytib, year, gdp:population)## # A tibble: 10,545 × 3\n##     year          gdp population\n##    <int>        <dbl>      <dbl>\n##  1  1960           NA    1636054\n##  2  1960  13828152297   11124892\n##  3  1960           NA    5270844\n##  4  1960           NA      54681\n##  5  1960 108322326649   20619075\n##  6  1960           NA    1867396\n##  7  1960           NA      54208\n##  8  1960  96677859364   10292328\n##  9  1960  52392699681    7065525\n## 10  1960           NA    3897889\n## # ℹ 10,535 more rows\n# Lựa chọn tất cả các biến có tên bắt đầu bằng infant\nselect(mytib, starts_with(\"infant\"))## # A tibble: 10,545 × 1\n##    infant_mortality\n##               <dbl>\n##  1            115. \n##  2            148. \n##  3            208  \n##  4             NA  \n##  5             59.9\n##  6             NA  \n##  7             NA  \n##  8             20.3\n##  9             37.3\n## 10             NA  \n## # ℹ 10,535 more rows\nmytib1<-mutate(mytib, gdp_per_capita = gdp/population)\n\n# Lựa chọn các biến có tên chứa \"gdp\"\nselect(mytib1, contains(\"gdp\")) ## # A tibble: 10,545 × 2\n##             gdp gdp_per_capita\n##           <dbl>          <dbl>\n##  1           NA            NA \n##  2  13828152297          1243.\n##  3           NA            NA \n##  4           NA            NA \n##  5 108322326649          5254.\n##  6           NA            NA \n##  7           NA            NA \n##  8  96677859364          9393.\n##  9  52392699681          7415.\n## 10           NA            NA \n## # ℹ 10,535 more rows\nselect(mytib1, - starts_with(\"gdp\"))## # A tibble: 10,545 × 8\n##    country  year infant_mortality life_expectancy fertility population continent\n##    <fct>   <int>            <dbl>           <dbl>     <dbl>      <dbl> <fct>    \n##  1 Albania  1960            115.             62.9      6.19    1636054 Europe   \n##  2 Algeria  1960            148.             47.5      7.65   11124892 Africa   \n##  3 Angola   1960            208              36.0      7.32    5270844 Africa   \n##  4 Antigu…  1960             NA              63.0      4.43      54681 Americas \n##  5 Argent…  1960             59.9            65.4      3.11   20619075 Americas \n##  6 Armenia  1960             NA              66.9      4.55    1867396 Asia     \n##  7 Aruba    1960             NA              65.7      4.82      54208 Americas \n##  8 Austra…  1960             20.3            70.9      3.45   10292328 Oceania  \n##  9 Austria  1960             37.3            68.8      2.7     7065525 Europe   \n## 10 Azerba…  1960             NA              61.3      5.57    3897889 Asia     \n## # ℹ 10,535 more rows\n## # ℹ 1 more variable: region <fct>"},{"path":"biến-đổi-và-sắp-xếp-dữ-liệu.html","id":"lọc-dữ-liệu-bằng-hàm-filter","chapter":"Chương 7 Biến đổi và sắp xếp dữ liệu","heading":"7.1.3 Lọc dữ liệu bằng hàm filter()","text":"Hàm filter() trong thư viện dplyr cho phép chúng ta lọc ra các quan sát có giá trị của một hoặc một vài biến thỏa mãn các điều kiện nào đó. Như chúng tôi đã đề cập ở trên, có một số thư viện khác trong R sử dụng hàm filter() với mục đích khác và chúng ta có thể không chắc chắn về thứ tự ưu tiên của các thư viện đang sẵn sàng trên môi trường làm việc hiện tại. Để đảm bảo gọi đúng hàm filter() trong thư viện dplyr, chúng ta định nghĩa lại hàm filter() như sauCách hoạt động của hàm filter() khá đơn giản. Ví dụ như chúng ta muốn lấy ra dữ liệu của năm 2010 từ dữ liệu gapminder, hàm filter() được sử dụng để lọc ra giá trị 2010 trong biến year như sau:Sau khi thực thi câu lệnh như trên, một tibble mới được tạo thành bao gồm các quan sát với giá trị cột year bằng 2010. Lưu ý rằng nếu chúng ta muốn lưu lại giá trị sau mỗi lần thực hiện biến đổi dữ liệu, hãy gán kết quả vào một dữ liệu mới.Hàm filter() có thể thực hiện việc lọc dữ liệu trên nhiều biến trong cùng một câu lệnh. Ví dụ, chúng ta muốn lọc ra các quan sát của năm 2010 của các quốc gia thuộc lục địa Châu Âu, có thể sử dụng hai phép sánh trong hàm filter() cùng lúc:","code":"\nfilter<-function(...) dplyr::filter(...)\nfilter(mytib, year == 2010) # Chỉ lọc ra các quan sát có year bằng 2010## # A tibble: 185 × 9\n##    country   year infant_mortality life_expectancy fertility population      gdp\n##    <fct>    <int>            <dbl>           <dbl>     <dbl>      <dbl>    <dbl>\n##  1 Albania   2010             14.8            77.2      1.74    2901883  6.14e 9\n##  2 Algeria   2010             23.5            76        2.82   36036159  7.92e10\n##  3 Angola    2010            110.             57.6      6.22   21219954  2.61e10\n##  4 Antigua…  2010              7.7            75.8      2.13      87233  8.37e 8\n##  5 Argenti…  2010             13              75.8      2.22   41222875  4.34e11\n##  6 Armenia   2010             16.1            73        1.55    2963496  4.10e 9\n##  7 Aruba     2010             NA              75.1      1.7      101597 NA      \n##  8 Austral…  2010              4.1            82        1.89   22162863  5.63e11\n##  9 Austria   2010              3.6            80.5      1.44    8391986  2.24e11\n## 10 Azerbai…  2010             33.9            70.1      1.97    9099893  2.12e10\n## # ℹ 175 more rows\n## # ℹ 2 more variables: continent <fct>, region <fct>\nfilter(mytib, year == 2010, continent == \"Europe\")## # A tibble: 39 × 9\n##    country    year infant_mortality life_expectancy fertility population     gdp\n##    <fct>     <int>            <dbl>           <dbl>     <dbl>      <dbl>   <dbl>\n##  1 Albania    2010             14.8            77.2      1.74    2901883 6.14e 9\n##  2 Austria    2010              3.6            80.5      1.44    8391986 2.24e11\n##  3 Belarus    2010              4.7            70.2      1.46    9492122 2.60e10\n##  4 Belgium    2010              3.6            80.1      1.84   10929978 2.67e11\n##  5 Bosnia a…  2010              6.4            77.9      1.24    3835258 8.21e 9\n##  6 Bulgaria   2010             11.2            73.7      1.49    7407297 1.92e10\n##  7 Croatia    2010              4.6            76.7      1.47    4316425 2.80e10\n##  8 Czech Re…  2010              3.4            77.5      1.5    10506617 8.21e10\n##  9 Denmark    2010              3.3            79.4      1.88    5550959 1.69e11\n## 10 Estonia    2010              3.6            76.4      1.63    1332089 8.01e 9\n## # ℹ 29 more rows\n## # ℹ 2 more variables: continent <fct>, region <fct>"},{"path":"biến-đổi-và-sắp-xếp-dữ-liệu.html","id":"sắp-xếp-dữ-liệu-bằng-hàm-arrange","chapter":"Chương 7 Biến đổi và sắp xếp dữ liệu","heading":"7.1.4 Sắp xếp dữ liệu bằng hàm arrange()","text":"Hàm arrange() tạo thành dữ liệu mới thu được bằng cách sắp xếp các quan sát của dữ liệu ban đầu theo thứ tự tăng dần hoặc giảm dần dựa trên giá trị của một hoặc nhiều biến. Nguyên tắc sắp xếp cũng tương tự như quy tắc sắp xếp của hàm sort khi sắp xếp trên véc-tơ, nghĩa là hàm bạn đọc có thể sắp xếp dữ liệu không chỉ theo biến kiểu numeric hay kiểu thời gian, mà còn có thể sắp xếp theo biến kiểu chuỗi ký tự. Lưu ý rằng khi véc-tơ kiểu chuỗi ký tự được định nghĩa dưới dạng factor thì thứ tự tăng dần sẽ được hiểu theo nghĩa là các level của biến kiểu factor tăng dần.Chúng ta sắp xếp dữ liệu gapmider theo thứ tự tăng dần cuả biến year như sau:Để sắp xếp dữ liệu theo thứ tự giảm dần của một biến kiểu số hoặc kiểu thời gian, bạn đọc chỉ cần thêm dấu - vào phía trước tên biến. Tuy nhiên, R sẽ báo lỗi nếu chúng ta thêm dấu - vào trước tên một biến kiểu chuỗi ký tự. Để không xảy ra lỗi này khi sắp xếp dữ liệu theo thứ tự giảm dần của một biến kiểu chuỗi ký tự, chúng ta sử dụng hàm desc() cho tên biến:Hàm desc() có thể sử dụng trên tất cả các kiểu biến khi chúng ta muốn sắp xếp dữ liệu theo thứ tự giá trị trong biến giảm dần. Thêm vào đó, việc sắp xếp dữ liệu sử dụng hàm arrange() có thể được thực hiện dựa trên nhiều biến cùng lúc. Ví dụ, để sắp xếp dữ liệu gapminder theo thứ tự tăng dần theo năm (year), theo Châu lục (continent), và theo vùng (region), bạn đọc viết câu lệnh như sau:Lưu ý rằng thứ tự sắp xếp cũng có thể là tăng theo một biến và giảm theo các biến khác:Khi trong biến dữ liệu sử dụng để sắp xếp có chứa giá trị không quan sát được thì các giá trị này luôn được sắp xếp xuống phía dưới của dữ liệu, bất kể chúng ta sắp xếp dữ liệu theo thứ tự tăng dần hay giảm dần. Thật vậy, cột gdp của dữ liệu gapminder có tỷ lệ giá trị NA khá cao. Khi quan sát phần đuôi của dữ liệu sau khi được sắp xếp theo biến gdp, chúng ta sẽ luôn thấy các giá trị NA được sắp xếp xuống phía dưới:Bạn đọc có thể thấy rằng phía đuôi của kết quả từ phép sắp xếp dữ liệu không thay đổi dù chúng ta có thực hiện sắp xếp theo thứ tự biến gdp tăng dần hay giảm dần. Nguyên nhân là hàm sắp xếp luôn chuyển các giá trị không quan sát được xuống đuôi của kết quả.","code":"\narrange(mytib, year)## # A tibble: 10,545 × 9\n##    country   year infant_mortality life_expectancy fertility population      gdp\n##    <fct>    <int>            <dbl>           <dbl>     <dbl>      <dbl>    <dbl>\n##  1 Albania   1960            115.             62.9      6.19    1636054 NA      \n##  2 Algeria   1960            148.             47.5      7.65   11124892  1.38e10\n##  3 Angola    1960            208              36.0      7.32    5270844 NA      \n##  4 Antigua…  1960             NA              63.0      4.43      54681 NA      \n##  5 Argenti…  1960             59.9            65.4      3.11   20619075  1.08e11\n##  6 Armenia   1960             NA              66.9      4.55    1867396 NA      \n##  7 Aruba     1960             NA              65.7      4.82      54208 NA      \n##  8 Austral…  1960             20.3            70.9      3.45   10292328  9.67e10\n##  9 Austria   1960             37.3            68.8      2.7     7065525  5.24e10\n## 10 Azerbai…  1960             NA              61.3      5.57    3897889 NA      \n## # ℹ 10,535 more rows\n## # ℹ 2 more variables: continent <fct>, region <fct>\n# Sắp xếp dữ liệu theo thứ tự giảm dần theo biến region\narrange(mytib, desc(region))## # A tibble: 10,545 × 9\n##    country   year infant_mortality life_expectancy fertility population      gdp\n##    <fct>    <int>            <dbl>           <dbl>     <dbl>      <dbl>    <dbl>\n##  1 Austria   1960             37.3            68.8      2.7     7065525  5.24e10\n##  2 Belgium   1960             29.5            69.6      2.6     9140563  6.82e10\n##  3 France    1960             23.7            70.5      2.77   45865699  3.50e11\n##  4 Germany   1960             34              69.3      2.41   73179665 NA      \n##  5 Luxembo…  1960             33              69.0      2.35     314586  4.30e 9\n##  6 Netherl…  1960             16.4            73.4      3.12   11418652  9.84e10\n##  7 Switzer…  1960             21.6            71.5      2.52    5296120 NA      \n##  8 Austria   1961             35              69.7      2.79    7105654  5.53e10\n##  9 Belgium   1961             28.1            70.5      2.63    9200393  7.16e10\n## 10 France    1961             22.4            71.1      2.8    46471083  3.69e11\n## # ℹ 10,535 more rows\n## # ℹ 2 more variables: continent <fct>, region <fct>\n# Sắp xếp dữ liệu theo thứ tự tăng dần theo 3 biến\narrange(mytib, year, continent, region)## # A tibble: 10,545 × 9\n##    country    year infant_mortality life_expectancy fertility population     gdp\n##    <fct>     <int>            <dbl>           <dbl>     <dbl>      <dbl>   <dbl>\n##  1 Burundi    1960            145.             40.6      6.95    2786740  3.41e8\n##  2 Comoros    1960            200              44.0      6.79     188732 NA     \n##  3 Djibouti   1960             NA              45.8      6.46      83636 NA     \n##  4 Eritrea    1960             NA              39.0      6.9     1407631 NA     \n##  5 Ethiopia   1960            162              37.7      6.88   22151218 NA     \n##  6 Kenya      1960            119.             47.4      7.95    8105440  2.12e9\n##  7 Madagasc…  1960            112              42.0      7.3     5099371  2.09e9\n##  8 Malawi     1960            218.             38.5      6.91    3618604  3.48e8\n##  9 Mauritius  1960             67.8            58.7      6.17     660023 NA     \n## 10 Mozambiq…  1960            183              38.2      6.6     7493278 NA     \n## # ℹ 10,535 more rows\n## # ℹ 2 more variables: continent <fct>, region <fct>\n# Sắp xếp tăng dần theo năm, giảm dần theo continent, region, và gdp\narrange(mytib, year, desc(continent), desc(region), -gdp) ## # A tibble: 10,545 × 9\n##    country    year infant_mortality life_expectancy fertility population     gdp\n##    <fct>     <int>            <dbl>           <dbl>     <dbl>      <dbl>   <dbl>\n##  1 French P…  1960              NA             56.3      5.66      78083 NA     \n##  2 Samoa      1960              92             51.4      7.65     108645 NA     \n##  3 Tonga      1960              NA             61.2      7.36      61600 NA     \n##  4 Kiribati   1960              NA             45.8      6.95      41234 NA     \n##  5 Micrones…  1960              NA             56.8      6.93      44539 NA     \n##  6 Papua Ne…  1960             135.            38.6      6.28    1966957  8.37e8\n##  7 Fiji       1960              54             55.7      6.46     393383  4.37e8\n##  8 New Cale…  1960              NA             56.4      5.22      78058 NA     \n##  9 Solomon …  1960             132.            50.6      6.39     117869 NA     \n## 10 Vanuatu    1960             107.            46.0      7.2       63701 NA     \n## # ℹ 10,535 more rows\n## # ℹ 2 more variables: continent <fct>, region <fct>\ntail(arrange(mytib, gdp))## # A tibble: 6 × 9\n##   country       year infant_mortality life_expectancy fertility population   gdp\n##   <fct>        <int>            <dbl>           <dbl>     <dbl>      <dbl> <dbl>\n## 1 Venezuela     2016               NA            74.8        NA         NA    NA\n## 2 West Bank a…  2016               NA            74.7        NA         NA    NA\n## 3 Vietnam       2016               NA            75.6        NA         NA    NA\n## 4 Yemen         2016               NA            64.9        NA         NA    NA\n## 5 Zambia        2016               NA            57.1        NA         NA    NA\n## 6 Zimbabwe      2016               NA            61.7        NA         NA    NA\n## # ℹ 2 more variables: continent <fct>, region <fct>\ntail(arrange(mytib, desc(gdp)))## # A tibble: 6 × 9\n##   country       year infant_mortality life_expectancy fertility population   gdp\n##   <fct>        <int>            <dbl>           <dbl>     <dbl>      <dbl> <dbl>\n## 1 Venezuela     2016               NA            74.8        NA         NA    NA\n## 2 West Bank a…  2016               NA            74.7        NA         NA    NA\n## 3 Vietnam       2016               NA            75.6        NA         NA    NA\n## 4 Yemen         2016               NA            64.9        NA         NA    NA\n## 5 Zambia        2016               NA            57.1        NA         NA    NA\n## 6 Zimbabwe      2016               NA            61.7        NA         NA    NA\n## # ℹ 2 more variables: continent <fct>, region <fct>"},{"path":"biến-đổi-và-sắp-xếp-dữ-liệu.html","id":"kết-hợp-các-phép-biến-đổi-bằng-toán-tử-pipe","chapter":"Chương 7 Biến đổi và sắp xếp dữ liệu","heading":"7.1.5 Kết hợp các phép biến đổi bằng toán tử pipe (%>%)","text":"Trước khi giới thiệu về các hàm số khác sử dụng để biến đổi dữ liệu trong thư viện dplyr, chúng tôi giới thiệu đến bạn đọc một công cụ hiệu quả để kết nối các phép biến đổi, đó là toán tử pipe (%>%). Toán tử pipe có thể sử dụng khi chúng ta thực hiện một chuỗi các phép biến đổi trên một dữ liệu mà không cần phải lặp lại việc gọi tên dữ liệu đó. Thuật ngữ toán tử pipe được mượn từ toán học khi nói đến việc sử dụng các hàm số nối tiếp nhau. Sử dụng toán tử pipe trong biến đổi dữ liệu giúp cho việc kết nối các câu lệnh gọi các hàm số trở nên đơn giản và không bị nhầm lẫn.Thật vậy, khi chúng ta muốn thực hiện một phân tích trên dữ liệu gapminder để trả lời câu hỏi: Ba quốc gia có thu nhập bình quân đầu người cao nhất năm 2000 là ba quốc gia nào?. Để trả lời câu hỏi này, bạn đọc sẽ cần thực hiện các phép biến đổi dữ liệu theo thứ tự như sau:Thứ nhất: tính toán thêm cột thu nhập bình quân đầu người, sử dụng hàm mutate().Thứ hai: lọc dữ liệu theo năm, chỉ lấy dữ liệu của năm 2000, sử dụng hàm filter().Thứ ba: lựa chọn cột tên quốc gia (biến country) và biến thu nhập bình quân đầu người vừa tính toán, sử dụng hàm select().Thứ tư: sắp xếp dữ liệu theo cột thu nhập bình quân đầu người, thứ tự sắp xếp là giảm dần, sử dụng hàm arrange().Thứ năm: lấy ra ba hàng đầu tiên của dữ liệu sau khi sắp xếp, sử dụng hàm head().Nếu viết các câu lệnh một cách thông thường, sau mỗi bước ở trên, bạn đọc sẽ phải lưu kết quả và gọi lại kết quả vào bước kế tiếp như sau:Khi viết các câu lệnh như trên sẽ gặp khó khăn và dễ bị nhầm lần chúng ta phải liên tục lưu kết quả của từng câu lệnh và gọi lại kết quả đó trong câu lệnh tiếp theo. Để tránh gặp phải vấn đề này, toán tử pipe, ký hiệu %>%, có thể giúp chúng ta kết nối các câu lệnh lại với nhau trong một câu lệnh duy nhất. Cùng với một yêu cầu như ở trên, cách viết các câu lệnh biến đổi dữ liệu sử dụng toán tử pipe như sau:Bạn đọc có thể thấy rằng kết quả thu được từ hai đoạn câu lệnh là hoàn toàn giống nhau. Cách viết câu lệnh sử dụng toán tử pipe có ưu điểm là rõ ràng, ngắn gọn, và không gây nhầm lẫn. Để bạn đọc làm quen với cách viết câu lệnh sử dụng %>%, từ phần này của cuốn sách, mọi phép biến đổi trên dữ liệu đều được ưu tiên sử dụng cách viết này.Chúng ta sẽ tiếp tục làm quen với các hàm số sử dụng để biến đổi dữ liệu của thư viện dplyr trong các phần tiếp theo.","code":"\n# Bước thứ nhất\nmytib1<-mutate(mytib,gdp_per_capita = gdp/population)\n\n# Bước thứ hai\nmytib1<-filter(mytib1, year == 2010) \n\n# Bước thứ ba\nmytib1<-select(mytib1, country, gdp_per_capita) \n\n# Bước thứ tư\nmytib1<-arrange(mytib1, desc(gdp_per_capita)) \n\n# Bước thứ năm\nhead(mytib1,3) ## # A tibble: 3 × 2\n##   country    gdp_per_capita\n##   <fct>               <dbl>\n## 1 Luxembourg         52210.\n## 2 Japan              40013.\n## 3 Norway             39954.\nmytib%>%\n  \n  # Bước thứ nhất\n  mutate(gdp_per_capita = gdp/population)%>%\n  \n  # Bước thứ hai\n  filter(year == 2010)%>%\n  \n  # Bước thứ ba\n  select(country, gdp_per_capita)%>%\n  \n  # Bước thứ tư\n  arrange(desc(gdp_per_capita)) %>%\n  \n  # Bước thứ năm\n  head(3)## # A tibble: 3 × 2\n##   country    gdp_per_capita\n##   <fct>               <dbl>\n## 1 Luxembourg         52210.\n## 2 Japan              40013.\n## 3 Norway             39954."},{"path":"biến-đổi-và-sắp-xếp-dữ-liệu.html","id":"tổng-hợp-dữ-liệu-bằng-summarise-và-group_by","chapter":"Chương 7 Biến đổi và sắp xếp dữ liệu","heading":"7.1.6 Tổng hợp dữ liệu bằng summarise() và group_by()","text":"Để biết thông tin về thu nhập quốc nội của một quốc gia, chúng ta có thể sử dụng hàm filter() để lọc ra một quan sát và không cần thực hiện thêm tính toán. Câu lệnh dưới đây cho biết thu nhập bình quân đầu người của Việt Nam năm 2000.Khi muốn sánh thu nhập bình quân đầu người của Việt Nam với thu nhập bình quân đầu người của vùng Đông Nam Á trong năm 2000, chúng ta cần lọc dữ liệu theo vùng South-Eastern Asia và năm 2000, loại bỏ các quan sát có giá trị NA, sau đó tính tổng giá trị của biến gdp chia cho tổng giá trị của biến population. Các phép tính toán được thực hiện trên nhiều quan sát cùng một lúc như vậy, với mục tiêu trả lại kết quả là một giá trị đặc trưng của các biến như tổng, giá trị trung bình, trung vị, phương sai,…, được gọi là các phép toán tổng hợp dữ liệu.Hàm summarise() trong thư viện dplyr là một công cụ hiệu quả để thực hiện các phép tính toán tổng hợp dữ liệu như vậy. Để thực hiện phép việc tính thu nhập bình quân đầu người của các quốc gia Đông Nam Á trong năm 2000, chúng ta viết câu lệnh với summarise() như sau:Bạn đọc có thể thấy trong dữ liệu kết quả từ hàm summarise() có bốn biến được tạo thành cũng là bốn biến được khai báo trong hàm số đó. Cách tính toán giá trị của các biến cũng được khai báo ngay bên trong hàm summarise(). Thu nhập bình quân đầu người của các quốc gia Đông Nam Á trong năm 2000 là $ 1257 trong khi thu nhập bình quân đầu người của Việt Nam trong năm 2000 chỉ là $388.Bên trong hàm summarise() chúng ta có thể sử dụng bất kỳ hàm số nào có thể thực thi trên các véc-tơ để tổng hợp giá trị của véc-tơ đó. Ngoài hàm sum() thực hiện để tính tổng, các hàm thông dụng khác có thể sử dụng như:Hàm length() cho biết có bao nhiêu giá trị trong véc-tơ.Hàm mean() cho biết giá trị trung bình của véc-tơ kiểu số.Hàm var() hàm sd() cho biết phương sai và độ lệch chuẩn của véc-tơ kiểu số.Hàm min(), max(), quantile() cho biết các giá trị nhỏ nhất, lớn nhất, các giá trị quantile của véc-tơ kiểu số.Tất cả các hàm có đầu vào là véc-tơ mà bạn đọc tự định nghĩa.Hàm summarise() kết hợp với hàm filter() có thể được sử dụng để tính toán thu nhập bình quân đầu người của các vùng, các Châu lục giống như cách chúng ta tính toán với vùng Đông Nam Á. Tuy nhiên, có thể thấy rằng, để có được giá trị là thu nhập bình quân đầu người của nhiều vùng, hoặc tất cả các châu lục, chúng ta cần thực hiện nhiều lần các câu lệnh như trên và tập hợp kết quả lại trong một dữ liệu duy nhất.Một phương pháp hiệu quả hơn để thực hiện việc này đó là sử dụng hàm group_by() thay thế cho hàm filter(). Hàm số này cho phép chúng ta thực hiện các tính toán theo nhóm được định nghĩa theo các giá trị của một hoặc một vài biến rời rạc. Ví dụ để tính thu nhập bình quân đầu người của tất cả các vùng trên thế giới trong năm 2000 sử dụng dữ liệu gapminder, chúng ta sẽ dùng hàm group_by() để nhóm dữ liệu theo biến gapminder này, sau đó gọi hàm summarise() để tổng hợp dữ liệu cho từng nhóm. Câu lệnh được viết như sau:Có thể thấy trong dữ liệu kết quả từ hàm summarise() có 22 quan sát tương ứng với 22 giá trị khác nhau của region và có 4 biến. Biến đầu tiên là biến region chứa tên 22 vùng; ba biến còn lại được khai báo và tính toán trong hàm summarise(). Quan trọng là khi được gọi bên trong hàm summarise(), các hàm số thực hiện tính toán véc-tơ như hàm sum() chỉ thực thi trên véc-tơ tương ứng với từng vùng, chứ không tính toán trên toàn bộ các quan sát. Bạn đọc có thể thấy trong kết quả các vùng có thu nhập bình quân đầu người ở mức cao hơn 20 nghìn USD là vùng Australia và New Zealand trong khi có những vùng chỉ có thu nhập bình quân đầu người khoảng 271 USD là vùng Đông Phi.Hàm group_by() được sử dụng với một hoặc một vài biến rời rạc và các hàm số được gọi sau hàm số này đều được tính toán theo nhóm thay vì tính toán theo từng quan sát riêng lẻ. Nếu bạn đọc muốn giữ nguyên mỗi quan sát tương ứng với một quốc gia và tính toán thu nhập bình quân đầu người theo vùng tương ứng với quốc gia đó, chúng ta sử dụng hàm transmute() thay thế cho summarise()Dữ liệu mới được tạo thành có 178 quan sát, mỗi mỗi quan sát tương ứng với một quốc gia trong năm 2000. Dữ liệu có 6 biến, trong đó biến region được gọi trong hàm group_by(), năm biến còn lại được khai báo và tính toán trong hàm transmute(). Khi tính toán 5 biến, các biến giữ nguyên giá trị khi chúng ta gán giá trị cho chính biến đó. Với các biến được tính toán dựa trên nhiều quan sát, như biến region_gdp_per_capita trong câu lệnh ở trên, chúng ta sử dụng các hàm số tính toán trên véc-tơ. Nếu bạn đọc muốn giữ nguyên các biến của dữ liệu ban đầu, có thể sử dụng mutate() thay thế cho transmute().Hàm group_by() có thể được sử dụng trên nhiều biến rời rạc cùng một lúc, hoặc có thể được gọi nhiều lần trong một câu lệnh nếu chúng ta muốn nhóm dữ liệu theo các cách khác nhau. Ví dụ, chúng ta muốn thêm vào dữ liệu của năm 2000 các cột chứa giá trị là thu nhập bình quân đầu người theo vùng, theo châu lục, và trên toàn thế giới, chúng ta nhóm dữ liệu lần lượt theo các biến region, continent, và nhóm tất cả dữ liệu, để tính toán trung bình theo nhóm:Bạn đọc có thể thấy trong dữ liệu được tạo thành có các biến region_gdp_per_capita, continent_gdp_per_capita, và global_gdp_per_capita là các biến được tính toán theo các nhóm được quy định bằng các hàm group_by(). Sau khi gọi hàm group_by() và thực hiện tính toán, chúng tôi đã sử dụng hàm ungroup() để trả lại dữ liệu về trạng thái ban đầu. Dữ liệu kết quả đã cho chúng ta một cái nhìn tổng quan hơn về thu nhập bình quân đầu người của tất cả các quốc gia, các vùng lãnh thổ, và các châu lục trên toàn thế giới trong năm 2000. Quan sát đầu tiên tương ứng với Australia, là một quốc gia phát triển, có thu nhập bình quân đầu người khoảng 21 nghìn USD, cao hơn một chút với vùng Australia New Zealand, cao hơn với thu nhập bình quân của Châu đại dương là khoảng 15.5 nghìn USD, và gấp khoảng 4 lần thu nhập bình quân đầu người trên thế giới.Có thể sử dụng nhiều biến rời rạc cùng một lúc trong hàm group_by(). Ví dụ, bạn đọc quan tâm đến sự thay đổi của thu nhập bình quân đầu người của các Châu lục trên thế giới trong các năm 1990, 2000, và 2010. Để thực hiện được tính toán, chúng ta cần nhóm dữ liệu đồng thời theo các biến continent và year như sau:Dữ liệu mới được tạo thành có ba biến, trong đó hai biến đầu tiên được gọi trong hàm group_by() và biến thứ ba có tên continent_gdp_per_capita được tính toán trong hàm summarise().","code":"\nmytib %>% \n  filter(country == \"Vietnam\", year == 2000) %>%\n  mutate(gdp_per_capita = gdp/population) %>%\n  select(country, gdp_per_capita)## # A tibble: 1 × 2\n##   country gdp_per_capita\n##   <fct>            <dbl>\n## 1 Vietnam           388.\nmytib %>% \n  filter(region == \"South-Eastern Asia\", year == 2000) %>%\n  drop_na() %>%\n  summarise(region = \"South-Eastern Asia\",\n            region_gdp = sum(gdp),\n            region_population = sum(population),\n            region_gdp_per_capita = region_gdp/region_population\n            )## # A tibble: 1 × 4\n##   region               region_gdp region_population region_gdp_per_capita\n##   <chr>                     <dbl>             <dbl>                 <dbl>\n## 1 South-Eastern Asia 601360044405         478509017                 1257.\nmytib%>% \n  # Lọc dữ liệu theo năm 2000\n  filter(year == 2000) %>% \n  \n  # Lấy ra 3 cột region, gdp, và population \n  select(region, gdp, population) %>% drop_na() %>%\n  \n  # Nhóm dữ liệu theo biến region\n  group_by(region) %>% \n  \n  # Tổng hợp dữ liệu theo các nhóm\n  summarise(region_gdp = sum(gdp),\n            region_population = sum(population),\n            region_gdp_per_capita = region_gdp/region_population\n            )## # A tibble: 22 × 4\n##    region                    region_gdp region_population region_gdp_per_capita\n##    <fct>                          <dbl>             <dbl>                 <dbl>\n##  1 Australia and New Zealand    4.68e11          22965485                20400.\n##  2 Caribbean                    1.50e11          36996369                 4062.\n##  3 Central America              6.53e11         138780471                 4707.\n##  4 Central Asia                 3.72e10          55117412                  675.\n##  5 Eastern Africa               6.62e10         244407086                  271.\n##  6 Eastern Asia                 6.64e12        1451508364                 4574.\n##  7 Eastern Europe               6.60e11         303788505                 2173.\n##  8 Melanesia                    8.59e 9           6992665                 1229.\n##  9 Micronesia                   3.02e 8            191836                 1573.\n## 10 Middle Africa                3.54e10          95976097                  369.\n## # ℹ 12 more rows\nmytib%>% \n  # Lọc dữ liệu theo năm 2000\n  filter(year == 2000) %>% \n  \n  # Loại bỏ các quan sát có NA\n  drop_na() %>%\n  \n  # Nhóm dữ liệu theo biến region\n  group_by(region) %>% \n  \n  # Tạo thành các cột mới\n  transmute(country = country,\n            gdp = gdp,\n            population = population,\n            gdp_per_capita = gdp/population,\n            region_gdp_per_capita = sum(gdp)/sum(population)\n            )## # A tibble: 178 × 6\n## # Groups:   region [22]\n##    region        country     gdp population gdp_per_capita region_gdp_per_capita\n##    <fct>         <fct>     <dbl>      <dbl>          <dbl>                 <dbl>\n##  1 Southern Eur… Albania 3.69e 9    3121965          1181.                13740.\n##  2 Northern Afr… Algeria 5.48e10   31183658          1757.                 1512.\n##  3 Middle Africa Angola  9.13e 9   15058638           606.                  369.\n##  4 Caribbean     Antigu… 8.03e 8      77648         10335.                 2619.\n##  5 South America Argent… 2.84e11   37057453          7669.                 3806.\n##  6 Western Asia  Armenia 1.91e 9    3076098           621.                 4713.\n##  7 Australia an… Austra… 4.17e11   19107251         21818.                20400.\n##  8 Western Euro… Austria 1.92e11    8050884         23857.                23445.\n##  9 Western Asia  Azerba… 5.27e 9    8117742           650.                 4713.\n## 10 Caribbean     Bahamas 6.33e 9     297891         21241.                 2619.\n## # ℹ 168 more rows\nmytib%>% \n  # Lọc dữ liệu theo năm 2000\n  filter(year == 2000) %>% \n  \n  # Lấy ra 5 cột, và loại bỏ quan sát có NA, thêm biến gdp_per_capita\n  select(country, continent, region, gdp, population) %>%\n  drop_na() %>%\n  mutate(gdp_per_capita = gdp/population) %>%\n  \n  # Nhóm dữ liệu theo biến region và thêm cột region_gdp_per_capita\n  group_by(region) %>%  \n  mutate(region_gdp_per_capita = sum(gdp)/sum(population)) %>% \n  ungroup() %>% # Bỏ nhóm theo reigon\n  \n  # Nhóm dữ liệu theo biến continent và thêm cột continent_gdp_per_capita\n  group_by(continent) %>%  \n  mutate(continent_gdp_per_capita = sum(gdp)/sum(population)) %>% \n  ungroup() %>% # Bỏ nhóm theo continent\n  \n  # Nhóm dữ liệu lại thành một nhóm duy nhất và thêm cột global_gdp_per_capita\n  group_by() %>%  \n  mutate(global_gdp_per_capita = sum(gdp)/sum(population)) %>% \n  ungroup() %>% # Bỏ nhóm\n  \n  # Sắp xếp lại theo biến continent\n  select(-gdp,-population) %>%\n  arrange(desc(continent)) ## # A tibble: 185 × 7\n##    country               continent region   gdp_per_capita region_gdp_per_capita\n##    <fct>                 <fct>     <fct>             <dbl>                 <dbl>\n##  1 Australia             Oceania   Austral…         21818.                20400.\n##  2 Fiji                  Oceania   Melanes…          2076.                 1229.\n##  3 French Polynesia      Oceania   Polynes…         14530.                 7615.\n##  4 Kiribati              Oceania   Microne…           808.                 1573.\n##  5 Micronesia, Fed. Sts. Oceania   Microne…          2175.                 1573.\n##  6 New Caledonia         Oceania   Melanes…         12773.                 1229.\n##  7 New Zealand           Oceania   Austral…         13374.                20400.\n##  8 Papua New Guinea      Oceania   Melanes…           655.                 1229.\n##  9 Samoa                 Oceania   Polynes…          1407.                 7615.\n## 10 Solomon Islands       Oceania   Melanes…          1055.                 1229.\n## # ℹ 175 more rows\n## # ℹ 2 more variables: continent_gdp_per_capita <dbl>,\n## #   global_gdp_per_capita <dbl>\nmytib%>% \n  # Lọc dữ liệu theo các năm 1990, 2000, 2010 và loại bỏ NA\n  filter(year %in% c(1990, 2000, 2010)) %>% \n  drop_na() %>%\n  \n  # Lấy ra 4 biến \n  select(continent, year, population, gdp) %>%\n  \n  # Nhóm dữ liệu theo biến region và biến year\n  group_by(continent, year) %>%  \n  \n  # Tạo thành dữ liệu mới, mỗi quan sát là 1 Châu lục trong 1 năm\n  summarise(continent_gdp_per_capita = sum(gdp)/sum(population))## # A tibble: 15 × 3\n## # Groups:   continent [5]\n##    continent  year continent_gdp_per_capita\n##    <fct>     <int>                    <dbl>\n##  1 Africa     1990                     699.\n##  2 Africa     2000                     738.\n##  3 Africa     2010                     867.\n##  4 Americas   1990                   12740.\n##  5 Americas   2000                   15201.\n##  6 Americas   2010                   16302.\n##  7 Asia       1990                    2074.\n##  8 Asia       2000                    2418.\n##  9 Asia       2010                    3215.\n## 10 Europe     1990                   10695.\n## 11 Europe     2000                   12742.\n## 12 Europe     2010                   14643.\n## 13 Oceania    1990                   13027.\n## 14 Oceania    2000                   15726.\n## 15 Oceania    2010                   17942."},{"path":"biến-đổi-và-sắp-xếp-dữ-liệu.html","id":"sắp-xếp-dữ-liệu-bằng-thư-viện-tidyr","chapter":"Chương 7 Biến đổi và sắp xếp dữ liệu","heading":"7.2 Sắp xếp dữ liệu bằng thư viện tidyr","text":"Dữ liệu trước khi được đưa vào bước trực quan hóa hoặc xây dựng mô hình cần phải được sắp xếp và trình bày một cách nhất quán. Hầu hết các dữ liệu có sẵn trong R, hoặc trong thư viện của R, nhìn chung đều đã được sắp xếp hoàn chỉnh nên chúng ta không gặp phải vấn đề này trong các ví dụ ở trên. Tuy nhiên, dữ liệu lấy từ các nguồn bên ngoài thường gặp phải các vấn đề về sự thiếu nhất quán. Hãy quan sát các ví dụ sau, các dữ liệu cùng thể hiện thông tin về tổng thu nhập quốc dân và dân số của các quốc gia trên thế giới từ năm 2000 đến 2010 nhưng lại được trình bày khác nhau:Tất cả dữ liệu kể trên đều trình bày chung một nguồn thông tin nhưng chỉ có mytib1 là được sắp xếp một cách nhất quán. Trong khi các dữ liệu khác chưa sẵn sàng để thực hiện các bước tiếp theo. Thật vậy:Dữ liệu lưu trong mytib2 có biến gdp_per_capita trình bày dưới dạng chuỗi ký tự, với số tổng thu nhập quốc dân và dân số được lưu trong cùng một cột và cách nhau bởi dấu /. Không thể thực hiện các phân tích hay tính toán với cột dữ liệu như vậy.Dữ liệu lưu trong mytib3 có biến type cho biết số tương ứng trong cột value là giá trị của tổng thu nhập quốc dân hay dân số của nước đó. Giá trị trong cột value không nhất quán vì vừa có thể là số tiền, vừa là số người.Dữ liệu lưu trong mytib4 cũng là một điển hình cho dữ liệu chưa được sắp xếp một cách nhất quán. Giá trị của biến year không được lưu dưới dạng véc-tơ cột mà được lưu dưới dạng tên các cột nên rất khó khăn trong thực hiện tính toán.Một dữ liệu được sắp xếp nhất quán cần phải đảm bảo hai yêu cầu:Thứ nhất: mỗi quan sát là một dòng dữ liệu.Thứ hai: mỗi biến nằm ở một cột. Một biến mô tả một thuộc tính, một tính chất của quan sát tương ứng. Giá trị trong cột phải đồng nhất và đúng định dạng.Lý chính khiến dữ liệu không được sắp xếp nhất quán là dữ liệu thường được tổ chức để thuận lợi cho một số mục tiêu khác với mục tiêu phân tích, chẳng hạn như mục tiêu nhập dữ liệu hoặc mục tiêu để hiển thị trực quan hơn với người quan sát dữ liệu.Quá trình sắp xếp dữ liệu là quá trình biến đổi, chuyển hóa dữ liệu từ các định dạng như dữ liệu trong mytib2, mytib3, hoặc mytib4 về dữ liệu có định dạng như mytib1. Nhìn chung, sắp xếp dữ liệu là công việc tương đối đơn giản với các quy trình khác. Trong phần này, bạn đọc chỉ cần nắm vững nguyên tắc của hai phép biến đổi là kéo dài dữ liệu bằng hàm gather() và mở rộng dữ liệu bằng hàm spread(). Trong các phiên bản mới của thư viện tidyr), các hàm gather() và spread() đã được bổ sung thêm các tham số mới và có thể được gọi bằng tên mới là pivot_longer() và pivot_wider(). Tuy nhiên, các nguyên tắc hoạt động của các hàm này là tương đồng nhau và không có sự khác biệt đáng kể.","code":"\nmytib1## # A tibble: 2,035 × 4\n##    country              year           gdp population\n##    <fct>               <int>         <dbl>      <dbl>\n##  1 Albania              2000   3686649387     3121965\n##  2 Algeria              2000  54790058957    31183658\n##  3 Angola               2000   9129180361    15058638\n##  4 Antigua and Barbuda  2000    802526701.      77648\n##  5 Argentina            2000 284203745280    37057453\n##  6 Armenia              2000   1911563665     3076098\n##  7 Aruba                2000   1858659293       90858\n##  8 Australia            2000 416887521196    19107251\n##  9 Austria              2000 192070749954     8050884\n## 10 Azerbaijan           2000   5272617196     8117742\n## # ℹ 2,025 more rows\nmytib2## # A tibble: 2,035 × 3\n##    country              year gdp_per_capita       \n##    <fct>               <int> <chr>                \n##  1 Albania              2000 3686649387/3121965   \n##  2 Algeria              2000 54790058957/31183658 \n##  3 Angola               2000 9129180361/15058638  \n##  4 Antigua and Barbuda  2000 802526700.6/77648    \n##  5 Argentina            2000 284203745280/37057453\n##  6 Armenia              2000 1911563665/3076098   \n##  7 Aruba                2000 1858659293/90858     \n##  8 Australia            2000 416887521196/19107251\n##  9 Austria              2000 192070749954/8050884 \n## 10 Azerbaijan           2000 5272617196/8117742   \n## # ℹ 2,025 more rows\nmytib3## # A tibble: 4,070 × 4\n##    country              year type               value\n##    <fct>               <int> <chr>              <dbl>\n##  1 Albania              2000 gdp          3686649387 \n##  2 Albania              2000 population      3121965 \n##  3 Algeria              2000 gdp         54790058957 \n##  4 Algeria              2000 population     31183658 \n##  5 Angola               2000 gdp          9129180361 \n##  6 Angola               2000 population     15058638 \n##  7 Antigua and Barbuda  2000 gdp           802526701.\n##  8 Antigua and Barbuda  2000 population        77648 \n##  9 Argentina            2000 gdp        284203745280 \n## 10 Argentina            2000 population     37057453 \n## # ℹ 4,060 more rows\nmytib4## # A tibble: 370 × 13\n##    country type   `2000`  `2001`  `2002`  `2003`  `2004`  `2005`  `2006`  `2007`\n##    <fct>   <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n##  1 Albania gdp   3.69e 9 3.94e 9 4.06e 9 4.29e 9 4.54e 9 4.79e 9 5.03e 9 5.33e 9\n##  2 Albania popu… 3.12e 6 3.12e 6 3.12e 6 3.12e 6 3.10e 6 3.08e 6 3.05e 6 3.01e 6\n##  3 Algeria gdp   5.48e10 5.62e10 5.89e10 6.29e10 6.62e10 6.96e10 7.10e10 7.31e10\n##  4 Algeria popu… 3.12e 7 3.16e 7 3.20e 7 3.24e 7 3.28e 7 3.33e 7 3.37e 7 3.43e 7\n##  5 Angola  gdp   9.13e 9 9.42e 9 1.08e10 1.11e10 1.24e10 1.46e10 1.77e10 2.17e10\n##  6 Angola  popu… 1.51e 7 1.56e 7 1.61e 7 1.67e 7 1.73e 7 1.79e 7 1.85e 7 1.92e 7\n##  7 Antigu… gdp   8.03e 8 8.20e 8 8.41e 8 8.84e 8 9.46e 8 9.85e 8 1.12e 9 1.01e 9\n##  8 Antigu… popu… 7.76e 4 7.90e 4 8.00e 4 8.09e 4 8.17e 4 8.26e 4 8.35e 4 8.44e 4\n##  9 Argent… gdp   2.84e11 2.72e11 2.42e11 2.63e11 2.87e11 3.14e11 3.40e11 3.70e11\n## 10 Argent… popu… 3.71e 7 3.75e 7 3.79e 7 3.83e 7 3.87e 7 3.91e 7 3.96e 7 4.00e 7\n## # ℹ 360 more rows\n## # ℹ 3 more variables: `2008` <dbl>, `2009` <dbl>, `2010` <dbl>"},{"path":"biến-đổi-và-sắp-xếp-dữ-liệu.html","id":"kéo-dài-dữ-liệu-bằng-gather","chapter":"Chương 7 Biến đổi và sắp xếp dữ liệu","heading":"7.2.1 Kéo dài dữ liệu bằng gather()","text":"Dữ liệu được lưu dưới dạng của mytib4 có thông tin về năm quan sát được lưu dưới dạng cột. Đây là trường hợp rất hay gặp phải khi lấy dữ liệu từ các nguồn bên ngoài vào. Các dữ liệu này được lưu dưới dạng các ma trận với ít dòng và nhiều cột để thuận lợi cho người sử dụng dữ liệu có quan sát trực quan. Để đưa dữ liệu như mytib4 về định dạng có thể phân tích được, mà mỗi dòng là một quốc gia, được quan sát trong 1 năm, chúng ta cần thêm vào dữ liệu một cột có tên year. Giá trị của biến year là tên tất cả các cột, từ cột 2000 đến cột 2010. Thêm cột year và kéo dài dữ liệu mytib4, chúng ta sử dụng hàm gather() như sau:Bạn đọc có thể thấy rằng kết quả thu được đã có thêm cột year cho biết thông tin mỗi quốc gia được quan sát trong năm bao nhiêu và cột gdp_population cho biết giá trị của tổng thu nhập quốc dân hoặc dân số của quốc gia đó. Qua cách sử dụng hàm gather(), có thể thấy rằngTham số key trong hàm gather() cho biết tên của cột trong dữ liệu mới được tạo thành. Biến này sẽ chứa giá trị là tên các cột của dữ liệu ban đầu được tập hợp lại. Tham số value cho biết tên cột trong dữ liệu mới được tạo thành. Biến này chứa tất cả giá trị trong các cột được tập hợp của dữ liệu ban đầu. Trong câu lệnh ở trên, biến year chứa giá trị là các năm là tên của các cột trong dữ liệu mytib4 trong khi biến value chứa tất cả các giá trị là dân số hoặc thu nhập quốc nội.Sau khi khai báo hai tham số key và value, bạn đọc cần khai báo chính xác thông tin các biến không bị tác động bởi hàm gather(). Trong ví dụ ở trên, tất các các giá trị chúng ta muốn tập hợp lại giá trị nằm trong các cột bắt đầu từ cột có tên 2000, tương ứng với các quan sát trong năm 2000, đến cột có tên 2010, tương ứng với các quan sát của năm 2010. Khai báo -country và -type trong hàm gather() có ý nghĩa là các biến được tập hợp thông tin lại thành một cột duy nhất là tất cả các cột của mytib4, ngoại trừ hai cột country và type.Trong các phiên bản mới của thư viện tidyr, hàm pivot_longer() thường được sử dụng thay thế cho gather(). Ưu điểm của pivot_longer() là câu lệnh dễ hiểu hơn và cho phép chúng ta quản lý tên cột bằng các hàm sử dụng cùng với các biểu thức chính quy, hay regular expression. Ví dụ, chúng ta có thể sử dụng pivot_longer() để tập hợp thông tin của tất cả các cột có tên cột bắt đầu bằng ký tự ‘2’ như sauBạn đọc có thể thấy rằng các tham số names_to và values_to trong hàm pivot_longer() được sử dụng tương tự như tham số key và value trong hàm gather().Hàm pivot_longer() cho phép kéo dài các bảng mà giá trị của nhiều biến được tích hợp trong tên của các cột. Ví dụ, dữ liệu trong mytib5 dưới đây lưu điểm của hai sinh viên theo hai kỳ học của các năm 2023 và năm 2024:Bạn đọc có thể thấy rằng tên các cột có bao gồm hai thông tin là năm học 2023 hoặc 2024 và thông tin về kỳ học S1 hoặc S2. Chúng ta có thể sử dụng pivot_longer() để tạo thành dữ liệu mới, với hai biến mới tương ứng với hai thông tin: year tương ứng với năm học và semester tương ứng với kỳ học của hai sinh viên:Trong các trường hợp phức tạp hơn, trong tên biến của dữ liệu ban đầu vừa chứa tên biến trong dữ liệu mới vừa chứa giá trị của biến trong dữ liệu mới như dữ liệu trong mytib6 dưới đây:Bạn đọc có thể thấy rằng dữ liệu chứa thông tin về 8 người, giữ các chức chức vụ lớp trưởng và bí thư tại 4 lớp với thông tin tương ứng với từng người là tên và điểm. Các cột dữ liệu Ten_LopTruong và Ten_BiThu vừa chứa tên của một biến là tên của người, vừa chứa giá trị của biến chức vụ của người đó. Tương tự, các cột dữ liệu 'Diem_LopTruong' và 'Diem_BiThu' vừa chứa tên của biến là điểm của bạn sinh viên tương ứng, vừa chứa giá trị của biến là chức vụ của người đó. Dữ liệu có thể được sắp xếp lại bằng pivot_longer() như sau:Trong câu lệnh ở trên, chúng tôi sử dụng tham số names_to với phần tử đầu tiên là .value thay vì sử dụng tham số values_to như trên. Mục đích là để khai báo rằng thành phần thứ nhất trong tên của các cột là tên biến, bao gồm các biến Ten và biến Diem. Phần tử thứ hai của tham số names_to là Chuc_vu tương ứng với biến Chuc_vu trong dữ liệu mới. Chúng ta sẽ tiếp tục thực hành với hàm gather() và pivot_longer() trong phần thực hành của chương.","code":"\nmytib4%>%gather(key = \"year\", value = \"gdp_population\", -country, -type)## # A tibble: 4,070 × 4\n##    country             type       year  gdp_population\n##    <fct>               <chr>      <chr>          <dbl>\n##  1 Albania             gdp        2000     3686649387 \n##  2 Albania             population 2000        3121965 \n##  3 Algeria             gdp        2000    54790058957 \n##  4 Algeria             population 2000       31183658 \n##  5 Angola              gdp        2000     9129180361 \n##  6 Angola              population 2000       15058638 \n##  7 Antigua and Barbuda gdp        2000      802526701.\n##  8 Antigua and Barbuda population 2000          77648 \n##  9 Argentina           gdp        2000   284203745280 \n## 10 Argentina           population 2000       37057453 \n## # ℹ 4,060 more rows\nmytib4 %>% pivot_longer(cols = starts_with(\"2\"),\n                      names_to = \"year\",\n                      values_to = \"gdp_population\")## # A tibble: 4,070 × 4\n##    country type  year  gdp_population\n##    <fct>   <chr> <chr>          <dbl>\n##  1 Albania gdp   2000      3686649387\n##  2 Albania gdp   2001      3944714844\n##  3 Albania gdp   2002      4059111575\n##  4 Albania gdp   2003      4290480934\n##  5 Albania gdp   2004      4543619309\n##  6 Albania gdp   2005      4793518372\n##  7 Albania gdp   2006      5033194290\n##  8 Albania gdp   2007      5330152753\n##  9 Albania gdp   2008      5740574515\n## 10 Albania gdp   2009      5930013474\n## # ℹ 4,060 more rows\nmytib5## # A tibble: 2 × 5\n##   Name  `2023 S1` `2023 S2` `2024 S1` `2024 S2`\n##   <chr>     <dbl>     <dbl>     <dbl>     <dbl>\n## 1 SV1         8.5       6.9       8.1       8.5\n## 2 SV2         8         8.2       8.8       8\nmytib5 %>% pivot_longer(cols = !Name, # Không tập hợp cột Names\n                      names_to = c(\"year\", \"semester\"),\n                      names_sep = \" \",\n                      values_to = \"GPA\")## # A tibble: 8 × 4\n##   Name  year  semester   GPA\n##   <chr> <chr> <chr>    <dbl>\n## 1 SV1   2023  S1         8.5\n## 2 SV1   2023  S2         6.9\n## 3 SV1   2024  S1         8.1\n## 4 SV1   2024  S2         8.5\n## 5 SV2   2023  S1         8  \n## 6 SV2   2023  S2         8.2\n## 7 SV2   2024  S1         8.8\n## 8 SV2   2024  S2         8\nmytib6## # A tibble: 4 × 5\n##   Lop   Ten_LopTruong Ten_BiThu Diem_LopTruong Diem_BiThu\n##   <chr> <chr>         <chr>              <int>      <int>\n## 1 Act61 LT1           BT1                    6          7\n## 2 Act62 LT2           BT2                    7          8\n## 3 Act63 LT3           BT3                    8          9\n## 4 Act64 LT4           BT4                    9         10\nmytib6%>%pivot_longer(cols = !Lop,\n                      names_to = c(\".value\", \"Chuc_vu\"),\n                      names_sep = \"_\")## # A tibble: 8 × 4\n##   Lop   Chuc_vu   Ten    Diem\n##   <chr> <chr>     <chr> <int>\n## 1 Act61 LopTruong LT1       6\n## 2 Act61 BiThu     BT1       7\n## 3 Act62 LopTruong LT2       7\n## 4 Act62 BiThu     BT2       8\n## 5 Act63 LopTruong LT3       8\n## 6 Act63 BiThu     BT3       9\n## 7 Act64 LopTruong LT4       9\n## 8 Act64 BiThu     BT4      10"},{"path":"biến-đổi-và-sắp-xếp-dữ-liệu.html","id":"mở-rộng-dữ-liệu-với-speard","chapter":"Chương 7 Biến đổi và sắp xếp dữ liệu","heading":"7.2.2 Mở rộng dữ liệu với speard()","text":"Ngược lại với gather(), chúng ta sử dụng speard() để mở rộng dữ liệu, nghĩa là biến đổi tên biến thành tên các cột. Dữ liệu cần được mở rộng khi giá trị trong các cột dữ liệu không được đồng nhất, giống như thông tin về tổng thu nhập quốc dân và dân số của các quốc gia trên thế giới trong dữ liệu được lưu trong mytib3Bạn đọc có thể thấy rằng trong cột gdp_population vừa có cả thông tin về tổng thu nhập quốc dân (biến gdp) và thông tin về dân số (biến population) của quốc gia đó. Đồng thời cột type cho biết giá trị đó là gdp hay population. Dữ liệu như trên có thể được sắp xếp lại bằng cách sử dụng hàm speard() như sau:Có thể thấy rằng dữ liệu mới đã được sắp xếp nhất quán và đã có thể được sử dụng trong phân tích và xây dựng mô hình. Trong hàm spread() ở trên,Tham số key cho biết cột nào trong dữ liệu ban đầu là cột chứa giá trị là tên các biến mới. cột type của dữ liệu mytib3 chỉ có chứa hai giá trị là gdp và population nên trong dữ liệu mới có hai cột mới được hình thành tương ứng với hai giá trị trong cột type.Tham số value được sử dụng để cho biết giá trị của biến nào trong dữ liệu ban đầu sẽ được lấy vào các cột mới được hình thành. Trong câu lệnh ở trên, cột value của mytib3 chứa giá trị tương ứng với tổng thu nhập quốc dân và dân số của mỗi nước được sử dụng để gán cho tham số value trong hàm spread().Trong các phiên bản mới của thư viện tidyr, hàm pivot_wider() được sử dụng để thay thế cho hàm spread() có nhiều ưu điểm hơn. cách sử dụng pivot_wider() tương tự như pivot_longer() nên chúng tôi không đi vào thảo luận chi tiết về hàm số này. Bạn đọc tự tham khảo cách sử dụng hàm pivot_wider() và thực hành trong phần bài tập của chương.","code":"\nmytib3## # A tibble: 4,070 × 4\n##    country              year type               value\n##    <fct>               <int> <chr>              <dbl>\n##  1 Albania              2000 gdp          3686649387 \n##  2 Albania              2000 population      3121965 \n##  3 Algeria              2000 gdp         54790058957 \n##  4 Algeria              2000 population     31183658 \n##  5 Angola               2000 gdp          9129180361 \n##  6 Angola               2000 population     15058638 \n##  7 Antigua and Barbuda  2000 gdp           802526701.\n##  8 Antigua and Barbuda  2000 population        77648 \n##  9 Argentina            2000 gdp        284203745280 \n## 10 Argentina            2000 population     37057453 \n## # ℹ 4,060 more rows\nmytib3%>%spread(key = type, value = value)## # A tibble: 2,035 × 4\n##    country  year        gdp population\n##    <fct>   <int>      <dbl>      <dbl>\n##  1 Albania  2000 3686649387    3121965\n##  2 Albania  2001 3944714844    3124093\n##  3 Albania  2002 4059111575    3123112\n##  4 Albania  2003 4290480934    3117045\n##  5 Albania  2004 4543619309    3103758\n##  6 Albania  2005 4793518372    3082172\n##  7 Albania  2006 5033194290    3050741\n##  8 Albania  2007 5330152753    3010849\n##  9 Albania  2008 5740574515    2968026\n## 10 Albania  2009 5930013474    2929886\n## # ℹ 2,025 more rows"},{"path":"biến-đổi-và-sắp-xếp-dữ-liệu.html","id":"phân-tách-và-kết-hợp-các-cột","chapter":"Chương 7 Biến đổi và sắp xếp dữ liệu","heading":"7.2.3 Phân tách và kết hợp các cột","text":"Đối với dữ liệu như mytib2 với biến gdp_per_capita trình bày dưới dạng chuỗi ký tự, với số tổng thu nhập quốc dân và dân số được lưu trong cùng một cột và cách nhau bởi dấu /,Việc biến đổi dữ liệu về nhất quán như mytib1 có thể được thực hiện một cách đơn giản bằng hàm seperate()Bạn đọc có thể thấy rằng dữ liệu mới đã nhất quán với hai cột mới được tạo thành là cột gdp là thu nhập quốc nội của các quốc gia và cột population là dân số của quốc gia đó.","code":"\nmytib2## # A tibble: 2,035 × 3\n##    country              year gdp_per_capita       \n##    <fct>               <int> <chr>                \n##  1 Albania              2000 3686649387/3121965   \n##  2 Algeria              2000 54790058957/31183658 \n##  3 Angola               2000 9129180361/15058638  \n##  4 Antigua and Barbuda  2000 802526700.6/77648    \n##  5 Argentina            2000 284203745280/37057453\n##  6 Armenia              2000 1911563665/3076098   \n##  7 Aruba                2000 1858659293/90858     \n##  8 Australia            2000 416887521196/19107251\n##  9 Austria              2000 192070749954/8050884 \n## 10 Azerbaijan           2000 5272617196/8117742   \n## # ℹ 2,025 more rows\nmytib2 %>% \n  \n  # Phân tách cột gdp_per_capita thành hai cột gdp và population\n  separate(gdp_per_capita, c(\"gdp\",\"population\"), sep = \"/\") %>%\n  \n  # Đổi giá trị cột gdp và population thành kiểu số\n  mutate(gdp = as.numeric(gdp), population = as.numeric(population))## # A tibble: 2,035 × 4\n##    country              year           gdp population\n##    <fct>               <int>         <dbl>      <dbl>\n##  1 Albania              2000   3686649387     3121965\n##  2 Algeria              2000  54790058957    31183658\n##  3 Angola               2000   9129180361    15058638\n##  4 Antigua and Barbuda  2000    802526701.      77648\n##  5 Argentina            2000 284203745280    37057453\n##  6 Armenia              2000   1911563665     3076098\n##  7 Aruba                2000   1858659293       90858\n##  8 Australia            2000 416887521196    19107251\n##  9 Austria              2000 192070749954     8050884\n## 10 Azerbaijan           2000   5272617196     8117742\n## # ℹ 2,025 more rows"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"trực-quan-hóa-dữ-liệu","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"Chương 8 Trực quan hóa dữ liệu","text":"","code":""},{"path":"trực-quan-hóa-dữ-liệu.html","id":"giới-thiệu-về-trực-quan-hóa-dữ-liệu","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.1 Giới thiệu về trực quan hóa dữ liệu","text":"Trực quan hóa dữ liệu là nghệ thuật mô tả dữ liệu thông qua việc sử dụng đồ họa và hình ảnh như các biểu đồ, sơ đồ, hình vẽ, bao gồm cả hình ảnh động hoặc hình ảnh tương tác. Đây là phương pháp truyền đạt thông tin một cách trực quan và dễ hiểu từ người quản lý dữ liệu đến người tiếp nhận. Trực quan hóa giúp mô tả một cách hiệu quả các mối quan hệ dữ liệu phức tạp, các thông tin chuyên sâu, và các vấn đề bất thường ẩn chứa trong dữ liệu.Tại sao lại cần trực quan hóa dữ liệu? Thứ nhất, não bộ của con người phản ứng tốt hơn với hình ảnh, màu sắc, kích thước, hay khoảng cách với các ký hiệu, chuỗi ký tự, hay các con số. Thứ hai, dữ liệu ngày càng trở nên lớn hơn và phức tạp hơn. Trực quan hóa là phương pháp hiệu quả nhất để tìm ra các giá trị ẩn chứa bên trong dữ liệu. Đây chính là nguyên nhân khiến kỹ năng trực quan hóa dữ liệu được đánh giá là kỹ năng quan trọng nhất đối với những người phân tích dữ liệu.Có nhiều công cụ để trực quan hóa dữ liệu một cách chuyên nghiệp. Tiêu biểu phải kể đến hai công cụ quen thuộc là Power BI và Tableau. Đây là hai công cụ thân thiện với người dùng, cho phép người dùng tạo bảng điều khiển và báo cáo tương tác một cách nhanh chóng và dễ dàng. Cả hai đều có giao diện kiểu kéo và thả con trỏ giúp dễ dàng tạo hình ảnh trực quan mà không cần bất kỳ kỹ năng lập trình nào.Khác với Power BI hay Tableau, R sử dụng thư viện ggplot2 để trực quan hóa dữ liệu. Sẽ là không dễ dàng cho người mới bắt đầu vẽ được đồ thị bằng các câu lệnh của ggplot2. Điểm mạnh của thư viện ggplot2 với các công cụ như Power BI hay Tableau là cho phép người dùng tạo các hình ảnh có khả năng tùy biến cao. ggplot2 là lựa chọn phù hợp dành cho các nhà phân tích dữ liệu, những người cảm thấy hứng thú với việc viết các câu lệnh để tạo ra các hình ảnh trực quan phức tạp, và quan trọng nhất là đúng theo ý muốn của mình. Với một chút kinh nghiệm về Power BI và Tableau, cùng với nhiều hơn một chút kinh nghiệm về ggplot2, chúng tôi cho rằng bạn đọc nên làm quen với cả hai cách trực quan hóa dữ liệu. Khi bạn phải tạo các báo cáo trực quan trong một thời gian ngắn, Power BI hay Tableau sẽ là lựa chọn tối ưu. Khi bạn muốn vẽ những hình ảnh phức tạp, có tính cá nhân cao, và bạn có thời gian để làm việc đó, hãy sử dụng R và thư viện ggplot2.","code":""},{"path":"trực-quan-hóa-dữ-liệu.html","id":"tổng-quan-về-thư-viện-ggplot2","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.2 Tổng quan về thư viện ggplot2","text":"Như chúng tôi đã giới thiệu, ggplot2 là một thư viện để trực quan hóa dữ liệu trong R. Ngoài ggplot2, bạn đọc cũng có thể sử dụng các đồ thị cơ bản của R hoặc các thư viện khác nhưlattice để vẽ đồ thị. Tuy nhiên, không giống như hầu hết các công cụ khác, ggplot2 trực quan hóa dữ liệu dựa trên Ngữ pháp của đồ thị (Wilkinson 2005). Hai chữ gg trong ggplot2 có nghĩa là “Grammar Graphics” - Ngữ pháp của đồ thị. Ngữ pháp này cho phép bạn đọc vẽ đồ thị bằng cách kết hợp các cấu phần độc lập lại với nhau. Đây chính là điểm mạnh của ggplot2. Thay vì bị giới hạn ở các bộ đồ thị đã được xác định trước, bạn đọc có thể tạo đồ thị mới phù hợp với mục tiêu của mình.Ý tưởng phải học ngữ pháp để vẽ đồ thị có thể làm bạn đọc cảm thấy nản chí, nhưng sự thật là ngữ pháp của ggplot2 thực sự dễ học. Chỉ có một số nguyên tắc cốt lõi đơn giản và rất ít trường hợp đặc biệt. Khi đã thông thạo Ngữ pháp của đồ thị, ngoài việc tạo ra những đồ thị quen thuộc, bạn đọc còn có thể tạo ra những đồ thị mới hơn, đẹp hơn và mang tính cá nhân riêng. Bạn đọc có thể gặp khó khăn một chút ban đầu nhưng chúng tôi tin rằng khi đã quen với thư viện ggplot2, sẽ rất ít bạn đọc muốn quay lại với các công cụ trực quan hóa dữ liệu khác.Chúng ta hãy thử xem một ví dụ để hình dung về cách thư viện ggplot2 trực quan hóa dữ liệu. Chúng ta sẽ bắt đầu với một dữ liệu có tên là murders trong thư viện dslabs. Đây là dữ liệu FBI cung cấp về số vụ sát nhân bằng súng tại các bang của Mỹ vào năm 2010. Giả sử bạn muốn du lịch đến Mỹ nhưng lo ngại về việc cho phép sử dụng súng ở quốc gia này và muốn biết ở những bang nào có tỷ lệ số vụ sát nhân bằng súng cao. Chúng ta sẽ bắt đầu bằng việc tìm hiểu thông tin sơ bộ về dữ liệu này. Nếu bạn đã quen với đối tượng kiểu data.frame trong R, bạn cũng sẽ quen với các câu lệnh giúp tìm hiểu dữ liệu như head(), str(), view():Dù dữ liệu chỉ có hơn 51 dòng và 5 cột nhưng thật khó để có thể có được cái nhìn tổng thể về dữ liệu nếu chỉ nhìn vào các bảng, các con số, các véc-tơ kiểu chuỗi ký tự như trên. Thay vì trình bày dữ liệu dưới dạng con số hay ký tự, bạn đọc có thể mô tả dữ liệu murders dưới dạng một đồ thị phân tán như Hình 8.1, thì hiệu quả sẽ cao hơn rất nhiều.\nHình 8.1: Số vụ sát nhân bằng súng tại 51 bang của Mỹ vào năm 2010. Có mối liên hệ cùng chiều giữa dân số của các bang và số vụ sát nhân bằng súng tại mỗi bang.\nChúng tôi đã sử dụng một vài kỹ thuật biến đổi dữ liệu kết hợp với kỹ thuật trực quan hóa để vẽ đồ thị ở trên:Biến tổng số vụ sát nhân (total) và biến dân số của mỗi bang (population) đều có đuôi dài sang phía bên phải, nghĩa là có nhiều điểm tập trung ở khu vực trung tâm, và một số ít điểm tập trung ở phía đuôi bên phải. Nếu sử dụng chính xác giá trị của các biến này trên đồ thị, các điểm của đồ thị phân tán sẽ phân bố không đồng đều. Để hiển thị các điểm một cách rõ ràng hơn, giá trị hiển thị trên đồ thị đã được điều chính lại theo hàm log() cơ số 10. Điều này giải thích tại sao bạn đọc thấy rằng trên trục y khoảng cách từ 10 (vụ sát nhân) đến 100 (vụ sát nhân) sẽ bằng khoảng cách từ 100 (vụ sát nhân) đến 1000 (vụ sát nhân), hay trên trục x khoảng cách từ 1 (triệu người) đến 3 (triệu người) tương đương với khoảng cách từ 3 (triệu người) đến 10 (triệu người)Chúng tôi thêm vào một đường thẳng tuyến tính đi qua trung tâm các điểm để mô tả mối quan hệ chung giữa hai biến total và population. Đường thẳng có độ dốc dương cho thấy mối quan hệ cùng chiều giữa biến. Điều này có thể giải thích là ở các bang có dân số càng đông thì tổng số vụ sát nhân bằng súng càng cao.Để bạn đọc dễ dàng phân biệt một bang thuộc vào vùng (region) nào, chúng tôi sử dụng các màu sắc khác nhau hiển thị cho một vùng.Mỗi bang được ghi chú bằng tên viết tắt của bang đó.Dựa trên đồ thị phân tán ở trên, bạn đọc có thể đưa ra được các nhận xét như sauBang có dân số càng cao thì số vụ sát nhân bằng súng càng nhiều.Hầu hết các bang nằm phía trên đường trung bình là các bang ở miền Nam.Các vùng còn lại không có sự phân biệt rõ ràng về tỷ lệ số vụ sát nhân bằng súng.Bang District Columbia là bang nằm cao hơn hẳn với đường trung bình, và cũng là bang có tỷ lệ số vụ sát nhân bằng súng cao nhất.Bang California có tổng số vụ sát nhân bằng súng lớn nhất, nhưng tỷ lệ số vụ sát nhân bằng súng trên đầu người chỉ bằng mức trung bình chung.Rõ ràng là không dễ dàng để đưa ra được các nhận xét như trên nếu chỉ dựa trên quan sát con số và dữ liệu. Thay vào đó chúng ta có thể đưa ra nhiều phân tích có ý nghĩa về dữ liệu khi sử dụng đồ thị như Hình 8.1.Wilkinson (2005) giới thiệu khái niệm Ngữ pháp đồ thị để mô tả các thành phần cơ bản làm nền tảng cho tất cả các đồ thị và cách thức các thành phần đó tương tác với nhau khi mô tả một dữ liệu. Ngữ pháp đồ thị là mô tả chính xác nhất cho câu hỏi đồ thị trực quan hóa dữ liệu là gì? Thư viện ggplot2 được Wickham giới thiệu vào năm 2009 và được xây dựng dựa trên Ngữ pháp đồ thị mà Wilkinson đã đề cập.Ngữ pháp đồ thị, theo Wickham (2009), là các quy tắc cho tương ứng các biến của dữ liệu đến các thuộc tính thẩm mỹ, được gọi là các aesthetic attributions, của các đối tượng hình ảnh, được gọi là các geometries, xuất hiện trên đồ thị. Đồ thị được trực quan bằng thư viện ggplot2 cũng có thể bao gồm hình ảnh mô tả các mô hình thống kê của dữ liệu và được mô tả trên một hệ tọa độ cụ thể. Ngoài ra, khi dữ liệu muốn hiển thị quá phức tạp, bạn đọc cũng có thể chia dữ liệu thành các tập hợp con dựa trên các biến rời rạc và mô tả dữ liệu thông qua một nhóm các đồ thị con dựa trên kỹ thuật facetting. Sự kết hợp của các thành phần độc lập kể trên tạo nên một đồ thị trực quan mô tả dữ liệu.Bạn đọc không cần phải lo lắng nếu khái niệm Ngữ pháp đồ thị chúng tôi vừa giải thích ở trên không có ý nghĩa ngay lập tức. Trong phần sau của cuốn sách, chúng tôi sẽ nói về ngữ pháp đồ thị một cách chi tiết hơn. Bạn sẽ có nhiều cơ hội hơn để tìm hiểu về Ngữ pháp và các sử dụng ngữ pháp để kết hợp các cấu phần độc lập của một đồ thị hoạt động cùng nhau. Trong phần giới thiệu này, chúng tôi muốn bạn đọc hãy ghi nhớ bảy thành phần độc lập tạo nên một đồ thị cơ bản trong thư viện ggplot2:Dữ liệu (Data) là dữ liệu hay tập hợp các dữ liệu mà bạn đọc muốn trực quan hóa. Thông thường thì chỉ có một dữ liệu chính mà bạn đọc muốn minh họa cho người tiếp nhận dữ liệu, trong khi các dữ liệu khác được sử dụng với mục đích để mô tả và minh họa cho dữ liệu chính. Các dữ liệu được sử dụng để minh họa dữ liệu chính thường được gọi là các meta data. Một ví dụ điển hình của dữ liệu minh họa là dữ liệu kiểu bản đồ. Chẳng hạn như khi bạn đọc muốn mô tả về dữ liệu murders ở trên, bạn đọc có thể sử dụng dữ liệu về bản đồ nước Mỹ để có mô tả tốt hơn. Chúng ta sẽ thảo luận về dữ liệu kiểu bản đồ trong phần sau của chương.Dữ liệu (Data) là dữ liệu hay tập hợp các dữ liệu mà bạn đọc muốn trực quan hóa. Thông thường thì chỉ có một dữ liệu chính mà bạn đọc muốn minh họa cho người tiếp nhận dữ liệu, trong khi các dữ liệu khác được sử dụng với mục đích để mô tả và minh họa cho dữ liệu chính. Các dữ liệu được sử dụng để minh họa dữ liệu chính thường được gọi là các meta data. Một ví dụ điển hình của dữ liệu minh họa là dữ liệu kiểu bản đồ. Chẳng hạn như khi bạn đọc muốn mô tả về dữ liệu murders ở trên, bạn đọc có thể sử dụng dữ liệu về bản đồ nước Mỹ để có mô tả tốt hơn. Chúng ta sẽ thảo luận về dữ liệu kiểu bản đồ trong phần sau của chương.Hình dạng đồ họa, được gọi là các geometries hay viết tắt là các geoms, là những hình dạng đồ họa mà chúng ta muốn nhìn thấy trên đồ thị. Các hình dạng này có thể là các điểm, các thanh, các đường.Hình dạng đồ họa, được gọi là các geometries hay viết tắt là các geoms, là những hình dạng đồ họa mà chúng ta muốn nhìn thấy trên đồ thị. Các hình dạng này có thể là các điểm, các thanh, các đường.Các ánh xạ thẩm mỹ, được gọi là các aesthetic mapping, là các quy tắc cho tương ứng từ các biến (hay các cột của dữ liệu) đến các thuộc tính thẩm mỹ của các hình dạng đồ họa. Các thuộc tính thẩm mỹ có thể là hình dạng, màu sắc, độ đậm nhạt.Các ánh xạ thẩm mỹ, được gọi là các aesthetic mapping, là các quy tắc cho tương ứng từ các biến (hay các cột của dữ liệu) đến các thuộc tính thẩm mỹ của các hình dạng đồ họa. Các thuộc tính thẩm mỹ có thể là hình dạng, màu sắc, độ đậm nhạt.Các mô hình hay biến đổi thống kê, được gọi là các statistics hay viết tắt là stats là các quy tắc tóm tắt dữ liệu để làm nổi bật các xu thế và hiển thị các giá trị ẩn trong dữ liệu. Các mô hình xây dựng trên dữ liệu được mô tả dưới dạng một hình dạng đồ họa nhằm tăng tính dễ hiểu cho đồ thị và giúp cho người tiếp nhận nhanh chóng tiếp nhận thông tin. Ví dụ như trong đồ thị phân tán mô tả dữ liệu murders, chúng tôi đã sử dụng một mô hình tuyến tính nhằm mô tả mối quan hệ giữa biến total và biến population với mục đích cho thấy mối liên hệ cùng chiều giữa hai biến này, đồng thời cho bạn đọc biết được các bang nào có tỷ lệ số vụ sát nhân bằng súng thấp hơn trung bình và các bang nào có tỷ lệ số vụ sát nhân bằng súng cao hơn với mức trung bình chung.Các mô hình hay biến đổi thống kê, được gọi là các statistics hay viết tắt là stats là các quy tắc tóm tắt dữ liệu để làm nổi bật các xu thế và hiển thị các giá trị ẩn trong dữ liệu. Các mô hình xây dựng trên dữ liệu được mô tả dưới dạng một hình dạng đồ họa nhằm tăng tính dễ hiểu cho đồ thị và giúp cho người tiếp nhận nhanh chóng tiếp nhận thông tin. Ví dụ như trong đồ thị phân tán mô tả dữ liệu murders, chúng tôi đã sử dụng một mô hình tuyến tính nhằm mô tả mối quan hệ giữa biến total và biến population với mục đích cho thấy mối liên hệ cùng chiều giữa hai biến này, đồng thời cho bạn đọc biết được các bang nào có tỷ lệ số vụ sát nhân bằng súng thấp hơn trung bình và các bang nào có tỷ lệ số vụ sát nhân bằng súng cao hơn với mức trung bình chung.Hệ tọa độ, hay Cordinate mô tả cách dữ liệu được trực quan hóa trên mặt phẳng của đồ họa. Đa số các trường hợp chúng ta sẽ sử dụng hệ tọa độ Descartes, nhưng cũng có một số hệ tọa độ khác có thể sử dụng bao gồm tọa độ cực và bản đồ.Hệ tọa độ, hay Cordinate mô tả cách dữ liệu được trực quan hóa trên mặt phẳng của đồ họa. Đa số các trường hợp chúng ta sẽ sử dụng hệ tọa độ Descartes, nhưng cũng có một số hệ tọa độ khác có thể sử dụng bao gồm tọa độ cực và bản đồ.Một thành phần mô tả cách dữ liệu được hiển thị là chia nhỏ dữ liệu để mô tả bằng một nhóm các đồ thị thay vì một đồ thị duy nhất được gọi là facetting. Thành phần này thường được sử dụng để mô tả khi dữ liệu có kích thước lớn và hoặc chúng ta muốn sánh trực quan dữ liệu ở các nhóm khác nhau.Một thành phần mô tả cách dữ liệu được hiển thị là chia nhỏ dữ liệu để mô tả bằng một nhóm các đồ thị thay vì một đồ thị duy nhất được gọi là facetting. Thành phần này thường được sử dụng để mô tả khi dữ liệu có kích thước lớn và hoặc chúng ta muốn sánh trực quan dữ liệu ở các nhóm khác nhau.Thành phần cuối cùng của đồ thị là ngữ cảnh của đồ thị, còn được gọi là các themes. Theme quy định khung hoặc nền mà đồ thị được hiển thị, chẳng hạn như kích thước phông chữ hoặc màu nền. Mặc dù các giá trị mặc định trong thư viện ggplot2 đã được lựa chọn hợp lý nhưng bạn đọc cũng có thể cần tham khảo các tài liệu tham khảo khác để tạo ra một ngữ cảnh phù hợp hơn cho đồ thị của mình.Thành phần cuối cùng của đồ thị là ngữ cảnh của đồ thị, còn được gọi là các themes. Theme quy định khung hoặc nền mà đồ thị được hiển thị, chẳng hạn như kích thước phông chữ hoặc màu nền. Mặc dù các giá trị mặc định trong thư viện ggplot2 đã được lựa chọn hợp lý nhưng bạn đọc cũng có thể cần tham khảo các tài liệu tham khảo khác để tạo ra một ngữ cảnh phù hợp hơn cho đồ thị của mình.Mỗi khi vẽ một đồ thị sử dụng ggplot2, bạn đọc cần tự định nghĩa ít nhất ba thành phần: 1. Dữ liệu; 2. Các hình dạng đồ họa; và 3. Các ánh xạ thẩm mỹ. Các thành phần 5. Hệ tọa độ; và 7. Ngữ cảnh; sẽ được tự động gán cho các giá trị mặc định nếu bạn đọc không quy định trong câu lệnh. Và các thành phần 4. Mô hình; và 6. Facetting; chỉ xuất hiện khi bạn đọc gọi lên.Trước khi đi vào nội dung chi tiết về cách tạo nên một đồ thị, bạn đọc cũng cần biết được các hạn chế khi trực quan hóa dữ liệu bằng ggplot2 như sauggplot2 là một thư viện của R nên bạn đọc cần có kỹ năng viết câu lệnh R tương đối thành thạo.Thư viện ggplot2 không gợi ý bạn đọc nên sử dụng đồ thị nào khi gặp một dữ liệu cụ thể. Điều đó cũng có nghĩa là bạn đọc cần có một chút kinh nghiệm về trực quan hóa dữ liệu trước khi sử dụng thư viện này.Thư viện ggplot2 không được phát triển để vẽ các đồ thị động hay đồ thị tương tác mà chỉ tập trung vào vẽ các đồ thị tĩnh. Muốn vẽ các đồ thị tương tác hay đồ thị động, bạn đọc phải sử dụng các thư viện đi kèm như gganimate hay ggplotly.Để kết thúc phần giới thiệu, chúng tôi sẽ sử dụng thư viện ggplot2 kết hợp với thư viện vẽ hình ảnh động gganimate, để kể một câu chuyện về sự phát triển về sự tiến bộ y tế của các quốc gia trên thế giới trong khoảng thời gian từ năm 1960 đến năm 2010, thông qua hai khía cạnh là tuổi thọ trung bình của các quốc gia và tỷ lệ tử vong trung bình tính trên mỗi 1000 trẻ sơ sinh. Dữ liệu chính được sử dụng là dữ liệu gapminder trong thư viện dslabs mà bạn đọc đã làm quen trong phần phân tích dữ liệu. Sự thay đổi của tuối thọ trung bình (life_expectancy) và tỷ lệ trẻ sơ sinh tử vong (infant_mortality) của các quốc gia trên thế giới được mô tả lại một cách sinh động qua Hình 8.2\nHình 8.2: Sự thay đổi trong tỷ lệ tử vong trẻ sơ sinh, tính trên 1000 trẻ, và tuổi thọ trung bình của cá quốc gia trên thế giới từ năm 1960 đến năm 2010\nDựa trên đồ thị ở trên, bạn đọc có thể suy nghĩ về các câu hỏi dưới đây:Xu hướng di chuyển chung của các điểm dữ liệu là như thế nào ? Điều này cho biết tỷ lệ tử vong của trẻ sơ sinh và tuổi thọ bình quân của các quốc gia trên thế giới từ năm 1960 đến năm 2010 thay đổi như thế nào ? Điều này cho thấy việc phát triển về y tế nhìn chung là như thế nào ?Xu hướng di chuyển chung của các điểm dữ liệu là như thế nào ? Điều này cho biết tỷ lệ tử vong của trẻ sơ sinh và tuổi thọ bình quân của các quốc gia trên thế giới từ năm 1960 đến năm 2010 thay đổi như thế nào ? Điều này cho thấy việc phát triển về y tế nhìn chung là như thế nào ?Trong xu thế phát triển chung đó, sự khác biệt của các Châu lục là như thế nào ?Trong xu thế phát triển chung đó, sự khác biệt của các Châu lục là như thế nào ?Kích thước của các điểm trong đồ thị phân tán cho biết dân số quốc gia đó, bạn có nhận thấy sự thay đổi của kích thước của các điểm theo thời gian là như thế nào không ? Bạn có nhận ra các quốc gia đông dân như Trung Quốc, Ấn Độ, Mỹ, Nhật Bản từ đồ thị trên hay không ?Kích thước của các điểm trong đồ thị phân tán cho biết dân số quốc gia đó, bạn có nhận thấy sự thay đổi của kích thước của các điểm theo thời gian là như thế nào không ? Bạn có nhận ra các quốc gia đông dân như Trung Quốc, Ấn Độ, Mỹ, Nhật Bản từ đồ thị trên hay không ?Một vài quốc gia Châu Phi có quỹ đạo di chuyển bất thường khi điểm dữ liệu bị “rơi” xuống theo trục \\(\\overrightarrow{Oy}\\) trong một vài năm, theo bạn đó là nguyên nhân gì ?Một vài quốc gia Châu Phi có quỹ đạo di chuyển bất thường khi điểm dữ liệu bị “rơi” xuống theo trục \\(\\overrightarrow{Oy}\\) trong một vài năm, theo bạn đó là nguyên nhân gì ?","code":"\nlibrary(dslabs)\nhead(murders)##        state abb region population total\n## 1    Alabama  AL  South    4779736   135\n## 2     Alaska  AK   West     710231    19\n## 3    Arizona  AZ   West    6392017   232\n## 4   Arkansas  AR  South    2915918    93\n## 5 California  CA   West   37253956  1257\n## 6   Colorado  CO   West    5029196    65\n# str(murders)\n# View(murders)"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"tạo-một-đồ-thị-cơ-bản","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.3 Tạo một đồ thị cơ bản","text":"Trước khi giới thiệu chi tiết về các thành phần độc lập của đồ thị trực quan và cách sử dụng ngữ pháp của đồ thị, chúng tôi cho rằng sẽ tốt hơn nếu bạn đọc bắt đầu vẽ các đồ thị đơn giản bằng cách sao chép và dán các câu lệnh vẽ đồ thị. Sau khi thực thi một vài lần, bạn đọc sẽ có cảm nhận được một phần cách mà một đồ thị của thư viện ggplot2 được xây dựng. Dữ liệu chúng tôi sử dụng để trực quan hóa trong suốt chương sách này là dữ liệu gapminder - dữ liệu mô tả về sức khỏe và thu nhập của tất cả các quốc gia trên thế giới bắt đầu từ năm 1960 đến năm 2016. Hình 8.3 mô tả tỷ lệ biến không dữ liệu không quan sát được của các biến qua các năm\nHình 8.3: Tỷ lệ giá trị không quan sát được của các biến trong dữ liệu gapminder theo năm bắt đầu từ 1960 đến 2016\nBạn đọc có thể thấy rằng dữ liệu gapminder có nhiều giá trị không quan sát được trong năm 2016. Hai cột có tỷ lệ không quan sát được qua các năm lớn là infant_mortality và gdp. Riêng biến gdp là gần như không quan sát được từ năm 2012 đến 2016. chỉ sử dụng dữ liệu với mục đích trực quan hóa nên chúng tôi sẽ xử lý việc dữ liệu không quan sát được này một cách đơn giản là xóa các quan sát của các năm 2012 đến 2016. Các giá trị không quan sát được từ năm 1960 đến 2011 sẽ được thay thế bằng cách nội suy tuyến tính theo chuỗi thời gian. Thư viện để nội suy tuyến tính các giá trị không quan sát được theo chuỗi thời gian là thư viện imputeTS.\nHình 8.4: Thu nhập bình quân đầu người và tuổi thọ trung bình của các quốc gia trên thế giới năm 2011\nKhi sử dụng hàm ggplot() ở trên, dữ liệu được đưa vào có tên là dat - dữ liệu được biến đổi từ dữ liệu gapminder bằng cách thêm vào cột thu nhâp bình quân đầu người (gdp_per_capita) và sau đó lọc theo năm 2011. Hình dạng đồ họa là các điểm trên trục tọa độ Descartes. Hình dạng đồ họa này được gọi bằng hàm geom_point(). Ánh xạ thẩm mỹ được khai báo thông qua hàm aes() nằm trong hàm ggplot(). Bên trong hàm aes(), chúng ta đã cho tương ứng (ánh xạ) biến life_expectancy với giá trị trên trục \\(\\overrightarrow{Ox}\\) và biến gdp_per_capita tương ứng (ánh xạ) với giá trị trên trục \\(\\overrightarrow{Oy}\\) của trục tọa độ Descartes.Mặc dù đồ thị trên Hình 8.4 còn đơn giản, nhưng chúng ta đã có thể nhận thấy được một số thông tin về tuổi thọ trung bình, thu nhập bình quân đầu người, và mối liên hệ giữa hai biến này:Có mối liên hệ đồng biến giữa tuổi thọ trung bình và thu nhập bình quân đầu người. Quốc gia nào có thu nhập bình quân đầu người cao thì tuổi thọ trung bình cũng sẽ cao. Điều này khá hợp lý bởi các quốc gia có thu nhập trung bình cao thường là các nước phát triển có hệ thống chăm sóc sức khỏe tốt, đó tuổi thọ trung bình cũng sẽ cao.Mối liên hệ đồng biến nhưng không tuyến tính, thu nhập bình quân đầu người tăng nhanh hơn rất nhiều ro với tuổi thọ trung bình.Có một vài điểm có khả năng là ngoại lai trong mối liên hệ đồng biến này. Nghĩa là có các quốc gia có mức thu nhập bình quân khá cao (từ 10 nghìn USD - 20 nghìn USD/1 người) nhưng lại có tuổi thọ trung bình không cao. Tuy nhiên chỉ với các thông tin như trên chúng ta không thể đưa ra giải thích cho các giá trị này.Hình dạng đồ họa là những hình dạng cụ thể mà bạn đọc nhìn thấy trên đồ thị, chẳng hạn như các điểm, các đường, thanh, hay các khối hình khác. Khi gọi các hình dạng đồ họa, thư viện ggplot2 luôn luôn sử dụng các hàm số bắt đầu bởi geom là viết tắt của từ geometries. Để làm quen với các khối hình khác trong ggplot2, bạn đọc có thể thử các câu lệnh để vẽ các khối hình khác như dưới đây:Còn nhiều hàm geom_() khác có thể được sử dụng để trực quan hóa dữ liệu. Bạn đọc có thể tham khảo danh sách các hàm geom_() thường sử dụng trong link dưới đây.https://www.maths.usyd.edu.au/u/UG/SM/STAT3022/r/current/Misc/data-visualization-2.1.pdfBạn đọc có thể thấy rằng trong danh sách các hàm geom_() có thể sử dụng bao gồm cả gợi ý cho người sử dụng nên dùng hàm geom_() nào trong từng trường hợp. Chẳng hạn như geom_point() được gợi ý sử dụng khi mô tả đông thời hai biến liên tục, hoặc geom_boxplot() được gợi ý khi mô tả đồng thời một biến liên tục và một biến rời rạc. Ngoài ra, bên cạnh gợi ý sử dụng, mỗi hàm geom_() sẽ có đi kèm với một danh sách các thuộc tính thẩm mỹ đi kèm. Ví dụ, khi sử dụng hàm geom_point() sẽ có các thuộc tính thẩm mỹ bao gồm x, y, alpha, color, fill, shape, size, và stroke. Bạn đọc cần tham khảo hướng dẫn sử dụng của hàm geom_point() (câu lệnh ? geom_point) để biết các thuộc tính thẩm mỹ này có ý nghĩa như thế nào. Trong các thuộc tính thẩm mỹ được sử dụng với geom_point(), các thuộc tính thẩm mỹ color, fill, shape, và size là các thuộc tính thẩm mỹ xuất hiện ở nhiều hàm geom_() khác. Đây là các thuộc tính thẩm mỹ thường xuyên được sử dụng để tăng khả năng mô tả dữ liệu của các đồ thị ggplot2.Chúng ta tiếp tục với ví dụ về mô tả trực quan mối liên hệ giữa thu nhập bình quân đầu người và tuổi thọ trung bình của các quốc gia trên thế giới vào năm 2011. Để đồ thị giải thích tốt hơn, chúng ta cần đưa thêm thông tin vào đồ thị trong Hình 8.4. Một phương pháp đơn giản để thêm biến khác vào một đồ thị là ánh xạ biến đó đến một trong các thuộc tính thẩm mỹ của đồ thị được vẽ bằng hàm geom_point(). Biến được thêm vào đồ thị trong Hình 8.5 là biến continent. Chúng ta sẽ ánh xạ biến này đến thuộc tính thẩm mỹ color như sau\nHình 8.5: Thu nhập bình quân đầu người và tuổi thọ trung bình của các quốc gia trên thế giới năm 2011. Biến continent được ánh xạ đến thuộc tính thẩm mỹ màu sắc của các điểm\nBằng cách thêm biến continent vào đồ thị và ánh xạ đến thuộc tính thẩm mỹ màu sắc, chúng ta đã có thể đưa ra thêm các phân tích về mối liên hệ giữa tuổi thọ trung bình và thu nhập bình quân đầu người của các quốc gia trên thế giới vào năm 2011:Có sự phân bố không đồng đều về thu nhập bình quân và tuổi thọ trung bình của các quốc gia trên thế giới theo châu lục. Đa số các quốc gia Châu Phi có thu nhập bình quân đầu người thấp và tuổi thọ trung bình thấp trong khi các quốc gia Châu Âu có thu nhập bình quân đầu người cao và tuổi thọ trung bình cao.Có sự phân hóa rõ ràng ở Châu Đại Dương và Châu Mỹ, một vài quốc gia nằm trong nhóm các nước có thu nhập cao, tuổi thọ trung bình cao trong khi đa số các quốc gia còn lại nằm trong nhóm thu nhập thấp và tuổi thọ trung bình thấp. Sự phân hóa ở các nước Châu Á không quá rõ ràng.Các nước có mối liên hệ giữa thu nhập bình quân và tuổi thọ trung bình ít giống như các nước khác là các quốc gia ở Châu Phi và Châu Mỹ.Có một số nguyên tắc chung, tuy không bắt buộc, nhưng khuyến khích khi sử dụng các thuộc tính thẩm mỹ như sauThuộc tính thẩm mỹ color thường được sử dụng với biến kiểu rời rạc.Thuộc tính thẩm mỹ size thường được sử dụng với biến liên tục.Thuộc tính thẩm mỹ shape chỉ có thể được sử dụng với biến rời rạc, R sẽ báo lỗi nếu bạn ánh xạ một biến liên tục vào thuộc tính thẩm mỹ này. Có tổng số 21 giá trị khác nhau cho thuộc tính thẩm mỹ shape và R sẽ đưa ra cảnh báo nếu bạn đọc ánh xạ một biến rời rạc có nhiều hơn 21 giá trị.Đồ thị trong hình 8.6 thêm biến population từ dữ liệu vào đồ thị bằng cách sử dụng thuộc tính thẩm mỹ size. Bạn đọc hãy luôn nhớ rằng khai báo ánh xạ thẩm mỹ từ một biến dữ liệu đến một thuộc tính thẩm mỹ luôn luôn phải thực hiện bên trong hàm aes(),\nHình 8.6: Thu nhập bình quân đầu người và tuổi thọ trung bình của các quốc gia trên thế giới năm 2011. Biến continent ánh xạ đến thuộc tính thẩm mỹ màu sắc của các điểm và biến population ánh xạ đến thuộc tính thẩm mỹ kích thước\nThuộc tính thẩm mỹ alpha sử dụng trong hàm geom_point() được nhận giá trị cố định là 0.5 và có thể hiểu là một phép thiết lập tham số cố định. Chúng ta sẽ phân biết về thiết lập tham số và xạ thẩm mỹ trong phần sau. Tham số alpha được sử dụng trong trường hợp dữ liệu có nhiều điểm bị trùng lên nhau; alpha nhận giá trị từ 0 đến 1 cho biết độ trong suốt của các điểm tăng dần. Khi đồ thị có quá nhiều điểm, để quan sát được dễ dàng hơn chúng ta có thể thiết lập cho tham số alpha nhận giá trị nhỏ hơn 1 để cho phép chúng ta quan sát được nhiều hơn các điểm trên đồ thị phân tán. Lưu ý rằng alpha cũng có thể được sử dụng trong hàm aes() như một thuộc tính thẩm mỹ. Chúng ta sẽ thảo luận chi tiết hơn về thuộc tính thẩm mỹ này trong phần sau của chương sách.Bạn đọc có thể thấy rằng khi thêm biến population bằng cách ánh xạ đến thuộc tính kích thước các điểm như Hình 8.6 đã giúp cho đồ thị có thêm thông tin:Chúng ta có thể nhận ra vị trí của các quốc gia đông dân tiêu biểu như Trung Quốc và Ấn Độ vào năm 2011, có thể nhận thấy hai quốc gia này vẫn nằm trong nhóm các nước có thu nhập bình quân đầu người thấp;Cũng có thể nhận ra Mỹ và Nhật Bản là các quốc gia nằm ở góc trên bên phải là các nước cũng có dân số tương đối lớn với các quốc gia khác. Tất nhiên, với thuộc tính thẩm mỹ màu sắc thì thuộc tính thẩm mỹ kích thước không hiệu quả bằng.Ngoài ra, bạn đọc cũng có thể nhận ra rằng khi cùng sử dụng nhiều thuộc tính thẩm mỹ trên một đồ thị, hiệu quả sẽ không được như mong muốn. Một phương pháp khác để tạo các đồ thị rõ ràng hơn, đặc biệt với các dữ liệu có nhiều quan sát, bạn đọc có thể chia nhỏ dữ liệu thành các nhóm và mô tả dữ liệu trong mỗi nhóm bằng một đồ thị khác nhau. Kỹ thuật này được gọi là facetting và được mô tả trong Hình 8.7\nHình 8.7: Chia dữ liệu thành năm nhóm tương ứng với năm lục địa và sử dụng năm đồ thị phân tán để mô tả phân bố của các điểm dữ liệu\nTrong các câu lệnh vẽ Hình 8.7, chúng tôi không sử dụng biến continent ánh xạ vào thuộc tính thẩm mỹ màu sắc, mà chia nhỏ dữ liệu ra thành 5 phần tương ứng với 5 giá trị trong biến này và mô tả mỗi thành phần của dữ liệu trong một đồ thị riêng biệt. Các đồ thị có miền giá trị trên các trục tọa độ x và y giống nhau để việc sánh trở nên dễ dàng.Có thể nhận thấy từ Hình 8.7 rằng sử dụng năm đồ thị phân tán có cùng khoảng giá trị của trục tọa độ x và y để mô tả mối quan hệ giữa thu nhập bình quân đầu người và tuổi thọ trung bình của các quốc gia thuộc năm châu lục là rõ ràng hơn rất nhiều với sử dụng một đồ thị duy nhất và phân biệt các lục địa khác nhau bằng màu sắc.Một thành phần tuy không bắt buộc nhưng bạn đọc có thể thêm vào đồ thị của ggplot2 để tăng tính thẩm mỹ và sự rành mạch là ngữ cảnh hay còn gọi là các themes. Có một số theme có sẵn khi chúng ta cài đặt thư viện và cũng có các ngữ cảnh nằm trong các thư viện cài đặt bổ sung như thư viện ggthemes. Chúng ta sẽ thảo luận chi tiết về cách tùy chỉnh ngữ cảnh và tự tạo ngữ cảnh cho đồ thị ở phần sau của chương. Để thay đổi ngữ cảnh mặc định của các đồ thị của ggplot2, chúng ta sử dụng các hàm theme_(). Ví dụ, trong Hình 8.8 chúng tôi thay đổi ngữ cảnh mặc định của Hình 8.7 thành ngữ cảnh khác bằng cách sử dụng hàm theme_minimal().\nHình 8.8: Thay đổi ngữ cảnh mặc định của ggplot sang ngữ cảnh khác giúp đồ thị rõ ràng hơn\nThành phần chưa được nhắc đến khi tạo đồ thị trực quan hóa dữ liệu là các statistics hay viết tắt là các stats. đây là thành phần phức tạp nhất và liên quan đến các kiến thức về xây dựng mô hình trên dữ liệu nên chúng tôi chưa đề cập đến trong phần này. Mục tiêu của chúng tôi trong phần giới thiệu là để bạn đọc làm quen với cách sử dụng các câu lệnh vẽ đồ thị trong ggplot2. Trong các phần tiếp theo, từng thành phần của đồ thị và các cấu phần thẩm mỹ quan trọng sẽ được thảo luận chi tiết cùng với ngữ pháp của đồ thị.","code":"\nlibrary(imputeTS) # Thư viện dùng để nội suy tuyến tính\nmydat<-gapminder%>%filter(year<=2011)\nlist_country<-unique(mydat$country)\nfor (ct in list_country){\n  ind<-(mydat$country == ct)\n  if (sum(!is.na(mydat$infant_mortality[ind]))>=2){\n    mydat$infant_mortality[ind]<-na.interpolation(mydat$infant_mortality[ind])\n  }\n  if (sum(!is.na(mydat$gdp[ind]))>=2){\n    mydat$gdp[ind] <- na.interpolation(mydat$gdp[ind])\n  }\n}\n# Biến đổi dữ liệu\ndat<-mydat%>%filter(year==2011)%>%\n  mutate(gdp_per_capita = gdp/population)\n\n# Trực quan hóa\nggplot(dat, aes(x = life_expectancy, y = gdp_per_capita)) +\n  geom_point()\n## geom_histogram() sử dụng các thanh\n## mô tả phân phối của một biến liên tục\nggplot(dat,aes(x = gdp_per_capita))+\n  geom_histogram()\n\n## geom_bar() sử dụng các thanh\n## mô tả phân phối của một biến rời rạc\nggplot(dat,aes(x = continent))+\n  geom_bar()\n\n## geom_boxplot() sử dụng các hình hộp\n## mô tả phân phối của biến liên tục\nggplot(dat,aes(x = continent, y = life_expectancy))+\n  geom_boxplot()\n\n## geom_line() sử dụng đường nối các điểm\n## mô tả các điểm theo thứ tự xuất hiện\ndat1<-filter(gapminder, year<=2011, country == \"United States\")%>%\n  select(year,gdp)\nggplot(dat1,aes(x = year, y = gdp))+\n  geom_line()\n# Vẽ đồ thị phân tán, ánh xạ biến continent đến màu sắc\nggplot(dat, aes(x=life_expectancy, y=gdp_per_capita,\n                color=continent))+\n  geom_point()\n# Vẽ đồ thị phân tán, ánh xạ biến continent đến màu sắc\n# ánh xạ population đến kích thước\nggplot(dat, aes(x = life_expectancy, y = gdp_per_capita,\n                color = continent, size = population)) +\n  geom_point(alpha = 0.5)\n# Dùng facet_wrap để chia dữ liệu ra thành các nhóm\nggplot(dat, aes(x = life_expectancy, y = gdp_per_capita,\n                size = population)) +\n  geom_point(alpha = 0.5)+\n  facet_wrap(~continent)\nggplot(dat, aes(x = life_expectancy, y = gdp_per_capita, size = population)) +\n  geom_point(shape = 21, alpha = 0.5, fill = \"#640514\")+\n  facet_wrap(~continent, ncol = 2)+\n  # thêm title\n  labs( title = \"Thu nhập bình quân và tuổi thọ trung bình\")+\n  xlab(\"Tuổi thọ trung bình (tuổi)\")+\n  ylab(\"Gdp bình quân đầu người (USD)\")+\n  theme_minimal()# thêm ngữ cảnh"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"cấu-trúc-nhiều-lớp-và-ngữ-pháp-của-đồ-thị","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.4 Cấu trúc nhiều lớp và ngữ pháp của đồ thị","text":"Cấu trúc theo lớp (nhiều layers) của đồ thị ggplot2 giúp cho người phân tích trực quan dữ liệu xây dựng đồ thị của mình theo một đối tượng có cấu trúc. Đồ thị được tạo thành từ ggplot2 từ đơn giản đến phức tạp đều được tạo thành từ (ít nhất) một đến nhiều lớp. Mỗi lớp trong đồ thị có mục tiêu hiển thị khác nhau:Mục tiêu hiện thị đầu tiên và cũng là mục tiêu chính, đó là để hiển thị dữ liệu. Luôn luôn có một hoặc một vài lớp chính với mục tiêu mô tả dữ liệu thô, mô tả cấu trúc tổng thể, hoặc mô tả các giá trị ngoại lai của dữ liệu. Lớp này xuất hiện trên tất cả các đồ thị. Trong giai đoạn đầu của quá trình mô tả dữ liệu bằng trực quan hóa, lớp này thường xuất hiện duy nhất. Đơn giản như khi mô tả mỗi quan hệ giữa thu nhập bình quân đầu người và tuổi thọ trung bình của các quốc gia trên thế giới năm 2011, lớp được hiển thị bằng hàm geom_point() là lớp hiển thị dữ liệu chính.Các lớp có mục tiêu tóm tắt và mô tả ý nghĩa thống kê của dữ liệu. Bằng cách thêm vào đồ thị các mô hình hoặc bằng cách hiển thị các dự đoán dựa trên mô hình mà người phân tích dữ liệu và người tiếp nhận dữ liệu sẽ nhận biết được những giá trị bên trong dữ liệu và những chi tiết mà khi xây dựng mô hình có thể bỏ sót.Các lớp có mục tiêu thêm vào ngữ cảnh của dữ liệu. Các lớp này hiển thị bối cảnh nền, thêm vào các chú thích giúp mang lại ý nghĩa cho dữ liệu thô hoặc các giá trị tham chiếu nhằm hỗ trợ việc sánh hoặc đánh giá. Đây thường là lớp cuối cùng được thêm vào trong đồ thị.Lớp chính của đồ thị có thể bao gồm bảy thành phần độc lập giống như chúng ta đã giới thiệu ở phần đầu. Cấu trúc của các lớp còn lại của đồ thị ggplot2 có thể bao gồm các thành phần sau:Dữ liệu: nếu bạn không khai báo dữ liệu trong mỗi lớp, ggplot2 sẽ sử dụng dữ liệu ban đầu là dữ liệu mặc định.Dữ liệu: nếu bạn không khai báo dữ liệu trong mỗi lớp, ggplot2 sẽ sử dụng dữ liệu ban đầu là dữ liệu mặc định.Ánh xạ thẩm mỹ: được khai báo trong hàm aes() trong mỗi lớp, nếu không có khai báo riêng về ánh xạ thẩm mỹ, ggplot2 sẽ sử dụng ánh xạ thẩm mỹ được khai báo trong hàm ggplot().Ánh xạ thẩm mỹ: được khai báo trong hàm aes() trong mỗi lớp, nếu không có khai báo riêng về ánh xạ thẩm mỹ, ggplot2 sẽ sử dụng ánh xạ thẩm mỹ được khai báo trong hàm ggplot().Một, hoặc một vài hình dạng đồ họa được gọi bằng các hàm geom_().Một, hoặc một vài hình dạng đồ họa được gọi bằng các hàm geom_().Một biến đổi thống kê hoặc một tóm tắt của dữ liệu được gọi bằng hàm stat_().Một biến đổi thống kê hoặc một tóm tắt của dữ liệu được gọi bằng hàm stat_().Vị trí xuất hiện của lớp đó trong bố cục chung.Vị trí xuất hiện của lớp đó trong bố cục chung.Khi đồ thị chỉ có một lớp với mục tiêu hiển thị dữ liệu chính, bạn đọc không cần phải hiểu về ngữ pháp của đồ thị. Bạn đọc chỉ cần khai báo chính xác ánh xạ thẩm mỹ trong hàm aes() để có được kết quả mong muốn. Tuy nhiên khi xây dựng đồ thị phức tạp có nhiều lớp, bạn đọc cần phải nắm được ngữ pháp của đồ thị để kết hợp các lớp chính và các lớp phụ lại với nhau theo ý muốn của mình. Thảo luận chi tiết về cấu trúc nhiều lớp của đồ thị sẽ có trong phần tiếp theo.","code":""},{"path":"trực-quan-hóa-dữ-liệu.html","id":"ánh-xạ-thẩm-mỹ-trong-đồ-thị-có-nhiều-lớp","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.4.1 Ánh xạ thẩm mỹ trong đồ thị có nhiều lớp","text":"Để hiểu về cách các lớp tương tác với nhau trong một đồ thị, hãy quan sát Hình 8.9. Sau khi sử dụng một lớp chính là các điểm được gọi bằng hàm geom_point() để mô tả mối liên hệ giữa thu nhập bình quân đầu người và tuổi thọ trung bình của các quốc gia trên thế giới vào năm 2011, bạn muốn thêm vào một lớp phụ là một đường cong mô tả mối liên hệ giữa hai biến. Hàm số dùng để thêm vào một đường mô tả mối liên hệ là geom_smooth()\nHình 8.9: Đồ thị có hai lớp bao gồm một đồ thị phân tán và một đường mô tả mối liên hệ giữa các điểm. Hình bên trái: ánh xạ thẩm mỹ màu sắc được khai báo trong hàm ggplot(). Hình bên phải: ánh xạ thẩm mỹ màu sắc được khai báo trong hàm geom_point()\nBạn đọc có thể thấy sự khác nhau giữa hai đồ thị là như sau:Các đường mô tả mối liên hệ giữa tuổi thọ trung bình và thu nhập bình quân đầu người được xây dựng cho từng lục địa cho hình bên trái Hình 8.9Chỉ có duy nhất một đường được xây dựng cho tất cả các quốc gia trong hình bên phải của Hình 8.9.Sự khác biệt này là :Trong hình bên trái chúng ta khai báo ánh xạ từ biến continent đến thuộc tính thẩm mỹ color bên trong hàm aes() nằm trong hàm ggplot(),Trong khi đó, trong hình bên phải, chúng ta đã khai báo ánh xạ từ biến continent đến thuộc tính thẩm mỹ color bên trong hàm aes() nằm trong hàm geom_point()Như chúng tôi đã đề cập ở trên, hàm geom_point() là lớp chính mô tả dữ liệu thô, còn hàm geom_smooth() là lớp phụ được thêm vào nhằm tăng khả năng mô tả của dữ liệu. Các ánh xạ thẩm mỹ được khai báo trong hàm ggplot() có thể hiểu như khai báo các biến toàn cục trong một đồ thị, còn các ánh xạ thẩm mỹ được khai báo trong các hàm geom_() có thể hiểu như khai báo các biến cục bộ trong hàm số đó. Theo quy tắc chung, các biến cục bộ nếu không được khai báo trong các hàm geom_() sẽ được tìm trên môi trường toàn cục của hàm ggplot(). Trong trường hợp trong các hàm geom_() và ggplot() các thuộc tính thẩm mỹ đều không được khai báo giá trị thì các thuộc tính thẩm mỹ trong các lớp phụ sẽ nhận giá trị mặc định.Dựa trên nguyên tắc này, trong hình bên trái của Hình 8.9, các thuộc tính thẩm mỹ x, y, và color được khai báo trong hàm ggplot(); đồng thời trong các hàm geom_point() và geom_smooth() không khai báo các ánh xạ thẩm mỹ; đó cả hai hàm này đều hiểu các thuộc tính thẩm mỹ x, y, và color giống như khai báo trong hàm ggplot().Trong hình bên phải của Hình 8.9, hai thuộc tính thẩm mỹ x và y được khai báo trong hàm ggplot() trong khi thuộc tính thẩm mỹ color được khai báo bên trong hàm geom_point(). đó, hàm geom_smooth() chỉ hiểu hai thuộc tính thẩm mỹ x và y như được khai báo trong ggplot(). Thuộc tính thẩm mỹ color của hàm geom_smooth() trong hình bên phải của Hình 8.9 sẽ được gán giá trị mặc định.Cách ghi nhận các thuộc tính thẩm mỹ của hai lớp, được gọi bằng các hàm geom_point() và geom_smooth(), của các đồ thị trong Hình 8.9 được tổng kết lại như sau:Đường mô tả mối liên hệ giữa hai biến thu nhập bình quân và tuổi thọ trung bình được xây dựng bằng hàm geom_smooth() dựa trên phương pháp được gọi là hồi quy cục bộ, locally estimated scatterplot smoothing hay viết tắt là loess. Phương pháp này sẽ được chúng tôi sẽ thảo luận trong Chương Mô hình cộng tính tổng quát. Khi thuộc tính thẩm mỹ color được sử dụng và ánh xạ đến một biến rời rạc, hàm geom_smooth() sẽ chia dữ liệu thành các nhóm, mỗi nhóm tương ứng với một giá trị của biến rời rạc ánh xạ đến thuộc tính color, sau đó xây dựng mô hình hồi quy với thu nhập bình quân phụ thuộc vào tuổi thọ trung bình trong mỗi nhóm. Điều này lý giải tại sao trong hình bên trái có năm (5) mô hình được xây dựng tương ứng với năm Châu lục, trong khi trong hình bên phải chỉ có một mô hình duy nhất được xây dựng cho tất cả các quốc gia trên thế giới.Vậy khi nào nên khai báo ánh xạ thẩm mỹ trong hàm ggplot() và khi nào bạn nên khai báo ánh xạ thẩm mỹ bên trong hàm geom_() nói chung? Câu trả lời như sau: nếu đa số các lớp bạn đọc sử dụng có chung một dữ liệu và dùng chung ánh xạ thẩm mỹ, bạn nên khai báo ánh xạ thẩm mỹ bên trong hàm ggplot(). Còn trong trường hợp các lớp sử dụng dữ liệu khác nhau, hoặc có ánh xạ thẩm mỹ khác nhau, bạn hãy khai báo ánh xạ thẩm mỹ bên trong mỗi hàm geom_(). Trong trường hợp bạn dùng một hàm thuộc nhóm các hàm geom_() và không muốn sử dụng ánh xạ thẩm mỹ đã khai báo trong ggplot(), bạn có thể khai báo lại ánh xạ đó, hoặc khai báo thuộc tính thẩm mỹ đó bằng giá trị NULL.Một lưu ý quan trọng cần được thảo luận trong ngữ pháp của đồ thị đó là sự khác nhau giữa sử dụng ánh xạ thẩm mỹ và thiết lập tham số. Trước hết, bạn đọc hãy lưu ý các câu lệnh vẽ đồ thị trực quan và kết quả nhận được trong Hình 8.10\nHình 8.10: Sự khác nhau giữa ánh xạ thẩm mỹ và thiết lập tham số. Thuộc tính thẩm mỹ color trong geom_smooth() được sử dụng theo các cách khác nhau. Hình góc trên bên trái: trong hàm geom_smooth() sử dụng không sử dụng ánh xạ thẩm mỹ đến thuộc tính color. Hình phía trên bê phải, trong hàm geom_smooth() không sử dụng khai báo ánh xạ thẩm mỹ và color được thiết lập cho giá trị là ‘black’. Hình góc dưới bên trái: trong hàm geom_smooth sử dụng khai báo ánh xạ thẩm mỹ va color được ánh xạ đến giá trị ‘black’. Hình góc dưới bên phải: hàm geom_smooth() sử dụng ánh xạ thẩm mỹ và thuộc tính color ánh xạ đến một cột dữ liệu nhận toàn các giá trị là ‘black’\nCó hai cách để chúng ta tác động đến các thuộc tính thẩm mỹ của đồ thị, đó là dùng ánh xạ thẩm mỹ và thiết lập tham số. Sự khác nhau giữa hai cách này là việc bạn khai báo giá trị của thuộc tính thẩm mỹ bên trong hay bên ngoài hàm aes(). Hình 8.10 cho thấy rằng:Hình góc trên bên trái có đường hồi quy liên tục mô tả mối liên hệ giữa hai biến có màu mặc định. Nguyên nhân là khi gọi hàm geom_smooth() chúng ta đã cho thuộc tính thẩm mỹ color nhận giá trị mặc định. Bạn đọc có thể thấy rằng trong câu lệnh vẽ hình góc trên bên trái, thuộc tính color được gọi trong hàm aes() của geom_smooth() và được ánh xạ đến giá trị NULL.Hình góc trên bên phải đã thực hiện thiết lập cấu phần thẩm mỹ color thay vì gọi ánh xạ. Thuộc tính color được gọi bên trong hàm geom_smooth() nhưng không sử dụng aes(). Giá trị được thiết lập là ‘black’, đó đường hồi quy được tạo ra sẽ có màu đen đúng như yêu cầu từ thiết lập thuộc tính thẩm mỹ. Để thiết lập giá trị cho cấu phần thẩm mỹ, bạn đọc cần sử dụng giá trị tương ứng với cấu phần thẩm mỹ tương ứng đó và sử dụng ngoài hàm aes(). Giá trị tương ứng với thuộc tính color có thể là bất kỳ chuỗi ký tự mô tả màu sắc có ý nghĩa trong ngôn ngữ R. Điều gì xảy ra nếu trong cùng một lớp (trong một hàm geom_() bạn đọc vừa sử dụng có ánh xạ thẩm mỹ vừa thiết lập thuộc tính thẩm mỹ? Câu trả lời là ggplot2 sẽ ưu tiên giá trị nằm ngoài aes(), nghĩa là ưu tiên thiết lập tham số.Hình góc dưới bên trái phức tạp hơn các hình phía trên. Trước hết, thuộc tính color được ánh xạ từ biến color trong hàm ggplot(). Sau đó, thuộc tính thẩm mỹ màu sắc lại được được ánh xạ từ giá trị ‘black’ trong hàm aes() của geom_smooth().\nBạn đọc có thể thấy rằng đường hồi quy được tạo từ hàm geom_smooth() không có màu đen như hình ở phía trên bên phải. Nguyên nhân là khi khai báo thuộc tính thẩm mỹ trong hàm aes(), chúng ta đã ánh xạ thuộc tính color của hàm geom_smooth() đến một giá trị kiểu ký tự là ‘black’. ggplot2 sẽ hiểu ‘black’ là một biến kiểu ký tự được ánh xạ đến thuộc tính thẩm mỹ màu sắc.\nTrước đó, trong hàm ggplot() biến continent được ánh xạ đến thuộc tính thẩm mỹ color. Khi chúng ta tiếp tục ánh xạ một biến nhận giá trị ‘black’ tới thuộc tính color thì ggplot2 hiểu rằng có thêm một giá trị mới cho thuộc tính màu sắc là ‘black’ và thêm vào với các giá trị hiện có là tên của 5 châu lục. Điều này lý giải tại sao trong chú giải của hình có 6 loại màu sắc thay vì 5 loại màu sắc như các hình ở trên.\nBạn đọc có thể thấy rằng đường hồi quy được tạo từ hàm geom_smooth() không có màu đen như hình ở phía trên bên phải. Nguyên nhân là khi khai báo thuộc tính thẩm mỹ trong hàm aes(), chúng ta đã ánh xạ thuộc tính color của hàm geom_smooth() đến một giá trị kiểu ký tự là ‘black’. ggplot2 sẽ hiểu ‘black’ là một biến kiểu ký tự được ánh xạ đến thuộc tính thẩm mỹ màu sắc.Trước đó, trong hàm ggplot() biến continent được ánh xạ đến thuộc tính thẩm mỹ color. Khi chúng ta tiếp tục ánh xạ một biến nhận giá trị ‘black’ tới thuộc tính color thì ggplot2 hiểu rằng có thêm một giá trị mới cho thuộc tính màu sắc là ‘black’ và thêm vào với các giá trị hiện có là tên của 5 châu lục. Điều này lý giải tại sao trong chú giải của hình có 6 loại màu sắc thay vì 5 loại màu sắc như các hình ở trên.Hình góc dưới bên phải được vẽ trên dữ liệu sau khi được thêm vào cột mới có tên newcol có tất cả các giá trị đều là ‘black’. Đồ thị vẫn bao gồm hai lớp là geom_point() và geom_smooth(). Cả hai lớp đều sử dụng chung thuộc tính thẩm mỹ x và y. Thuộc tính thẩm mỹ color của geom_point() được ánh xạ đến biến continent trong khi thuộc tính thẩm mỹ color của geom_smooth() ánh xạ đến cột mới được tạo thành. Bạn đọc có thể thấy rằng đồ thị được tạo ra hoàn toàn giống như hình góc dưới bên phải khi chúng ta gán trực tiếp thuộc tính color của geom_smooth() với giá trị ‘black’.Câu hỏi đặt ra là khi nào sử dụng ánh xạ thẩm mỹ và khi nào sử dụng thiết lập giá trị cho các thuộc tính thẩm mỹ. Để trả lời, bạn đọc cần cân nhắc về việc có muốn tác động lên thuộc tính thẩm mỹ nữa hay không. Nếu bạn muốn cố định giá trị cho thuộc tính thẩm mỹ, hãy sử dụng thiết lập giá trị. Còn nếu bạn muốn tác động lên thuộc tính thẩm mỹ sau đó, hãy sử dụng ánh xạ thẩm mỹ. Chúng ta sẽ thảo luận thêm về vấn đề này khi nói về các hàm scale_().Bạn đọc hãy lưu ý về cách chú giải ghi nhận giá trị mới của một thuộc tính thẩm mỹ. Trong đồ thị góc dưới bên trái của Hình 8.10, khi chúng ta khai báo giá trị ‘black’ cho thuộc tính color, đồ thị ghi nhận thêm ‘black’ như một giá trị mới tương đương với tên các Châu lục đã sử dụng trong khai báo trước đó. Cách ghi nhận tên biến mới trong chú giải sẽ rất hữu ích khi chúng ta muốn tạo một đồ thị có nhiều lớp và đặt tên cho từng lớp trong phần chú giải của đồ thị. Ví dụ, khi chúng ta muốn sánh ba phương pháp xây dựng mô hình trong lớp geom_smooth() khi mô tả mối liên hệ giữa biến tuổi thọ trung bình và biến thu nhập bình quân đầu người bao gồm:Phương pháp hồi quy tuyến tính thông thường, sử dụng method = ‘lm’,Phương pháp hồi quy loess, sử dụng method = ‘loess’,Phương pháp hồi quy cộng tính tổng quát method = ‘gam’,chúng ta có thể sử dụng ánh xạ thẩm mỹ color như sau:\nHình 8.11: Sử dụng đồ thị trực quan để sánh ba phương pháp xây dựng mô hình mô tả mối liên hệ giữa tuổi thọ trung binh và thu nhập bình quân đầu người của các quốc gia trên thế giới năm 2011.\nĐồ thị trong Hình 8.11 có bốn lớp. Khi chúng ta khai báo thuộc tính thẩm mỹ x và y trong hàm ggplot(), cả bốn lớp đều sử dụng chung các thuộc tính thẩm mỹ này. Hàm geom_point() không sử dụng thêm ánh xạ thẩm mỹ nào. Mỗi hàm geom_smooth() thêm một đường hồi quy vào trong đồ thị, và thêm một giá trị vào thuộc tính thẩm mỹ color. Kết quả thu được là một đồ thị có ba màu sắc mô tả ba đường hồi quy tương ứng, với chú giải là tên của phương pháp xây dựng đường hổi quy.","code":"\n## Hình bên trái, khai báo color trong ggplot()\np1<-dat%>%ggplot(aes(x = life_expectancy, y = gdp_per_capita,\n                color = continent)) +\n  geom_point(alpha = 0.5)+\n  geom_smooth(se=FALSE)+\n  theme(legend.position = \"none\")+\n  theme_minimal()\n\n## Hình bên phải, khai báo color trong geom_point()\np2<-dat%>%ggplot(aes(x = life_expectancy, y = gdp_per_capita))+\n  geom_point(aes(color = continent), alpha = 0.5) +\n  geom_smooth(se=FALSE)+\n  theme(legend.position = \"none\")+\n  theme_minimal()\n\n## Vẽ p1 và p2 trên cùng một đồ thị\ngrid.arrange(p1,p2,nrow= 1 , ncol = 2)\n## Hình góc trên bên trái, geom_smooth có aes(color = NULL)\np1<-dat%>%ggplot(aes(x = life_expectancy, y = gdp_per_capita,\n                color = continent)) +\n  geom_point(alpha = 0.5)+\n  geom_smooth(aes(color=NULL), se = FALSE)+\n  theme(legend.position = \"right\")+\n  theme_minimal()\n\n## Hình góc trên bên phải, geom_smooth có thiết lập (color = back)\np2<-dat%>%ggplot(aes(x = life_expectancy, y = gdp_per_capita,\n                color = continent)) +\n  geom_point(alpha = 0.5)+\n  geom_smooth(color=\"black\", se = FALSE)+\n  theme(legend.position = \"right\")+\n  theme_minimal()\n\n## Hình góc dưới bên trái, geom_smooth có aes(color = \"black\")\np3<-dat%>%ggplot(aes(x = life_expectancy, y = gdp_per_capita,\n                color = continent)) +\n  geom_point(alpha = 0.5)+\n  geom_smooth(aes(color=\"black\") , se = FALSE)+\n  theme(legend.position = \"right\")+\n  theme_minimal()\n\n\n## Hình góc dưới bên phải, geom_smooth có aes(color = newcol)\np4<-dat%>%mutate(newcol = \"black\")%>%ggplot(aes(x = life_expectancy, y = gdp_per_capita)) +\n  geom_point(aes(color = continent))+\n  geom_smooth(aes(color = newcol) , se = FALSE)+\n  theme(legend.position = \"right\")+\n  theme_minimal()\n\n## Vẽ các đồ thị trên cùng một hình\ngrid.arrange(p1,p2,p3,p4, nrow= 2 , ncol = 2)\n# So sánh ba phương pháp xây dựng mô hình khác nhau của hàm geom_smooth\ndat%>%ggplot(aes(x = life_expectancy, y = gdp_per_capita)) +\n  #Layer 1: đồ thị rải điểm\n  geom_point(alpha = 0.4)+\n\n  # Layer 2: Đường hồi quy tuyến tính\n  geom_smooth(aes(color=\"Hồi quy tuyến tính\"), method = \"lm\" , se = FALSE)+\n\n  # Layer 3: Đường hồi quy loess\n  geom_smooth(aes(color=\"Hồi quy loess\"), method = \"loess\", span = 0.3 , se = FALSE)+\n\n  # Layer 4: Mô hình GAM (generalized additive model)\n  geom_smooth(aes(color=\"Mô hình cộng tính tổng quát\"), method = \"gam\" , se = FALSE)+\n  theme_minimal()"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"các-hàm-geom_-cơ-bản","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.4.2 Các hàm geom_() cơ bản","text":"Các hình dạng đồ họa, gọi tắt là các geoms, là một cách phổ biến để hiển thị một lớp của một đồ thị trực quan. Ví dụ như sử dụng geom_point() sẽ tạo ra một đồ thị phân tán hay còn gọi là đồ thị rải điểm; khi sử dụng geom_line() sẽ tạo ra các đồ thị theo đường. Danh sách các geoms và các thuộc tính thẩm mỹ bạn đọc có thể tìm trong danh sách được liệt kê trong link ở phần @ref(sec:ggplot_intro). Trong phần này, chúng tôi phân loại và giải thích cách sử dụng các geoms chi tiết hơn.","code":""},{"path":"trực-quan-hóa-dữ-liệu.html","id":"mô-tả-một-biến","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.4.2.1 Mô tả một biến","text":"Khi sử dụng đồ thị trực quan bằng thư viện ggplot2 để mô tả một biến rời rạc, hàm thường được sử dụng là hàm geom_bar(). Tần suất xuất hiện của các giá trị trong các biến rời rạc được mô tả dưới dạng các thanh. Các thuộc tính thẩm mỹ quan trọng trong hàm geom_bar() bao gồm:Thuộc tính thẩm mỹ x được ánh xạ đến tên biến (rời rạc).Thuộc tính thẩm mỹ color là màu sắc của đường viền xung quanh các thanh.Thuộc tính thẩm mỹ fill là màu sắc của các thanh. fill ngoài ý nghĩa tăng tính thẩm mỹ cho đồ thị dạng thanh, còn có ý nghĩa khi mô tả mối liên hệ giữa biến rời rạc một biến rời rạc khác.Hình 8.12 sử dụng đồ thị dạng thanh mô tả phân phối xác suất của biến continent trong dữ liệu gapminder được lọc theo năm 2011. Khi sử dụng đồ thị dạng thanh, chúng ta thường sắp xếp sao cho các thanh có chiều cao tăng dần hoặc giảm dần.\nHình 8.12: Phân phối xác suất của biến continent trong dữ liệu gapminder trong năm 2011. Hình bên trái: phân phối xác suất của biến continent mô tả theo thứ tự của giá trị xuất hiện. Hình bên phải: phân phối xác suất của biến continent mô tả theo thứ tự của tần suất xuất hiện của các biến tăng dần.\nKhi mô tả biến rời rạc, geom_bar() luôn mặc định sắp xếp các thanh theo thứ tự các giá trị xuất hiện trong biến rời rạc tăng dần. Tuy nhiên, để đồ thị dạng thanh mô tả hiệu quả hơn, chúng ta thường để các thanh xuất hiện theo thứ tự có chiều cao tăng dần hoặc giảm dần giống như hình bên phải của Hình 8.12. Để thực hiện việc này, chúng ta cần thay đổi thứ tự xuất hiện của các giá trị trên trục \\(\\overrightarrow{Ox}\\) theo thứ tự tần suất tăng dần hay giảm dần bằng cách sử dụng hàm scale_x_discrete(). Chúng ta sẽ thảo luận về các hàm này trong phần sau của chương.Hàm geom_bar() cũng có thể được sử dụng để mô tả các giá trị liên tục được lưu trong một biến tương ứng với các giá trị rời rạc được lưu trong biến khác. Ví dụ, khi chúng ta muốn mô tả thu nhập bình quân của 10 nước có thu nhập bình quân đầu người lớn nhất thế giới năm 2011, chúng ta có thể sử dụng geom_bar() với đầy đủ hai thuộc tính thẩm mỹ x và y như sau:\nHình 8.13: 10 quốc gia có thu nhập bình quân đầu người cao nhất thế giới năm 2011. Hình bên trái: Thứ tự các nước không được sắp xếp theo thu nhập bình quân đầu người. Hình bên phải: các nước xuất hiện theo thứ tụ thu nhập bình quân đâu người giảm dần.\nKhi sử dụng geom_bar() để mô tả hai biến như Hình 8.13, chúng ta cần cho tham số stat nhận giá trị bằng identity để phân biệt với khi sử dụng geom_bar() khi mô tả một biến liên tục. Chúng tôi sẽ giải thích tham số stat trong phần lập trình ggplot2 ở phần cuối của chương. Để biểu diễn các cột theo thứ tự chiều cao tăng dần hay giảm dần, bạn đọc sử dụng hàm reorder(). Trong đồ thị bên phải của Hình 8.13, chúng tôi ánh xạ cấu phần thẩm mỹ y của geom_bar() đến biến country nhưng được sắp xếp theo thứ tự gdp_per_capita của giảm dần.Để mô tả phân phối xác suất của một biến liên tục, chúng ta sử dụng geom_histogram(). Hình dạng đồ họa của geom_histogram() giống với geom_bar() khi cùng sử dụng hình dạng kiểu các thanh/cột để mô tả phân phối xác suất của một biến. Nguyên tắc vẽ đồ thị của hàm geom_histogram() là chia miền giá trị được xác định từ giá trị nhỏ nhất đến giá trị lớn nhất của biến liên tục thành \\(k\\) khoảng bằng nhau, sau đó đếm trong mỗi khoảng có bao nhiêu giá trị của biến liên tục xuất hiện. Chiều cao của các cột là số lần xuất hiện của các giá của biến liên tục trong khoảng đó. Tham số bins trong hàm geom_histogram() được sử dụng để gán giá trị cho số khoảng giá trị. bins càng lớn thì số cột càng lớn và chiểu rộng của các cột càng nhỏ; trong khi bins càng nhỏ thì số cột càng nhỏ và chiều rộng của các cột càng lớn. Lựa chọn số bins phù hợp để mô tả chính xác phân phối xác suất của biến liên tục là rất quan trọng. Ngoài tham số bins, các cấu phần thẩm mỹ của geom_histogram() tương đối giống với geom_bar() nên chúng tôi sẽ không nhắc lại.Hình 8.14 mô tả biến thu nhập bình quân đầu người trong năm 2011 của tất cả các quốc gia trên thế giới.\nHình 8.14: Phân phối của biến thu nhập bình quân đầu người của các quốc gia trên thế giới năm 2011. Hình bên trái: Sử dụng 10 bins để mô tả. Hình bên phải: Sử dụng 30 bins để mô tả.\nNhư chúng tôi đã đề cập, lựa chọn số bins để hiển thị là rất quan trọng trong mô tả phân phối xác suất của một biết liên tục. Trong trường hợp biến có ít quan sát như Hình 8.13, lựa chọn giữa 10 bins hoặc 30 bins không dẫn đến sự khác biệt nhiều. Tuy nhiên, khi biến liên tục có nhiều quan sát, lựa chọn số bins quá ít sẽ làm cho chúng ta hiểu sai về phân phối của biến. Hãy quan sát ví dụ khi chúng ta mô tả biến price trong dữ liệu có tên là diamond. Đây là một dữ liệu nằm trong thư viện dslabs, với biến price là biến chứa giá của hơn 50 nghìn viên kim cương.\nHình 8.15: Phân phối của biến price trong dữ liệu diamonds với hơn 50 nghìn quan sát. Hình bên trái: Sử dụng 10 bins để mô tả. Hình bên phải: Sử dụng 60 bins để mô tả.\nCó thể nhận thấy rằng nếu chúng ta sử dụng quá ít bins để mô tả một số lượng quan sát lớn có thể dẫn đến kết luận sai về phân phối của biến liên tục. Hình bên trái của Hình 8.15 là phân phối của một biến ngẫu nhiên chỉ có một giá trị mode (một đỉnh) tại giá trị $2500 và sau đó có tần suất xuất hiện giảm dần. Hình bên phải của Hình 8.15 lại cho biết đây là một phân phối liên tục có hai đỉnh tại các giá trị 1000 và 4500. Phương pháp tốt nhất để lựa chọn số bins phù hợp đó là tăng dần tham số này cho đến khi phân phối xác suất của biến liên tục không còn bị thay đổi quá nhiều.Cũng để mô tả phân phối xác suất của biến liên tục, geom_density() có thể được sử dụng một cách độc lập hoặc bổ sung với geom_histogram() để mô tả phân phối của các biến liên tục một cách tốt hơn. Hình 8.16 mô tả cách sử dụng geom_density() cùng với geom_histogram() để mô tả phân phối của các biến liên tục.\nHình 8.16: Kết hợp geom_density() và geom_histogram() để mô tả phân phối xác suất của biến liên tục. Hình bên trái: phân phối của biến thu nhập bình quân đầu người của các quốc gia trên thế giới năm 2011. Hình bên phải: phân phối của giá của các viên kim cương trong dữ liệu diamonds\nĐể hiển thị đồng thời đồ thị vẽ bằng geom_histogram() và đồ thị vẽ bằng geom_density() trên cùng một đồ thị, chúng ta cần phải biến đổi đồ thị histogram từ mô tả số lần xuất hiện của biến liên tục thành tần suất xuất hiện. Bạn đọc thực hiện phép biến đổi này bằng cách thêm vào sau phần khai báo ánh xạ thẩm mỹ của geom_histogram() câu lệnh after_stat(density) để tổng diện tích của các hình được tạo bởi các thanh được quy đổi về 1 đơn vị.Phương pháp vẽ đồ thị của geom_density() cũng giống như hàm geom_density() có sẵn trong thư viện stats khi cho kết quả là một đường liên tục là ước lượng cho hàm mật độ xác suất của một biến ngẫu nhiên liên tục. Hàm mật độ này được ước lượng bằng phương pháp Kernel. Giá trị hàm mật độ tại một điểm x bất kỳ nằm trong miền giá trị của một biến liên tục được tính bằng trung bình giá trị hàm \\(K\\), được gọi là hàm Kernel, tính trên khoảng cách từ điểm x tới tất cả các quan sát. Ký hiệu \\(\\hat{f}(x)\\) là giá trị hàm mật độ tính tại x bằng phương pháp Kernel thì ta có\n\\[\\begin{align}\n\\hat{f}(x) = \\cfrac{1}{nh} \\times \\sum\\limits_{= 1}^{n} \\ K\\left( \\cfrac{x - x_i}{h} \\right)\n\\tag{8.1}\n\\end{align}\\]\ntrong đó \\(x_i\\) là giá trị quan sát thứ \\(\\) và h là được gọi là tham số làm mịn. h càng lớn thì hàm \\(\\hat{f}\\) sẽ càng mịn. Hàm \\(K\\) được sử dụng làm hàm Kernel mặc định cho geom_density() là hàm mật độ của biến ngẫu nhiên phân phối chuẩn.Một hàm số khác cũng có thể được sử dụng để mô tả phân phối của một biến liên tục là geom_boxplot() nhưng hàm số này có thể được sử dụng để mô tả mối liên hệ giữa biến rời rạc và biến liên tục nên chúng tôi sẽ thảo luận ở phần sau.","code":"\np1<-dat%>%ggplot() +\n  geom_bar(aes(x = continent), color = \"darkblue\", fill = \"#640514\", alpha = 0.5)+\n  theme_minimal()\np2<-dat%>%ggplot() +\n  geom_bar(aes(x = continent), color = \"darkblue\", fill = \"#640514\", alpha = 0.5)+\n  scale_x_discrete(limits = names(sort(table(dat$continent))))+\n  theme_minimal()\ngrid.arrange(p1,p2, nrow= 1 , ncol = 2)\np1<-dat%>%arrange(desc(gdp_per_capita))%>%head(10)%>%\n  ggplot() +\n  geom_bar(aes(x = gdp_per_capita, y = country),\n           stat = \"identity\",\n           color = \"darkblue\", fill = \"#640514\", alpha = 0.5)+\n  theme_minimal()\np2<-dat%>%arrange(desc(gdp_per_capita))%>%head(10)%>%\n  ggplot() +\n  geom_bar(aes(x = gdp_per_capita, y = reorder(country,gdp_per_capita)),\n           stat = \"identity\",\n           color = \"darkblue\", fill = \"#640514\", alpha = 0.5)+\n  ylab(\"country\")+\n  theme_minimal()\ngrid.arrange(p1,p2, nrow= 1 , ncol = 2)\np1<-dat%>%ggplot() +\n  geom_histogram(aes(x = gdp_per_capita), bins = 10,\n           color = \"darkblue\", fill = \"#640514\", alpha = 0.5)+\n  theme_minimal()\np2<-dat%>%ggplot() +\n  geom_histogram(aes(x = gdp_per_capita), bins = 40,\n           color = \"darkblue\", fill = \"#640514\", alpha = 0.5)+\n  theme_minimal()\ngrid.arrange(p1,p2, nrow= 1 , ncol = 2)\np1<-diamonds%>%ggplot() +\n  geom_histogram(aes(x = price), bins = 10,\n           color = \"darkblue\", fill = \"#640514\", alpha = 0.5)+\n  theme_minimal()\np2<-diamonds%>%ggplot() +\n  geom_histogram(aes(x = price), bins = 60,\n           color = \"darkblue\", fill = \"#640514\", alpha = 0.5)+\n  theme_minimal()\ngrid.arrange(p1,p2, nrow= 1 , ncol = 2)\np1<-dat%>%ggplot() +\n  geom_histogram(aes(x = gdp_per_capita, after_stat(density)), bins = 30,\n          fill = \"#640514\", alpha = 0.2)+\n  geom_density(aes(x = gdp_per_capita), color = \"darkblue\")+\n  theme_classic()\np2<-diamonds%>%ggplot() +\n  geom_histogram(aes(x = price, after_stat(density)), bins = 60,\n           fill = \"#640514\", alpha = 0.2)+\n  geom_density(aes(x = price),color = \"darkblue\")+\n  theme_classic()\ngrid.arrange(p1,p2, nrow= 1 , ncol = 2)"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"mô-tả-hai-biến-liên-tục","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.4.2.2 Mô tả hai biến liên tục","text":"Đồ thị phân tán hay đồ thị rải điểm được trực quan bằng hàm geom_point() là cách hiệu quả nhất để mô tả trực quan hai biến liên tục. Bạn đọc đã làm quen với geom_point() cùng với các thuộc tính thẩm mỹ như x, y, color, shape, size, để mô tả mối liên hệ giữa các biến thu nhập bình quân đầu người và tuổi thọ bình quân của các quốc gia trên thế giới nên chúng tôi sẽ không nhắc lại cách sử dụng các cấu phần thẩm mỹ này khi sử dụng geom_point().Đồ thị phân tán thường được sử dụng cùng với geom_smooth() để mô tả mối liên hệ giữa hai biến. Phương pháp xây dựng mô hình trong hàm geom_smooth() bao gồm:Phương pháp loess là phương pháp mặc định để xây dựng đường hồi quy mô tả mối liên hệ giữa biến liên tục được ánh xạ tới y phụ thuộc vào biến liên tục được ánh xạ tới x. Phương pháp này được sử dụng khi số lượng dòng của dữ liệu nhỏ hơn hoặc bằng 1000. Nguyên nhân là thời gian xây dựng mô hình bằng phương pháp loess tăng lên tỷ lệ với bình phương của số lượng quan sát, đó sẽ mất nhiều thời gian để vẽ đường hồi quy mô tả mối liên hệ giữa hai biến khi dữ liệu lớn.Phương pháp loess là phương pháp mặc định để xây dựng đường hồi quy mô tả mối liên hệ giữa biến liên tục được ánh xạ tới y phụ thuộc vào biến liên tục được ánh xạ tới x. Phương pháp này được sử dụng khi số lượng dòng của dữ liệu nhỏ hơn hoặc bằng 1000. Nguyên nhân là thời gian xây dựng mô hình bằng phương pháp loess tăng lên tỷ lệ với bình phương của số lượng quan sát, đó sẽ mất nhiều thời gian để vẽ đường hồi quy mô tả mối liên hệ giữa hai biến khi dữ liệu lớn.Phương pháp lm sẽ ước lượng đường thẳng tuyến tính mô tả mối liên hệ giữa biến liên tục ánh xạ đến x và biến liên tục ánh xạ đến y.Phương pháp lm sẽ ước lượng đường thẳng tuyến tính mô tả mối liên hệ giữa biến liên tục ánh xạ đến x và biến liên tục ánh xạ đến y.Phương pháp gam sẽ ước lượng một hàm liên tục được biến đến với tên gọi là một smoothing spline mô tả mối liên hệ giữa hai biến liên tục. Đây là phương pháp mặc định để xây dựng mô hình khi dữ liệu có kích thước lớn hơn 1000. Chúng ta sẽ thảo luận về smoothing spline trong Chương mô hình cộng tính tổng quát.Phương pháp gam sẽ ước lượng một hàm liên tục được biến đến với tên gọi là một smoothing spline mô tả mối liên hệ giữa hai biến liên tục. Đây là phương pháp mặc định để xây dựng mô hình khi dữ liệu có kích thước lớn hơn 1000. Chúng ta sẽ thảo luận về smoothing spline trong Chương mô hình cộng tính tổng quát.Trong trường hợp mô tả trực quan hai biến liên tục nhưng có nhiều điểm bị trùng nhau lên nhau thì geom_point() có thể sẽ gây nhầm lẫn về mật độ xuất hiện của các điểm. Hãy quan sát ví dụ khi chúng tôi sử dụng geom_point() để mô tả trực quan hai biến city và hwy của dữ liệu mpg. Đây là dữ liệu nằm trong thư viện ggplot2 mô tả mức độ tiêu hao nhiên liệu của 234 loại xe ô tô khác nhau được sản xuất vào các năm 1998 và 2008 và hai biến city và hwy lần lượt là mức độ tiêu hao nhiên liệu khi ô tô di chuyển trong thành phố và ô tô di chuyển trên đường cao tốc. Đơn vị của hai biến này đều là miles per gallon, nghĩa là cho biết số dặm mà xe đi được trên mỗi gallon nhiên liệu.\nHình 8.17: Sử dụng đồ thị phân tán để mô tả trực quan hai biến liên tục là hwy và cty trong dữ liệu mpg. Hình bên trái: không sử dụng tham số alpha. Hình bên phải sử dụng tham số alpha bằng 0.2 để biết mật độ xuất hiện của các điểm\nBạn đọc có thể nhận thấy rằng số lượng điểm xuất hiện trên đồ thị bên trái của Hình 8.17 không tương ứng với số quan sát của dữ liệu. Nhận xét này được khẳng định thêm từ đồ thị bên phải của Hình 8.17. Khi chúng ta cho tham số alpha nhận giá trị 0.2, độ đậm nhạt của các điểm là rất khác nhau. Điều này cho thấy sự xuất hiện trùng lặp của của các điểm tại một số giá trị nhất định. Để có hiển thị tốt hơn với dữ liệu như vậy, bạn đọc có thể sử dụng geom_jitter() thay thế cho geom_point(). Hàm geom_jitter() cũng hiển thị các điểm trên hai trục tọa độ giống như geom_point(), tuy nhiên khác biệt của geom_jitter() đó là mỗi điểm sẽ được di chuyển các một cách ngẫu nhiên xung quanh điểm ban đầu để tránh việc hiển thị điểm bị trùng nhau.\nHình 8.18: Sử dụng đồ thị phân tán kết hợp với di chuyển ngẫu nhiên bằng geom_jitter() để mô tả trực quan hai biến liên tục là hwy và cty trong dữ liệu mpg. Hình bên trái: các điểm được di chuyển một cách ngẫu nhiên với trung bình bằng 1 đơn vị. Hình bên phải: các điểm được di chuyển một cách ngẫu nhiên với trung bình bằng 3 đơn vị.\nCó thể thấy rằng các điểm dữ liệu đã được hiển thị đầy đủ hơn trong Hình 8.18. Hai tham số quan trọng trong geom_jitter() là width và height cho biết các điểm được di chuyển theo chiều ngang và chiều dọc với giá trị trung bình là bao nhiêu. Nếu lựa chọn giá trị cho hai tham số này quá nhỏ, mục tiêu hiển thị đầy đủ các điểm sẽ không được đảm bảo, trong khi lựa chọn giá trị cho hai tham số này quá lớn sẽ làm cho dữ liệu bị thay đổi về bản chất.Một phương pháp khác được sử dụng để mô tả trực quan hai biến liên tục là geom_text() hoặc geom_label(). Thay vì hiển thị các điểm như geom_point(), geom_text() hiển thị một biến kiểu chuỗi ký tự thay vì hiển thị điểm. geom_text() thường được sử dụng kết hợp với geom_point() hoặc cũng có thể sử dụng độc lập trên những dữ liệu nhỏ. Khi dữ liệu có kích thước trung bình trở lên, geom_text() nên được sử dụng để nhấn mạnh hoặc chú thích cho một vài điểm quan trọng hơn là được sử dụng cho tất cả các điểm. Khi hiển thị biến kiểu ký tự và các điểm trên cùng một đồ thị, rất dễ dẫn đến hiện tượng ký tự và điểm bị trùng nhau hiển thị chồng lên nhau. Để điều chỉnh ký tự xuất hiện về các phía, bạn đọc cần phải sử dụng thêm các tham số như hjust, vjust.Theo kinh nghiệm của chúng tôi, để hiện thị biến kiểu ký tự tốt hơn, nên sử dụng các hàm geom_text_repel() và geom_label_repel() thay thế cho geom_text() và geom_label(). Để sử dụng hai hàm này cần cài đặt thêm thư viện bổ sung là thư viện \\(\\textbf{ggrepel}\\).\nHình 8.19: Tỷ lệ sinh trung bình mỗi phụ nữ và tỷ lệ tử vong trên 1000 trẻ sơ sinh cả các quốc gia Đông Nam Á năm 2011. Hình phía trên bên phải: Sử dụng geom_text. Hình phía trên bên trái: Sử dụng geom_label. Hình phía dưới bên trái: Sử dụng geom_text_rebel. Hình phía dưới bên phải: Sử dụng geom_label_rebel\nKhi một trong hai biến liên tục là biến dạng thời gian thì chúng ta thường sử dụng geom_line() để trực quan dữ liệu. geom_point() cũng có thể sử dụng cùng với geom_line() nếu số lượng điểm dữ liệu không quá lớn. Nguyên tắc vẽ hình của geom_line() là sử dụng các đường thẳng để nối các điểm xuất hiện trong dữ liệu theo thứ tự tăng dần của biến được ánh xạ tới cấu phần thẩm mỹ x. Khi vẽ đồ thị của một biến liên tục theo thời gian, biến thời gian luôn luôn được ánh xạ đến thuộc tính x.\nHình 8.20: Thu nhập bình quân đầu người thay đổi theo thời gian của bốn quốc gia là Pháp, Nhật Bản, Mỹ, và Vương quốc Anh từ năm 1960 đến năm 2016\nHình 8.20 mô tả sự thay đổi của thu nhập bình quân đầu người của các quốc gia phát triển trên thế giới từ năm 1960 đến 2016. Biến thu nhập bình quân đầu người được ánh xạ đến thuộc tính y trong khi biến thời gian (year) được ánh xạ đến thuộc tính thẩm mỹ x. Để mô tả mỗi quốc gia bằng một đường khác nhau, bạn đọc có các lựa chọn là ánh xạ biến country đến một trong các thuộc tính thẩm mỹ là: group, linetype, hoặc color.Khi trực quan hai biến liên tục với số lượng quan sát lớn thì việc hiển thị trực quan bằng các điểm trên trục tọa độ sẽ không hiệu quả. Thay vào đó, chúng ta có thể hiển thị tần xuất hay mật độ xuất hiện của các điểm để đồ thị được rõ ràng hơn. geom_bin2d() và geom_density2d() là các hàm để trực quan hóa phân phối của hai biến liên tục.geom_bin2d() chia miền giá trị của từng biến thành các khoảng bằng nhau sau đó đếm trên mặt phằng hai chiều trong mỗi một hình chữ nhật đơn vị có bao nhiêu điểm sau đó sử dụng màu sắc từ đậm tới nhạt để mô tả số lượng điểm trong từng hình chữ nhật từ lớn đến nhỏ.geom_bin2d() chia miền giá trị của từng biến thành các khoảng bằng nhau sau đó đếm trên mặt phằng hai chiều trong mỗi một hình chữ nhật đơn vị có bao nhiêu điểm sau đó sử dụng màu sắc từ đậm tới nhạt để mô tả số lượng điểm trong từng hình chữ nhật từ lớn đến nhỏ.geom_density2d() sử dụng phương pháp Kernel để tính giá trị hàm mật độ trong không gian hai chiều giống như cách tính toán của geom_density() trong công thức (8.1). Khoảng cách từ quan sát \\((x_{,1}, x_{,2})\\) đến điểm \\((x_1, x_2)\\) cần xác định mật độ được sử dụng là khoảng cách Euclide thay vì \\(|x_i-x|\\) trong không gian một chiều. Hàm Kernel được sử dụng là hàm mật độ của biến ngẫu nhiên phân phối chuẩn hai chiều. Hàm geom_density2d() vẽ các đường nối các điểm có giá trị hàm mật độ bằng nhau lại với nhau, đường này còn được gọi là các đường bàng quang (hay contour). Hình vẽ dưới đây mô tả phân phối đồng thời của hai biến price và carat trong dữ liệu diamond.geom_density2d() sử dụng phương pháp Kernel để tính giá trị hàm mật độ trong không gian hai chiều giống như cách tính toán của geom_density() trong công thức (8.1). Khoảng cách từ quan sát \\((x_{,1}, x_{,2})\\) đến điểm \\((x_1, x_2)\\) cần xác định mật độ được sử dụng là khoảng cách Euclide thay vì \\(|x_i-x|\\) trong không gian một chiều. Hàm Kernel được sử dụng là hàm mật độ của biến ngẫu nhiên phân phối chuẩn hai chiều. Hàm geom_density2d() vẽ các đường nối các điểm có giá trị hàm mật độ bằng nhau lại với nhau, đường này còn được gọi là các đường bàng quang (hay contour). Hình vẽ dưới đây mô tả phân phối đồng thời của hai biến price và carat trong dữ liệu diamond.\nHình 8.21: Biểu diễn phân phối của hai biến liên tục là price và carat trong dữ liệu diamonds. Hình bên trái: sử dụng geom_bin2d() để chia miền giá trị của các biến ra thành các ô vuông nhỏ và sử dụng màu sắc để mô tả mật độ xuất hiện. Hình bên phải: sử dụng geom_density2d() kết nối các điểm có cùng ước lượng của hàm mật độ.\nHình 8.21 cho thấy phân phối đồng thời của hai biến carat và price trong dữ liệu diamond là phân phối có nhiều mode. Các điểm có tập trung mật độ đặc biệt cao là các điểm có (price, carat) bằng (1000, 0.3), (2200,0.7), và (4700, 1.0).","code":"\np1<-mpg%>%ggplot(aes(x = cty,y = hwy)) +\n  geom_point(color = \"#640514\")+\n  geom_smooth(se = FALSE, linetype = 2, size = 0.7, color = \"darkblue\")+\n  theme_minimal()\np2<-mpg%>%ggplot(aes(x = cty,y = hwy)) +\n  geom_point(color = \"#640514\", alpha = 0.2)+\n  geom_smooth(se = FALSE, linetype = 2, size = 0.7, color = \"darkblue\")+\n  theme_minimal()\ngrid.arrange(p1,p2, nrow= 1 , ncol = 2)\np1<-mpg%>%ggplot(aes(x = cty,y = hwy)) +\n  geom_jitter(width = 1, height = 1, alpha = 0.5, color = \"#640514\")+\n  geom_smooth(se = FALSE, linetype = 2, size = 0.7, color = \"darkblue\")+\n  theme_minimal()\np2<-mpg%>%ggplot(aes(x = cty,y = hwy)) +\n  geom_jitter(width = 3, height = 3,alpha = 0.5, color = \"#640514\")+\n  geom_smooth(se = FALSE, linetype = 2, size = 0.7, color = \"darkblue\")+\n  theme_minimal()\ngrid.arrange(p1,p2, nrow= 1 , ncol = 2)\np1<-dat%>%filter(region == \"South-Eastern Asia\")%>%\n  ggplot(aes(fertility, infant_mortality))+\n  geom_point(color = \"#640514\")+\n  geom_text(aes(label = country), size = 2.5,vjust=  - 1.1, color = \"#640514\")+\n  ggtitle(\"Sử dụng geom_text()\")+\n  theme_minimal()\np2<-dat%>%filter(region == \"South-Eastern Asia\")%>%\n  ggplot(aes(fertility, infant_mortality))+\n  geom_point(color = \"#640514\")+\n  geom_label(aes(label = country), size = 2.5, vjust= - 1.1, color = \"#640514\")+\n  ggtitle(\"Sử dụng geom_label()\")+\n  theme_minimal()\n\np3<-dat%>%filter(region == \"South-Eastern Asia\")%>%\n  ggplot(aes(fertility, infant_mortality))+\n  geom_point(color = \"#640514\")+\n  geom_text_repel(aes(label = country), size = 2.5,color = \"#640514\")+\n  ggtitle(\"Sử dụng geom_text_repel()\")+\n  theme_minimal()\np4<-dat%>%filter(region == \"South-Eastern Asia\")%>%\n  ggplot(aes(fertility, infant_mortality), )+\n  geom_point(color = \"#640514\")+\n  geom_label_repel(aes(label = country),size = 2.5,color = \"#640514\")+\n  ggtitle(\"Sử dụng geom_label_repel()\")+\n  theme_minimal()\ngrid.arrange(p1,p2,p3,p4,nrow=2,ncol=2)\ngapminder%>%\n  filter(country %in% c(\"United States\",\"Japan\",\"France\",\"United Kingdom\"))%>%\n  ggplot(aes(x = year, y = gdp/population,color = country))+\n  geom_line()+\n  geom_point(size = 0.5, alpha = 0.5)+\n  theme_minimal()\np1<-diamonds%>%\n  ggplot(aes(price, carat))+geom_bin2d(bins = 40)+\n  scale_x_log10()+scale_y_log10()+\n  theme_minimal()+scale_fill_viridis_c()+\n  ggtitle(\"geom_bind2d\")\n\np2<-diamonds%>%\n  ggplot(aes(price, carat))+geom_density2d(color = \"#640514\",alpha = 0.5)+\n  scale_x_log10()+scale_y_log10()+\n  theme_minimal()+\n  ggtitle(\"geom_density2d\")\n\ngrid.arrange(p1,p2,nrow=1, ncol = 2)"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"mô-tả-một-biến-liên-tục-và-một-biến-rời-rạc","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.4.2.3 Mô tả một biến liên tục và một biến rời rạc","text":"Đồ thị boxplot là phương pháp thông dụng nhất để mô tả mối liên hệ giữa một biến liên tục với một biến rời rạc. Đồ thị boxplot được vẽ bằng hàm geom_boxplot() với thuộc tính thẩm mỹ x được ánh xạ đến biến rời rạc và thuộc tính thẩm mỹ y được ánh xạ đên biến liên tục, hoặc ngược lại. Các thuộc tính thẩm mỹ như color và fill được sử dụng giống như geom_histogram(). Hình 8.22 mô tả mối liên hệ giữa biến thu nhập bình quân đầu người và biến Châu lục trong dữ liệu gapminder được lọc theo năm 2011.\nHình 8.22: Logarit của thu nhập bình quân đầu người của các quốc gia trên thế giới theo Châu lục năm 2011. Hình bên trái: Các châu lục được sắp xếp theo thứ tự tên Châu lục tăng dần. Hình bên phải: các châu lục được sắp xếp theo thứ tự giá trị trung bình của biến thu nhập bình quân đầu người tăng dần\nThứ tự của các đồ thị hình hộp sẽ xuất hiện trên trục \\(\\overrightarrow{Ox}\\) theo thứ tự của các biến rời rạc. Tuy nhiên, để hiệu quả trực quan được tốt hơn, các đồ thị hình hộp nên được sắp xếp theo thứ tự mà giá trị trung bình của biến liên tục tương ứng với mỗi giá trị rời rạc tăng dần giống như đồ thị bên phải của Hình 8.22. Chúng ta có thể thấy rằng thu nhập bình quân đầu người của Châu Mỹ thấp hơn Châu Á mặc dù các giá trị trung vị và tứ phân vị thứ nhất cao hơn. Nguyên nhân là phân phối của biến thu nhập bình quân đầu người của châu Á lệch phải mạnh hơn với phân phối của biến này tại các nước châu Mỹ.geom_boxplot() chỉ thể hiện các giá trị phân vị của phân phối xác suất, nên đôi khi sẽ không cung cấp đầy đủ thông tin về phân phối của biến liên tục. đó, người phân tích dữ liệu thường sử dụng geom_violin() kết hợp cùng với geom_boxplot() để cho mô tả tốt hơn về phân phối xác suất của biến liên tục trong từng nhóm. geom_violin() đơn giản là vẽ hàm mật độ của biến liên tục trong từng nhóm được định nghĩa bởi biến rời rạc.\nHình 8.23: Logarit thu nhập bình quân đầu người của các quốc gia trên thế giới theo Châu lục năm 2011 kết hợp geom_boxplot và geom_violin\nTham số draw_quantiles cho biết các giá ngưỡng phân vị mà chúng ta muốn vẽ cùng với các hàm mật độ. Trong Hình 8.23 sử dụng các ngưỡng phân vị 25%, 50% và 75% tương tự như geom_boxplot().","code":"\np1<-dat%>%ggplot(aes(x = continent, y = log(gdp_per_capita),\n                     fill=continent))+\n  geom_boxplot(color = \"#640514\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")\np2<-dat%>%ggplot(aes(x = reorder(continent, gdp_per_capita),\n                     y = log(gdp_per_capita), fill=continent))+\n  geom_boxplot(color = \"#640514\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")\ngrid.arrange(p1,p2,nrow=1, ncol = 2)\np1<-dat%>%ggplot(aes(x = reorder(continent, log(gdp_per_capita)),\n                     y = log(gdp_per_capita), fill=continent))+\n  geom_boxplot(color = \"#640514\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")\np2<-dat%>%ggplot(aes(x = reorder(continent, log(gdp_per_capita)),\n                     y = log(gdp_per_capita)))+\n  geom_violin(draw_quantiles = c(0.25,0.5,0.75),\n              color = \"#640514\")+\n  theme_minimal()\ngrid.arrange(p1,p2,nrow=1, ncol = 2)"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"mô-tả-hai-biến-rời-rạc","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.4.2.4 Mô tả hai biến rời rạc","text":"Đồ thị thường được sử dụng để mô tả trực quan phân phối của hai biến rời rạc là đồ thị kiểu bong bóng. Hàm số được sử dụng để trực quan đồ thị này là geom_count(). Tương ứng với mỗi cặp giá trị của hai biến rời rạc, hàm geom_count() tính toán số lượng điểm dữ liệu tương ứng với hai giá trị này và phản ánh số lượng điểm dữ liệu lên trên đồ thị thông qua kích thước của mỗi bong bóng. Để mô tả cách sử dụng của geom_count(), chúng ta mô tả phân phối của hai biến rời rạc là cut và color trong dữ liệu diamond như sau:\nHình 8.24: Đồ thị bong bóng mô tả phân phối của hai biến rời rạc là cut và color trong dữ liệu diamonds. Hình bên trái sử dụng hình dạng tròn (shape = 21) để mô tả số điểm dữ liệu. Hình bên phải sử dụng hình vuông (shape = 22) để dễ phân biệt kích thước hơn\nCác thuộc tính thẩm mỹ của geom_count() hoàn toàn giống với geom_point() nên chúng ta có thể lựa chọn các hình dạng cho phép phân biệt kích thước tốt hơn thay vì sử dụng hình tròn như mặc định. Đồ thị trực quan trong Hình 8.24 còn sử dụng hàm scale_size() để giúp cho hiển thị được tốt hơn. Chúng ta sẽ thảo luận về các hàm scale_() trong các phần tiếp theo. Từ Hình 8.24 để nhận ra tỷ lệ lớn các viên kim cương có biến cut nhận giá trị ‘ideal’ và tỷ lệ lớn các viên kim cương có màu sắc nhận giá trị ‘G’. Các viên kim cương có biến cut nhận giá trị \\('ideal'\\) và biến color nhận giá trị ‘G’ cũng xuất hiện nhiều nhất trong dữ liệu với số lượng hơn 4000 viên.Một phương pháp khác để trực quan hai biến rời rạc là trực quan một biến bằng geom_bar() sau đó ánh xạ thuộc tính fill đến biến rời rạc còn lại.","code":"\np1<-diamonds%>%ggplot(aes(cut,color))+\n  geom_count(fill=\"#640514\",alpha = 0.5,shape = 21)+\n  theme_minimal()+scale_size(range = c(1,12))+\n  theme(legend.position = \"top\")\n\np2<-diamonds%>%ggplot(aes(cut,color))+\n  geom_count(fill=\"#640514\",alpha = 0.5,shape = 22)+\n  theme_minimal()+scale_size(range = c(1,12))+\n  theme(legend.position = \"top\")\ngrid.arrange(p1,p2,nrow=1, ncol = 2)"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"mô-tả-ba-biến","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.4.2.5 Mô tả ba biến","text":"Thư viện ggplot2 có hỗ trợ vẽ các hình ảnh trong không gian ba chiều, nhưng sử dụng hình ảnh kiểu 3 chiều không phải là một phương pháp tốt để hiển thị ba biến trên cùng một đồ thị. Khi mô tả mối liên hệ giữa ba biến, phương pháp đơn giản và hiệu quả nhất là sử dụng ba đồ thị, và mỗi đồ thị trực quan mô tả mối liên hệ giữa hai biến với nhau. Hướng tiếp cận khác để mô tả ba biến trên cùng một đồ thị là lựa chọn đồ thị trực quan cho hai biến trước sau đó ánh xạ biến còn lại vào một thuộc tính thẩm mỹ của đồ thị đó.Trong trường hợp hai trong ba biến là biến liên tục và biến còn lại là biến rời rạc, hãy sử dụng đồ thị phân tán để mô tả hai biến liên tục và sử dụng màu sắc để mô tả (ánh xạ) từ biến rời rạc còn lại.Trong trường hợp hai trong ba biến là biến liên tục và biến còn lại là biến rời rạc, hãy sử dụng đồ thị phân tán để mô tả hai biến liên tục và sử dụng màu sắc để mô tả (ánh xạ) từ biến rời rạc còn lại.Khi hai trong ba biến là các biến rời rạc trong khi biến còn lại là biến liên tục, chúng ta có thể sử dụng geom_tile(). Thật vậy, hàm geom_tile() là một phương pháp hiệu quả khi mô tả mối liên hệ giữa hai biến rời rạc với một biến liên tục bằng cách ánh xạ hai biến rời rạc vào các thuộc tính thẩm mỹ x và y, trong khi giá trị của biến liên tục được mô tả thông qua màu sắc. Nếu tương ứng với một cặp giá trị của biến rời rạc ánh xạ đến thuộc tính x và thuộc tính y có nhiều giá trị của biến liên tục thì màu sắc được hiển thị nên là một giá trị thống kê đại diện cho giá trị biến liên tục, giá trị trung bình là một ví dụ. Thật vậy, hãy lấy ví dụ khi chúng ta muốn mô tả ba biến region, year, và life_expectancy của dữ liệu gapminder trên cùng một đồ thị. Các biến region và year là các biến rời rạc, đó sẽ được ánh xạ đến các thuộc tính thẩm mỹ y và x của geom_tile(). Tương ứng với mỗi giá trị của region và year, chúng ta có một véc-tơ giá trị của biến liên tục life_expectancy. Để có thể trực quan hóa được bằng geom_tile(), chúng ta sẽ cần tính life_expectancy trung bình của mỗi vùng trước khi thực hiện trực quan hóa.Khi hai trong ba biến là các biến rời rạc trong khi biến còn lại là biến liên tục, chúng ta có thể sử dụng geom_tile(). Thật vậy, hàm geom_tile() là một phương pháp hiệu quả khi mô tả mối liên hệ giữa hai biến rời rạc với một biến liên tục bằng cách ánh xạ hai biến rời rạc vào các thuộc tính thẩm mỹ x và y, trong khi giá trị của biến liên tục được mô tả thông qua màu sắc. Nếu tương ứng với một cặp giá trị của biến rời rạc ánh xạ đến thuộc tính x và thuộc tính y có nhiều giá trị của biến liên tục thì màu sắc được hiển thị nên là một giá trị thống kê đại diện cho giá trị biến liên tục, giá trị trung bình là một ví dụ. Thật vậy, hãy lấy ví dụ khi chúng ta muốn mô tả ba biến region, year, và life_expectancy của dữ liệu gapminder trên cùng một đồ thị. Các biến region và year là các biến rời rạc, đó sẽ được ánh xạ đến các thuộc tính thẩm mỹ y và x của geom_tile(). Tương ứng với mỗi giá trị của region và year, chúng ta có một véc-tơ giá trị của biến liên tục life_expectancy. Để có thể trực quan hóa được bằng geom_tile(), chúng ta sẽ cần tính life_expectancy trung bình của mỗi vùng trước khi thực hiện trực quan hóa.\nHình 8.25: Tuổi thọ trung bình của các vùng trên thế giới thay đổi qua các năm từ năm 1960 đến năm 2015\nTrong các câu lệnh vẽ Hình 8.25 chúng tôi đã sử dụng thêm các hàm scale_() để kiểm soát các ánh xạ thẩm mỹ: giá trị của biến year xuất hiện trên trục \\(\\overrightarrow{Ox}\\) sẽ là cách đều 5 năm, các vùng trên trục \\(\\overrightarrow{Oy}\\) được sắp xếp theo thứ tự có tuổi thọ trung bình trên toàn bộ dữ liệu tăng dần. Dải màu sắc cũng được gán giá trị cho dải màu liên tục hai giá trị màu sắc khai báo trong các câu lệnh. Chúng ta sẽ thảo luận về scale_() trong phần sau của chương sách.","code":"\n# Tạo danh sách các vùng có tuổi thọ trung bình tăng dần\ndat1<-gapminder%>%group_by(region)%>%\n     summarise(life_expectancy = mean(life_expectancy,na.rm = TRUE))%>%\n    arrange(desc(life_expectancy))\nregion_list<-dat1$region\n\n# Tạo dải màu rời rạc từ cam tới xanh\n#\nmycol<-colorRampPalette(c(\"#EB492E\", \"grey95\"),space = \"Lab\")(5)\nmycol<-c(mycol,colorRampPalette(c(\"grey95\",\"#4C99EB\"),space = \"Lab\")(5) )\n\n#mycol<-hcl_palettes(palette = \"Red-Blue\", n = 5)\n\n# Trực quan hóa 3 biến region, year, và life_expectancy\ngapminder%>%group_by(year,region)%>%\n     summarise(life_expectancy = mean(life_expectancy,na.rm = TRUE))%>%\n     ggplot()+\n     geom_tile(aes(x = year, y = region , fill = life_expectancy),color = \"grey30\", size = 0.1)+\n     scale_fill_gradientn(colours = mycol,\n                          guide = guide_legend(title = \"Tuổi thọ trung bình\") )+\n\n     scale_x_continuous(breaks = seq(1960,2015,5),\n                        limits = c(1960,2015))+\n     scale_y_discrete(limits = region_list)+\n     theme_minimal()+\n    xlab(\"\")+ylab(\"\")+\n    theme(legend.position = \"top\")"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"các-hàm-stat_","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.4.3 Các hàm stat_()","text":"Bạn đọc cũng có thể xây dựng các lớp cho đồ thị ggplot2 bằng cách sử dụng các hàm stat_(). Các hàm số này không hiển thị dữ liệu ở trạng thái ban đầu mà thường hiển thị dữ liệu dưới một phép biến đổi thống kê hoặc một phương pháp tóm tắt dữ liệu. Có sự tương đương giữa các hàm stat_() với các hàm geom_(), nghĩa là chúng ta có thể gọi hàm geom_() bằng một hàm stat_() và ngược lại. Ví dụ stat_bin() tương đương với geom_histogram() và geom_bar(); stat_smooth() tương đương với geom_smooth(). Về bản chất, các geom và các stat đều có nguồn gốc từ chung một hàm tạo một lớp mới cho đồ thị là hàm layer_(). Chúng ta sẽ thảo luận về các hàm này trong phần Kiến thức nâng cao về ggplot2.Ví dụ, thay vì sử dụng geom_(), chúng ta có thể sử dụng stat_() để mô tả phân phối của các biến liên tục:\nHình 8.26: Phân phối của biến tỷ lệ sinh trung bình một phụ nữ (fertility) năm 2011. Hình bên trái: histogram và mật độ của biến fertility. Hình bên phải: phân phối của biến fertility theo các lục địa\nBạn đọc có thể thấy rằng các đồ thị trong Hình 8.26 được tạo bằng các hàm stat_() và cho kết quả hoàn toàn giống với các hàm geom_() tương ứng.","code":"\np1<-dat%>%ggplot(aes(fertility, after_stat(density)))+\n  stat_bin(fill = \"#640514\",alpha = 0.5)+\n  stat_density(color = \"darkblue\",alpha = 0.1)+\n  theme_minimal()\np2<-dat%>%ggplot(aes(x = reorder(continent,fertility), y = fertility,fill = continent))+\n  stat_boxplot(alpha = 0.7, color = \"#640514\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")\ngrid.arrange(p1,p2,nrow=1,ncol=2)"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"nhóm-hàm-scale_","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.5 Nhóm hàm scale_()","text":"Các hàm scale_() trong thư viện ggplot2 được sử dụng để kiểm soát ánh xạ thẩm mỹ từ các biến trong dữ liệu đến thuộc tính thẩm mỹ của đồ thị. Các hàm này sử dụng dữ liệu thô ban đầu để biến đổi thành các đối tượng trực quan mà chúng ta có thể nhìn thấy như kích thước, màu sắc, vị trí, hoặc hình dạng. Bạn đọc có thể tạo đồ thị bằng thư viện ggplot2 mà không cần biết chính xác các ánh xạ thẩm mỹ hoạt động như thế nào vì các cài mặc định của thư viện ggplot2 đã được lựa chọn kỹ càng. Tuy nhiên, hiểu về nguyên tắc biến đổi từ giá trị thành đối tượng trực quan của ggplot2 và hiểu cách hoạt động của các hàm scale_() sẽ giúp bạn kiểm soát tốt những đối tượng trực quan trên đồ thị và tạo được đồ thị trực quan theo ý của mình.","code":""},{"path":"trực-quan-hóa-dữ-liệu.html","id":"vị-trí-xuất-hiện-trên-trục-tọa-độ","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.5.1 Vị trí xuất hiện trên trục tọa độ","text":"Đa số các đồ thị trực quan được vẽ bằng thư viện ggplot2 hiển thị dữ liệu trên trục tọa độ Descartes nên chúng tôi sẽ tập trung vào cách dữ liệu được mô tả khi ánh xạ đến trục tọa độ \\(\\overrightarrow{Ox}\\) và \\(\\overrightarrow{Oy}\\). Khi ánh xạ các biến của dữ liệu tới các trục tọa, nếu chúng ta không sử dụng các hàm scale_(), dữ liệu sẽ được hiển thị đúng như giá trị ban đầu trên các trục tọa độ. Trong nhiều trường hợp, hiển thị tại vị trí đúng như dữ liệu ban đầu sẽ không mang lại hiệu quả. Chúng ta quay trở lại ví dụ khi mô tả hai biến total và population của dữ liệu murders trong thư viện dslabs. Bạn đọc có thể sánh cách hiển thị giữa việc không kiểm soát và có kiểm soát ánh xạ thẩm mỹ như Hình 8.27\nHình 8.27: Hiển thị dân số và số vụ sát nhân bằng súng của các bang trong dữ liệu murders. Hình bên trái: vị trí các điểm trên trục tọa độ là giá trị dữ liệu thô. Hình bên phải: vị trí trên các trục tọa độ đã được biến đổi bằng cách lấy logarit cơ số 10\nCó thể thấy rằng đồ thị bên phải của Hình 8.27 hiển thị rõ ràng hơn đồ thị bên trái. Các điểm dữ liệu hiển thị rõ ràng hơn nhờ vào chúng ta đã gọi các hàm bằng các hàm scale_x_continuous() và scale_y_continuous() để tác động đến ánh xạ từ biến population đến thuộc tính x và ánh xạ từ biến total đến thuộc tính y. Đây là hai hàm số được dùng để kiểm soát vị trí xuất hiện của các điểm trên trục tọa độ khi các biến trong ánh xạ là các biến kiểu số liên tục. Các tham số có thể được sử dụng trong các hàm này bao gồm có:Tham số trans, là viết tắt của transformation, nhận giá trị mặc định là ‘identity’, nghĩa là lấy chính xác giá trị của dữ liệu khi ánh xạ đến các thuộc tính x hoặc y. Để biết các giá trị khác mà tham số này có thể nhận được, bạn đọc có thể tham khảo trong tài liệu đi kèm với các hàm scale_x_continuous() và scale_y_continuous(). Khi sử dụng hàm các hàm này với tham số trans, với các biến \\(X_1\\) và \\(X_2\\) là các biến của dữ liệu được ánh xạ tới các thuộc tính thẩm mỹ x và y, và một hàm \\(f\\) được gán giá trị cho tham số trans, giá trị xuất hiện trên trục tọa độ \\(\\overrightarrow{Ox}\\) và \\(\\overrightarrow{Oy}\\) sẽ tương ứng là \\(f(X_1)\\) và \\(f(X_2)\\). Chẳng hạn như trong đồ thị bên phải của Hình 8.27, khi chúng ta sử dụng hàm scale_x_continuous() và scale_y_continuous(), với tham số trans được gán bằng ‘log10’, tọa độ (giá trị xuất hiện) của mỗi quốc gia trên các trục \\(\\overrightarrow{Ox}\\) và \\(\\overrightarrow{Oy}\\) sẽ là log10(population) và log10(total). Việc chuyển đổi này sẽ hữu ích bởi rất đa số các bang có dân số nhỏ, trong khi có một vài bang có dân số rất lớn. Thực hiện chuyển đổi dữ liệu bằng hàm ‘log10’ sẽ giúp cho khoảng cách của các điểm cách đều nhau hơn và dễ dàng phân biệt hơn với người quan sát đồ thị.Tham số limits giới hạn giá trị trên các thuộc tính thẩm mỹ x và y của đồ thị. Mỗi khi chúng ta vẽ đồ thị và sử dụng thư viện ggplot2, tham số limits mặc định sẽ đảm bảo việc hiển thị được đầy đủ nhất. Trong một vài trường hợp, khi chúng ta cần phải thay đổi các giá trị giới hạn của các trục tọa độ, việc thay đổi miền giá trị là cần thiết để truyền tải ý nghĩa của dữ liệu. Ví dụ như khi muốn sánh hai dữ liệu trên cùng một miền giá trị các biến được ánh xạ tới các trục tọa độ \\(\\overrightarrow{Ox}\\) và \\(\\overrightarrow{Oy}\\): các đồ thị trong Hình 8.28 mô tả hai biến fertility và life_expectancy trong các năm 1960 và 2011 và không sử dụng các hàm scale_()\nHình 8.28: Mối liên hệ giữa hai biến tỷ lệ sinh trung bình của mỗi phụ nữ và tuổi thọ trung bình của tất cả các quốc gia trên thế giới trong năm 1960 và năm 2010. Miền giá trị trên các trục tọa độ là khác nhau. Hình bên trái: dữ liệu năm 1960. Hình bên phải: dữ liệu năm 2011\nKhông thể dễ dàng nhận biết được sự khác biệt giữa hai đồ thị mô tả mối liên hệ giữa hai biến tỷ lệ sinh trung bình và tuổi thọ trung bình của các quốc gia trên thế giới sau 50 năm, từ năm 1960 đến năm 2010, chúng ta không biểu diễn các biến trên cùng một miền giá trị của các trục tọa độ. Để khắc phục vấn đề này, Hình 8.29 sử dụng tham số limits trong các hàm scale_x_continuous() và scale_y_continuous(). Để khai báo tham số cho tham số này, chúng ta sử dụng một véc-tơ hai chiều chứa giá trị nhỏ nhất và giá trị lớn nhất trên trục tọa độ mà bạn muốn hiển thị.\nHình 8.29: Mối liên hệ giữa tỷ lệ sinh trung bình của mỗi phụ nữ và tuổi thọ trung bình của các quốc gia trên thế giới trong năm 1960 và 2010 sử dụng cùng một miền giá trị trên mỗi trục tọa độ. Hình bên trái: dữ liệu năm 1960. Hình bên phải: dữ liệu năm 2010\nTham số breaks kiểm soát vị trí các điểm được đánh dấu xuất hiện trên các trục tọa độ. Chúng tôi thường kết hợp breaks với tham số labels để kiểm soát đồng thời vị trí và cách hiển thị trên các trục số. Ví dụ như trong đồ thị mô tả hai biến fertility và life_expectancy của các năm 1960 và năm 2010, chúng ta muốn giá trị xuất hiện trên trục \\(\\overrightarrow{Ox}\\) là các số 2, 4, 6, 8 và các số trên trục \\(\\overrightarrow{Oy}\\) xuất hiện tại các vị trí 10, 30, 50, 70, và 90, chúng ta chỉ cần khai báo giá trị cho tham số breaks bằng một véc-tơ chứa các giá trị mà chúng ta muốn hiển thị. Lưu ý rằng breaks có chữ s ở cuối để phân biệt với từ khóa break.\nHình 8.30: Mối liên hệ giữa hai biến tỷ lệ sinh trung bình và tuổi thọ trung bình của các quốc gia trên thế giới biểu diễn trên cùng một miền giá trị của mỗi trục tọa độ. Giá trị trên trục tọa độ được định nghĩa lại bằng các tham số breaks và labels. Hình bên trái: dữ liệu năm 1960. Hình bên phải: dữ liệu năm 2011\nKhi một trong hai biến liên tục là biến kiểu thời gian thì hàm số sử dụng để kiểm soát giá trị hiển thị trên trục tọa độ là scale_x_date(), cùng với hai tham số thường được sử dụng là date_break và date_labels. Cách sử dụng của các tham số này tương tựng như các tham số breaks và labels. Bạn đọc có thể tham khảo cách sử dụng của hàm scale_x_date() thông qua ví dụ sau: chúng ta mô tả biến số lượng hành khách trung bình từng tháng được lưu trong dữ liệu AirPassengers theo một biến thời gian bắt đầu từ tháng 01 năm 1949:\nHình 8.31: Số lượng hành khách trung bình theo tháng trong dữ liệu AirPassenger. Hình bên trái: không sử dụng scale_x_date. Hình bên phải: sử dụng scale_x_date để hiển thị tốt hơn giá trị ngày tháng trên trục tọa độ\nKhi giá trị trên trục \\(\\overrightarrow{Ox}\\) hoặc trục \\(\\overrightarrow{Oy}\\) là các giá trị rời rạc, các hàm số sử dụng để kiểm soát ánh xạ thẩm mỹ từ các biến đến các trục tọa độ là các hàm scale_x_discrete() và scale_y_discrete() và các tham số thường sử dụng đi kèm với các hàm này là limits và labels. Tham số limits được sử dụng để cho biết các giá trị nào của biến rời rạc xuất hiện trên đồ thị, trong khi tham số labels cho biết từng giá trị của biến rời rạc xuất hiện như thế nào\nHình 8.32: Phân phối của biến tỷ lệ số vụ xả súng trên một triệu người dân theo vùng vào năm 2010 tại Mỹ. Hình bên trái: không sử dụng scale. Hình bên phải: sử dụng limits trên trục y và labels trên trục x cho hiển thị tốt hơn\n","code":"\np1<-murders%>%ggplot(aes(x = population,y = total))+\n  geom_point(size = 2, shape = 21, color = \"#640514\")+\n  theme_minimal()+ggtitle(\"Không sử dụng scale\")\np2<-murders%>%ggplot(aes(x = population,y = total))+\n  geom_point(size = 2, shape = 21, color = \"#640514\")+\n  theme_minimal()+\n  scale_x_continuous(trans = \"log10\")+\n  scale_y_continuous(trans = \"log10\")+\n  ggtitle(\"Có sử dụng scale (log10)\")\ngrid.arrange(p1,p2,nrow=1,ncol=2)\np1<-gapminder%>%filter(year==1960)%>%\n  ggplot(aes(fertility,life_expectancy))+\n  geom_point(size = 2, shape = 21 ,color = \"#640514\")+\n  ggtitle(\"Năm 1960\")+\n  theme_minimal()\np2<-gapminder%>%filter(year==2011)%>%\n  ggplot(aes(fertility,life_expectancy))+\n  geom_point(size = 2, shape = 21,color = \"#640514\")+\n  ggtitle(\"Năm 2011\")+\n  theme_minimal()\ngrid.arrange(p1,p2,nrow=1,ncol=2)\np1<-gapminder%>%filter(year==1960)%>%\n  ggplot(aes(fertility,life_expectancy))+\n  geom_point(size = 2, shape = 21 ,color = \"#640514\")+\n  ggtitle(\"Năm 1960\")+\n  scale_x_continuous(limits = c(1,9))+\n  scale_y_continuous(limits = c(25,85))+\n  theme_minimal()\np2<-gapminder%>%filter(year==2010)%>%\n  ggplot(aes(fertility,life_expectancy))+\n  geom_point(size = 2, shape = 21,color = \"#640514\")+\n  ggtitle(\"Năm 2010\")+\n  scale_x_continuous(limits = c(1,9))+\n  scale_y_continuous(limits = c(25,85))+\n  theme_minimal()\ngrid.arrange(p1,p2,nrow=1,ncol=2)\np1<-gapminder%>%filter(year==1960)%>%\n  ggplot(aes(fertility,life_expectancy))+\n  geom_point(size = 2, shape = 21 ,color = \"#640514\")+\n  ggtitle(\"Năm 1960\")+\n  scale_x_continuous(limits = c(1,9),\n                     breaks = c(2,4,6,8),\n                     labels = paste(c(2,4,6,8),\"trẻ em\"))+\n  scale_y_continuous(limits = c(25,85),\n                     breaks = c(10,30,50,70,90),\n                     labels = paste(c(10,30,50,70,90),\"tuổi\"))+\n  theme_minimal()\np2<-gapminder%>%filter(year==2010)%>%\n  ggplot(aes(fertility,life_expectancy))+\n  geom_point(size = 2, shape = 21 ,color = \"#640514\")+\n  ggtitle(\"Năm 2010\")+\n  scale_x_continuous(limits = c(1,9),\n                     breaks = c(2,4,6,8),\n                     labels = paste(c(2,4,6,8),\"trẻ em\"))+\n  scale_y_continuous(limits = c(25,85),\n                     breaks = c(10,30,50,70,90),\n                     labels = paste(c(10,30,50,70,90),\"tuổi\"))+\n  theme_minimal()\ngrid.arrange(p1,p2,nrow=1,ncol=2)\ndat0<-data.frame(Number_Passengers = AirPassengers,\n                Month = seq(as.Date(\"1949-01-01\"), by = \"month\", length.out = 144))\np1<-dat0%>%ggplot(aes(x = Month, y = Number_Passengers))+\n  geom_line(color = \"#640514\") + ggtitle(\"Không sử dụng scale\")+\n  theme_minimal()\np2<-dat0%>%ggplot(aes(x = Month, y = Number_Passengers))+\n  geom_line(color = \"#640514\")+ ggtitle(\"Sử dụng scale_x_date()\")+\n  scale_x_date(date_break = \"2 years\", date_labels = \"%b\\n%Y\" )+\n  scale_y_continuous(breaks = seq(100,600,length=6))+\n  theme_minimal()\n\ngrid.arrange(p1,p2,nrow=1,ncol=2)\n# Không sử dụng scale\np1<-murders%>%mutate(rate = total/population*10^6)%>%\n  ggplot(aes(reorder(region,rate),rate, fill = region))+\n  geom_boxplot(color = \"#640514\")+\n  ggtitle(\"Không sử dụng scale\")+\n  theme_minimal()+xlab(\"\")+\n  theme(legend.position = \"none\")\n# Sử dụng tham số labels cho trục x\n# và sử dụng limits cho trục y\np2<-murders%>%mutate(rate = total/population*10^6)%>%\n  ggplot(aes(reorder(region,rate),rate,fill = region))+\n  geom_boxplot(color = \"#640514\")+\n  scale_y_continuous(limits = c(0,50))+\n  # Thay thế giá trị hiển thị trên trục số bằng labels\n  scale_x_discrete(labels = c(\"Northeast\" = \"Đông Bắc\",\n                              \"West\" = \"Miền Tây\",\n                              \"South\" = \"Miền Nam\",\n                              \"North Central\" = \"Miền Bắc\"))+\n  ggtitle(\"Sử dụng limits và labels\")+\n  theme_minimal()+xlab(\"\")+\n  theme(legend.position = \"none\")\ngrid.arrange(p1,p2,nrow=1,ncol=2)"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"màu-sắc-hiển-thị","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.5.2 Màu sắc hiển thị","text":"Thuộc tính thẩm mỹ được sử dụng phổ biến nhất là màu sắc. Có nhiều cách để ánh xạ giá trị của biến tới màu sắc khi trực quan hóa dữ liệu bằng thư viện ggplot2. Vì màu sắc là một chủ đề phức tạp, chúng tôi sẽ bắt đầu bằng thảo luận sơ lược về lý thuyết màu sắc. Sau đó, chúng tôi sẽ giới thiệu đến bạn đọc về thang màu liên tục, thang màu rời rạc và thang màu tổng hợp được sử dụng để ánh xạ các biến rời rạc và biến liên tục trong trực quan hóa dữ liệu. Chúng tôi cũng sẽ đề cập đến các thang màu dành cho biến kiểu thời gian, kiểu ngày tháng, độ trong của các màu sắc hiển thị, và nguyên tắc chú giải cho màu sắc được thiết lập trong các đồ thị của ggplot2.","code":""},{"path":"trực-quan-hóa-dữ-liệu.html","id":"cảm-nhận-của-con-người-về-màu-sắc","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.5.2.1 Cảm nhận của con người về màu sắc","text":"Trong vật lý, màu sắc được tạo ra bởi hỗn hợp các bước sóng ánh sáng. Để mô tả đầy đủ về một màu sắc, chúng ta cần biết sự kết hợp chính xác của các bước sóng. Thực tế, mắt con người chỉ có ba cơ quan cảm nhận màu sắc khác nhau, vì vậy chúng ta có thể tóm tắt khả năng cảm nhận bất kỳ màu nào chỉ bằng ba con số. Một không gian màu quen thuộc với bạn đọc là không gian màu RGB, không gian mà mọi màu sắc được xác định theo cường độ ánh sáng đỏ, xanh da trời và xanh lá cây để tạo ra màu đó. Ưu điểm của không gian màu này là sự đơn giản mỗi màu sắc đều được mô tả bằng ba con số từ 0 đến 255 hoàn toàn độc lập với nhau. Một vấn đề với không gian này là các dải màu liên tục nhận được bằng cách tăng giảm các cường độ màu đỏ, xanh lá cây, và xanh dương lại không giống như cách nhận thức về màu sắc của con người. Khi nhìn vào một màu cụ thể, chúng ta không thể ước tính được cường độ mỗi màu là bao nhiêu, điều này có thể gây khó khăn cho việc tạo ánh xạ từ một biến liên tục sang một dải màu.Mỗi khi hiển thị một giá trị màu sắc trong không gian RGB,ngôn ngữ R cũng như đa số các ngôn ngữ khác thường sử dụng kiểu chuỗi ký tự có 6 chữ số viết theo hệ 16, bắt đầu từ 0 và kết thúc ở F, và bắt đầu bằng một dấu ‘#’. Hai chữ số đầu đại diện cho sắc đỏ, 2 chữ số tiếp theo đại diện cho màu xanh lá cây và 2 chữ số cuối đại diện cho màu xanh da trời. Cường độ ánh sáng của mỗi màu sẽ bắt đầu từ ‘00’ cho đến ‘FF’, nghĩa là có 256 mức độ cho mỗi màu. Bạn đọc có thể dễ dàng suy diễn ra mã của các màu sắc quen thuộc:Màu đen: ‘#000000’Màu trắng: ‘#FFFFFF’Màu đỏ: ‘#FF0000’Màu xanh lá cây: ‘#00FF00’Màu xanh da trời: ‘#0000FF’Dễ dàng suy diễn và nhận biết chính là điểm mạnh của không gian màu RGB. Tuy nhiên, như chúng tôi đã thảo luận, sự liên tục của màu sắc trong không gian này lại không liên tục giống như cách cảm nhận màu sắc của con người. Chính vì thế những nhà nghiên cứu về màu sắc luôn cố gắng xây dựng các không gian màu sắc giống với cảm nhận về màu sắc của con người hơn không gian RGB.Một không gian màu có thể được sử dụng thay thế cho không gian RGB là không gian Lab mà trong đó:L đại diện cho độ tương phản sáng-tối của màu sắc;trục tọa độ cho biết các vị trí của màu trên trục từ xanh lá cây đến đỏ;trục tọa độ b cho biết các vị trí của màu trên trục từ xanh da trời đến màu vàng.Cải tiến từ không gian RGB sang không gian Lab giúp cho các dải màu sắc tương ứng hơn với khả năng nhận biết màu sắc của con người, tuy nhiên vẫn còn khoảng cách giữa không gian Lab với nhận thức màu sắc. Nhìn chung, không gian Lab có các ưu điểm vượt trội hơn không gian RGB đó thư viện ggplot2 mặc định sử dụng không gian Lab khi nội suy tuyến tính các màu sắc nằm giữa hai màu bất kỳ khi chúng ta ánh xạ một biến liên tục lên thuộc tính thẩm mỹ màu sắc.Một không gian màu khác có thể hạn chế vấn đề của không gian RGB là không gian màu HCL với ba thành phần màu: sắc độ (Hue), độ bão hòa (Chroma) và độ sáng (Luminance):Sắc độ (Hue) nằm trong khoảng từ 0 đến 360 (một góc) và cho biết màu sắc chính muốn hiển thị.Độ bão hòa (Chroma) là “độ tinh khiết” hay đậm của một màu, nằm trong khoảng từ 0 (xám) đến mức tối đa thay đổi theo mức độ đậm.Độ sáng là độ sáng của màu, dao động từ 0 (đen) đến 1 (trắng).Ba chiều có những đặc tính khác nhau. Tương tự như không gian màu Lab, màu sắc trong HCL được sắp xếp xung quanh một hình tròn và không được coi là có trật tự; ví dụ: màu xanh lá cây không lớn hơn hay nhỏ hơn màu đỏ và màu xanh da trời không lớn hơn hay nhỏ hơn màu vàng. Ngược lại, độ bão hòa (đậm nhạt) và độ sáng đều được coi là có trật tự: màu hồng được coi là nằm giữa màu đỏ và trắng, và màu xám được coi là nằm giữa màu đen và trắng. Tạo các thang màu sắc từ không gian HCL thường được dựa trên nguyên tắc cố định 2 tham số và thay đổi tham số còn lại. không gian màu HCL gần với nhận thức màu sắc của con người hơn nên các dải màu được tạo ra sẽ “cách đều” nhau hơn theo cách mà chúng ta nhận thức.Xin được nhắc lại với bạn đọc rằng màu sắc là một chủ đề phức tạp mà phạm vi của nó vượt rất xa những gì mà chúng tôi đề cập ở trên. Bạn đọc nên tham khảo thêm các tài liệu chuyên ngành khoa học máy tính để có thể sử dụng màu sắc một cách hiệu quả nhất.","code":""},{"path":"trực-quan-hóa-dữ-liệu.html","id":"dải-màu-liên-tục","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.5.2.2 Dải màu liên tục","text":"Dải màu liên tục được sử dụng để hiển thị giá trị của một biến liên tục trên bề mặt phẳng. Để kiểm soát màu sắc trong thư viện ggplot2, chúng ta sử dụng các hàm scale_color_(). Lưu ý rằng các thuộc tính thẩm mỹ color và fill có thể được sử dụng song song với đa số các hình dạng đồ họa, đó bất kỳ hàm scale_color_() cũng có hàm scale_fill_() tương ứng.Dải màu liên tục thường được sử dụng cùng với các hàm geom_() có hình dạng đồ họa cần màu sắc để phân biệt trên trên mặt phẳng như geom_polygon(), geom_tile(), geom_raster()), và geom_bin2d(). Mỗi khi chúng ta cho một biến liên tục ánh xạ đến thuộc tính thẩm mỹ màu sắc, thư viện ggplot2 sẽ tự động hiểu rằng chúng ta sử dụng dải màu liên tục để mô tả biến đó.Chúng ta sẽ làm quen với các dải màu liên tục thông qua trực quan hóa hàm mật độ của biến ngẫu nhiên phân phối chuẩn hai chiều với trung bình 0, phương sai 1 và hệ số tương quan \\(\\rho = 0.8\\). Lưu ý rằng hàm mật độ của hai biến ngẫu nhiên phân phối chuẩn \\(\\mathcal{N}(0,1)\\) với hệ số tương quan \\(\\rho = 0.8\\) được tính như sau\n\\[\\begin{align}\nf(x,y) = \\cfrac{1}{2 \\pi \\sqrt{1-\\rho^2}} \\ \\exp \\left(- \\cfrac{x^2 + y^2 - 2\\rho x y}{1-\\rho^2}  \\right)\n\\end{align}\\]Đồ thị hàm mật độ của véc-tơ ngẫu nhiên có phân phối chuẩn hai chiều được lưu trong đối tượng có tên p và được tạo thành từ các đoạn câu lệnh như dưới như dưới đâyPhương pháp đơn giản nhất để kiểm soát ánh xạ thẩm mỹ từ một biến liên tục đến thuộc tính màu sắc là lựa chọn các dải màu liên tục có sẵn trong thư viện ggplot2, hoặc trong các thư viện được cài đặt bổ sung. Các dải màu có sẵn này đều đã được xây dựng để ngay cả những người gặp khó khăn trong phân biệt màu sắc cũng có thể cảm nhận được. Trong Hình 8.32, chúng tôi lựa chọn các dải màu như sau:Dải màu liên tục mặc định của thư viện ggplot2;Dải màu liên tục viridis, được gọi bằng hàm scale_fill_viridis_c();Dải màu liên tục distiller, được gọi bằng hàm scale_fill_distiller();Dải màu liên tục fermenter, được gọi bằng hàm scale_fill_fermenter.Trong mỗi hàm scale_fill_() chúng ta đều sử dụng tham số palette để lựa chọn dải các dải màu sắc có sẵn.\nHình 8.33: Hàm mật độ của véc-tơ ngẫu nhiên phân phối chuẩn hai chiều với hệ số tương quan bằng 0.8. Hình góc trên bên trái: dải màu liên tục mặc định của ggplot2. Hình góc trên bên phải: dải màu viridis với option = ‘’. Hình góc dưới bên trái: dải màu liên tục distiller số 3. Hình góc dưới bên phải: dải màu liên tục fermenter số 2\nĐể dải màu sắc liên tục có tính cá nhân hóa cao hơn, bạn đọc có thể chỉ định thang màu sắc thay vì sử dụng các thang màu có sẵn. Nhóm các hàm scale_*_gradient() là các công cụ mạnh mẽ giúp bạn đọc thực hiện việc này. Bạn đọc cần cung cấp các giá trị màu sắc tương ứng với giá trị bắt đầu của dải màu, giá trị kết thúc của dải màu, và có thể thêm một vài giá trị trung gian, thư viện ggplot2 sẽ nội suy tuyến tính ra các màu sắc thành một dải màu tương ứng với các giá trị mà bạn khai báo. Các hàm số có thể được sử dụng để tạo dải màu liên tục bao gồm có:Hàm scale_fill_gradient() tạo một thang màu liên tục giữa hai màu sắc mà bạn khai báo. Hai tham số được sử dụng để khai báo là giá trị bắt đầu và giá trị kết thúc của dải màu là tham số low và tham số high. Đây cũng chính là cách tạo dải màu liên tục mặc định của thư viện ggplot2; mỗi khi chúng ta sử dụng ánh xạ thẩm mỹ từ một biến liên tục đến thuộc tính màu sắc, thư viện ggplot2 sử dụng dải màu liên tục theo hàm số scale_fill_gradient() với giá trị tham số low là #132B43 và giá trị tham số high là #56B1F7. Không gian nội suy tuyến tính thang màu là luôn luôn là không gian màu Lab.Một hàm số khác cũng được dùng để tạo một dải màu liên tục là scale_fill_gradient2(). Ngoài hai tham số low và high tương ứng với là điểm bắt đầu và điểm kết thúc của thang màu, chúng ta cần khai báo thêm một màu ở giữa bằng tham số mid. Ngoài ra, chúng ta cần khai báo tham số midpoint, là giá trị của biến liên tục tương ứng với màu được khai báo với tham số mid! Nếu không khai báo, tham số midpoint sẽ nhận giá trị mặc định là 0.Hàm scale_fill_gradientn() tạo một thang màu liên tục từ một véc-tơ chứa các màu sắc mà bạn đọc khai báo. Dải màu này bắt đầu từ màu sắc có vị trí đầu tiên trong véc-tơ, đi qua lần lượt các màu sắc được khai báo, và kết thúc ở màu sắc tương ứng với giá trị cuối cùng của véc-tơ.Cách sử dụng các hàm scale_*_gradient() được thể hiện thông qua ví dụ trong Hình 8.34\nHình 8.34: Hàm mật độ của biến ngẫu nhiên phân phối chuẩn hai chiều với hệ số tương quan bằng 0.8. Hình góc trên bên trái: dải màu liên tục mặc định của ggplot2. Hình góc trên bên phải: dải màu liên tục bắt đầu từ xanh da trời (low) và kết thúc tại màu đỏ (high). Hình góc dưới bên trái: dải màu liên tục bắt đầu từ xanh da trời (low) đi qua màu trắng (mid) và kết thúc tại màu đỏ (high). Hình góc dưới bên phải: dải màu liên tục bắt đầu từ xanh lá cây đi qua, màu trắng, màu xanh da trời và kết thúc tại màu vàng.\nCả ba hàm số ở trên đều nội suy tuyến tính trong không gian màu Lab để tạo ra các giải màu liên tục. Khi nói đến nội suy tuyến tính giữa hai màu sắc, sẽ dễ hiểu nếu bạn đọc sử dụng không gian RGB mà tất cả các màu đều nằm trong một hình lập phương với điểm (0,0,0) là màu đen, (1,1,1) là màu trắng. Có thể hiểu nội suy màu sắc một cách đơn giản như sau: mỗi màu sắc hiển thị có ba thành phần là cường độ màu đỏ (r), cường độ màu xanh lá (g) cường độ màu xanh lam (b) … Một dải màu bao gồm \\(n\\) màu, bắt đầu từ màu \\(m_1\\) bao gồm các thành phần \\((r_1, g_1, b_1)\\), đến màu \\(m_n\\) với thành phần \\((r_n, g_n, b_n)\\) sẽ là các màu \\(m_i\\) có các thành phần tương ứng\n\\[\\begin{align}\nr_i = \\left[r_1 + (-1) * \\cfrac{r_n - r_1}{(n-1)} \\right] \\\\\ng_i = \\left[g_1 + (-1) * \\cfrac{g_n - g_1}{(n-1)} \\right] \\\\\nb_i = \\left[b_1 + (-1) * \\cfrac{b_n - b_1}{(n-1)} \\right]\n\\end{align}\\]Nói một cách đơn giản, trong không gian RGB dải màu liên tục sẽ là tất cả các điểm nằm trên đường thẳng nối điểm bắt đầu (low) và điểm kết thúc (high). Đáng tiếc là trong không gian Lab việc nội suy màu sắc không đơn giản như vậy. Việc nội suy dựa trên các tính toán phức tạp và kết quả cuối cùng là các công thức gần đúng. Ưu điểm của nội suy màu sắc trong không gian Lab với không gian RGB sự chuyển đổi màu sắc giữa các điểm mượt mà hơn rất nhiều trong cách nhận biết màu sắc của con người.Hàm số để nội suy một véc-tơ màu rời rạc từ hai màu sắc bất kỳ trên không gian RGB hoặc không gian Lab là hàm colorRampPalette() của thư viện grDevices. Ví dụ, chúng ta có thể sử dụng hàm colorRampPalette() để nội suy các véc-tơ màu bắt đầu từ màu xanh da trời và kết thúc ở màu cam như sau:Để sánh hiệu quả khi nội suy dải màu trên không gian RGB và không gian Lab, chúng ta sẽ sử dụng hai dải màu kể trên mô tả hàm mật độ xác suất của biến phân phối chuẩn hai chiều. các hàm scale_fill_gradient() luôn nội suy trên không gian Lab nên để hiển thị dải màu RGB, chúng ta cần rời rạc hóa giá trị mật độ hàm mật độ trước khi ánh xạ đến dải màu rời rạc được tạo ra từ hàm colorRampPalette()\nHình 8.35: Hàm mật độ của véc-tơ ngẫu nhiên phân phối chuẩn hai chiều với hệ số tương quan bằng 0.8. Hình bên trái: dải màu nội suy trên không gian RGB. Hình bên phải: dải màu nội suy trên không gian Lab\nCả hai đồ thị đều sử dụng dải màu liên tục từ màu xanh da trời đến màu cam để mô tả mật độ của phân phối chuẩn hai chiều có hệ số tương quan \\(\\rho=0.8\\). Bạn đọc có thể thấy rằng việc chuyển hóa màu sắc trên không gian màu Lab ít làm thay đổi độ sáng tối của màu sắc và tự nhiên với mắt quan sát hơn với không gian RGB. Đây là lý tại sao các dải màu liên tục của thư viện ggplot2 mặc định sử dụng không gian Lab để nội suy màu sắc.Các tham số limits, breaks, và label cũng có thể được sử dụng trong các hàm scale_fill_() và scale_color_() để kiểm soát các thang màu liên tục.Tham số limits khi sử dụng cần được gán giá trị là một véc-tơ hai phần tử, phần tử thứ nhất cho biết màu sắc bắt đầu trong thang màu tương ứng với giá trị nào trong biến liên tục và phần tử thứ hai cho biết màu sắc kết thúc của thang màu ứng với giá trị nào của biến liên tục.Các tham số breaks và labels được sử dụng để thay đổi giá trị trên thang màu của chú giải.\nHình 8.36: Hàm mật độ của véc-tơ ngẫu nhiên phân phối chuẩn hai chiều với hệ số tương quan bằng 0.8. Hình bên trái: sử dụng tham số limits trong scale_fill_gradient(). Hình bên phải: sử dụng limits, breaks và labels trong scale_fill_gradient()\nĐồ thị bên trái của Hình 8.36 sử dụng giá trị của tham số limits là từ 0 đến 0.8 trong khi giá trị lớn nhất của hàm mật độ tại tâm ellipse chỉ khoảng 0.3. Màu bắt đầu của dải màu là màu xanh da trời tương ứng với giá trị thứ nhất của tham số limits là 0 và màu kết thúc của dải màu là màu cam tương ứng với giá trị thứ hai của tham số limits là 0.8. Điều này giải thích tại sao cả các giá trị nằm trong tâm của hình ellipse chưa chuyển thành màu cam.Đồ thị bên phải của Hình 8.36 sử dụng tham số limits từ 0 đến 0.3 nên các giá trị càng nằm gần tâm đường ellipse càng chuyển sang màu cam. Tham số breaks thay đổi các vị trí giải thích thang màu trên chú giải của thuộc tính màu sắc, trong khi tham số labels kiểm soát cách hiển thị tại các vị trí trên thang màu.","code":"\n# tạo lưới điểm trên hình vuông [-2,2] * [2-,2]\nn<-100\nx<-rep(1:n,n)/n*4-2\ny<-sort(x, decreasing = FALSE)\nrho<-0.8\ndat0<-data.frame(X=x,Y=y,\n                dens = 1/(2*pi*sqrt(1-rho^2)) *\n                  exp(-(x^2+y^2-2*rho*x*y)/(1-rho^2)))\np<-dat0%>%ggplot(aes(x,y,fill=dens))+geom_raster()+\n  theme_minimal()\np1<-p + scale_fill_continuous()+\n  ggtitle(\"Màu mặc định\") # sử dụng dải màu mặc định\np2<-p + scale_fill_viridis_c(option = \"A\")+ # Dải màu viridis liên tục\n  ggtitle(\"Dải màu viridis\")\np3<-p + scale_fill_distiller(palette = 3)+ # Dải màu distiller\n  ggtitle(\"Dải màu distiller\")\np4<-p + scale_fill_fermenter(palette = 2)+ # Dải màu fermenter\n  ggtitle(\"Dải màu fermenter\")\ngrid.arrange(p1,p2,p3,p4,nrow=2,ncol=2)\np1<-p + ggtitle(\"Màu mặc định\") # sử dụng dải màu mặc định\np2<-p + scale_fill_gradient(low = \"blue\", high = \"red\")+\n  ggtitle(\"Dải màu từ xanh lam đến đỏ\") # sử dụng dải màu từ xanh lam đến đỏ\np3<-p + scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\", midpoint = 0.12)+\n  ggtitle(\"Dải màu từ xanh lam đến đỏ điểm giữa là trắng\")\np4<-p +  scale_fill_gradientn(colours = c(\"#00FF00\",\"#FFFFFF\",\"#0000FF\", \"#FFFF00\"))+\n  ggtitle(\"Dải màu đi qua nhiều điểm màu\")\ngrid.arrange(p1,p2,p3,p4,nrow=2,ncol=2)\nn<-200\nmy_rgb_palette<-colorRampPalette(c(\"blue\", \"orange\"),space = \"rgb\")(n+1)\nmy_lab_palette<-colorRampPalette(c(\"blue\", \"orange\"),space = \"Lab\")(n+1)\nx<-rep(1:n,n)/n*4-2\ny<-sort(x, decreasing = FALSE)\nrho<-0.8\ndat0<-data.frame(x=x,y=y,dens = 1/(2*pi*sqrt(1-rho^2)) * exp(-(x^2+y^2-2*rho*x*y)/(1-rho^2)))\nh<-(max(dat0$dens)-min(dat0$dens))/n\ndat0<-mutate(dat0,dens.d = round((dens - min(dat0$dens))/h))\ndat0$dens.d<-as.factor(dat0$dens.d)\n\nmycol<-colorRampPalette(c(\"blue\", \"orange\"),space = \"rgb\")(n+1)\n\np1<-dat0%>%ggplot(aes(x,y,fill=dens.d))+geom_raster()+theme_minimal()+\n  scale_fill_manual(values= mycol)+\n  theme(legend.position = \"none\")+\n  ggtitle(\"Nội suy trên RGB\")\n\nmycol<-colorRampPalette(c(\"blue\", \"orange\"),space = \"Lab\")(n+1)\np2<-dat0%>%ggplot(aes(x,y,fill=dens.d))+geom_raster()+theme_minimal()+\n  scale_fill_manual(values= mycol)+\n  theme(legend.position = \"none\")+\n  ggtitle(\"Nội suy trên Lab\")\ngrid.arrange(p1,p2,ncol=2,nrow=1)\n# limits cho biết hai giá trị tương ứng với điểm đầu và cuối của dải màu\np1<-p + scale_fill_gradient(low = \"blue\", high = \"orange\",\n                            limits = c(0,0.8))+\n  ggtitle(\"Tham số limits\")\n# breaks cho biết các giá trị nào xuất hiện trên chú giải\n# labels cho biết giá trị hiển thị trong chú giải\np2<-p + scale_fill_gradient(low = \"blue\", high = \"orange\",\n                            limits = c(0,0.3),\n                            breaks = c(0.1,0.15,0.25),\n                            labels = paste(\"Density at\", c(0.1,0.15,0.25)))+\n  ggtitle(\"Tham số breaks và labels\")\ngrid.arrange(p1,p2,nrow=1,ncol=2)"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"dải-màu-rời-rạc","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.5.2.3 Dải màu rời rạc","text":"Dải màu rời rạc dùng để mô tả thuộc tính thẩm mỹ màu sắc khi ánh xạ đến thuộc tính thẩm mỹ này là các biến rời rạc. Hàm số dùng để kiểm soát màu sắc rời rạc khi trực quan hóa dữ liệu bằng thư viện ggplot2 là các hàm scale_fill_discrete() và scale_color_discrete(). Mỗi khi sử dụng các hàm số kể trên, thư viện ggplot2 sẽ mặc định sử dụng dải màu rời rạc cách đều nhau trong không gian màu HCL. Dải màu rời rạc mặc định có cùng độ bão hòa (Chroma), được ký hiệu bằng tham số c, cùng độ sáng (Luminance), được ký bằng tham số l, và khác nhau về sắc độ (Hue), được ký hiệu bằng tham số h. Sắc độ là tham số chính trong ba cấu phần và nhận giá trị từ 0 đến 360 (độ). Sắc độ h của một dải màu rời rạc mặc định luôn cách đều nhau với giá trị ban đầu là 15 (độ).Bạn đọc muốn sử dụng các dải màu rời rạc trong không gian HCL để ánh xạ tới biến rời rạc thì có thể sử dụng các hàm scale_fill_hue() và scale_color_hue() thay thế cho scale_fill_discrete() và scale_color_discrete(). Cách sử dụng các hàm số này được thể hiện qua ví dụ trong Hình 8.37\nHình 8.37: Mô tả phân phối của biến continent trong dữ liệu gapminder lọc theo năm 2011. Hình bên trái: Sử dụng dải màu rời rạc mặc định. Hình ở giữa: sử dụng dải màu rời rạc trong không gian HCL với sắc độ (tham số h) thay đổi. Hình bên phải: sử dụng dải màu rời rạc trong không gian HCL với độ bão hòa (tham số c) thay đổi\nDải màu mặc định đối với biến rời rạc sử dụng tham số c bằng 100 và tham số l bằng 65 trong khi tham số h nhận các giá trị cách đều nhau, bắt đầu từ h = 15 (độ). Lưu ý rằng:h nhận giá trị từ 0 độ đến 360 độ nên trong trong đồ thị ở trên, khi biến continent có năm giá trị, các màu sắc sẽ lần lượt nhận các giá trị với tham số h là \\(15\\), \\(15 + 360/5\\), \\(15 + 2 \\times 360/5\\), \\(15 + 3 \\times 360/5\\) và \\(15 + 4 \\times 360/5\\). Đó là màu sắc của các thanh trong đồ thị bên trái của Hình 8.37 theo thứ tự từ trái qua phải.Trong đồ thị ở giữa, khi chúng ta tăng giá trị ban đầu của h thêm 360/5 (độ), chúng ta có thể thấy các màu sắc bắt đầu từ \\(h = 15 + 360/5\\) và kết thúc ở \\(h = 15\\). Nghĩa là màu sắc trong thanh thứ nhất của đồ thị bên trái đã trở thành màu sắc của thanh thứ năm trong đồ thị ở giữa.Trong đồ thị bên phải, chúng tôi giảm độ chói (tham số c) xuống còn 40. Chúng ta có thể thấy dải màu vẫn tương tự như hai đồ thị còn lại nhưng có sự khác biệt về độ chói.Bạn đọc cũng có thể sử dụng các dải màu rời rạc được thiết kế sẵn trong thư viện ggplot2. Dải màu rời rạc mà chúng tôi thường sử dụng là dải màu brewer. Những dải màu này được thiết kế để hoạt động tốt trong nhiều tình huống khác nhau kể cả đối với những người khó khăn khi nhận biết màu sắc hay khi sử dụng để hiển thị trên những bề mặt lớn. Hàm số để kiểm soát ánh xạ thẩm mỹ màu sắc sử dụng dải màu brewer là scale_color_brewer() và scale_fill_brewer(). Bạn đọc cần cài đặt thư viện RColorBrewer để sử dụng được các hàm này. Để xem các dải màu có sẵn trong thư viện này, bạn đọc sử dụng câu lệnh sauTham số palette trong hàm scale_color_brewer() được sử dụng để lựa chọn dải màu:\nHình 8.38: Mô tả phân phối xác suất của biến continent trong dữ liệu gapminder lọc theo năm 2011 và màu sắc sử dụng là dải màu brewer. Hình bên trái: sử dụng dải màu Dark2. Hình ở giữa: sử dụng dải màu Set1. Hình bên phải: sử dụng dải màu Spectral\nBạn đọc có thể tự tạo ra dải màu rời rạc cho các giá trị của thuộc tính thẩm mỹ màu sắc bằng cách sử dụng các hàm scale_fill_manual() và scale_color_manual(). Tham số values được sử dụng để nhận giá trị là véc-tơ chứa màu sắc mà bạn đọc tự tạo. Số lượng phần tử trong véc-tơ phải tương ứng với số lượng phần tử trong biến rời rạc.Như chúng tôi đã giới thiệu trong phần dải màu sắc liên tục, hàm số colorRampPalette() của thư viện grDevices có thể được sử dụng để nội suy ra một véc-tơ màu rời rạc giữa hai giá trị màu cho trước. Ví dụ, để tạo ra một véc-tơ có độ dài 5, mỗi giá trị là một màu sắc được nội suy tuyến tính từ màu xanh da trời đến màu cam chúng ta viết câu lệnh như sau:Các đồ thị trong Hình 8.39 sử dụng các véc-tơ màu sắc rời rạc tự định nghĩa bằng cách liệt kê các màu sắc trong scale_fill_manual() và bằng nội suy tuyến tính trong không gian RGB và không gian Lab.\nHình 8.39: Mô tả phân phối của biến continent trong dữ liệu gapminder được lọc theo năm 2011 và sử dụng dải màu tự định nghĩa. Hình bên trái: dải màu được tự định nghĩa bằng cách liệt kê tên các màu sắc. Hình ở giữa: nội suy trong không gian RGB giữa xanh da trời và màu cam. Hình bên phải: nội suy trong không gian Lab giữa màu xanh da trời và màu cam\nCách sử dụng tham số limits, breaks, và label trong các hàm scale_fill_manual() và scale_color_manual() cũng tương tự như khi sử dụng đối với dải màu liên tục:Tham số limits cho biết các giá trị nào trong biến rời rạc được ánh xạ tới dải màu sắc.Tham số breaks cho biết các giá trị nào không được sử dụng trong ánh xạ thẩm mỹ.Tham số label cho biết cách các màu sắc hiển thị trong phần chú giải.Sự thật thì tham số breaks không có nhiều ý nghĩa khi sử dụng đối với dải màu sắc rời rạc, trong khi tham số limits có ý nghĩa quan trọng khi bạn đọc cần cố định ánh xạ màu sắc lên biến rời rạc khi vẽ nhiều biểu đồ khác nhau và để kiểm soát thứ tự xuất hiện của biến liên tục trên đồ thị. Hãy quan sát ví dụ sau để thấy sự quan trọng của tham số limits\nHình 8.40: Dân số của ba nước Philippines, Việt Nam, và Indonesia trong top 10 nước đông dân nhất châu Á. Hình bên trái: Dữ liệu năm 1960. Hình bên phải: Dữ liệu năm 2011\nChúng tôi đã sử dụng tham số limits để cố định màu sắc tương ứng với các giá trị của biến rời rạc như trong Hình 8.40. Giá trị biến rời rạc là Philippines được cố định với màu sắc là xanh da trời, Vietnam được cố định với màu đỏ, trong khi Indonesia được cố định với màu vàng. Bạn đọc có thể dễ dàng nhận ra sự thay đổi về thứ hạng về quy mô dân số của ba 3 quốc gia Philippines, Việt Nam, và Indonesia trong nhóm 10 nước có dân số lớn nhất châu Á trong các năm 1960 và 2010.","code":"\np1<-gapminder%>%filter(year==2011)%>%\n  ggplot(aes(continent,fill=continent))+\n  geom_bar()+ggtitle(\"Màu rời rạc mặc định\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")\np2<-gapminder%>%filter(year==2011)%>%\n  ggplot(aes(continent,fill=continent))+geom_bar()+\n  scale_fill_hue(h=c(0,360)+15+360/5)+\n  ggtitle(\"Thay đổi tham số h\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")\np3<-gapminder%>%filter(year==2011)%>%\n  ggplot(aes(continent,fill=continent))+geom_bar()+\n  scale_fill_hue(c=30)+ggtitle(\"Thay đổi tham số c\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")\ngrid.arrange(p1,p2,p3,nrow=1,ncol=3)\ndisplay.brewer.all()\np1<-gapminder%>%filter(year==2011)%>%\n  ggplot(aes(continent,fill=continent))+geom_bar()+\n  scale_fill_brewer(palette = \"Dark2\")+\n  ggtitle(\"Sử dụng dải màu Dark2\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")\np2<-gapminder%>%filter(year==2011)%>%\n  ggplot(aes(continent,fill=continent))+geom_bar()+\n  scale_fill_brewer(palette = \"Set1\")+\n  ggtitle(\"Sử dụng dải màu Set1\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")\np3<-gapminder%>%filter(year==2011)%>%\n  ggplot(aes(continent,fill=continent))+geom_bar()+\n  scale_fill_brewer(palette = \"Spectral\")+\n  ggtitle(\"Sử dụng dải màu Spectral\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")\ngrid.arrange(p1,p2,p3,nrow=1,ncol=3)\n# nội suy trong RGB\nmypalette1<-colorRampPalette(c(\"blue\",\"orange\"), space = \"rgb\")(5)\n# nội suy trong Lab\nmypalette2<-colorRampPalette(c(\"blue\",\"orange\"), space = \"Lab\")(5)\np1<-gapminder%>%filter(year==2011)%>%\n  ggplot(aes(continent,fill=continent))+geom_bar()+\n  scale_fill_manual(values = c(\"blue\",\"green\",\"grey\",\"yellow\",\"orange\"))+\n  ggtitle(\"Màu tự định nghĩa\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")\np2<-gapminder%>%filter(year==2011)%>%\n  ggplot(aes(continent,fill=continent))+geom_bar()+\n  scale_fill_manual(values = mypalette1)+\n  ggtitle(\"Màu nội suy trong RGB\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")\np3<-gapminder%>%filter(year==2011)%>%\n  ggplot(aes(continent,fill=continent))+geom_bar()+\n  scale_fill_manual(values = mypalette2)+\n  ggtitle(\"Màu nội suy trong Lab\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")\ngrid.arrange(p1,p2,p3,nrow=1,ncol=3)\np1<-gapminder%>%filter(year==1960, continent == \"Asia\")%>%\n  arrange(-population)%>%head(10)%>%\n  ggplot(aes(fill=country))+\n  geom_bar(aes(x = population, y = reorder(country,population)),\n           stat=\"identity\",col=\"darkblue\", alpha = 0.7)+\n  ylab(\"\")+ggtitle(\"Năm 1960\")+theme_minimal()+\n  theme(legend.position = \"top\")+\n  scale_x_continuous(labels = scales::comma)+\n  scale_fill_manual(values = c(\"blue\",\"red\",\"yellow\"), limits = c(\"Philippines\",\"Vietnam\", \"Indonesia\"))\np2<-gapminder%>%filter(year==2011, continent == \"Asia\")%>%\n  arrange(-population)%>%head(10)%>%\n  ggplot(aes(fill=country))+\n  geom_bar(aes(x = population, y = reorder(country,population)),\n           stat=\"identity\",col=\"darkblue\", alpha = 0.7)+\n  ylab(\"\")+ggtitle(\"Năm 2010\")+theme_minimal()+theme(legend.position = \"top\")+\n  scale_x_continuous(labels = scales::comma)+\n  scale_fill_manual(values = c(\"blue\",\"red\",\"yellow\"), limits = c(\"Philippines\",\"Vietnam\", \"Indonesia\"))\n\ngrid.arrange(p1,p2,nrow=1,ncol=2)"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"các-thuộc-tính-thẩm-mỹ-khác","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.5.3 Các thuộc tính thẩm mỹ khác","text":"Ngoài vị trí trên các trục tọa độ và màu sắc, còn có một số thuộc tính thẩm mỹ khác mà thư viện ggplot2 có thể sử dụng để mô tả trực quan dữ liệu. Trong phần này, chúng ta sẽ xem xét thuộc tính kích thước (size), hình dạng (shape), chiều rộng của line (linewidth) và kiểu line (linetype) khi sử dụng cùng với các thuộc tính vị trí trên trục tọa độ và màu sắc để trực quan một cách hiệu quả nhất các biến trong dữ liệu. Ngoài đề cập đến các giá trị mặc định, chúng tôi cũng sẽ thảo luận về các hàm số thuộc nhóm scale_() tương ứng với các thuộc tính thẩm mỹ để bạn đọc có thể sử dụng để kiểm soát tốt các thuộc tính này.","code":""},{"path":"trực-quan-hóa-dữ-liệu.html","id":"thuộc-tính-thẩm-mỹ-kích-thước","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.5.3.1 Thuộc tính thẩm mỹ kích thước","text":"Thuộc tính thẩm mỹ kích thước (size) thường được sử dụng để mô tả hình dạng đồ họa kiểu điểm hoặc ký tự. Như chúng tôi đã đề cập trong phần giới thiệu, thuộc tính kích thước cho hiệu quả tốt nhất khi được ánh xạ từ các biến liên tục. Nếu không có hàm kiểm soát ánh xạ thẩm mỹ, bán kính của điểm tương ứng với giá trị nhỏ nhất luôn là 1 và bán kính của điểm có giá trị lớn nhất luôn là 6, nghĩa là có bán kính gấp 6 lần bán kính của điểm nhỏ nhất. Khi nội suy ra kích thước của các điểm khác, thư viện ggplot2 mặc định cho kích thước của điểm là diện tích của hình tròn mô tả điểm đó chứ không phải bán kính của hình tròn. Hơn thế nữa, kích thước của điểm sẽ phụ thuộc vào thứ hạng (rank) của giá trị đó trong biến liên tục chứ không được tính bằng giá trị thực của điểm đó. Thực vậy, nếu \\(area_m\\) là diện tích của hình tròn tương ứng với giá trị nhỏ nhất và \\(area_M\\) tương ứng với diện tích của hình tròn tương ứng với giá trị lớn nhất thì diện tích của hình tròn tương ứng với giá trị có thứ hạng \\(k\\) trong tổng số \\(n\\) giá trị của biến liên tục là\n\\[\\begin{align}\narea = area_m + (k-1) \\times \\cfrac{area_M - area_m}{n - 1}\n\\end{align}\\]Để hiểu về cách thư viện ggplot2 ánh xạ kích thước đến giá trị các biến, bạn đọc có thể quan sát kích thước của các hình tròn trong Hình 8.41\nHình 8.41: Ánh xạ véc-tơ số tự nhiên đến thuộc tính thẩm mỹ kích thước. Hình bên trái: ánh xạ các số 1, 2, 3 đến kích thước ba hình tròn. Hình ở giữa: ánh xạ bình phương của 1, 2, 3 đến kích thước các hình tròn. Hình bên phải: ánh xạ hai số 2 và 3 đến kích thước của hai hình tròn.\nTừ Hình 8.41 chúng ta có thể thấy rằng:Trong đồ thị bên trái: kích thước của các hình tròn ở các tọa độ (1,1), (2,2), và (3,3) được ánh xạ đến các giá trị số lần lượt là 1, 2, và 3. Tham số mặc định của các hàm scale_size_() là range = c(1,6) nên hình tròn tại vị trí tọa độ (1,1) có bán kính là 1 trong khi hình tròn ở vị trí tọa độ (3,3) có bán kính là 6. Diện tích của hình tròn nằm ở tọa độ (2,2) được nội suy theo diện tích của hai hình tròn tại tọa độ (1,1) và (3,3) bằng trung bình cộng diện tích của hình tròn nằm ở vị trí (1,1) và (3,3). diện tích của hình tròn nằm ở vị trí (3,3) bằng \\(6^2 = 36\\) lần diện tích của hình tròn tại vị trí \\((1,1)\\) nên diện tích của hình tròn tại (2,2) bằng \\(\\cfrac{36+1}{2} = 18,5 \\textit{(lần)}\\) diện tích hình tròn tại tọa độ (1,1), hay nói cách khác bán kính của hình tròn tại vị trí (2,2) bằng \\(\\sqrt{18,5} \\sim 4,3 \\text{ (lần)}\\) bán kính của hình tròn tại vị trí (1,1).Đồ thị ở giữa: chúng ta ánh xạ thuộc tính thẩm mỹ kích thước với \\(z^2\\), nghĩa là các giá trị thực của biến được ánh xạ đến thuộc tính kích thước là \\(1^2\\), \\(2^2\\), và \\(3^2\\). Tuy nhiên, kích thước các hình tròn xuất hiện vẫn không hề thay đổi với hình bên trái. Giống như chúng ta đã thảo luận, thư viện ggplot2 sử dụng thứ hạng của các giá trị trong véc-tơ số chứ không sử dụng giá trị thực. Thứ hạng của \\(1^2\\), \\(2^2\\), và \\(3^2\\) vẫn là 1, 2, và 3, đồng thời hình tròn nhỏ nhất vẫn có bán kính bằng 1 và đường tròn lớn nhất vẫn có bán kính bằng 6. Kết quả là kích thước của các hình xuất hiện vẫn không thay đổi.Đồ thị bên phải: khi chúng ta chỉ trực quan hai điểm tại vị trí (2,2) và (3,3) và thuộc tính thẩm mỹ kích thước được ánh xạ vào hai giá trị là 2 và 3; có thể thấy rằng diện tích hình tròn nhỏ nhất và diện tích hình tròn lớn nhất vẫn không thay đổi.Hàm số dùng để kiểm soát giá trị của ánh xạ thẩm mỹ kích thước là hàm scale_size(). Để thay đổi miền giá trị của thuộc tính kích thước, chúng ta sử dụng tham số range.\nHình 8.42: Ánh xạ các số tự nhiên đến thuộc tính thẩm mỹ kích thước. Hình bên trái: ánh xạ các số 1, 2, 3 đến kích thước ba hình tròn. Hình bên phải: sử dụng scale_size để hình nhỏ nhất có bán kính bằng 6 và hình lớn nhất có bán kính bằng 12.\nHình 8.42 mô tả cách sử dụng tham số range trong hàm scale_size().Đồ thị bên trái: bán kính của hình tròn nhỏ nhất là 1, bán kính của hình tròn lớn nhất là 6.Đồ thị bên trái: bán kính của hình tròn nhỏ nhất là 1, bán kính của hình tròn lớn nhất là 6.Đồ thị bên phải: bán kính của hình nhỏ nhất là 6 bằng với kích thước của hình lớn nhất của đồ thị bên trái. Trong khi đó, bán kính của hình tròn lớn nhất là 12. Mặc dù khi khai báo tham số range được hiểu là bán kính của các hình, nhưng khi nội suy kích thước, hình tròn ở tọa độ (2,2) lại được nội suy theo diện tích, chứ không phải theo bán kính.Đồ thị bên phải: bán kính của hình nhỏ nhất là 6 bằng với kích thước của hình lớn nhất của đồ thị bên trái. Trong khi đó, bán kính của hình tròn lớn nhất là 12. Mặc dù khi khai báo tham số range được hiểu là bán kính của các hình, nhưng khi nội suy kích thước, hình tròn ở tọa độ (2,2) lại được nội suy theo diện tích, chứ không phải theo bán kính.Trong trường hợp bạn đọc muốn sử dụng nội suy kích thước theo bán kính thay vì nội suy theo diện tích, hàm scale_radius() thay thế cho scale_size(). Hình 8.43 mô tả sự khác nhau khi sử dụng scale_size() và scale_radius():\nHình 8.43: Sự khác nhau giữa scale_size() và scale_radius(). Hình bên trái: sử dụng scale_size() với range = c(1,7). Hình ở giữa: sử dụng scale_radius() với range = c(1,7). Hình bên phải: sử dụng scale_radius() với range = c(4,10)\nĐồ thị bên trái sử dụng scale theo diện tích và bán kính hình tròn lớn nhất bằng 7 lần đường tròn nhỏ; hình tròn ở giữa có bán kính bằng \\(\\sqrt{\\cfrac{7^2+1^2}{2}} = 5 \\text{ (lần)}\\) bán kính hình tròn nhỏ nhất.Đồ thị ở giữa, scale theo bán kính hình tròn nên hình ở giữa có bán kính bằng \\(\\cfrac{7+1}{2} = 4 \\textit{ (lần)}\\) bán kính hình tròn nhỏ. Bạn đọc có thể thấy rằng kích thước của hình tròn ở vị trí tọa độ (2,2) trong đồ thị ở giữa nhỏ hơn hình tròn ở vị trí tọa độ (2,2) trong hình bên trái.Trong đồ thị bên phải, bán kính của hình nhỏ nhất là 4, của hình tròn lớn nhất là 10, nên bán kính hình ở giữa là \\(\\cfrac{4+10}{2} = 7\\) nội suy bằng hàm scale_radius(). Bạn đọc có thể thấy rằng kích thước của hình ở vị trí (2,2) của đồ thị này bằng với kích thước của hình tròn ở vị trí (3,3) của hình ở giữa.Các tham số limits, breaks, và label được sử dụng tương tự như khi sử dụng với thuộc tính thẩm mỹ màu sắc:Tham số limits cho biết miền giá trị nào của biến được ánh xạ đến thuộc tính thẩm mỹ size.Tham số breaks cho biết các giá trị nào của kích thước nào xuất hiện trên chú giải về cấu phần thẩm mỹ kích thước.Tham số labels mô tả thuộc tính thẩm mỹ kích thước trên chú giải của đồ thị.Bạn đọc tham khảo cách sử dụng các tham số này trong ví dụ dưới đây khi mô tả hai biến liên tục là tỷ lệ trẻ sơ sinh tử vong và tuổi thọ trung bình bằng đồ thị phân tán và ánh xạ biến dân số vào kích thước của các điểm\nHình 8.44: Tỷ lệ trẻ sơ sinh tử vong và tuổi thọ trung bình của các quốc gia trên thế giới năm 2011\nÁnh xạ thẩm mỹ từ biến dân số đến thuộc tính thẩm mỹ kích thước của các điểm được điều chỉnh bằng hàm scale_size() như sau:Tham số range = c(1,12) cho biết bán kính của hình tròn tương ứng với nước có dân số nhỏ nhất bằng 1 và bán kính của hình tròn tương ứng với nước có dân số lớn nhất là 12.Tham số limits cho biết chỉ các nước có dân số 10 triệu trở lên được đưa vào trong đồ thị.Tham số breaks cho biết các giá trị xuất hiện trên chú giải là các giá trị 100 triệu, 200 triệu, 500 triệu và 1 tỷ.Tham số labels cho biết các số viết trên chú giải sử dụng cách viết giá trị lên chú giải là theo đơn vị triệu.","code":"\ndat0<-data.frame(x=1:3,y=1:3,z=1:3)\n# Hình bên trái\np1<-dat0%>%ggplot(aes(x,y,size=z))+\n  geom_point(shape=21,fill= \"#640514\", alpha = 0.7, color = \"darkblue\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  scale_x_continuous(limits = c(0.9,3.1))+\n  scale_y_continuous(limits = c(0.9,3.1))\n# Hình ở giữa\np2<-dat0%>%ggplot(aes(x,y,size=z^2))+\n  geom_point(shape=21,fill= \"#640514\", alpha = 0.7, color = \"darkblue\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  scale_x_continuous(limits = c(0.9,3.1))+\n  scale_y_continuous(limits = c(0.9,3.1))\n# Hình bên phải\np3<-dat0%>%filter(z>1)%>%ggplot(aes(x,y,size=z))+\n  geom_point(shape=21,fill= \"#640514\", alpha = 0.7, color = \"darkblue\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  scale_x_continuous(limits = c(0.9,3.1))+\n  scale_y_continuous(limits = c(0.9,3.1))\ngrid.arrange(p1,p2,p3,ncol=3,nrow=1)\ndat0<-data.frame(x=1:3,y=1:3,z=1:3)\n# Hình bên trái\np1<-dat0%>%ggplot(aes(x,y,size=z))+\n  geom_point(shape=21,fill= \"#640514\", alpha = 0.7, color = \"darkblue\")+\n  theme(legend.position = \"none\")+\n  scale_x_continuous(limits = c(0.9,3.25))+\n  scale_y_continuous(limits = c(0.9,3.25))+\n  theme_minimal()+ggtitle(\"Không sử dụng scale_size\")\n# Hình bên phải\np2<-dat0%>%ggplot(aes(x,y,size=z))+\n  geom_point(shape=21,fill= \"#640514\", alpha = 0.7, color = \"darkblue\")+\n  scale_size(range=c(6,12))+\n  theme(legend.position = \"none\")+\n  scale_x_continuous(limits = c(0.9,3.25))+\n  scale_y_continuous(limits = c(0.9,3.25))+\n  theme_minimal()+ggtitle(\"Sử dụng scale_size với range = (6,12)\")\ngrid.arrange(p1,p2,ncol=2,nrow=1)\ndat0<-data.frame(x=1:3,y=1:3,z=1:3)\n# Hình bên trái\np1<-dat0%>%ggplot(aes(x,y,size=z))+\n  geom_point(shape=21,fill= \"#640514\", alpha = 0.7, color = \"darkblue\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  scale_x_continuous(limits = c(0.9,3.1))+\n  scale_y_continuous(limits = c(0.9,3.1))+\n  scale_size(range = c(1,7))\n\np2<-dat0%>%ggplot(aes(x,y,size=z))+\n  geom_point(shape=21,fill= \"#640514\", alpha = 0.7, color = \"darkblue\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  scale_x_continuous(limits = c(0.9,3.1))+\n  scale_y_continuous(limits = c(0.9,3.1))+\n  scale_radius(range=c(1,7))\n# Hình bên phải\np3<-dat0%>%ggplot(aes(x,y,size=z))+\n  geom_point(shape=21,fill= \"#640514\", alpha = 0.7, color = \"darkblue\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  scale_x_continuous(limits = c(0.9,3.1))+\n  scale_y_continuous(limits = c(0.9,3.1))+\n  theme(legend.position = \"none\")+\n  scale_radius(range=c(4,10))\ngrid.arrange(p1,p2,p3,ncol=3,nrow=1)\ndat%>%\n  ggplot(aes(infant_mortality,life_expectancy, size = population))+\n  geom_point(shape=21,fill= \"#640514\", alpha = 0.5, color = \"darkblue\")+\n  theme_minimal()+\n  scale_size(range = c(1,12),\n             limits = c(10^7,max(gapminder$population)),\n             breaks = c(10^8,2*10^8,5*10^8,10^9),\n             labels = c(paste(c(10^8,2*10^8,5*10^8)/10^6,\"triệu\"), \"Một tỷ\"))"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"thuộc-tính-thẩm-mỹ-hình-dạng","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.5.3.2 Thuộc tính thẩm mỹ hình dạng","text":"Thuộc tính thẩm mỹ hình dạng được sử dụng trong các đồ thị trực quan để mô tả một hoặc một vài biến rời rạc với điều kiện biến này không có quá nhiều giá trị riêng biệt. Theo kinh nghiệm của chúng tôi thì hình dạng chỉ nên sử dụng với các biến có nhỏ hơn năm giá trị riêng biệt. Mặc dù thư viện ggplot2 cho phép sử dụng lên đến 25 hình dạng khác nhau, nhưng sử dụng nhiều hơn hoặc bằng năm hình dạng trong một đồ thị sẽ làm cho đồ thị trở nên rắc rối và khó khăn khi nhận diện. Tại phiên bản ggplot2 mà chúng tôi đang sử dụng, có 25 hình dạng khác nhau có thể dùng để mô tả biến rời rạc. Các hình dạng này được sử dụng bằng cách ánh xạ thẩm mỹ một biến rời rạc đến thuộc tính shape hoặc thiết lập tham số cho shape tương ứng với 25 số tự nhiên từ 1 đến 25 được mô tả trong Hình 8.45\nHình 8.45: Các hình dạng có thể được sử dụng trong trực quan hóa dữ liệu của thư viện ggplot2\nBạn đọc cần lưu ý rằng có một số hình dạng trông giống nhau nhưng lại có thuộc tính thẩm mỹ khác nhau. Chẳng hạn như hình dạng tương ứng với số 1 là một điểm hình tròn với thuộc tính thẩm mỹ color là màu sắc của toàn bộ hình tròn đó, trong khi hình dạng tương ứng với số 21 có thuộc tính thẩm mỹ color là màu viền bên ngoài của hình tròn và thuộc tính thẩm mỹ fill mới là màu sắc bên trong hình tròn.Để kiểm soát ánh xạ thẩm mỹ đến thuộc tính hình dạng, bạn đọc sử dụng hàm scale_shape_manual(). Bạn đọc có thể tham khảo cách sử dụng hàm này thông qua ví dụ dưới đây:\nHình 8.46: Thu nhập bình quân đầu người và tuổi thọ trung bình của các quốc gia châu Á vào năm 2011\nTham số được sử dụng để gán giá trị cho biến rời rạc đến hình dạng cụ thể là tham số values. Nhìn chung, ánh xạ biến rời rạc đến thuộc tính thẩm mỹ hình dạng chỉ cho hiệu quả tốt khi dữ liệu không có quá nhiều quan sát và số lượng giá trị riêng biệt của biến rời rạc là nhỏ. Trong trường hợp dữ liệu có nhiều quan sát và biến rời rạc nhận nhiều hơn năm giá trị khác nhau, bạn đọc nên thận trọng khi sử dụng thuộc tính thẩm mỹ này!","code":"\ngapminder%>%filter(year==2011, continent == \"Asia\")%>%\n  ggplot(aes(gdp/population,life_expectancy, shape = region))+\n  geom_point(color = \"#640514\")+\n  scale_x_continuous(trans=\"log10\")+\n  scale_shape_manual(values=c(21:24,8) )+\n  theme_minimal()"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"kích-thước-và-hình-dạng-của-các-đường","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.5.3.3 Kích thước và hình dạng của các đường","text":"Đối với hình dạng đồ họa là các đường được vẽ bằng các hàm như geom_line(), geom_path() hay geom_segment(), chúng ta có thể ánh xạ các biến rời rạc vào độ rộng hoặc hình dạng của đường. Hình dạng và kích thước của các đường được sử dụng tương đương như hình dạng và kích thước của các điểm nên không có nhiều kiến thức mới cần thảo luận trong phần này.Hình 8.47 mô tả sự thay đổi của biến tổng thu nhập quốc dân (gdp) của ba quốc gia bao gồm Mỹ, Trung Quốc và Nhật Bản theo thời gian từ năm 1960 đến năm 2011 sử dụng dữ liệu gapminder. Các đường mô tả được phân biệt bằng cách sử dụng ba kiểu đường khác nhau:\nHình 8.47: Tổng thu nhập quốc dân của Mỹ, Trung Quốc, và Nhật Bản từ năm 1960 đến 2011\nHàm số dùng để kiểm soát ánh xạ thẩm mỹ vào hình dạng của các đường là scale_linetype_manual(). Thư viện ggplot2 có 13 hình dạng cho các đường được đánh số từ 1 đến 13 như Hình 8.48 dưới đây\nHình 8.48: Hình dạng của các đường có thể sử dụng để trực quan hóa dữ liệu trong thư viện ggplot2\nĐể các đường có hình dạng như mong muốn, chúng ta gán giá trị tham số values trong hàm scale_linetype_manual() cho một véc-tơ chứa các số nhận giá trị từ 1 đến 13 tương ứng với hình dạng mà bạn lựa chọn như sau\nHình 8.49: Tổng thu nhập quốc dân của Mỹ, Trung Quốc, và Nhật Bản từ năm 1960 đến 2011\n","code":"\ngapminder%>%filter(country %in% c(\"United States\", \"China\", \"Japan\"), year <= 2011)%>%\n  ggplot(aes(x = year,y = gdp/10^9))+\n  geom_line(aes(linetype = country), color = \"#640514\")+\n  theme_minimal()+\n  ylab(\"GDP in Billion USD\")+\n  scale_x_continuous(breaks = seq(1960,2010,10))+\n  scale_y_continuous(labels = scales::label_comma())\ngapminder%>%filter(country %in%\n                     c(\"United States\", \"China\", \"Japan\"), year <= 2011)%>%\n  ggplot(aes(x = year,y = gdp/10^9))+\n  geom_line(aes(linetype = country),\n            color = \"#640514\")+\n  theme_minimal()+\n  ylab(\"GDP in $B\")+\n  scale_x_continuous(breaks = seq(1960,2010,10))+\n  scale_y_continuous(labels = scales::label_comma())+\n  scale_linetype_manual(values = c(4,7,12))"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"tùy-chỉnh-chú-giải-của-ánh-xạ-thẩm-mỹ","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.6 Tùy chỉnh chú giải của ánh xạ thẩm mỹ","text":"Về mặt hình thức, nếu coi các hàm scale_() như các ánh xạ từ tập hợp các giá trị của biến đến tập hợp các giá trị của thuộc tính thẩm mỹ thì chú giải là ánh xạ ngược từ thuộc tính thẩm mỹ đến miền giá trị của biến. Chú giải cho phép bạn chuyển đổi các thuộc tính trực quan trở lại giá trị của dữ liệu. Giá trị xuất hiện trên các trục tọa độ và các chú giải có cách hiển thị khác nhau nhưng về bản chất lại có cùng một mục đích là cho phép người tiếp nhận quan sát các hình ảnh đồ họa trực quan và ánh xạ chúng trở lại giá trị của dữ liệu. Các cấu phần khác nhau của chú giải được mô tả trong Hình 8.50\nHình 8.50: Các thành phần và tên gọi của chú giải\nChú giải có khả năng giải thích tốt hơn giá trị xuất hiện trên các trục tọa độ bởi các nguyên nhân sauChú giải có thể giải thích nhiều biến cùng lúc trong khi giá trị trên trục tọa độ chỉ cho phép một biến.Chú giải có thể giải thích nhiều biến cùng lúc trong khi giá trị trên trục tọa độ chỉ cho phép một biến.Chú giải có thể tùy biến dễ hơn: có thể xuất hiện ở các vị trí theo ý muốn của người xây dựng đồ thị, có thể xuất hiện theo bất kỳ hướng nào.Chú giải có thể tùy biến dễ hơn: có thể xuất hiện ở các vị trí theo ý muốn của người xây dựng đồ thị, có thể xuất hiện theo bất kỳ hướng nào.Bạn đọc hãy lưu ý rằng dù chúng ta không gọi bất kỳ hàm scale_() nào trong các câu lệnh thì mỗi khi vẽ đồ thị, thư viện ggplot2 vẫn luôn luôn sử dụng một nhóm hàm scale_() mặc định để ánh xạ từ các biến đến các thuộc tính thẩm mỹ của đồ thị trực quan. Mỗi khi bạn đọc gọi hàm scale_() để kiểm soát ánh xạ thẩm mỹ, các giá trị mà bạn khai báo sẽ thay thế cho các giá trị mặc định. Trong trường hợp bạn gọi nhiều hàm scale_() cùng tác động đến một thuộc tính thẩm mỹ thì chỉ có hàm scale_() được gọi ra sau cùng được sử dụng. Hãy quan sát ví dụ dưới đây:\nHình 8.51: Thu nhập bình quân đầu người của các quốc gia Đông Nam Á năm 2011\nĐồ thị trực quan trong Hình 8.51 được vẽ bằng các câu lệnh gọi hàm scale_x_continuous() lặp lại hai (2) lần và hàm scale_y_continuous() lặp lại ba (3) lần. Quan sát kết quả, bạn đọc có thể thấy rằng chỉ có câu lệnh sau cùng được chấp nhận. Ngoài ra, khi thực thi đoạn lệnh ở trên, thư viện ggplot2 cũng sẽ đưa ra các cảnh báo về các hàm scale_() đã xuất hiện và sẽ bị thay thế bằng các hàm cùng tên.Để kiểm soát chú giải của các ánh xạ thẩm mỹ, bạn đọc sử dụng tham số guide trong các hàm scale_() tương ứng. Giá trị gán cho tham số guide là một trong các hàm số sau đây:Hàm guide_axis() là hàm số dùng để gán cho tham số guide khi chúng ta sử dụng các hàm scale_() nhằm kiểm soát ánh xạ thẩm mỹ đến các trục tọa độ.\nHình 8.52: Thu nhập bình quân đầu người của các quốc gia Tây Âu năm 2011. Hàm guide_axis() được sử dụng để kiểm soát chú giải cho các trục tọa độ x và y\nBạn đọc có thể thấy rằng tham số title trong hàm guide_axis() đã thay thế cho tham số name trong các hàm scale_x_discrete() và scale_y_discrete(). Tham số angle cho biết hướng các giá trị xuất hiện trên trục tọa độ. Trong Hình 8.52, tên các quốc gia trên trục tọa độ x đã được xoay một góc 90 độ. Bạn đọc tham khảo hướng dẫn sử dụng hàm guide_axis() để hiểu về các tham số khác như n.dodge, order, hay position.Hàm guide_legend() là hàm số dùng để gán cho tham số guide khi gọi các hàm scale_() kiểm soát ánh xạ từ các biến rời rạc đến màu sắc. Có rất nhiều tham số có thể sử dụng trong hàm số này. Bạn đọc tham khảo hướng dẫn sử dụng hàm để biết đầy đủ các tham số.\nHình 8.53: Thu nhập bình quân đầu người của các quốc gia Nam Mỹ năm 2011. Hàm guide_legend được sử dụng để kiểm soát chú giải cho ánh xạ thẩm mỹ màu sắc\nTương tự như hàm guide_legend(), hàm guide_colorbar() được sử dụng khi chú giải cho các ánh xạ từ biến liên tục đến dải màu liên tụcHàm guide_bin() được dùng khi chú giải cho các ánh xạ từ biến liên tục đến thuộc tính thẩm mỹ kích thước (size).","code":"\np<-gapminder%>%filter(year==2011,region==\"South-Eastern Asia\")%>%\n  mutate(gdp_per_capita = gdp/population)%>%\n  ggplot(aes(reorder(country,gdp_per_capita),\n             gdp_per_capita,fill = country))+\n  geom_bar(stat=\"identity\")+\n  theme_minimal()\np+theme(legend.position = \"none\")+\n  scale_y_continuous(name = \"Thu nhập bình quân đầu người\",\n                     labels = scales::label_comma())+\n  scale_x_discrete(name = \"Country\")+\n  scale_y_continuous(trans = \"sqrt\")+\n  scale_x_discrete(name = \"Quốc gia\", labels = c(\n    \"Vietnam\" = \"VN\",\n    \"Thailand\" = \"TL\",\n    \"Timor-Leste\" = \"Đông Timor\"))+\n  scale_y_continuous(name = \"Thu nhập bình quân đầu người\",\n                     labels = scales::label_dollar())\ngapminder%>%filter(year==2011,region==\"Western Europe\")%>%\n  mutate(gdp_per_capita = gdp/population)%>%\n  filter(!is.na(gdp_per_capita))%>%\n  ggplot(aes(reorder(country,gdp_per_capita),gdp_per_capita,fill = country))+\n  geom_bar(stat=\"identity\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  scale_x_discrete(name = \"Country\",\n                   guide = guide_axis(title = \"Quốc gia\",\n                                      angle = 90))+\n  scale_y_continuous(name = \"GDP per capita\",\n                     labels = scales::label_dollar(),\n                     guide = guide_axis(title = \"Thu nhập bình quân đầu người\"))\ngapminder%>%filter(year==2011,region==\"South America\")%>%\n  mutate(gdp_per_capita = gdp/population)%>%\n  filter(!is.na(gdp_per_capita))%>%\n  ggplot(aes(reorder(country,gdp_per_capita),gdp_per_capita,fill = country))+\n  geom_bar(stat=\"identity\")+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  scale_x_discrete(guide = guide_axis(title = \"Quốc gia\",angle = 90))+\n  scale_y_continuous(labels = scales::label_dollar(),\n                     guide = guide_axis(title = \"Thu nhập bình quân đầu người\"))+\n  scale_fill_brewer(palette = \"Paired\",\n                    guide = guide_legend(title = \"Quốc gia\",\n                                         title.position = \"top\",ncol = 2))"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"chủ-đề-và-ngữ-cảnh-của-đồ-thị","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.7 Chủ đề và ngữ cảnh của đồ thị","text":"Ngữ cảnh cho phép bạn đọc kiểm soát tốt các cấu phần không ánh xạ đến dữ liệu trong đồ thị như phông chữ, hình nền, vị trí chú giải, … Sự phân tách giữa các thành các phần có ánh xạ đến dữ liệu và thành phần không ánh xạ đến dữ liệu trong các đồ thị trực quan của thư viện ggplot2 là điểm khác biệt với đồ họa cơ sở. Trong đồ họa cơ sở hầu hết các hàm đều có một số lượng lớn các tham số số chỉ định đồng thời cho dữ liệu và cho cả phần không liên quan đến dữ liệu, điều này làm cho các hàm trong đồ thị cơ sở của R trở nên phức tạp và khó kiểm soát. Thư viện ggplot2 tiếp cận theo cách khác: khi tạo đồ thị, bạn xác định cách hiển thị dữ liệu trước, sau đó bạn có thể chỉnh sửa mọi chi tiết không liên quan đến dữ liệu bằng các hàm kiểm soát chủ đề và ngữ cảnh. Để kiểm soát chủ đề và ngữ cảnh của đồ thị, bạn đọc cần nắm vững các nội dung sau:Các chủ đề và ngữ cảnh đã được hoàn chỉnh và sẵn có trong thư viện ggplot2 và trong các thư viện cài đặt bổ sung, chẳng hạn như ggthemes.Cách kiểm soát các thành phần của chủ đề và ngữ cảnh như: tiêu đề của đồ thị (kiểu chữ, kích thước, vị trí), cách hiển thị các số trên các trục, cách hiển thị các hình dạng đồ họa trên chú giải, kiểu chữ, kích thước hay vị trí của chú giải…Kiểm soát các tùy biến của các hàm dùng để gán giá trị cho các thành phần của chủ đề. Ví dụ như hàm element_text() có thể dùng để chỉnh kích thước phông chữ, màu sắc và giao diện của các thành phần văn bản.Cách sử dụng hàm theme() với một danh sách dài các tùy biến cho phép bạn sao chép lên các thành phần của chủ đề và ngữ cảnh mặc định.","code":""},{"path":"trực-quan-hóa-dữ-liệu.html","id":"tạo-đồ-thị-tương-tác-và-đồ-thị-động-với-r","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.8 Tạo đồ thị tương tác và đồ thị động với R","text":"Các đồ thị trực quan được vẽ bằng các câu lệnh của thư viện ggplot2 đều là các đồ thị tĩnh. Như chúng tôi đã đề cập trong phần giới thiệu, thư viện ggplot2 không có tính năng vẽ các đồ thị dạng động và các đồ thị tương tác. Tuy nhiên, trong yêu cầu của trực quan hóa dữ liệu nói chung, các đồ thị động và đồ thị tương tác luôn có vị trí nhất định. Các lợi thế của đồ thị động và đồ thị tương tác với đồ thị tĩnh có thể liệt kê ra như sau:Các đồ thị dạng động đặc biệt hiệu quả trong việc mô tả sự thay đổi dữ liệu theo thời gian. Một đồ thị tĩnh khi mô tả biến theo thời gian thường chỉ có thể mô tả yếu tố thời gian lên một trục tọa độ và rất khó để có thể mô tả sự thay đổi đồng thời của một nhóm các biến theo thời gian trên một đồ thị tĩnh.Cùng với đồ thị động, các đồ thị tương tác có lợi thế ở việc thu hút thị giác của người tiếp nhận và có khả năng mô tả dữ liệu một cách đầy đủ thông tin hơn. Các đồ thị tương tác cho phép hiển thị thông tin bằng con trỏ, hoặc phóng , thu nhỏ từng phần của đồ thị. Người trực quan hóa dữ liệu không cần phải hiển thị quá nhiều thông tin lên đồ thị cùng lúc, đặc biệt là với các dữ liệu có nhiều biến.Ngoài các ưu điểm kể trên, khuyết điểm lớn nhất của các đồ thị tương tác và các đồ thị động đó là không thể biểu diễn trên các bản cứng.Trong phần này của chương sách, chúng tôi sẽ thảo luận về hai thư viện dùng để tạo đồ thị tương tác và đồ thị dạng động là ggiraph và plotly. Nếu như ggiraph là thư viện bổ sung cho ggplot2 và được xây dựng dựa trên cấu trúc ngữ pháp đồ thị thì plotly là một thư viện độc lập với ggplot2 và chuyên được sử dụng để tạo đồ thị dạng động và tương tác. Ưu nhược điểm và cách vẽ đồ thị của các thư viện này sẽ được thảo luận trong phần tiếp theo của chương.","code":""},{"path":"trực-quan-hóa-dữ-liệu.html","id":"tạo-đồ-thị-tương-tác-với-ggiraph","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.8.1 Tạo đồ thị tương tác với ggiraph","text":"Ưu điểm lớn nhất của thư viện ggiraph đó là các câu lệnh tạo đồ thị cũng được dựa trên ngữ pháp của đồ thị, nghĩa là hoàn toàn tương đồng với các câu lệnh trong thư viện ggplot2. Để tạo một đồ thị trực quan tương tác hoặc đồ thị động với ggiraph, bạn đọc chỉ cần thêm các thuộc tính thẩm mỹ của đồ thị tương tác và đồ thị động cùng với các thuộc tính của đồ thị tĩnh mà chúng ta đã làm quen khi vẽ đồ thị với thư viện ggplot2. Tại thời điểm chúng tôi viết chương sách này, thư viện ggiraph đang ở phiên bản 0.8.7 và hướng dẫn sử dụng ở trong đường dẫn như sau:https://cloud.r-project.org/web/packages/ggiraph/ggiraph.pdfTrong danh sách các hàm số trong thư viện ggiraph, bạn đọc có thể thấy rằng đa số các hàm geom_() của thư viện ggplot2 đều có một hàm tương ứng để tạo đồ thị tương tác tương ứng là geom_*_interactive(). Chẳng hạn như hàm geom_point() của thư viện ggplot2 sẽ có hàm tương ứng trong thư viện ggiraph là geom_point_interactive().Hai cấu phần thẩm mỹ thường được sử dụng để tạo đồ thị tương tác là tooltip và data_id. Bạn đọc cần lưu ý là hàm geom_point_interactive() không trực tiếp tạo ra đồ thị tương tác, mà bạn đọc cần lưu đối tượng được tạo bằng hàm số này, sau đó thực hiện câu lệnh tạo đồ thị tương tác bằng hàm girafe() của thư viện ggiraphHình 8.54 là đồ thị trực quan tương tác được vẽ bằng thư viện ggiraph mô tả số vụ sát nhân bằng súng tại Mỹ năm 2010 từ dữ liệu murders.\nHình 8.54: Đồ thị tương tác mô tả số vụ sát nhân bằng súng tại 51 bang của Mỹ vào năm 2010\nThuộc tính thẩm mỹ tooltip được ánh xạ đến các biến chứa thông tin mà bạn đọc muốn hiển thị của các điểm trên đồ thị khi sử dụng con trỏ. Trong Hình 8.54 chúng tôi ánh xạ thuộc tính này đến các biến state, region và population. Các biến này chỉ hiển thị khi bạn đọc sử dụng con trỏ di chuyển đến một điểm trên đồ thị.Thuộc tính thẩm mỹ data_id khi được ánh xạ đến một biến sẽ cho biết (làm nổi bật) các điểm dữ liệu có cùng giá trị trên biến đó. Trong đồ thị trên, biến region ánh xạ đến thuộc tính thẩm mỹ data_id, đó mỗi khi di chuyển con trỏ đến một bang, tất cả các bang có cùng giá trị của biến region sẽ được làm nổi bật. Bạn đọc có thể sử dụng con trỏ di chuyển đến từng các điểm trên đồ thị trong Hình 8.54 để xem kết quả của ánh xạ đến thuộc tính tooltip và data_id như miêu tả.Không chỉ trong đồ thị phân tán, các loại đồ thị cơ bản các cũng có cách sử dụng các thuộc tính thẩm mỹ tooltip và data_id hoàn toàn tương tự. Dưới đây là một vài ví dụ:Hình 8.55 mô tả đồ thị bong bóng dạng tương tác. mắt quan sát không dễ dàng đánh giá được kích thước của các hình tròn, kể cả khi chúng ta sử dụng chú giải cho kích thước, đó việc sử dụng đồ thị tương tác để hiển thị số lượng điểm tại mỗi hình tròn giúp cho dữ liệu càng trở nên sinh động và trực quan hơn\nHình 8.55: Đồ thị bong bóng tương tác mô tả số lượng viên kim cương theo màu sắc (color) và giác cắt (cut)\nHình 8.56 sử dụng đồ thị dạng đường và đồ thị dạng hình hộp chữ nhật có tương tác\nHình 8.56: Đồ thị tương tác mô tả tỷ lệ thất nghiệp của nước Mỹ qua các thời kỳ Tổng thống và các Đảng cầm quyền\nĐỒ thị trong Hình 8.56 được trực quan từ hai dữ liệu. Dữ liệu chính là dữ liệu economics với biến unemploy cho biết số lượng người thất nghiệp tại Mỹ được quan sát theo tháng từ năm 1967 đến năm 2015. Dữ liệu thứ hai là dữ liệu về các nhiệm kỳ của các tổng thống Mỹ trong các khoảng thời gian tương ứng. Bạn đọc có thể nhận thấy sự khác biệt về sự biến động của tỷ lệ thất nghiệp qua các thời kỳ cầm quyền của các đảng cầm quyền: tỷ lệ thất nghiệp luôn có xu thế giảm trong giai đoạn đảng Dân chủ nắm quyền, trong khi lại có xu thế tăng trong giai đoạn đảng Cộng hòa nắm chính quyền.Hình 8.57 sử dụng các đồ thị tương tác dạng thanh để mô tả thu nhập bình quân đầu người của các quốc gia vùng Đông Á trong năm 2011\nHình 8.57: Thu nhập bình quân đầu người của các quốc gia vùng Đông Á năm 2011\nHình 8.58 sử dụng bản đồ tương tác để mô tả biến tỷ lệ trẻ sơ sinh tử vong trong dữ liệu gapminder lọc theo năm 2011.\nHình 8.58: Bản đồ mô tả tỷ lệ trẻ sơ sinh tử vong các quốc gia trên thế giới năm 2011\nBạn đọc có thể thấy rằng bản đồ tương tác đặc biệt hiệu quả trong hiển thị thông tin thay thế cho chú giải. Màu sắc từ xanh da trời đến màu cam cho biết vùng quốc gia - vùng lãnh thổ nào có tỷ lệ trẻ sơ sinh tử vong thấp và quốc gia - vùng lãnh thổ nào có tỷ lệ trẻ sơ sinh tử vong cao. Bạn đọc muốn biết thông tin chi tiết về quốc gia đó có thể sử dụng con trỏ để hiển thị thông tin, bao gồm có thông tin về tên nước, dân số, và tỷ lệ trẻ sơ sinh tử vong.","code":"\np<-murders %>% ggplot(aes(y = total, x = population)) +\n  geom_point_interactive(aes(fill=region,\n                             tooltip = paste0(\"Bang: \", state, \n                                              \"\\n Vùng: \", region, \n                                              \"\\n Dân số: \", round(population/1000,0)*1000),\n                             data_id = region),\n                         size = 4, shape=21, alpha = 0.8, color = \"black\") +\n  geom_smooth(method = \"lm\", se = FALSE, linetype = 2, color=\"#640514\")+\n  scale_x_continuous(trans = \"log10\", labels = scales::label_comma()) +\n  scale_y_log10() +\n  scale_fill_brewer(palette = \"Dark2\",\n                    guide = guide_legend(title = \"Vùng\"))+\n  theme_minimal()+\n  ggtitle(\"Số vụ sát nhân bằng súng tại các bang năm 2010\")+\n  xlab(\"Dân số\")+ylab(\"Số vụ sát nhân bằng súng\")\n\ngirafe(ggobj = p, width_svg = 6.5, height_svg = 3.5,\n       options = list(\n                opts_sizing(width = .7),\n                opts_tooltip(css= \"font-family: Source Code Pro; \n                              color: white; \n                               background-color: #640514\")\n                ))\np<-diamonds%>%group_by(cut,color)%>%mutate(ave_price = mean(price))%>%ungroup()%>%\n  as.data.frame()%>%\n  ggplot(aes(cut,color))+\n  geom_count_interactive(aes(tooltip = paste0(\"Số lượng: \", after_stat(n))),\n                         alpha = 0.7, color = \"darkblue\",\n                         shape = 21, fill = \"#640514\")+\n  scale_size(range=c(1,12))+\n  theme_minimal()+\n  theme(legend.position = \"none\")+xlab(\"Giác cắt\")+ylab(\"Màu sắc\")\ngirafe(ggobj = p, width_svg = 5, height_svg = 4,\n        options = list(opts_sizing(width = .55),\n        opts_tooltip(css = \"font-family: Source Code Pro; \n                               padding:3pt; color: white; \n                               background-color: #640514\")\n                ))\ndat1<-presidential[3:11,]\np<-economics%>%mutate(unemploy_rate = unemploy/pop)%>%\n  ggplot()+\n  geom_rect_interactive(data=dat1,\n            aes(xmin = start, xmax = end,\n                ymin = 0.005, ymax = 0.06,\n                tooltip = paste(\"Tổng thống: \", name),\n                data_id = name,\n                fill = party),color = \"white\",size=0.08,alpha = 0.7)+\n  theme_minimal()+\n  scale_fill_manual(values=c(\"blue\",\"red\"),\n                    labels = c(\"Democratic\" = \"Dân chủ\",\"Republican\" = \"Cộng hòa\"),\n                    guide = guide_legend(title = \"Đảng cầm quyền:\"))+\n  geom_line(aes(x = date, y = unemploy_rate),size = 0.5, col= \"#A1FDFD\")+\n  geom_point_interactive(aes(x = date, y = unemploy_rate,\n                             tooltip = paste(round(unemploy_rate*100,2),\"%\")), \n                         col = \"#A1FDFD\",size = 0.3, alpha = 0.5)+\n  scale_y_continuous(limits = c(0.005,0.06),labels = scales::label_percent())+\n  xlab(\"Năm\") + ylab(\"Tỷ lệ thất nghiệp\")+\n  theme(legend.position = \"top\")\n\ngirafe(ggobj = p, width_svg = 6, height_svg = 3.5,\n        options = list(opts_sizing(width = .65),\n        opts_tooltip(css = \"font-family: Source Code Pro; \n                               padding:3pt; color: white; \n                               background-color: #640514 ; \n                               border-radius:5px\")\n                ))\np<-gapminder%>%filter(year==2011,region==\"Eastern Asia\")%>%\n  mutate(gdp_per_capita = gdp/population)%>%\n  filter(!is.na(gdp_per_capita))%>%\n  ggplot(aes(reorder(country,gdp_per_capita),gdp_per_capita,fill = country))+\n  geom_bar_interactive(aes(\n    tooltip = paste0(\"GDP: \", round(gdp/10^9,2), \n                     \" tỷ USD \\n Dân số: \", round(population/10^6,2),\n                     \" triệu \\n Tuổi thọ bình quân: \", life_expectancy)),\n                       stat=\"identity\")+\n  theme_minimal()+\n  scale_x_discrete(guide = guide_axis(title = \"\", angle = 90))+\n  scale_y_continuous(labels = scales::label_dollar(),\n                     guide = guide_axis(title = \"Thu nhập bình quân đầu người\"))+\n  scale_fill_brewer(palette = \"Paired\",\n                    guide = guide_legend(title = \"Quốc gia\",\n                                         title.position = \"top\"))+\n  ggtitle(\"Các nước Đông Á năm 2011\")+\n  theme(legend.position = \"none\")\ngirafe(ggobj = p, width_svg = 6, height_svg = 4,\n        options = list(opts_sizing(width = .6),\n        opts_tooltip(css = \"font-family: Source Code Pro; \n                               padding:3pt; color: white; \n                               background-color: #640514 ; \n                               border-radius:5px\")\n                ))\ndat_map<-map_data(\"world\")\nmycol<-colorRampPalette(c(\"#5AA0EB\",\"grey95\"), space = \"Lab\")(5)\nmycol<-c(mycol,colorRampPalette(c(\"grey95\",\"#EB5541\"), space = \"Lab\")(5))\n\ndat<-filter(gapminder,year == 2011)\ndat$country<-as.character(dat$country)\ndat$country[dat$country == \"Congo, Dem. Rep.\"]<-\"Democratic Republic of the Congo\"\ndat$country[dat$country == \"Congo, Rep.\"]<-\"Republic of Congo\"\ndat$country[dat$country == \"Dominican Republic\"]<-\"Dominica\"\ndat$country[dat$country == \"Kyrgyz Republic\"]<-\"Kyrgyzstan\"\ndat$country[dat$country == \"Lao\"]<-\"Laos\"\ndat$country[dat$country == \"St. Lucia\"]<-\"Saint Lucia\"\ndat$country[dat$country == \"United States\"]<-\"USA\"\ndat$country[dat$country == \"United Kingdom\"]<-\"UK\"\ndat$country[dat$country == \"Trinidad and Tobago\"]<-\"Trinidad\"\ndat$country<-as.factor(dat$country)\n\nind<-match(dat_map$region,dat$country)\ndat_map<-dat_map%>%mutate(gdp = dat$gdp[ind],\n                 population = dat$population[ind],\n                 infant_mortality = dat$infant_mortality[ind])\nind<-is.na(dat_map$infant_mortality)\ndat_map$infant_mortality[ind]<-round(mean(dat_map$infant_mortality,na.rm=TRUE),2)\n\np<-dat_map%>%\n  ggplot(aes(x=long,y=lat,group=group,label = region, fill = infant_mortality))+\n  geom_polygon_interactive(aes(tooltip = paste0(region, \"\\n Dân số: \", round(population/10^6,2),\n                                                \" triệu \\n Tỷ lệ tử vong trẻ sơ sinh: \", infant_mortality,\"/1000\")),\n                           color=\"black\",size = 0.1)+\n  scale_x_continuous(expand=c(0,0))+\n  scale_fill_gradientn(colors = mycol,\n                       guide = guide_legend(title = \"Tỷ lệ (phần nghìn)\"))+\n  theme_minimal()+xlab(\"\")+ylab(\"\")+ggtitle(\"Tỷ lệ trẻ sơ sinh tử vong năm 2011\")+\n  theme(legend.position = \"top\")\ngirafe(ggobj = p, \n        options = list(opts_sizing(width = .9),\n        opts_tooltip(css = \"font-family: Source Code Pro; \n                               padding:3pt; color: white; \n                               background-color: #640514\")\n                ))"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"tạo-đồ-thị-tương-tác-bằng-thư-viện-plotly","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.8.2 Tạo đồ thị tương tác bằng thư viện plotly","text":"Để tạo một đồ thị tương tác bằng thư viện plotly dễ dàng hơn với sử dụng thư viện ggiraph vì chúng ta không cần viết các câu lệnh có ngữ pháp. Việc duy nhất cần làm là sử dụng hàm ggplotly() trên một đối tượng được tạo bằng hàm ggplot(). Đoạn câu lệnh dưới đây mô tả dữ liệu murders dưới dạng đồ thị tương tác.\nHình 8.59: Đồ thị tương tác mô tả số vụ sát nhân bằng súng tại 51 bang của Mỹ vào năm 2010\nBạn đọc có thể tương tác với đồ thị tạo bằng ggplotly() bằng các thao tác như sau:Sử dụng con trỏ chỉ vào các điểm để xem thông tin chính xác về dân số, số vụ sát nhân, tên bang, và tên vùng của mỗi điểm.Sử dụng con trỏ chỉ vào các điểm để xem thông tin chính xác về dân số, số vụ sát nhân, tên bang, và tên vùng của mỗi điểm.Sử dụng con trỏ, hoặc các nút phóng , thu nhỏ để xem từng phần của đồ thị.Sử dụng con trỏ, hoặc các nút phóng , thu nhỏ để xem từng phần của đồ thị.Sử dụng con trỏ trên chú giải để lựa chọn các vùng nào hiển thị, hoặc không hiển thị trên đồ thị.Sử dụng con trỏ trên chú giải để lựa chọn các vùng nào hiển thị, hoặc không hiển thị trên đồ thị.Sử dụng con trỏ trượt theo đường thẳng tạo bởi geom_smooth() để biết giá trị trên trục total và population của mỗi điểm trên đường thẳng. Lưu ý rằng giá trị xuất hiện là giá trị sau khi đã chuyển đổi bằng hàm log10().Sử dụng con trỏ trượt theo đường thẳng tạo bởi geom_smooth() để biết giá trị trên trục total và population của mỗi điểm trên đường thẳng. Lưu ý rằng giá trị xuất hiện là giá trị sau khi đã chuyển đổi bằng hàm log10().Các thông tin bạn đọc muốn hiển thị bằng con trỏ là tất cả các biến dữ liệu đã được ánh xạ vào trong các thuộc tính thẩm mỹ của đồ thị. Đồ thị trong Hình 8.59 hiển thị thông tin trên các điểm bao gồm giá trị các biến population, total, state, và region là tất cả các biến được sử dụng trong ánh xạ thẩm mỹ của hàm geom_point(). Dọc theo đường hồi quy tuyến tính, chúng ta sẽ có thông tin về giá trị của các biến population và total là các biến được sử dụng trong ánh xạ thẩm mỹ của hàm geom_smooth().Tham số tooltip trong hàm ggplotly() được sử dụng để kiểm soát các thuộc tính thẩm mỹ xuất hiện trên đồ thị tương tác. Ví dụ như trong đồ thị phân tán trong Hình 8.59, nếu chúng ta chỉ muốn hiển thị thông tin về tên của bang và thông tin về vùng. tên của bang được ánh xạ tới thuộc tính thẩm mỹ group và vùng được ánh xạ tới thuộc tính thẩm mỹ fill, nên chúng ta có thể sử dụng tham số tooltip như sauHàm số ggplotly() có thể được sử dụng để tạo đồ thị tương tác với đa số các đồ thị được tạo bởi \\(ggplot2\\), dưới đây là một số ví dụHình 8.60 vẽ đồ thị kiểu bong bóng tương tác mô tả số lượng và giá trung bình của kim cương khi phân loại theo màu sắc và giác cắt.\nHình 8.60: Số lượng và giá trung bình của kim cương phân loại theo màu sắc và giác cắt\nHình 8.61 sử dụng đồ thị tương tác dạng đường để mô tả tổng thu nhập quốc dân của năm quốc gia phát triển trên thế giới là Mỹ, Đức, Pháp, Nhật và Trung Quốc từ năm 1970 đến năm 2011.\nHình 8.61: Tổng thu nhập quốc dân của các quốc gia Mỹ, Đức, Pháp, Nhật và Trung Quốc từ năm 1970 đến năm 2011\nHình 8.62 sử dụng đồ thị tương tác dạng thanh để trực quan hóa hai biến rời rạc là thu nhập bình quân đầu người và châu lục vào năm 2011. Thu nhập bình quân đầu người được phân loại theo ba mức độ: thấp tương ứng với thu nhập bình quân dưới 3000 USD, trung bình tương ứng với thu nhập bình quân từ 3000 USD đến 8000 USD, và cao tương ứng với thu nhập bình quân trên 8000 USD.\nHình 8.62: Tỷ lệ các nước thu nhập thấp, trung bình, và cao tại các châu lục năm 2011\n","code":"\np<-murders %>%\n  ggplot(aes(x = population/10^6, y = total)) +\n  geom_point(aes(group = state, fill = region ), size = 3, shape=21, alpha = 0.8) +\n  geom_smooth(method = \"lm\", se = FALSE, linetype = 2, color=\"#640514\", alpha = 0.5)+\n  scale_x_log10() +\n  scale_y_log10() +\n  scale_fill_brewer(palette = \"Dark2\",\n                    guide = guide_legend(title = \"Vùng\"))+\n  xlab(\"Dân số của bang (triệu dân)\") +\n  ylab(\"Tổng số vụ sát nhân bằng súng\") +\n  ggtitle(\"Số vụ sát nhân bằng súng trong năm 2010 tại Mỹ\")+\n  theme_minimal()\nggplotly(p)\n# Thông tin chỉ bao gồm tên bang và vùng\nggplotly(p, tooltip = c(\"group\",\"fill\"))\nmycol = colorRampPalette(c(\"#5AA0EB\",\"grey90\"), space = \"Lab\")(5)\nmycol = c(mycol,colorRampPalette(c(\"grey90\",\"orange\"), space = \"Lab\")(5))\n\np<-diamonds%>%group_by(cut,color)%>%mutate(ave_price = round(mean(price)))%>%ungroup()%>%\n  as.data.frame()%>%\n  ggplot(aes(cut,color,fill = ave_price))+\n  geom_count(shape = 21, alpha = 0.9, color = \"#640514\")+\n  scale_fill_gradientn(colors = mycol,\n                       guide = guide_legend(title = \"Giá trung bình\"))+\n  scale_size(range=c(1,12))+\n  theme_minimal()\nggplotly(p, tooltip = c(\"n\", \"color\"))\np<-gapminder%>%filter(country %in% c(\"United States\",\"Japan\",\"Germany\",\"France\", \"China\"),\n                   year <= 2011, year >= 1970)%>%mutate(gdp_bil_usd = gdp/10^9)%>%\n  ggplot(aes(x = year, y = gdp_bil_usd, color = country))+\n  geom_line()+\n  scale_y_continuous(labels = scales::label_comma())+\n  theme_minimal()\nggplotly(p, tooltip = c(\"x\",\"y\", \"color\"))\np<-gapminder%>%filter(year == 2011)%>%drop_na()%>%\n  mutate(gdp_per_capita = gdp/population,\n         gdp_levels = ifelse(gdp_per_capita<3000,\"Thấp\",\n                            ifelse(gdp_per_capita<8000,\"Trung bình\",\"Cao\")),\n         gdp_range = factor(gdp_levels, levels = c(\"Cao\",\"Trung bình\",\"Thấp\")))%>%\n  ggplot(aes(x = continent,fill = gdp_range))+\n  geom_bar(color=\"#640514\",alpha=0.7)+\n  scale_fill_manual(values = c(\"orange\",\"grey90\",\"#5AA0EB\"))+\n  theme_minimal()\nggplotly(p, tooltip = \"count\")"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"đồ-thị-động","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.8.3 Đồ thị động","text":"Đồ thị động là một phương pháp thường được sử dụng để mô tả dữ liệu biến đổi theo thời gian. Đồ thị dạng động ngoài yếu tố thẩm mỹ còn giúp cho người tiếp nhận dữ liệu nhanh chóng tiếp nhận được sự thay đổi của các biến liên tục và rời rạc theo thời gian một cách trực quan nhất. Chúng tôi sẽ giới thiệu đến bạn đọc cách tạo các đồ thị động với thư viện plotly và thư viện gganimate.Để hiểu cách tạo đồ thị động, hãy bắt đầu với một dữ liệu đơn giản bao gồm hai biến liên tục là x, y và một biến thời gian:Để trực quan hóa ba biến đều là kiểu số, bao gồm x, y và time, phương pháp thường được sử dụng là trực quan hóa hai biến x và y bằng một đồ thị phân tán, sau đó ánh xạ biến time vào một thuộc tính thẩm mỹ phù hợp, chẳng hạn như kích thước của các điểm. Đồ thị như vậy được mô tả trong Hình 8.63\nHình 8.63: Mô tả ba biến liên tục sử dụng thuộc tính thẩm mỹ kích thước\nMột phương pháp khác để mô tả ba biến trong dữ liệu kể trên là sử dụng đồ thị động, một tập hợp của nhiều đồ thị tĩnh xuất hiện liên tục mà mỗi đồ thị tương ứng với một giá trị của biến time. Bạn đọc có thể thực hiện thao tác này bằng thư viện plotly. Thuộc tính thẩm mỹ để tạo đồ thị dạng động là frame. Chúng ta khai báo thêm ánh xạ thẩm mỹ từ tham số frame đến biến time để tạo một đồ thị động trực quan như Hình 8.64\nHình 8.64: Đồ thị động mô tả sự chuyển động của một điểm theo biến time của dữ liệu\nĐồ thị dạng động sẽ được kích hoạt mỗi khi chúng ta bấm nút play. Bạn đọc có thể thấy rằng cách mô tả sự thay đổi của điểm theo thời gian của đồ thị động trong Hình 8.64 trực quan và hiệu quả hơn với Hình 8.63.Vẽ đồ thị dạng động bằng ggplotly() có ưu điểm là đơn giản và hiệu quả đặc biệt là khi mô tả các biến thay đổi theo thời gian. Bạn đọc có thể sử dụng tham số frame với biến year trong dữ liệu gapminder để mô tả sự thay đổi của các biến khác trong dữ liệu này theo thời gian. Ví dụ, chúng ta muốn mô tả hai biến tuổi thọ trung bình và tỷ lệ sinh trung bình của một phụ nữ qua các năm, chúng ta có thể ánh xạ hai biến lên hai trục tọa độ, sau đó sử dụng màu sắc để mô tả biến châu lục, sử dụng kích thước để mô tả biến dân số, và sau cùng sẽ gán tham số frame với biến year:\nHình 8.65: Đồ thị động mô tả sự thay đổi của tỷ lệ sinh trung bình và tuổi thọ trung bình của tất cả các quốc gia trên thế giới từ năm 1960 đến 2011\n","code":"\ndat<-data.frame(x=1:30,y=(1:30)^2,time=1:30)\ndat%>%ggplot(aes(x,y,size = time))+\n  geom_point(alpha=0.3,shape = 21, color = \"darkblue\", fill = \"#640514\")+\n  scale_size(range=c(1,15))+\n  theme_minimal()\np<-dat%>%ggplot(aes(x=x,y=y,size=time,frame = time))+\n  geom_point(alpha=0.3,shape = 21, color = \"darkblue\", fill = \"#640514\")+\n  scale_size(range=c(1,15))+\n  theme_minimal()\nggplotly(p, tooltip = \"size\")\np<-gapminder%>%filter(year %in% 1960:2011)%>%\n  ggplot(aes(x = fertility, y = life_expectancy, size = population,\n             fill = continent, frame = year))+\n  geom_point(alpha = 0.5,shape=21)+\n  scale_fill_brewer(palette = \"Set1\")+\n  scale_size(range=c(1,15))+\n  theme_minimal()+\n  ggtitle(\"Tuổi thọ và tỷ lệ sinh trung bình 1960 đến 2011\")\nggplotly(p, tooltip = c())"},{"path":"trực-quan-hóa-dữ-liệu.html","id":"bài-tập-1","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.9 Bài tập","text":"","code":""},{"path":"trực-quan-hóa-dữ-liệu.html","id":"phụ-lục-3","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.10 Phụ lục","text":"","code":""},{"path":"trực-quan-hóa-dữ-liệu.html","id":"lập-trình-trong-ggplot2","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.10.1 Lập trình trong ggplot2","text":"","code":""},{"path":"trực-quan-hóa-dữ-liệu.html","id":"tạo-dashboard-với-thư-viện-shiny","chapter":"Chương 8 Trực quan hóa dữ liệu","heading":"8.10.2 Tạo dashboard với thư viện shiny","text":"","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"mô-hình-hồi-quy-tuyến-tính","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"Chương 9 Mô hình hồi quy tuyến tính","text":"","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"giới-thiệu-chung-1","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.1 Giới thiệu chung","text":"Chương sách này thảo luận về mô hình hồi quy tuyến tính - phương pháp cơ bản nhất trong các phương pháp xây dựng mô hình học máy có giám sát. Mặc dù đơn giản nhưng mô hình hồi quy tuyến tính lại là một công cụ hữu ích để đưa ra các dự đoán hoặc mô tả sự tác động của một biến giải thích lên các biến khác. Hồi quy tuyến tính là một chủ đề đã được nghiên cứu từ rất lâu, từ trước khi có máy tính điện tử, đồng thời cũng là chủ đề của vô số sách tham khảo. Trong thời đại ngày nay, mặc dù mô hình này có vẻ hơi nhàm chán với một số phương pháp học thống kê/học máy hiện đại, hồi quy tuyến tính vẫn là một phương pháp học thống kê hữu ích và được sử dụng rộng rãi. Hơn nữa, đây còn là điểm khởi đầu tốt cho các phương pháp tiếp cận mới hơn như chúng ta sẽ thấy trong các chương sau. Nhiều phương pháp học máy tiên tiến nhất hiện nay có thể được coi là sự khái quát hóa hoặc mở rộng của hồi quy tuyến tính. đó, tầm quan trọng của việc hiểu rõ về hồi quy tuyến tính trước khi nghiên cứu các phương pháp phức tạp hơn là không thể phủ nhận.Trong phần đầu của chương này, chúng ta xem xét một số ý tưởng chính làm cơ sở cho mô hình hồi quy tuyến tính, cũng như phương pháp bình phương nhỏ nhất được sử dụng phổ biến nhất để ước lượng tham số cho mô hình này. Trong phần sau của chương, chúng ta sẽ thảo luận về các phương pháp lựa chọn mô hình và các phương pháp rút gọn tham số (shrinkage methods).","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"những-nội-dung-cơ-bản-của-mô-hình-quy-tuyến-tính","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2 Những nội dung cơ bản của mô hình quy tuyến tính","text":"Trước khi đi vào các nội dung cơ bản, hãy lấy một ví dụ đơn giản về một yêu cầu phân tích dữ liệu mà có thể tìm được lời giải được bằng mô hình hồi quy tuyến tính. Một công ty thực hiện một chiến dịch quảng cáo sản phẩm cho 55 cửa hàng trên phạm vi toàn quốc trong một năm thông qua ba phương thức quảng cáo làQuảng cáo qua truyền hình: biến TV;Quảng cáo qua truyền hình: biến TV;Quảng cáo qua các nền tảng mạng xã hội: biến Social_Media; và,Quảng cáo qua các nền tảng mạng xã hội: biến Social_Media; và,Quảng cáo qua phát tờ rơi: biến Flyer.Quảng cáo qua phát tờ rơi: biến Flyer.Hình 9.1 mô tả mối liên hệ giữa doanh thu bán hàng, biến Sales, với chi phí thực hiện các phương thức quảng cáo ở 55 cửa hàng. Lưu ý rằng doanh thu bán hàng được tính bằng đơn vị tỷ đồng trong khi các chi phí quảng cáo được tính bằng đơn vị triệu đồng.\nHình 9.1: Doanh thu bán hàng (tỷ đồng) và mối liên hệ với chi phí quảng cáo. Hình bên trái: Chi phí quảng cáo trên Tivi. Hình ở giữa: chi phí quảng cáo qua các nền tảng mạng xã hội. Hình bên phải: quảng cáo theo hình thức phát tờ rơi\nGiả sử với vai trò là một chuyên gia tư vấn, chúng ta được yêu cầu đưa ra đề xuất trên cơ sở dữ liệu quan sát được, một kế hoạch quảng cáo cho năm tới nhằm mang lại doanh thu bán sản phẩm cao. Thông tin nào từ dữ liệu sẽ hữu ích để đưa ra khuyến nghị cho chiến dịch quảng cáo? Dưới đây là một số câu hỏi quan trọng mà chúng ta cần tìm cách giải quyết nhằm đưa ra khuyến nghị:Có mối quan hệ giữa ngân sách chi cho từng hình thức quảng cáo và doanh thu bán hàng không? Để trả lời câu hỏi này chúng ta cần xác định xem dữ liệu có cung cấp minh chứng về mối liên hệ tuyến tính giữa chi phí cho từng hình thức quảng cáo với doanh thu bán hàng. Nếu mối liên hệ là yếu, hoặc thậm chí là mối liên hệ âm thì chúng ta có thể lập luận rằng không nên chi tiền cho quảng cáo.Có mối quan hệ giữa ngân sách chi cho từng hình thức quảng cáo và doanh thu bán hàng không? Để trả lời câu hỏi này chúng ta cần xác định xem dữ liệu có cung cấp minh chứng về mối liên hệ tuyến tính giữa chi phí cho từng hình thức quảng cáo với doanh thu bán hàng. Nếu mối liên hệ là yếu, hoặc thậm chí là mối liên hệ âm thì chúng ta có thể lập luận rằng không nên chi tiền cho quảng cáo.Mối liên hệ giữa ngân sách chi cho quảng cáo và doanh thu nếu tồn tại thì mạnh đến mức nào? Nếu mối liên hệ là mạnh, thì với một ngân sách quảng cáo nhất định, liệu chúng ta có thể dự đoán doanh số bán hàng với độ chính xác cao không, hay dự đoán về doanh số bán hàng dựa trên chi tiêu quảng cáo chỉ tốt hơn một chút với dự đoán một cách ngẫu nhiên?Mối liên hệ giữa ngân sách chi cho quảng cáo và doanh thu nếu tồn tại thì mạnh đến mức nào? Nếu mối liên hệ là mạnh, thì với một ngân sách quảng cáo nhất định, liệu chúng ta có thể dự đoán doanh số bán hàng với độ chính xác cao không, hay dự đoán về doanh số bán hàng dựa trên chi tiêu quảng cáo chỉ tốt hơn một chút với dự đoán một cách ngẫu nhiên?Phương tiện truyền thông nào góp phần tăng doanh số bán hàng? Cả ba phương tiện truyền thông qua Tivi, mạng xã hội và phát tờ rơi có đóng góp vào doanh số bán hàng hay chỉ một hoặc hai phương tiện quảng cáo có đóng góp? Để trả lời câu hỏi này, chúng ta phải tìm cách tách biệt những tác động riêng lẻ của từng phương tiện quảng cáo đến doanh thu khi chúng ta đã chi tiền cho cả ba phương tiện.Phương tiện truyền thông nào góp phần tăng doanh số bán hàng? Cả ba phương tiện truyền thông qua Tivi, mạng xã hội và phát tờ rơi có đóng góp vào doanh số bán hàng hay chỉ một hoặc hai phương tiện quảng cáo có đóng góp? Để trả lời câu hỏi này, chúng ta phải tìm cách tách biệt những tác động riêng lẻ của từng phương tiện quảng cáo đến doanh thu khi chúng ta đã chi tiền cho cả ba phương tiện.Chúng ta có thể ước tính chính xác tác động của chi phí từng phương tiện quảng cáo đến doanh thu bán hàng như thế nào? Với cùng một mức chi cho quảng cáo trên một phương tiện cụ thể, doanh thu bán hàng sẽ tăng bao nhiêu? Chúng ta có thể dự đoán mức tăng này chính xác đến mức nào?Chúng ta có thể ước tính chính xác tác động của chi phí từng phương tiện quảng cáo đến doanh thu bán hàng như thế nào? Với cùng một mức chi cho quảng cáo trên một phương tiện cụ thể, doanh thu bán hàng sẽ tăng bao nhiêu? Chúng ta có thể dự đoán mức tăng này chính xác đến mức nào?Mối liên hệ hay sự tác động của chi phí cho từng hình thức quảng cáo đến doanh số bán hàng có tuyến tính không? Nếu không, liệu có phương pháp biến đổi như thế nào để mối liên hệ vẫn là tuyến tính?Mối liên hệ hay sự tác động của chi phí cho từng hình thức quảng cáo đến doanh số bán hàng có tuyến tính không? Nếu không, liệu có phương pháp biến đổi như thế nào để mối liên hệ vẫn là tuyến tính?Có sự tác động qua lại giữa các chi phí cho các phương tiện quảng cáo không? Chẳng hạn như nên chi đồng thời 10 triệu đồng cho quảng cáo trên mạng xã hội và 10 triệu đồng cho quảng cáo tờ rơi liệu có mang lại doanh thu cao hơn việc phân bổ 20 triệu cho riêng từng hình thức? Trong tiếp thị quảng cáo, đây được gọi là hiệu ứng tổng hợp.Có sự tác động qua lại giữa các chi phí cho các phương tiện quảng cáo không? Chẳng hạn như nên chi đồng thời 10 triệu đồng cho quảng cáo trên mạng xã hội và 10 triệu đồng cho quảng cáo tờ rơi liệu có mang lại doanh thu cao hơn việc phân bổ 20 triệu cho riêng từng hình thức? Trong tiếp thị quảng cáo, đây được gọi là hiệu ứng tổng hợp.Những cơ sở của mô hình hồi quy tuyến tính được thảo luận trong chương này sẽ giúp bạn đọc lần lượt trả lời các câu hỏi đặt ra ở trên.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"mô-hình-hồi-quy-tuyến-tính-đơn-biến","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.1 Mô hình hồi quy tuyến tính đơn biến","text":"Hồi quy tuyến tính đơn biến, đúng như tên gọi, đó là một cách tiếp cận tuyến tính đơn giản để dự đoán phản ứng định lượng của một biến mục tiêu \\(Y\\) trên cơ sở biến độc lập \\(X\\). Mô hình giả định rằng có mối quan hệ tuyến tính giữa \\(Y\\) và \\(X\\). Về mặt toán học, chúng ta có thể viết mối quan hệ tuyến tính này như sau\n\\[\\begin{align}\nY \\sim \\beta_0 + \\beta_1 \\cdot X\n\\tag{9.1}\n\\end{align}\\]\nBạn có thể hiểu ‘\\(\\sim\\)’ theo nghĩa xấp xỉ hoặc gần đúng. Đôi khi chúng ta sẽ mô tả phương trình (9.1) bằng cách nói rằng chúng ta đang hồi quy \\(Y\\) theo \\(X\\). Trong ví dụ trình bày ở trên, \\(X\\) có thể đại diện cho chi phí quảng cáo trên truyền hình (TV) và \\(Y\\) có thể đại diện cho doanh số bán hàng (Sales) tại các cửa hàng. Sau đó, chúng ta có thể hồi quy doanh số bán hàng theo chi phí quảng cáo trên truyền hình theo một mô hình hồi quy tuyến tính đơn biến như sau\n\\[\\begin{align}\n\\text{Sales} \\sim \\beta_0 + \\beta_1 \\cdot \\text{TV}\n\\tag{9.2}\n\\end{align}\\]Trong phương trình (9.2), \\(\\beta_0\\) và \\(\\beta_1\\) là hai hằng số chưa biết biểu thị hệ số chặn và hệ số góc của đường thẳng trong mô hình tuyến tính. Cùng với nhau, \\((\\beta_0, \\beta_1)\\) được gọi là các hệ số tuyến tính hoặc tham số của mô hình. Các hệ số này sẽ được ước lượng dựa trên dữ liệu thu thập được dựa trên phương pháp người xây dựng mô hình lựa chọn. Các ước lượng cho hệ số tuyến tính thường được thêm dấu mũ ở trên để phân biệt với tham số của mô hình tuyến tính. Nói cách khác chúng ta có \\(\\hat{\\beta}_0\\) và \\(\\hat{\\beta}_1\\) là các ước lượng của \\(\\beta_0\\) và \\(\\beta_1\\). Với \\(Y\\) là biến doanh thu bán hàng và \\(X\\) là biến chi phí quảng cáo trên truyền hình chúng ta sẽ có một dự đoán cho doanh thu bán hàng \\(\\hat{y}\\) dựa trên một quan sát của chi phí quảng cáo \\(X = x\\)\n\\[\\begin{align}\n\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot x\n\\tag{9.3}\n\\end{align}\\]Lưu ý rằng chúng tôi luôn sử dụng dấu mũ để mô tả một ước lượng cho một tham số, hoặc là giá trị dự đoán cho một giá trị không biết.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"ước-lượng-hệ-số-trong-mô-hình-đơn-biến","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.1.1 Ước lượng hệ số trong mô hình đơn biến","text":"Trong mô hình hồi quy tuyến tính đơn biến, \\(\\beta_0\\) và \\(\\beta_1\\) là các tham số không biết và cần được ước lượng từ dữ liệu. Giả sử dữ liệu chúng ta quan sát được bao gồm \\(n\\) cặp \\((x_i, y_i)\\) như sau\n\\[\\begin{align}\n(x_1, y_1), (x_2, y_2), \\cdots, (x_n, y_n)\n\\end{align}\\]\ntrong đó \\(x_i\\) là các giá trị quan sát được của biến \\(X\\) và \\(y_i\\) là các giá trị quan sát được tương ứng của biến ngẫu nhiên \\(Y\\), với \\(\\) = \\(1\\), \\(2\\), …, \\(n\\). Trong ví dụ về chi phí cho quảng cáo, tập dữ liệu bao gồm ngân sách quảng cáo qua truyền hình và doanh số bán sản phẩm với \\(n = 55\\) cửa hàng khác nhau. Mục tiêu của chúng ta là thu được các ước lượng cho hệ số \\(\\beta_0\\) và \\(\\beta_1\\) sao cho mô hình tuyến tính (9.2) phù hợp tốt với dữ liệu có sẵn. Nói cách khác, chúng ta muốn tìm hệ số chặn \\(\\beta_0\\) và hệ số góc \\(\\beta_1\\) sao cho đường thẳng ước lượng được càng gần \\(n = 55\\) điểm dữ liệu càng tốt.Có nhiều phương pháp khác nhau để định nghĩa thế nào là một đường thẳng gần nhất với một tập hợp điểm. Tuy nhiên, cho đến nay cách tiếp cận phổ biến nhất là tối thiểu hóa tổng bình phương các khoảng cách từ các điểm đến đường thẳng đó. Phương pháp này được gọi là phương pháp bình phương nhỏ nhất và chúng ta áp dụng cách tiếp cận này để ước lượng các tham số. Chi tiết về phương pháp bình phương nhỏ nhất sẽ được trình bày trong các phần sau của chương.\nHình 9.2: Phương pháp bình phương nhỏ nhất được sử dụng để ước lượng hệ số cho mô hình hồi quy đơn biến doanh thu bán hàng theo chi phí quảng cáo trên truyền hình. Đường hồi quy tuyến tính được ước lượng bằng phương pháp bình phương nhỏ nhất là đường thẳng có tổng bình phương khoảng cách các điểm dữ liệu đến đường thẳng này là nhỏ nhất\nHình 9.2 mô tả đường hồi quy tuyến tính đơn được xây dựng trên dữ liệu về quảng cáo với biến phụ thuộc là doanh số bán hàng và biến độc lập là chi phí quảng cáo trên truyền hình, với \\(\\hat{\\beta}_0\\) = 5.103 và \\(\\hat{\\beta}_1\\) = 0.024.Điểm \\((x_i,y_i)\\) trên hình vẽ mô tả chi phí quảng cáo trên truyền hình, \\(x_i\\), của cửa hàng thứ \\(\\) và doanh thu bán hàng \\(y_i\\) tương ứng. Với \\(\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot x_i\\) là dự đoán cho \\(Y\\) dựa trên giá trị thứ \\(\\) của \\(X\\). Khi đó ta ký hiệu \\(e_i = y_i − \\hat{y}_i\\) đại diện cho sai số, hay còn gọi là phần dư, của quan sát thứ \\(\\). Nói một cách khác phần dư là sự khác biệt giữa giá trị quan sát được của biến mục tiêu và giá trị ước lượng được cho biến mục tiêu được tính toán bởi mô hình. Chúng ta xác định tổng bình phương của phần dư, được gọi là Residual Sum Squares hay RSS, bằng công thức như sau\n\\[\\begin{align}\nRSS & = e_1^2 + e_2^2 + \\cdots + e_n^2 \\\\\n& = (y_1 - \\hat{\\beta}_0 - \\hat{\\beta}_1 \\cdot x_1)^2 + (y_2 - \\hat{\\beta}_0 - \\hat{\\beta}_1 \\cdot x_2)^2 + \\cdots + (y_n - \\hat{\\beta}_0 - \\hat{\\beta}_1 \\cdot x_n)^2\n\\end{align}\\]Phương pháp bình phương nhỏ nhất lựa chọn \\(\\hat{\\beta}_0\\) và \\(\\hat{\\beta}_1\\) sao cho giá trị của RSS là nhỏ nhất trong công thức phía trên là nhỏ nhất. Bạn đọc có thể giải bài toán tối ưu bằng cách cho đạo hàm của RSS theo \\(\\hat{\\beta}_0\\) và \\(\\hat{\\beta}_1\\) bằng 0 và cho kết quả như sau\n\\[\\begin{align}\n\\hat{\\beta}_1 & = \\cfrac{\\sum\\limits_{=1}^n (x_i - \\bar{x}) (y_i - \\bar{y})}{\\sum\\limits_{=1}^n (x_i - \\bar{x})^2} \\\\\n\\hat{\\beta}_0 & = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\n\\tag{9.4}\n\\end{align}\\]\ntrong đó \\(\\bar{y} = \\sum\\limits_{=1}^n y_i\\) và \\(\\bar{x} = \\sum\\limits_{=1}^n x_i\\) là các giá trị trung bình của các quan sát. Chúng ta sẽ quay trở lại với phương pháp ước lượng bình phương nhỏ nhất trong phần sau của chương.Để thực hiện ước lượng mô hình tuyến tính trong R, chúng ta sử dụng hàm lm() của thư viện stat. Câu lệnh thực hiện ước lượng mô hình tuyến tính như sauTừ kết quả của mô hình, chúng ta có một ước lượng cho mô hình tuyến tính đơn giản mà biến Sales phụ thuộc vào biến TV như sau:\n\\[\\begin{align}\n\\text{Sales} = 5.10303  + 0.02409  \\cdot \\text{TV}\n\\tag{9.5}\n\\end{align}\\]Theo như mô hình ước lượng được, khi thêm 1 triệu đồng chi cho quảng cáo trên truyền hình dẫn đến việc doanh thu bán hàng trung bình tăng thêm khoảng 24.1 triệu đồng. Doanh thu bán hàng trung bình tăng thêm 24.1 triệu có thể hiểu là có cửa hàng có doanh thu tăng nhiều hơn, có cửa hàng có doanh thu tăng ít hơn, nhưng khi lấy giá trị trung bình phần doanh thu tăng thêm của các cửa hàng sẽ có kết quả là khoảng 24.1 triệu đồng.Bạn đọc có thể thực hiện tương tự các bước như trên để đưa ra đánh giá về mối liên hệ giữa chi phí quảng cáo trên mạng xã hội, hoặc chi phí quảng cáo bằng hình thức phát tờ rơi, đến doanh thu bán sản phẩm trung bình của các cửa hàng.","code":"\n# Lấy dữ liệu advertising vào R\nAdvertising<-read.csv(\".../advertise.csv\")\n# Thực hiện ước lượng mô hình\n# Doanh thu bán hàng (Sales) hồi quy theo TV\nlm(Sales~TV, data = Advertising)"},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"đánh-giá-sự-chính-xác-của-các-hệ-số-ước-lượng","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.1.2 Đánh giá sự chính xác của các hệ số ước lượng","text":"Trong mô hình tuyến tính đơn biến mà Sales phụ thuộc vào biến TV chúng ta ước lượng được hệ số \\(\\beta_2\\) bằng 0.02409 và dẫn đến kết luận là khi chi phí quảng cáo trên truyền hình tăng thêm 1 triệu đồng sẽ dẫn đến doanh thu bán hàng trung bình tăng thêm khoảng 24.1 triệu đồng. Chúng tôi dùng từ “khoảng” vì không có gì đảm bảo là doanh thu bán hàng trung bình sẽ tăng thêm đúng 24.1 triệu đồng. Để đưa ra được mối liên hệ giữa doanh thu trung bình thực tế tăng thêm, một giá trị mà chúng ta không biết, với giá trị ước lượng được là 24.1 triệu đồng, chúng ta cần đánh giá sự chính xác khi ước lượng hệ số \\(\\beta_0\\) và \\(\\beta_1\\).Nhắc lại rằng trong các mô hình học máy có giám sát, mối liên hệ thực tế giữa biến mục tiêu \\(Y\\) và biến phụ thuộc \\(X\\) được mô tả thông qua một hàm \\(f\\),\n\\[\\begin{align}\nY = f(X) + \\epsilon\n\\end{align}\\]\ntrong đó \\(\\epsilon\\) là thành phần hoàn toàn độc lập với biến \\(X\\), nghĩa là không thể đưa ra được thêm bất kỳ thông tin nào về \\(\\epsilon\\) dựa trên dữ liệu \\(X\\). Trong trường hợp hàm \\(f\\) thực sự là một hàm tuyến tính, mối liên hệ giữa \\(X\\) và \\(Y\\) sẽ được mô tả thông qua hệ số chặn \\(\\beta_0\\) và hệ số góc \\(\\beta_1\\)\n\\[\\begin{align}\nY = \\beta_0 + \\beta_1 X + \\epsilon\n\\tag{9.6}\n\\end{align}\\]Mô hình tuyến tính trong phương trình (9.6) được gọi là đường hồi quy tuyến tính thực. Trong thực tế, không thể biết được đường hồi quy tuyến tính thực, mà chúng ta chỉ có thể dựa trên các giá trị quan sát được của biến mục tiêu và biến phụ thuộc để ước lượng ra các tham số \\(\\hat{\\beta}_0\\) và \\(\\hat{\\beta}_1\\). Đường thẳng có hệ số chặn \\(\\hat{\\beta}_0\\) và hệ số góc \\(\\hat{\\beta}_1\\) được gọi là đường hồi quy tuyến tính ước lượng được.\nHình 9.3: Hình bên trái: Đường hồi quy tuyến tính thật màu đen và đường hồi quy tuyến tính ước lượng màu đỏ. Hình bên phải: Đường hồi quy tuyến tính thật màu đen và các đường hồi quy tuyến tính ước lượng màu xanh\nĐường màu đen ở phần bên trái của Hình 9.3 hiển thị đường hồi quy tuyến tính thực, \\(f(x) = 1 + 2 \\cdot x\\), trong khi đường màu đỏ là ước lượng bình phương nhỏ nhất dựa trên dữ liệu quan sát được. Mối quan hệ thực sự thường không thể biết được, nhưng đường bình phương nhỏ nhất luôn có thể được ước lượng bằng cách sử dụng phương trình (9.4). Nói cách khác, trong các ứng dụng thực tế, mỗi khi chúng ta có một tập hợp các quan sát là từ đó chúng ta có thể tính toán đường bình phương nhỏ nhất; đồng thời, đường hồi quy tuyến tính thực là không thể tính toán được. Trong phần bên phải của Hình 9.3, chúng tôi đã tạo ra mười bộ dữ liệu khác nhau từ mô hình hồi quy thực và vẽ mười đường bình phương nhỏ nhất tương ứng. Lưu ý rằng các tập dữ liệu khác nhau được tạo ra từ cùng một mô hình thực sẽ dẫn đến các đường bình phương nhỏ nhất hơi khác nhau một chút, nhưng đường hồi quy tổng thể không quan sát được không thay đổi.Quan sát trên hình vẽ, sự khác biệt giữa đường hồi quy tổng thể và đường bình phương nhỏ nhất có vẻ khó nhận thấy và khó hiểu. Về cơ bản, khái niệm hai đường này là sự mở rộng của phương pháp thống kê tiêu chuẩn về việc sử dụng thông tin từ một mẫu để ước tính các đặc điểm của một tổng thể. Ví dụ, giả sử chúng ta muốn biết trung bình tổng thể \\(\\mu\\) của một biến ngẫu nhiên \\(Y\\) nào đó. \\(\\mu\\) là một giá trị không biết, nhưng chúng ta có \\(n\\) quan sát từ của \\(Y\\), mà chúng ta có thể viết là \\(y_1, y_2, \\cdots , y_n\\) và chúng ta có thể sử dụng để ước lượng \\(\\mu\\). Một ước lượng hợp lý cho \\(\\mu\\) là \\(\\hat{\\mu} = \\bar{y}\\), trong đó\n\\[\\begin{align}\n\\bar{y} = \\cfrac{\\sum\\limits_{=1}^n y_i}{n}\n\\end{align}\\]\nlà giá trị trung bình mẫu. Trung bình mẫu và trung bình tổng thể là khác nhau, nhưng nói chung trung bình mẫu sẽ cung cấp ước tính tốt về trung bình tổng thể. Theo cách tương tự, các hệ số chưa biết \\(\\beta_0\\) và \\(\\beta_1\\) trong hồi quy tuyến tính là hệ số đường hồi quy tổng thể hay đường hồi quy thực. Chúng ta ước lượng các hệ số chưa biết này bằng cách sử dụng \\(\\hat{\\beta_0}\\) và \\(\\hat{\\beta_1}\\).Sự tương tự giữa ước lượng các hệ số của hồi quy tuyến tính và ước lượng giá trị trung bình của một biến ngẫu nhiên còn được thể hiện qua các tính chất của các ước lượng. Chẳng hạn như chúng ta luôn mong muốn các ước lượng là các ước lượng không chệch. Đối với trung bình tổng thể, chúng ta luôn tìm các ước lượng \\(\\hat{\\mu}\\) sao cho \\(\\mathbb{E}(\\hat{\\mu}) = \\mu\\). Tính chất không chệch của ước lượng đảm bảo rằng nếu chúng ta có thể có một số lượng đủ lớn các quan sát thì giá trị trung bình mẫu sẽ xấp xỉ giá trị trung bình tổng thể. Các hệ số của mô hình hồi quy tuyến tính bằng phương pháp bình phương nhỏ nhất cũng là các ước lượng không chệch, nghĩa là nếu chúng ta ước lượng \\(\\beta_0\\) và \\(\\beta_1\\) trên cơ sở một tập dữ liệu cụ thể và nhỏ thì các ước lượng sẽ không chính xác bằng \\(\\beta_0\\) và \\(\\beta_1\\). Nhưng nếu chúng ta có thể lặp lại việc ước lượng nhiều lần và tính trung bình các ước lượng thu được từ một số lượng lớn tập dữ liệu cùng lấy ra từ tổng thể thì giá trị trung bình của các ước lượng này sẽ xấp xỉ \\(\\beta_0\\) và \\(\\beta_1\\). Trên thực tế, chúng ta có thể thấy từ hình bên phải của Hình 9.3 rằng giá trị trung bình của nhiều đường bình phương tối thiểu, mỗi đường được ước tính từ một tập dữ liệu riêng biệt, khá gần với đường hồi quy tổng thể thực.Một câu hỏi khác cần được đặt ra với ước lượng trung bình tổng thể \\(\\mu\\) của biến ngẫu nhiên \\(Y\\) là: giá trị trung bình mẫu \\(\\hat{\\mu}\\) ước tính của \\(\\mu\\) chính xác như thế nào? Chúng ta đã biết rằng giá trị trung bình của các \\(\\hat{\\mu}\\) trên nhiều tập dữ liệu sẽ rất gần với \\(\\mu\\), nhưng một ước tính duy nhất của \\(\\hat{\\mu}\\) trên một dự liệu cụ thể sẽ chênh lệch với \\(\\mu\\) như thế nào? Nhìn chung, để trả lời câu hỏi này chúng ta cần tính độ lệch chuẩn của \\(\\hat{\\mu}\\), được ký hiệu là \\(SE(\\hat{\\mu})\\). Chúng ta đã biết rằng\n\\[\\begin{align}\nSE(\\hat{\\mu}) = \\cfrac{\\sigma}{\\sqrt{n}}\n\\end{align}\\]\nvới \\(\\sigma\\) là độ lệch chuẩn của biến \\(Y\\).\\(SE(\\hat{\\mu})\\) cho chúng ta biết một ước lượng cụ thể \\(\\hat{\\mu}\\) sẽ chênh lệch với \\(\\mu\\) như thế nào. Có thể dễ dàng thấy rằng khi số lượng quan sát \\(n\\) đủ lớn, \\(SE(\\hat{\\mu})\\) sẽ càng gần đến 0 và chênh lệch giữa \\(\\hat{\\mu}\\) với \\(\\mu\\) sẽ càng nhỏ. Lập luận hoàn toàn tương tự, để biết các ước lượng cho các hệ số chặn và hệ số góc trong mô hình tuyến tính chênh lệch với các giá trị thật \\(\\beta_0\\) và \\(\\beta_1\\) như thế nào, chúng ta cần tính toán độ lệch chuẩn của các ước lượng đó. Tính toán độ lệch chuẩn của các ước lượng cho hệ số sẽ được trình bày chi tiết trong các phần sau. Bạn đọc cần biết là độ lệch chuẩn của \\(\\hat{\\beta_0}\\) và \\(\\hat{\\beta_1}\\) có thể tính toán được như sau\n\\[\\begin{align}\nSE(\\hat{\\beta}_0) = \\sigma \\cdot \\sqrt{\\cfrac{1}{n} + \\cfrac{\\bar{x}^2}{\\sum\\limits_{=1}^n (x_i - \\bar{x})^2} } ; SE(\\hat{\\beta}_1) = \\cfrac{\\sigma}{\\sqrt{\\sum\\limits_{=1}^n (x_i - \\bar{x})^2} }\n\\tag{9.8}\n\\end{align}\\]\ntrong đó \\(\\sigma = \\sqrt{Var(\\epsilon)}\\).Các công thức cho độ lệch tiêu chuẩn của \\(\\hat{\\beta_0}\\) và \\(\\hat{\\beta_1}\\) ở trên đi kèm với giả định là các sai số \\(\\epsilon_i\\) là độc lập với nhau và có cùng phương sai là \\(\\sigma^2\\). Giả thiết này thường không đạt được trong thực tế tuy nhiên công thức (9.8) vẫn là một xấp xỉ tốt cho phương sai của các ước lượng. Lưu ý trong công thức ở trên rằng \\(SE(\\hat{\\beta}_1)\\) nhỏ hơn khi \\(x_i\\) trải rộng hơn quanh giá trị trung bình của nó. Chúng ta cũng thấy rằng \\(SE(\\hat{\\beta}_0)\\) sẽ giống như độ lệch chuẩn của trung bình mẫu nếu \\(\\bar{x}\\) bằng 0. Điểm đáng lưu ý là \\(\\sigma^2\\) cũng là một đại lượng chưa biết chưa nhưng có thể ước lượng được từ dữ liệu. Ước lượng cho \\(\\sigma\\) được gọi là độ lệch chuẩn của phần dư, ký hiệu RSE (hay Residual Standard Error), và được tính theo công thức\n\\[\\begin{align}\nRSE = \\sqrt{RSS/(n - 2)}\n\\tag{9.9}\n\\end{align}\\]RSE có thể được sử dụng để tính toán các khoảng tin cậy cho các hệ số ước lượng. Khoảng tin cậy ở một mức xác suất, chẳng hạn như mức \\(\\alpha\\), được định nghĩa là một khoảng giá trị sao cho với xác suất \\(\\alpha\\), khoảng giá trị đó sẽ chứa giá trị thực chưa biết của tham số. Với giả thiết phần dư \\(\\epsilon\\) có phân phối chuẩn, có thể chứng minh được rằng \\(\\hat{\\beta_0}\\) và \\(\\hat{\\beta_1}\\) cũng có phân phối chuẩn. Khoảng tin cậy ở mức xác suất \\(\\alpha\\) được sử dụng là làm các khoảng tin cậy cho tham số \\(\\beta_i\\); với = 1, 2; có dạng\n\\[\\begin{align}\n\\left[\\hat{\\beta_i} - z_{1 + \\alpha/2} \\cdot SE(\\hat{\\beta_i}); \\hat{\\beta_i} + z_{1 + \\alpha/2} \\cdot SE(\\hat{\\beta_i}) \\right]\n\\end{align}\\]\ntrong đó \\(z_{1+\\alpha/2}\\) là giá trị tại mức xác suất \\((1 + \\alpha/2)\\) của biến ngẫu nhiên phân phối chuẩn \\(\\mathcal{N}(0,1)\\).Quay trở lại với ví dụ về doanh thu bán hàng phụ thuộc vào chi phí quảng cáo trên truyền hình. Với mức độ tin cậy \\(\\alpha = 95\\%\\), giá trị tại mức xác suất \\((1 + \\alpha/2)\\) của phân phối chuẩn \\(\\mathcal{N}(0,1)\\) xấp xỉ bằng 1.96. Ta có các khoảng tin cậy tại mức xác suất 95% cho hệ số chặn là\n\\[\\begin{align}\n(3.372; 6.834)\n\\end{align}\\]\nvà khoảng tin cậy cho hệ số góc là\n\\[\\begin{align}\n(0.012; 0.036)\n\\end{align}\\]Điều này có nghĩa là, không tính đến quảng cáo trên truyền hình, doanh thu trung bình của các cửa hàng rơi vào khoảng 3.372 tỷ đồng đến 6.834 tỷ đồng. Đồng thời, mỗi triệu đồng tăng thêm cho quảng cáo trên truyền hình, sẽ làm cho doanh thu trung bình tăng thêm khoảng 12.4 triệu đồng đến 35.7 triệu đồng.Độ lệch tiêu chuẩn còn được sử dụng để trả lời câu hỏi là liệu mối liên hệ giữa biến \\(X\\) và \\(Y\\) có thực sự có ý nghĩa. Theo thống kê toán, chúng ta cần phải kiểm đinh cặp giả thuyết:\n\\[\\begin{align}\nH_0: \\beta_1 = 0 \\\\\nH_1: \\beta_1 \\neq 0\n\\end{align}\\]\nvì nếu \\(\\beta_1 = 0\\) thì mô hình hồi quy tuyến tính đơn trở thành \\(Y = \\beta_0 + \\epsilon\\) và \\(X\\) không có liên hệ với \\(Y\\) . Để kiểm định giả thuyết \\(H_0\\), chúng ta cần xác định xem liệu ước lượng của \\(\\beta_1\\), là \\(\\hat{\\beta}_1\\), có đủ xa giá trị 0 để chúng ta có thể tin tưởng rằng \\(\\beta_1\\) khác 0 hay không. Nhưng như thế nào là đủ xa thì lại phụ thuộc vào độ chính xác của \\(\\hat{\\beta}_1\\), nghĩa là cũng phụ thuộc vào \\(SE(\\hat{\\beta}_1)\\). Nếu \\(\\hat{\\beta}_1\\) tương đối nhỏ, nhưng \\(SE(\\hat{\\beta}_1)\\) lại rất nhỏ, thì chúng ta vẫn có thể khá chắc chắn rằng \\(\\beta \\neq 0\\), và đó có mối liên hệ giữa \\(X\\) và \\(Y\\). Ngược lại, nếu \\(\\hat{\\beta}_1\\) tương đối xa giá trị 0, nhưng \\(SE(\\hat{\\beta}_1)\\) lại rất lớn, thì cũng rất khó để khẳng định rằng \\(\\beta \\neq 0\\). Trong thực tế, chúng ta tính toán một thống kê t\n\\[\\begin{align}\nt = \\cfrac{\\hat{\\beta}_1 - 0}{SE(\\hat{\\beta}_1)}\n\\tag{9.10}\n\\end{align}\\]\ndùng để đo độ lệch tương đối giữa \\(\\hat{\\beta}\\) với giá trị 0. Với giả thiết \\(\\epsilon\\) có phân phối chuẩn, và dưới giả thuyết \\(H_0\\), có thể chứng minh được rằng thống kê \\(t\\) sẽ có phân phối student với bậc tự là \\(n-2\\). Phân phối student cũng có hình dạng quả chuông giống như phân phối chuẩn và sẽ tiệm cận phân phối chuẩn nếu tham số bậc tự đủ lớn. đó, chúng ta có thể tính toán được xác suất mà một biến ngẫu nhiên phân phối student bất kỳ có giá trị tuyệt đối lớn hơn hoặc bằng giá trị thống kê \\(t\\) tính toán được trong phương trình (9.10). Xác suất này còn thường được gọi là p-value.Nhìn chung, chúng ta có thể suy diễn p-value như sau: nếu p-value nhận giá trị nhỏ thì rất khó có thể có được giá trị thống kê \\(t\\) có giá trị tuyệt đối lớn như vậy dưới giả thuyết \\(H_0\\), nghĩa là có cơ sở để bác bỏ giả thuyết \\(H_0\\). Hay nói một cách khác, có mối liên hệ giữa biến độc lập và biến mục tiêu. Giá trị p-value thường được coi là nhỏ nếu nằm dưới các ngưỡng như 5% hoặc thậm chí 1%.\nBảng 9.1: Các hệ số ước lượng trong mô hình hồi quy đơn cho dữ liệu Quảng cáo\nBảng 9.1 cung cấp thông tin chi tiết về tham số ước lượng được trong mô hình hồi quy tuyến tính đơn bằng phương pháp bình phương nhỏ nhất để hồi quy doanh thu bán hàng đơn theo ngân sách quảng cáo trên truyền hình trong dữ liệu về quảng cáo. Lưu ý rằng các hệ số \\(\\hat{\\beta_0}\\) và \\(\\hat{\\beta_1}\\) rất lớn với độ lệch chuẩn của các ước lượng này, đó giá trị thống kê t cũng lớn. Xác suất để một biến ngẫu nhiên phân phối Student có tham số bậc tự bằng 55 - 2 = 53 có giá trị lớn hơn các giá trị tuyệt đối của thống kê \\(t\\) dưới giả thuyết \\(H_0\\) đúng là gần như bằng 0. đó chúng ta có thể kết luận rằng \\(\\beta_0 \\neq 0\\) và \\(\\beta_1 \\neq 0\\).","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"đánh-giá-mô-hình-hồi-quy-tuyến-tính-đơn","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.1.3 Đánh giá mô hình hồi quy tuyến tính đơn","text":"Sau khi chúng ta đã bác bỏ giả thuyết về các hệ số bằng 0, công việc tiếp theo sẽ là đưa ra các đánh giá định lượng về mức độ phù hợp của mô hình với dữ liệu. Chất lượng của mô hình hồi quy tuyến tính thường được đánh giá bằng cách sử dụng hai đại lượng: thứ nhất: độ lệch chuẩn của phần dư và hệ số \\(R^2\\).Độ lệch chuẩn của phần dư được gọi là Residual Standard Error hay viết tắt là RSE. Phần dư trong mô hình tuyến tính là phần độc lập với biến giải thích \\(X\\), nghĩa là trong các mô hình có sự hiện diện của phần dư, ngay cả khi chúng ta biết được đường hồi quy thực cũng không thể đưa ra dự đoán chính xác được về \\(Y\\) từ \\(X\\). Phần dư luôn có giá trị trung bình bằng 0 vì nếu không phần giá trị trung bình sẽ được giải thích bằng hệ số chặn. đó, người xây dựng mô hình thường quan tâm đến độ lệch chuẩn của phần dư, hay còn gọi là RSE\n\\[\\begin{align}\nRSE = \\sqrt{\\cfrac{RSS}{n-2}} = \\sqrt{\\cfrac{\\sum\\limits_{=1}^n (y_i - \\hat{y}_i)^2 }{n-2}}\n\\tag{9.11}\n\\end{align}\\]Trong mô hình hồi quy tuyến tính trên dữ liệu Quảng cáo, RSE bằng 0.235. Điều này có nghĩa là sai số giữa doanh thu bán hàng thực tế và doanh thu bán hàng được ước lượng từ mô hình hồi quy tuyến tính sẽ có độ lệch chuẩn khoảng 0.235 tỷ đồng. Tuy nhiên, độ lệch chuẩn là 0.235 có phải là con số có thể chấp nhận được hay không còn tùy thuộc vào bối cảnh. Trong dữ liệu quảng cáo, giá trị trung bình của doanh số bán hàng trên tất cả các cửa hàng là khoảng 8.7 tỷ đồng và đó sai số phần trăm là khoảng 0.235/8.7 \\(\\approx\\) 2.7 %. RSE có thể coi là thước đo mức độ phù hợp của các mô hình tuyến tính trên dữ liệu. Nếu các dự đoán thu được bằng cách sử dụng mô hình rất gần với giá trị kết quả thực, tức là, nếu các \\(\\hat{y}_i\\) rất gần với các \\(y_i\\), với \\(= 1, 2, \\cdots, n\\), khi đó RSE sẽ nhỏ và chúng ta có thể kết luận rằng mô hình rất phù hợp với dữ liệu. Mặt khác, \\(\\hat{y}_i\\) rất xa các \\(y_i\\) đối với một hoặc nhiều quan sát thì RSE có thể khá lớn, cho thấy mô hình không phù hợp với dữ liệu.RSE là một thước đo tuyệt đối về sự phù hợp của mô hình hồi quy tuyến tính trên dữ liệu. Nhưng vì RSE được đo bằng độ lệch chuẩn nên khi tính toán RSE tương đối trên giá trị trung bình của \\(Y\\) sẽ không cho chúng ta một cái nhìn chính xác thế nào là một RSE tốt. Thay vào đó, hệ số \\(R^2\\) cung cấp một thước đo tương đối về mức độ phù hợp của mô hình. \\(R^2\\) có dạng tỷ lệ giữa phương sai được giải thích trên tổng phương sai nên hệ số này luôn nhận giá trị từ 0 đến 1 và không phụ thuộc vào đơn vị của biến \\(Y\\). Hệ số \\(R^2\\), hay còn được gọi là R-squared, được tính bằng công thức sau\n\\[\\begin{align}\nR^2 = \\cfrac{TSS - RSS}{TSS} = 1 - \\cfrac{RSS}{TSS}\n\\tag{9.11}\n\\end{align}\\]\nvới \\(TSS = \\sum (y_i - \\bar{y})^2\\).TSS là viết tắt của Total Sum Squares, là tổng phương sai của biến mục tiêu \\(Y\\) và có thể được coi là mức độ biến thiên của biến mục tiêu xung quanh giá trị trung bình của nó. Giá trị này không phụ thuộc vào mô hình hồi quy tuyến tính. RSS đo lường mức độ biến thiên mà không giải thích được bởi mô hình hồi quy tuyến tính. đó, TSS − RSS đo lường mức độ biến thiên được giải thích bằng cách thực hiện hồi quy và hệ số \\(R^2\\) đo lường tỷ lệ biến thiên của biến mục tiêu \\(Y\\) có thể được giải thích bằng biến giải thích \\(X\\) trong mô hình tuyến tính. Hệ số \\(R^2\\) gần bằng 1 cho biết rằng phần lớn sự biến thiên trong biến mục tiêu đã được giải thích bằng mô hình hồi quy. Giá trị \\(R^2\\) càng gần 0 cho thấy mô hình hồi quy không giải thích được nhiều về sự biến thiên của biến mục tiêu. Mô hình có \\(R^2\\) nhỏ thông thường là dạng của mô hình tuyến tính là sai, mô hình tuyến tính bị thiếu biến giải thích, hoặc phần dư \\(\\epsilon\\) có phương sai lớn.Các đại lượng RSS, RSE, TSS, và R-squared trong mô hình tuyến tính đơn mà biến mục tiêu doanh thu được hồi quy theo chi phí quảng cáo trên truyền hình được cho trong bảng 9.2\nBảng 9.2: Đo lường mức độ phù hợp của mô hình tuyến tính đơn trên dữ liệu Quảng cáo\nTrong Bảng 9.2, R-squared bằng 0.237 có nghĩa là chỉ 23.7% sự biến thiên trong doanh số được giải thích bằng hồi quy tuyến tính theo chi phí quảng cáo trên truyền hình. Rõ ràng, hệ số R-squared dễ dàng diễn giải hơn với RSE, vì đại lượng này luôn nằm trong khoảng từ 0 đến 1. Tuy nhiên, vẫn có thể gặp khó khăn khi xác định thế nào là giá trị R-squared tốt. Điều này lại tùy thuộc vào từng ngữ cảnh thực tế. Ví dụ, trong một số dữ liệu thu thập được từ vật lý hay khoa học máy tính, chúng ta có thể đã biết rằng dữ liệu thực sự đến từ một mô hình tuyến tính có phần dư nhỏ. Hệ số R-squared thu được sẽ xấp xỉ bằng 1 và giá trị R-squared nhỏ hơn 0.9 có thể cho thấy có vấn đề với thử nghiệm mà dữ liệu được tạo ra. Mặt khác, trong các ứng dụng điển hình về kinh tế hay xã hội học, các mô hình tuyến tính thường có phần dư có phương sai rất lớn có rất nhiều các yếu tố khác không được đo lường được từ dữ liệu. Trong trường hợp này, chúng ta chỉ cần một tỷ lệ phương sai được giải thích rất nhỏ. Hệ số R-squared bằng 0.05 hoặc 0.1 trong các dữ liệu như vậy lại có thể là bằng chứng cho một mô hình tốt!Trong mô hình hồi quy tuyến tính đơn biến, giá trị R-squared chính là bình phương của hệ số tương quan giữa biến mục tiêu \\(Y\\) và biến độc lập \\(X\\). Hệ số tương quan giữa \\(Y\\) và \\(X\\), ký hiệu \\(\\rho(X,Y)\\), và được ước lượng bằng công thức như sau\n\\[\\begin{align}\n\\hat{\\rho}(X,Y) = \\cfrac{ \\sum\\limits_{=1}^n (x_i - \\bar{x})(y_i - \\bar{y}) }{ \\sqrt{\\sum\\limits_{=1}^n (x_i - \\bar{x})^2}\\sqrt{\\sum\\limits_{=1}^n (y_i - \\bar{y})^2} }\n\\end{align}\\]Hệ số tương quan \\(\\rho(X,Y)\\) đo lường mối liên hệ tuyến tính giữa hai biến \\(X\\) và \\(Y\\). Hệ số \\(\\rho(X,Y)\\) nằm trong khoảng \\([-1,1]\\), vàKhi \\(\\rho(X,Y) = 0\\), chúng ta nói rằng giữa \\(X\\) và \\(Y\\) không có mối liên hệ tuyến tính.Khi \\(\\rho(X,Y) > 0\\), chúng ta nói rằng giữa \\(X\\) và \\(Y\\) có mối liên hệ tuyến tính cùng chiều, nghĩa là khi \\(X\\) tăng thì nhiều khả năng \\(Y\\) cũng sẽ tăng theo một tỷ lệ cố định.Khi \\(\\rho(X,Y) < 0\\), chúng ta nói rằng giữa \\(X\\) và \\(Y\\) có mối liên hệ tuyến tính ngược chiều, nghĩa là khi \\(X\\) tăng thì nhiều khả năng \\(Y\\) sẽ giảm theo một tỷ lệ cố định.Bạn đọc hãy lưu ý rằng đẳng thức \\(R^2 = \\left(\\hat{\\rho}(X,Y)\\right)^2\\) chỉ đúng trong mô hình hồi quy đơn biến. Trong phần tiếp theo, chúng ta sẽ thảo luận về mô hình hồi quy tuyến tính đa biến, trong đó chúng ta sẽ sử dụng đồng thời nhiều biến độc lập để giải thích một biến mục tiêu. Chúng ta sẽ thấy nhiều hơn ý nghĩa của hệ số R-squared trong các mô hình như vậy.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"mô-hình-hồi-quy-tuyến-tính-đa-biến","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.2 Mô hình hồi quy tuyến tính đa biến","text":"Hồi quy tuyến tính đơn là một phương pháp hữu ích để dự đoán biến mục tiêu dựa trên một biến giải thích duy nhất. Tuy nhiên, trong thực tế chúng ta thường có nhiều hơn một yếu tố để giải thích biến mục tiêu. Ví dụ: trong dữ liệu Quảng cáo, chúng ta đã kiểm tra mối quan hệ giữa doanh thu bán hàng và ngân sách quảng cáo trên truyền hình. Chúng ta cũng có dữ liệu về số tiền chi cho quảng cáo trên các mạng xã hội và quảng cáo thông qua tờ rơi, đó chúng ta sẽ muốn biết rằng liệu các phương thức quảng cáo này có liên quan đến doanh thu bán hàng hay không; nghĩa là làm cách nào chúng ta có thể mở rộng phân tích dữ liệu Quảng cáo để phù hợp khi bổ sung thêm hai biến giải thích.Bạn đọc có thể sử dụng ba mô hình hồi quy tuyến tính đơn riêng biệt, mỗi mô hình sử dụng một biến giải thích tương ứng với một phương thức quảng cáo khác nhau làm biến giải thích. Kết quả ước lượng ba mô hình tuyến tính đơn được cho trong các Bảng 9.3, 9.4, và 9.5\nBảng 9.3: Doanh thu bán sản phẩm phụ thuộc vào chi phí quảng cáo trên truyền hình\n\nBảng 9.4: Doanh thu bán sản phẩm phụ thuộc vào chi phí quảng cáo trên mạng xã hội\n\nBảng 9.5: Doanh thu bán sản phẩm phụ thuộc vào chi phí quảng cáo tờ rơi\nBạn đọc có thể nhận thấy rằng nếu sử dụng ba mô hình hồi quy đơn, các biến giải thích đều có tác động lên biến mục tiêu một cách có ý nghĩa các giá trị p-value đều rất nhỏ. Chúng ta sẽ thảo luận chi tiết về các hệ số tuyến tính trong các Bảng 9.3, 9.4, và 9.5 trong phần sau của cuốn sách. Tuy nhiên cách tiếp cận như trên sẽ gặp phải hai vấn đề. Thứ nhất: chúng ta sẽ không biết làm thế nào để đưa ra một dự đoán duy nhất về doanh thu bán hàng tương ứng với một phân bổ ngân sách quảng cáo cho ba hình thức quảng cáo, vì khi phân bổ ngân sách đến từng phương tiện quảng cáo sẽ có ba giá trị dự đoán riêng biệt. Thứ hai, mỗi phương trình hồi quy đơn đều bỏ qua hai phương tiện còn lại trong việc hình thành ước tính cho các hệ số hồi quy. Chúng ta sẽ sớm thấy rằng nếu ngân sách truyền thông có tương quan với nhau tại các cửa hàng, điều mà rất có thể xảy ra, thì điều này có thể dẫn đến những ước lượng có sai lệch rất lớn về tác động của từng phương tiện quảng cáo lên doanh thu bán hàng.Thay vì điều chỉnh một mô hình hồi quy tuyến tính đơn giản riêng biệt cho từng yếu tố dự đoán, cách tiếp cận tốt hơn là mở rộng mô hình hồi quy tuyến tính đơn bằng cách cho tương ứng với mỗi biến giải thích một hệ số góc riêng. Nói chung, giả sử rằng chúng ta có \\(p\\) biến giải thích riêng biệt. Khi đó mô hình hồi quy tuyến tính đa biến có dạng\n\\[\\begin{align}\nY = \\beta_0 + \\beta_1 \\cdot X_1 + \\beta_2 \\cdot X_2 + \\cdots + \\beta_p \\cdot X_p + \\epsilon\n\\tag{9.12}\n\\end{align}\\]\ntrong đó \\(X_j\\) đại diện cho biến giải thích thứ \\(j\\) và hệ số \\(\\beta_j\\) định lượng mối liên hệ tuyến tính giữa biến giải thích đó và biến mục tiêu. Có thể coi \\(\\beta_j\\) là đại lượng phản ánh sự thay đổi của biến mục tiêu \\(Y\\) khi biến giải thích \\(X_j\\) tăng thêm một đơn vị trong khi tất cả các biến giải thích khác không thay đổi. Trong ví dụ về dữ liệu quảng cáo, ta có mô hình hồi quy tuyến tính như sau\n\\[\\begin{align}\n\\text{Sales} = \\beta_0 + \\beta_1 \\times \\text{TV} + \\beta_2 \\times \\text{Social_Media} + \\beta_3 \\times \\text{Flyer} + \\epsilon\n\\tag{9.13}\n\\end{align}\\]\ntrong đó Sales là doanh thu từ bán hàng của 55 cửa hàng, TV là chi phí quảng cáo trên truyền hình, Social_Media là chi phí quảng cáo qua mạng xã hội, và Flyer là chi phí quảng cáo qua tờ rơi.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"ước-lượng-tham-số-cho-mô-hình-đa-biến","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.2.1 Ước lượng tham số cho mô hình đa biến","text":"Tương tự như trong mô hình hồi quy tuyến tính đơn, các hệ số hồi quy \\(\\beta_0\\), \\(\\beta_1\\), \\(\\cdots\\), \\(\\beta_p\\) trong phương trình (9.12) là chưa biết và cần được ước lượng. Các tham số này cũng được ước lượng bằng cách sử dụng phương pháp bình phương nhỏ nhất. Tuy nhiên, không giống như các ước lượng hồi quy tuyến tính đơn, các ước lượng hệ số hồi quy đa biến khá phức tạp cần được biểu diễn dưới dạng véc-tơ và ma trận. Chính vì lý này, chúng tôi không đi sâu vào vấn đề này ở đây. Chi tiết của phương pháp bình phương nhỏ nhất trong hồi quy đa biến bạn đọc có thể tham khảo trong phần 9.3. Với các ước lượng \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\), \\(\\cdots\\), \\(\\hat{\\beta}_p\\) chúng ta có thể đưa ra dự đoán cho biến mục tiêu \\(y\\) như sau\n\\[\\begin{align}\n\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot x_1 + \\hat{\\beta}_2 \\cdot x_2 + \\cdots + \\hat{\\beta}_p \\cdot x_p\n\\tag{9.14}\n\\end{align}\\]Bạn đọc có thể sử dụng hàm lm() để thực hiện ước lượng các hệ số tuyến tính. Chúng ta thực hiện ước lượng mô hình đa biến cho dữ liệu Quảng cáo như sau\nBảng 9.6: Các hệ số ước lượng trong mô hình hồi quy đa biến cho dữ liệu Quảng cáo\nBảng 9.6 hiển thị ước tính hệ số hồi quy đa biến khi ngân sách quảng cáo trên truyền hình, mạng xã hội, và tờ rơi được sử dụng để dự đoán doanh thu bán sản phẩm trên dữ liệu Quảng cáo. Chúng ta có thể giải thích những kết quả này như sau:Đối với một ngân sách cố định cho quảng cáo trên truyền hình và một ngân sách cố định cho quảng cáo qua mạng xã hội, việc chi thêm 1 triệu đồng cho quảng cáo bằng hình thức tờ rơi sẽ dẫn đến doanh thu bán hàng trung bình tăng khoảng 11.7 triệu đồng. Con số tương tự với quảng cáo trên truyền hình và qua mạng xã hội lần lượt là 63 triệu đồng và 16.3 triệu đồng. sánh các con số này với các Bảng 9.3, 9.4, và 9.5, chúng ta có thể nhận thấy rằng các hệ số ước lượng đã thay đổi đáng kể với việc sử dụng ba mô hình hồi quy đơn biến.Trong mô hình hồi quy đơn, hệ số tuyến tính của biến chi phí quảng cáo qua tờ rơi (Flyer) là có ý nghĩa, trong khi trong mô hình hồi quy đa biến, hệ số của biến này lại không khác 0 một cách có ý nghĩa. Điều này thể hiện qua giá trị của thống kê \\(t\\) khá nhỏ và p-value khá lớn (khoảng 0.343)Sự khác biệt này xuất phát từ thực tế là trong trường hợp hồi quy đơn, hệ số góc thể hiện tác động trung bình của việc tăng 1 triệu đồng trong quảng cáo qua tờ rơi và bỏ qua các yếu tố dự đoán khác là quảng cáo qua truyền hình và qua mạng xã hội. Ngược lại, trong mô hình hồi quy đa biến, hệ số tuyến tính của biến Flyer thể hiện tác động trung bình của việc tăng chi phí quảng cáo qua tờ rơi thêm 1 triệu đồng trong khi giữ nguyên chi phí quảng cáo trên truyền hình và qua mạng xã hội. Vậy liệu có hợp lý không khi mô hình hồi quy đa biến cho thấy không có mối quan hệ giữa doanh thu bán hàng và chi phí quảng cáo qua tờ rơi trong khi hồi quy tuyến tính đơn lại hàm ý ngược lại? Câu trả lời là có! Hãy quan sát ma trận hệ số tương quan của ba biến giải thích và biến mục tiêu trong Bảng ??.\nHình 9.4: Ma trận hệ số tương quan của các biến trong dữ liệu Quảng cáo\nBạn đọc có thể thấy rằng hệ số tương quan giữa chi phí quảng cáo qua tờ rơi,biến Flyer, với hai biến giải thích còn lại bao gồm TV và Social_Media là khá cao, lần lượt là 0.54 và 0.51. Điều này cho thấy xu hướng chi tiêu nhiều hơn cho quảng cáo qua hình thức tờ rơi ở các cửa hàng nơi chi tiêu nhiều hơn cho quảng cáo trên qua truyền hình hoặc qua mạng xã hội. Các mô hình hồi quy đơn và mô hình hồi quy đa biến đều cho kết luận là tăng chi tiêu quảng cáo qua truyền hình và quảng cáo qua mạng xã hội thực sự có ý nghĩa làm tăng doanh thu. Giả sử rằng kết luận này là đúng, khi đó việc sử dụng mô hình hồi quy tuyến tính đơn để kiểm tra mối liên hệ giữa doanh thu bán hàng theo quảng cáo trên tờ rơi cho hệ số ước lượng có ý nghĩa là cả hai biến này đều có tương quan cao với chi phí quảng cáo qua truyền hình và mạng xã hội, chứ thực sự thì chi tiêu cho quảng cáo qua tờ rơi không có tác động đến doanh thu bán hàng.Đây là kết quả rất thường gặp khi xây dựng mô hình trên dữ liệu thực tế. Một ví dụ thường được nhắc đến để mô tả tình huống này trong nhiều sách tham khảo là khi hồi quy số các cuộc tấn công của cá mập theo doanh số bán kem trên các bãi biển trong một khoảng thời gian nhất định. Đây là hai biến về bản chất không có mối liên hệ nhưng sẽ cho hệ số góc là một số dương có ý nghĩa thống kê. Cũng giống như chi phí quảng cáo qua hình thức tờ rơi và doanh thu bán hàng, việc không tính đến các biến giải thích có tác động thực sự lên biến mục tiêu sẽ khiến cho chúng ta lầm tưởng rằng doanh số bán kem có tác động đến số cuộc tấn công của cá mập! Trên thực tế, nhiệt độ cao hơn khiến nhiều người đến bãi biển hơn, từ đó dẫn đến doanh số bán kem nhiều hơn và nhiều vụ cá mập tấn công hơn. Nếu chúng ta xây dựng mô hình hồi quy bội mà số các cuộc tấn công của cá mập phụ thuộc vào doanh số bán kem và nhiệt độ của vùng đó sẽ cho kết quả là doanh số bán kem không còn có ý nghĩa giải thích số các cuộc tấn công!","code":"\n# Doanh thu bán hàng (Sales) hồi quy theo 3 biến\nlm(Sales ~ TV + Social_Media + Flyer, data = Advertising)"},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"kiểm-định-mô-hình-tuyến-tính-đa-biến","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.2.2 Kiểm định mô hình tuyến tính đa biến","text":"Mục đích của kiểm định mô hình đa biến là để trả lời hai câu hỏiThứ nhất: mô hình hồi quy có ý nghĩa giải thích biến mục tiêu \\(Y\\) hay không? Hay nói một cách khác là có ít nhất một biến trong số các biến giải thích \\(X_1\\), \\(X_2\\), \\(\\cdots\\), \\(X_p\\) có tác động lên biến mục tiêu?Thứ hai: nếu mô hình hồi quy đa biến có ý nghĩa, thì tất cả các biến đều có ý nghĩa tác động lên biến mục tiêu, hay chỉ một tập hợp con các biến có tác động?Để trả lời cho câu hỏi thứ nhất, nhắc lại với bạn đọc rằng trong kiểm định mô hình hồi quy tuyến tính đơn, để xác định liệu có mối quan hệ giữa biến mục tiêu và biến giải thích hay không, chúng ta chỉ cần kiểm định giả thuyết \\(H_0: \\beta_1 = 0\\). Trong mô hình hồi quy đa biến với \\(p\\) biến giải thích dự đoán, chúng ta cần kiểm định giả thuyết liệu hệ số hồi quy của tất cả các biến giải thích đều bằng 0, tức là liệu có xảy ra trường hợp \\(\\beta_1 = \\beta_2 = \\cdots = \\beta_p = 0\\). Cặp giả thuyết \\(H_0\\) - \\(H_1\\) trong mô hình hồi quy đa biến được viết như sau\n\\[\\begin{align}\n& H_0: \\beta_1 = \\beta_2 = \\cdots = \\beta_p = 0 \\\\\n& H_1: \\text{ít nhất có một } \\beta_j \\text{ khác 0}\n\\tag{9.15}\n\\end{align}\\]Để kiểm định cặp giả thuyết trong (9.15), chúng ta sử dụng thống kê \\(F\\)\n\\[\\begin{align}\nF = \\cfrac{(TSS - RSS)/p}{RSS/(n-p-1)}\n\\tag{9.16}\n\\end{align}\\]Nếu giả thuyết \\(H_0\\) là đúng thì thống kê \\(F\\) sẽ có phân phối \\(\\mathcal{F}(p, n - p - 1)\\). giá trị trung bình của biến ngẫu nhiên phân phối \\(\\mathcal{F}(p, n - p - 1)\\) là 1 nên khi giá trị thống kê \\(F\\) lớn thì khả năng bác bỏ giả thuyết \\(H_0\\) là lớn. Để hiểu được tại sao lại sử dụng phân phối \\(\\mathcal{F}\\) để kiểm định giả thuyết, bạn đọc tham khảo phần 9.3. Chúng tôi không giải thích chi tiết vấn đề này tại đây để tránh sự phức tạp không cần thiết.Thống kê \\(F\\) cho mô hình hồi quy tuyến tính đa biến thu được bằng cách hồi quy doanh thu bán hàng theo chi phí quảng cáo qua truyền hình, mạng xã hội, và tờ rơi được trình bày là 18.75. Vì giá trị này lớn hơn 1 rất nhiều nên đây có cơ sở để bác bỏ giả thuyết \\(H_0\\). Nói cách khác, giá trị thống kê \\(F\\) lớn cho thấy rằng ít nhất một trong các phương tiện quảng cáo phải liên quan đến doanh thu bán hàng. Tuy nhiên, thống kê \\(F\\) cần phải lớn đến mức nào để chúng ta có thể bác bỏ \\(H_0\\) và kết luận rằng có mối quan hệ và điều gì sẽ xảy ra nếu thống kê \\(F\\) gần với 1 hơn? Để trả lời câu hỏi này còn phụ thuộc vào giá trị của \\(n\\) và \\(p\\). Khi \\(n\\) lớn, ngay cả khi thống kê \\(F\\) chỉ lớn hơn 1 một chút chúng ta vẫn có thể có cơ sở để bác bỏ \\(H_0\\). Ngược lại, thống kê \\(F\\) cần lớn hơn để có cơ sở bác bỏ \\(H_0\\) nếu \\(n\\) nhỏ.Bạn đọc có thể quan sát hàm mật độ của biến ngẫu nhiên phân phối \\(\\mathcal{F}\\) với các tham số \\((p = 3,n - p - 1 = 51)\\) trong Hình 9.5. Khả năng một biến ngẫu nhiên có phân phối \\(\\mathcal{F}\\) lớn hơn giá trị thống kê \\(F\\) tính toán từ dữ liệu là khoảng \\(2.5 \\times 10^{-8}\\). Nói cách khác, với p-value rất nhỏ, chúng ta có cơ sở để bác bỏ giả thuyết \\(H_0\\). Điều này đồng nghĩa với việc có ít nhất một ngân sách chi cho quảng cáo có tác động đến doanh thu bán hàng.\nHình 9.5: Hàm mật độ của phân phối F(3,51) cho dữ liệu quảng cáo. Giá trị thống kê F (F - value) đủ lớn để bác bỏ giả thuyết \\(H_0\\)\nĐể trả lời cho câu hỏi thứ hai, chúng ta cần thực hiện các kiểm định liệu một nhóm biến giải thích có tác động lên biến mục tiêu hay không. Giả sử các biến giải thích có số thứ tự lần lượt là \\(1 \\leq i_1 < i_2 < \\cdots < i_h \\leq p\\). Khi đó, giả thuyết \\(H_0\\) - \\(H_1\\) để thực hiện kiểm định giả thuyết được viết như sau\n\\[\\begin{align}\n& H_0: \\beta_{i_j} = 0 \\ \\ \\forall j = 1,2, \\cdots, h \\\\\n& H_1: \\text{Tồn tại ít nhất $j$ sao cho} \\ \\beta_{i_j} > 0\n\\tag{9.17}\n\\end{align}\\]Tương tự như trong trường hợp kiểm định giả thuyết trong phương trình (9.15), chúng ta có thể sử dụng phân phối \\(\\mathcal{F}\\) để thực hiện kiểm định giả thuyết. Thống kê \\(F\\) được tính toán như sau\n\\[\\begin{align}\nF = \\cfrac{(RSS_1 - RSS)/h}{RSS/(n-p-1)}\n\\tag{9.18}\n\\end{align}\\]\ntrong đó \\(RSS_1\\) là tổng bình phương sai số của mô hình hồi quy tuyến tính không bao gồm các biến độc lập có hệ số tuyến tính được liệt kê trong phương trình (9.17).Nếu giả thuyết \\(H_0\\) trong (9.17) là đúng, thì có thể chứng minh được rằng (tham khảo phần 9.3) thống kê \\(F\\) sẽ có phân phối \\(\\mathcal{F}(h,n-p-1)\\). Giá trị của thống kê \\(F\\) lớn cho thấy rằng ít nhất một trong các biến độc lập có hệ số tuyến tính được liệt kê trong phương trình (9.17) có tác động tuyến tính lên biến phụ thuộc. Trong trường hợp đặc biệt khi \\(h=1\\), nghĩa là khi chúng ta cần kiểm định từng biến có ý nghĩa ở trong mô hình hồi quy tuyến tính, giá trị thống kê \\(F\\) trong phương trình (9.18) chính là bình phương của thống kê \\(t\\) khi kiểm định từng biến độc lập riêng lẻ. Giá trị của thống kê \\(t\\) và giá trị p-value tương ứng khi kiểm định từng chi phí quảng cáo có tác động đến doanh thu bán hàng hay không được cho trong Bảng 9.6. Các giá trị p-value này chỉ ra rằng truyền hình và mạng xã hội có liên quan đến doanh thu bán hàng, nhưng không có bằng chứng nào cho thấy quảng cáo qua hình thức tờ rơi có liên quan đến doanh thu bán hàng khi tính đến cả quảng cáo trên truyền hình và quảng cáo qua mạng xã hội.Khi đã có các p-value riêng lẻ cho từng biến, tại sao chúng ta cần xem xét thống kê \\(F\\) trong kiểm định đồng thời? Liệu có phải rằng p-value của một biến riêng lẻ là nhỏ thì ít nhất một trong các yếu tố dự đoán có liên quan đến phản hồi? Điều này không phải lúc nào cũng đúng, đặc biệt khi số lượng biến giải thích \\(p\\) khá lớn. Chẳng hạn như khi số lượng biến giải thích \\(p = 20\\) và chúng ta kiểm định giả thuyết \\(H_0: \\beta_1 = \\beta_2 = \\cdots = \\beta_{20} = 0\\). Ngay cả khi \\(H_0\\) là thực sự đúng, thì với mức ý nghĩa 5%, vẫn sẽ có trung bình \\(5\\% \\times 20 = 1\\) (biến) không có p-value lớn hơn 0.05! Điều này cũng giống như khi chúng ta tạo ra 20 biến ngẫu nhiên phân phối Student thì sẽ có trung bình một biến rơi vào miền giá trị có xác suất 0.05. đó, nếu chúng ta sử dụng thống kê \\(t\\) riêng lẻ và các p-value liên quan để quyết định xem có bất kỳ mối liên hệ nào giữa các biến giải thích và biến mục tiêu hay không, thì có khả năng cao là chúng ta sẽ kết luận sai rằng có một mối quan hệ. Sử dụng thống kê \\(F\\) không gặp phải vấn đề này vì thống kê \\(F\\) có tính toán đến số lượng biến giải thích đưa vào trong kiểm định. Nếu giả thuyết \\(H_0\\) thực sự đúng thì chỉ có 5% khả năng thống kê \\(F\\) có p-value nhỏ hơn 0.05, bất kể số lượng biến giải thích là bao nhiêu.Bước đầu tiên trong xây dựng một mô hình tuyến tính thường là ước lượng mô hình và tính toán giá trị thống kê \\(F\\). Nếu chúng ta kết luận dựa trên p-value của thống kê \\(F\\) rằng ít nhất một trong các biến giải thích có liên quan đến biến mục tiêu, thì câu hỏi tiếp theo cần trả lời sẽ là các biến nào sẽ thực sự có ý nghĩa trong mô hình. Chúng ta có thể xem xét các p-value riêng lẻ cho từng biến như trong bảng 9.6, nhưng như đã thảo luận, nếu \\(p\\) khá lớn thì chúng ta có thể thực hiện một số nhận định sai. Quá trình xác định những biến giải thích có liên quan đến biến mục tiêu để tìm ra một mô hình duy nhất chỉ bao gồm các biến có liên quan được gọi là quá trình lựa chọn biến. Vấn đề lựa chọn biến được thảo luận kỹ hơn trong phần 9.4.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"kiểm-tra-sự-phù-hợp-của-mô-hình","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.2.3 Kiểm tra sự phù hợp của mô hình","text":"Như đã đề cập trong mô hình tuyến tính đơn, hai thước đo định lượng phổ biến nhất về mức độ phù hợp của mô hình hồi quy tuyến tính là sai số của phần dư RSE và hệ số R-squared. Hãy nhớ lại rằng trong hồi quy đơn, R-squared là bình phương hệ số tương quan giữa biến mục tiêu và biến giải thích. Trong hồi quy tuyến tính đa biến, có thể chứng minh được rằng hệ số R-squared chính là bình phương hệ số tương quan giữa \\(Y\\) và \\(\\hat{Y}\\). Giá trị R-squared gần bằng 1 cho thấy mô hình giải thích được phần lớn phương sai của biến mục tiêu. Hệ số R-squared trong hồi quy đa biến được tính toán dựa trên phương trình @ref\\tag{9.11} tương tự như hồi quy đơn. Hệ số R-squared được tính toán bằng hàm lm() như sauĐối với Dữ liệu quảng cáo, mô hình sử dụng cả ba phương tiện quảng cáo để dự đoán doanh thu bán hàng có hệ số R-squared là 0.524. Mặt khác, mô hình chỉ sử dụng TV và Social_Media để dự đoán doanh thu bán hàng có giá trị R-squared là 0.516. Nói cách khác, có một sự gia tăng nhỏ trong R-squared nếu chúng ta đưa quảng cáo bằng tờ rơi vào mô hình đã có sẵn quảng cáo trên truyền hình và mạng xã hội, mặc dù trước đó chúng ta đã thấy rằng giá trị p-value cho quảng cáo trên tờ rơi trong Bảng 9.6 là không đáng kể.Thực ra thì hệ số R-squared sẽ luôn tăng khi có nhiều biến hơn được thêm vào mô hình, ngay cả khi những biến đó không có liên quan hoặc liên quan yếu đến biến mục tiêu. Bạn đọc cần lưu ý vấn đề này khi lựa chọn mô hình. Hệ số R-squared mà chúng ta thảo luận ở đây chỉ là hệ số R-squared tính trên dữ liệu huấn luyện mô hình chứ không phải là trên dữ liệu kiểm tra mô hình. Theo kinh nghiệm thực tế thì khi thêm các biến như quảng cáo tờ rơi vào mô hình chỉ làm cho R-squared tăng thêm một chút là bằng chứng cho thấy biến Flyer nên bị loại khỏi mô hình. Ngược lại, khi chúng ta sử dụng mô hình chỉ chứa biến TV là biến giải thích có hệ số R-squared là 0.237. Việc thêm biến Social_Media vào mô hình sẽ dẫn đến sự cải thiện đáng kể về R-squared. Điều này ngụ ý rằng mô hình sử dụng hai biến chi phí quảng cáo qua truyền hình và qua mạng xã hội để dự đoán doanh thu bán hàng sẽ tốt hơn đáng kể với mô hình chỉ sử dụng quảng cáo trên truyền hình.RSE cũng có thể là một thước đo định lượng để đánh giá sự phù hợp của mô hình. Bạn đọc có thể quan sát RSE của các mô hình với tổ hợp các biến giải thích khác nhau trong bảng 9.7\nBảng 9.7: Sai số phần dư của các mô hình tuyến tính trên dữ liệu Quảng cáo\nTrong các mô hình đơn biến, có thể thấy rằng mô hình sử dụng biến Flyer làm biến giải thích có RSE thậm chí còn nhỏ hơn với mô hình chỉ sử dụng biến TV. Khi sử dụng hai biến để giải thích biến doanh thu, bạn đọc có thể nhận thấy rằng mô hình sử dụng TV và Social_Media có RSE nhỏ hơn hẳn với các mô hình còn lại. Khi thêm biến Flyer vào mô hình đã bao gồm TV và Social_Media, RSE gần như không thay đổi. Không giống như hệ số R-squared luôn tăng khi thêm biến vào mô hình, các mô hình có nhiều biến hơn có thể có RSE cao hơn nếu mức giảm RSS nhỏ hơn với sự gia tăng số lượng biến.Sau khi chúng ta đã tìm ra mô hình phù hợp, có thể sử dụng các hệ số tuyến tính để đưa ra dự đoán cho biến mục tiêu \\(Y\\) trên giá trị các biến giải thích \\(X_1, X_2, \\cdots , X_p\\). Tuy nhiên, trước khi đưa ra dự đoán cho biến mục tiêu dựa trên mô hình tuyến tính, có những vấn đề mà bạn đọc cần lưu ý:Thứ nhất: kể cả khi mối quan hệ giữa biến mục tiêu với các biến giải thích là mối quan hệ tuyến tính, thì chúng ta cũng không biết được giá trị thực của các hệ số tuyến tính. Các hệ số \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\cdots, \\hat{\\beta}_p\\) chỉ là các ước lượng cho các hệ số tuyến tính thực \\(\\beta_0, \\beta_1, \\cdots, \\beta_p\\) dựa trên dữ liệu quan sát được. Sai số giữa ước lượng và các giá trị thực có thể giảm bớt được dựa trên độ lớn của dữ liệu và kỹ năng của người xây dựng mô hình.Thứ hai: đó là sai số về mặt mô hình, nghĩa là mối quan hệ giữa các biến giải thích và các biến mục tiêu không phải là mối liên hệ tuyến tính nhưng chúng ta sử dụng mô hình tuyến tính để đưa ra dự đoán. Sai số này có thể được giảm bớt tùy theo kỹ năng của người xây dựng mô hình, chẳng hạn như sử dụng các phép biến đổi dữ liệu, hoặc thay đổi kiểu mô hình. Các mô hình phi tuyến sẽ được trình bày trong các Chương tiếp theo của cuốn sách.Thứ ba: đó là ngay cả khi chúng ta biết được mối quan hệ thực giữa biến mục tiêu và các biến giải thích, vẫn có những sai số mà hoàn toàn không thể được giải thích dựa trên dữ liệu. Các sai số này là không thể giảm bớt được.Với các ước lượng cho hệ số tuyến tính và sai số của phần dư, chúng ta có thể xây dựng được khoảng tin cậy với mức xác suất \\(\\alpha\\) cho giá trị trung bình của biến mục tiêu\n\\[\\begin{align}\n\\left(\\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot x_1 + \\cdots + \\hat{\\beta}_p \\cdot x_p - z_{1 - \\alpha/2} \\cdot \\hat{\\sigma} ; \\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot x_1 + \\cdots + \\hat{\\beta}_p \\cdot x_p + z_{1 - \\alpha/2} \\cdot \\hat{\\sigma}\\right)\n\\tag{9.19}\n\\end{align}\\]Đối với dữ liệu về chi phí quảng cáo và doanh thu bán sản phẩm, giả sử mô hình được lựa chọn là mô hình với hai biến giải thích là TV và Social_Media. Với ngân sách cho quảng cáo trên trền hình là 150 triệu đồng và ngân sách cho quảng cáo trên mạng xã hội 30 triệu, chúng ta có khoảng tin cậy 95% cho doanh thu bán sản phẩm là \\(\\left(8.64 , 9.38 \\right)\\) tỷ đồng. Khoảng tin cậy này được tính bởi các tham số được ước lượng từ dữ liệu quan sát như sau:\n\\[\\begin{align}\n& 8.64 = 4.06 + 0.019 \\times 150 + 0.07 \\times 30 - 1.96 \\times 0.189 \\\\\n& 9.38 = 4.06 + 0.019 \\times 150 + 0.07 \\times 30 + 1.96 \\times 0.189\n\\end{align}\\]","code":"\n# Hệ số R-squared trong mô hình hồi quy 3 biến\nsummary(lm(Sales ~ TV + Social_Media + Flyer,data = Advertising))$r.squared\n\n# Hệ số R-squared trong mô hình hồi quy 2 biến: TV, Social_Media\nsummary(lm(Sales ~ TV + Social_Media,data = Advertising))$r.squared"},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"những-cân-nhắc-khi-xây-dựng-mô-hình-hồi-quy-tuyến-tính","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.3 Những cân nhắc khi xây dựng mô hình hồi quy tuyến tính","text":"Trong phần này chúng ta sẽ thảo luận thêm về các vấn đề thường gặp phải khi xây dựng mô hình tuyến tính trên dữ liệu thực tế bao gồm có vấn đề biến giải thích có kiểu định tính và vấn đề về tồn tại mối liên hệ phi tuyến tính giữa biến mục tiêu và biến giải thích","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"biến-giải-thích-là-biến-định-tính","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.3.1 Biến giải thích là biến định tính","text":"Khi ước lượng hệ số tuyến tính bằng phương pháp bình phương nhỏ nhất, chúng ta luôn giả định rằng tất cả các biến trong mô hình đều là biến định lượng. Trong thực tế chúng ta lại rất hay thường gặp các biến giải thích là kiểu biến định tính. Ví dụ: dữ liệu có tên exposure.csv là dữ liệu về yêu cầu bồi thường viện phí và tổng số tiền bồi thường của khác hàng tham gia bảo hiểm sức khỏe tự nguyện tại một công ty bảo hiểm. Chúng tôi để mô hình ở dạng đơn giản nhất khi chỉ có hai biến phụ thuộc là giới tính, biến Gender, và độ tuổi, biến Age, của người được thanh toán bảo hiểm sức khỏe. Biến mục tiêu trong mô hình sẽ là số tiền bồi thường trung bình của những khách hàng, biến Ave_Claim, được tính bằng tổng số tiền của tất cả các lần bồi thường chia cho tổng số lần khách hàng gửi yêu cầu.Giả sử chúng ta muốn xây dựng mô hình tuyến tính mà biến mục tiêu là số tiền bồi thường trung bình của khách hàng và các biến giải thích là độ tuổi và giới tính của khách hàng. Biến Age có thể coi là biến định lượng và có thể nhận giá trị là mọi số tự nhiên từ 18 tuổi đến 65 tuổi. Biến Gender không thể được sử dụng như một biến định lượng bởi vì chúng ta không thể đưa ra các sánh định lượng giữa hai giá trị mà biến giới tính nhận.\nHình 9.6: Hình bên trái: Mối liên hệ giữa số tiền bồi thường trung bình với độ tuổi của người được bảo hiểm; Hình bên phải: Mối liên hệ giữa số tiền bồi thường trung bình với giới tính của người được bảo hiểm\nHình 9.6 mô tả mối liên hệ giữa số tiền yêu cầu bồi thường trung bình với độ tuổi và giới tính của người được bảo hiểm. Bạn đọc có thể thấy rằng có mối liên hệ giữa các biến giải thích đến các biến mục tiêu, số tiền yêu cầu bồi thường trung bình có xu hướng tăng khi tuổi của người được bảo hiểm tăng, và số tiền yêu cầu bồi thường trung bình của nam giới cao hơn với nữ giới. Như vậy tuổi và giới tính có nhiều khả năng là các biến có liên hệ đến biến mục tiêu. Ước lượng hệ số tuyến tính của biến Age có thể được thực hiện giống như các biến định lượng thông thường. Để sử dụng biến giới tính như một biến giải thích, chúng ta tạo một biến mới có dạng như sau\n\\[\\begin{align}\n\\text{Gender}_i = \\begin{cases}\n1 \\text{ nếu giới tính là nữ} \\\\\n0 \\text{ nếu giới tính là nam}\n\\end{cases}\n\\tag{9.20}\n\\end{align}\\]Mô hình tuyến tính với biến mục tiêu là số tiền yêu cầu bồi thường trung bình, biến \\(Y_i\\), và hai biến giải thích là độ tuổi, biến Age\\(_i\\), và giới tính, biến Gender\\(_i\\), được viết như sau\n\\[\\begin{align}\nY_i = & \\beta_0 + \\beta_1 \\cdot Gender_i + \\beta_2 \\cdot Age_i + \\epsilon_i \\\\\n= &\n\\begin{cases}\n(\\beta_0 + \\beta_1) + \\beta_2 \\cdot Age_i + \\epsilon_i  \\ \\ \\text{ nếu giới tính là nữ} \\\\\n\\beta_0 + \\beta_2 \\cdot Age_i + \\epsilon_i \\ \\ \\text{ nếu giới tính là nam}\n\\end{cases}\n\\tag{9.21}\n\\end{align}\\]Hệ số \\(\\beta_0\\) trong phương trình (9.19) là hệ số chặn trong mô hình hồi quy tuyến tính đơn mà số tiền yêu cầu bồi thường trung bình phụ thuộc vào độ tuổi nếu người được bảo hiểm là nam giới, trong khi \\((\\beta_0 + \\beta_1)\\) là hệ số chặn trong mô hình hồi quy tuyến tính đơn mà số tiền yêu cầu bồi thường trung bình phụ thuộc vào độ tuổi nếu người được bảo hiểm là nữ giới. Để ước lượng mô hình hồi quy tuyến tính với biến định tính Gender bằng hàm lm(), bạn đọc hãy đảm bảo biến định tính có kiểu factor trước khi đưa vào trong hàm ước lượng.\nBảng 9.8: Các hệ số ước lượng trong mô hình hồi quy tuyến tính với biến định tính Gender nhận một trong hai giá trị là Male hoặc Female\nHệ số ước lượng của mô hình tuyến tính với biến phụ thuộc định tính được trình bày trong bảng 9.8. Bạn đọc thấy rằng các hệ số ước lượng được đều có ý nghĩa thống kê vì giá trị p-value đều rất nhỏ. Hệ số tuyến tính của biến độ tuổi bằng 1.95 cho thấy rằng nếu tuổi của người được bảo hiểm tăng thêm 1 tuổi, thì số tiền bồi thường trung bình sẽ tăng khoảng 1.95 triệu đồng. Hệ số tuyến tính của biến Gender-Nữ là số âm cho biết cùng một độ tuổi, trung bình mỗi lần yêu cầu bồi thường nữ giới sẽ có số tiền yêu cầu ít hơn nữ giới khoảng 14.32 triệu đồng. Việc lựa chọn mã hóa giới tính trong phương trình (9.20) là hoàn toàn tự và không ảnh hưởng đến kết quả của mô hình hồi quy. Nếu bạn đọc sử dụng cách mã hóa nữ giới là 0 và nam giới là 1, kết quả thu được sẽ có hệ số của biến Gender-Nam là số dương, có giá trị bằng với giá trị tuyệt đối của hệ số của biến Gender-Nữ trong bảng 9.8.Bạn đọc có thể đặt ra câu hỏi về việc biến định tính nhận nhiều hơn hai giá trị. Cách ước lượng của mô hình tuyến tính là hoàn toàn tương tự như trường hợp hai biến. Giả sử mô hình hồi quy tuyến tính có biến \\(Y\\) là biến mục tiêu và hai biến giải thích: \\(X_1\\) là biến định lượng và \\(X_2\\) là biến định tính. \\(X_2\\) có thể nhận \\(J\\) giá trị khác nhau lần lượt là \\(1, 2, \\cdots, J\\). Khi đó, ước lượng mô hình tuyến tính có \\(J + 1\\) hệ số tuyến tính cần được ước lượng như sau\n\\[\\begin{align}\nY = \\begin{cases}\n\\beta_0 + \\beta_1 \\cdot X_1 + \\epsilon \\ \\ \\text{ nếu } X_2 = 1 \\\\\n(\\beta_0 + \\beta_2) + \\beta_1 \\cdot X_1 + \\epsilon \\ \\ \\text{ nếu } X_2 = 2 \\\\\n(\\beta_0 + \\beta_3) + \\beta_1 \\cdot X_1 + \\epsilon \\ \\ \\text{ nếu } X_2 = 3 \\\\\n\\cdots \\\\\n(\\beta_0 + \\beta_J) + \\beta_1 \\cdot X_1 + \\epsilon \\ \\ \\text{ nếu } X_2 = J\n\\end{cases}\n\\tag{9.22}\n\\end{align}\\]\nCó thể thấy rằng, nếu biến định tính nhận quá nhiều giá trị, số lượng tham số của mô hình tuyến tính tăng lên tương ứng. Khi mô hình sử dụng quá nhiều hệ số sẽ dễ dẫn đến hiện tượng overfitting. Giải pháp khi gặp biến định tính nhận nhiều giá trị là nhóm các giá trị có hệ số tuyến tính \\(\\beta\\) không khác nhau vào cùng một nhóm để giảm số lượng biến. Chúng ta sẽ thảo luận kỹ hơn về giải pháp này trong phần thực hành trên mô hình tuyến tính.","code":"\n# Load dữ liệu exposure\ndat<-read.csv(\"../KHDL_KTKD Final/Dataset/exposure.csv\")\n\n# Chỉ giữ lại những khác hàng có yêu cầu bồi thường\ndat<-filter(dat,Claim_Count>0)\ndat$Gender <- ifelse(dat$Gender == 0, \"Nam\", \"Nữ\")\n# Đổi dữ liệu cột Gender thành factor\ndat$Gender<-as.factor(dat$Gender)"},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"basiclmconsideration2","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.3.2 Mối quan hệ phi tuyến giữa biến mục tiêu và biến giải thích","text":"Mối liên hệ giữa số tiền yêu cầu bồi thường trung bình và biến độ tuổi trong Hình 9.6 không phải là một mối liên hệ tuyến tính. Bạn đọc có thể thấy rằng khi độ tuổi tăng thì số tiền yêu cầu bồi thường tăng lên nhanh hơn, điều này giải thích tại sao đường thẳng mô tả mối liên hệ giữa hai biến có độ dốc tăng dần khi độ tuổi tăng. Điều này gợi ý cho người xây dựng mô hình rằng mối liên hệ giữa số tiền bồi thường trung bình và độ tuổi là mối liên hệ phi tuyến hơn là tuyến tính. Đa số các phương pháp xây dựng mô hình hiện đại đều được xây dựng để mô tả mối quan hệ phi tuyến giữa biến giải thích và biến mục tiêu. Trong khuôn khổ mô hình hồi quy tuyến tính, chúng tôi giới thiệu một phương pháp tiếp cận đơn giản nhất, đó là hồi quy theo đa thức. Mối liên hệ giữa biến mục tiêu và biến giải thích trong Hình 9.6 có dạng parabol, đó chúng ta có thể thêm vào mô hình biến giải thích là bình phương của độ tuổi với hi vọng là sẽ có một mô hình giải thích tốt hơn biến mục tiêu. Mô hình có dạng như sau\n\\[\\begin{align}\nY = \\begin{cases}\n(\\beta_0 + \\beta_1) + \\beta_2 \\cdot \\text{Age} + \\beta_3 \\cdot \\text{Age}^2 + \\epsilon  \\ \\ \\text{ nếu giới tính là nam} \\\\\n\\beta_0 + \\beta_2 \\cdot \\text{Age}_i + \\beta_3 \\cdot \\text{Age}^2 + \\epsilon \\ \\ \\text{ nếu giới tính là nữ}\n\\end{cases}\n\\tag{9.23}\n\\end{align}\\]\nBảng 9.9: Các hệ số ước lượng trong mô hình hồi quy quy đa thức với bình phương của biến Age là biến giải thích\nKết quả ước lượng trong Bảng 9.9 cho thấy tất cả các hệ số tuyến tính đều có ý nghĩa, điều này cho thấy mối liên hệ giữa số tiền bồi thường trung bình và độ tuổi là mối liên hệ phi tuyến hơn là tuyến tính. Mô hình có biến giải thích độ tuổi bình phương có hệ số R-squared lớn hơn nhiều với mô hình không có biến độ tuổi bình phương, điều này cho thấy mô hình có biến độ tuổi bình phương phù hợp hơn để giải thích biến mục tiêu. Tuy nhiên, bạn đọc cũng có thể nhận thấy rằng, mô hình đã trở nên khó giải thích hơn một chút. Chúng ta không thể đưa ra đánh giá ngay lập tức cho biến mục tiêu khi tuổi của người yêu cầu bồi thường tăng 1 hay giảm 1 tuổi. Đó là sự đánh đổi giữa khả năng giải thích và khả năng dự đoán mà bạn đọc sẽ thường xuyên gặp phải khi xây dựng mô hình trên dữ liệu. Chúng ta sẽ thảo luận về các kỹ thuật mô tả mối liên hệ phi tuyến giữa biến mục tiêu và biến giải thích trong Chương mô hình cộng tính tổng quát.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"sự-kết-hợp-giữa-các-biến-giải-thích-không-chỉ-là-cộng-tính","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.3.3 Sự kết hợp giữa các biến giải thích không chỉ là cộng tính","text":"Trong nhiều trường hợp, biến mục tiêu không chỉ phụ thuộc vào từng biến giải thích một cách riêng lẻ, mà còn phụ thuộc vào sự tương tác giữa các biến giải thích. Một ví dụ điển hình cho trường hợp này là khi sử dụng mô hình tuyến tính để mô tả mối liên hệ giữa số lượng thành phẩm của một nhà máy sản xuất, biến products, với số lượng công nhân, biến workers, và số lượng máy chế tạo, biến machines. Nhìn chung khi tăng số lượng công nhân hoặc tăng số lượng máy thì số lượng thành phẩm sẽ tăng lên. Tuy nhiên mô hình hồi quy tuyến tính chỉ bao gồm hai biến giải thích workers và machines sẽ không mô tả được thực tế là khi tăng số lượng công nhân lên quá nhiều sẽ dẫn đến việc công nhân không có máy để sản xuất nên số lượng thành phẩm cũng sẽ không tăng theo tương ứng. Chính vì thế, để mô tả được thực tế đó, mô hình tuyến tính cần có biến giải thích mô tả sự tương tác giữa workers và machines:\n\\[\\begin{align}\n\\text{products} = \\beta_0 + \\beta_1 \\cdot \\text{workers}  + \\beta_2 \\cdot \\text{machines} + \\beta_3 \\cdot \\text{workers} \\times \\text{machines} + \\epsilon\n\\tag{9.24}\n\\end{align}\\]\nhoặc chúng ta cũng có thể viết mô hình (9.24) dưới dạng mô hình tuyến tính mà hệ số tuyến tính của biến machines phụ thuộc vào biến workers\n\\[\\begin{align}\n\\text{products} = & \\beta_0 + \\beta_1 \\cdot \\text{workers}  + \\left(\\beta_2 + \\beta_3 \\cdot \\text{workers}\\right) \\cdot \\text{machines} + \\epsilon \\\\\n= & \\beta_0 + \\left(\\beta_1 + \\beta_3 \\cdot \\text{machines} \\right)  \\cdot \\text{workers}  + \\beta_2 \\cdot \\text{machines} + \\epsilon\n\\tag{9.25}\n\\end{align}\\]Có thể giải thích mô hình (9.25) rằng mỗi khi tăng thêm 1 máy sản xuất, số lượng thành phẩm sẽ tăng lên tương ứng là bằng \\((\\beta_2 + \\beta_3 \\cdot \\text{workers})\\), hoặc tăng thêm 1 công nhân, số lượng thành phẩm sẽ tăng lên là \\((\\beta_1 + \\beta_3 \\cdot \\text{machines})\\). Hay nói một cách khác, số lượng thành phẩm tăng khi số lượng máy móc tăng nhưng tốc độ tăng còn phụ thuộc vào số lượng công nhân hiện tại; hoặc số lượng thành phẩm tăng khi tăng số lượng công nhân nhưng tốc độ tăng còn phụ thuôc vào số máy móc hiện có. Mô hình (9.25) sẽ phù hợp hơn mô hình tuyến tính chỉ bao gồm hai biến giải thích workers và machines khi giải thích biến mục tiêu products.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"những-khiếm-khuyết-của-mô-hình-hồi-quy-tuyến-tính","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.4 Những khiếm khuyết của mô hình hồi quy tuyến tính","text":"Khi chúng ta ước lượng mô hình hồi quy tuyến tính cho dữ liệu cụ thể những vấn đề dưới đây có thể xảy ra làm cho kết quả ước lượng của mô hình trở nên kém hiệu quả:Tồn tại mối liên hệ phi tuyến giữa biến mục tiêu và biến giải thích;Tồn tại mối liên hệ phi tuyến giữa biến mục tiêu và biến giải thích;Các sai số \\(\\epsilon_i\\) có tương quan với nhau.Các sai số \\(\\epsilon_i\\) có tương quan với nhau.Phương sai của các \\(\\epsilon_i\\) không phải là hằng số.Phương sai của các \\(\\epsilon_i\\) không phải là hằng số.Trong dữ liệu có điểm ngoại lai.Trong dữ liệu có điểm ngoại lai.Các biến giải thích có tương quan cao với nhau, hay còn gọi là đa cộng tuyến.Các biến giải thích có tương quan cao với nhau, hay còn gọi là đa cộng tuyến.Trong thực tế, việc xác định và khắc phục những vấn đề này là những chủ đề khoa học được nghiên cứu xuyên suốt cho đến thời điểm hiện tại. Có nhiều cuốn sách có chủ đề tập trung vào mô hình hồi quy tuyến tính có thể giải quyết một hoặc một vài vấn đề được nêu ở trên. Vì mô hình hồi quy tuyến tính không phải là trọng tâm của cuốn sách này nên chúng tôi sẽ chỉ tóm tắt ngắn gọn về các vấn đề và một số hướng giải quyết ngắn gọn.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"dữ-liệu-quan-sát-được-có-dạng-phi-tuyến-tính","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.4.1 Dữ liệu quan sát được có dạng phi tuyến tính","text":"Như chúng tôi đã trình bày ở phần ??, khi tồn tại mối liên hệ phi tuyến giữa biến mục tiêu và biến giải thích, sử dụng mô hình tuyến tính thông thường sẽ không phù hợp và làm cho kết quả dự đoán không được chính xác. Mối liên hệ phi tuyến có thể được phát hiện khi vẽ đồ thị biến mục tiêu theo biến giải thích giống như Hình 9.6 hoặc chúng ta vẽ đồ thị phần dư của mô hình theo biến mục tiêu\nHình 9.7: Đồ thị mô tả phần dư của mô hình tuyến tính theo biến mục tiêu trên dữ liệu về số tiền yêu cầu bồi thường bảo hiểm y tế. Hình bên trái: Phần dư của mô hình tuyến tính thông thường theo biến mục tiêu. Hình bên phải: Phần dư của mô hình hồi quy đa thức bậc hai theo biến mục tiêu\nHình 9.7 mô tả mối liên hệ giữa phần dư của mô hình tuyến tính thông thường và mô hình hồi quy đa thức với biến mục tiêu là số tiền yêu cầu bồi thường trung bình. Đường mô tả mối liên hệ trong mô hình hồi quy đa thức gần với đường trung bình của phần dư hơn cho thấy mối liên hệ phi tuyến giữa biến mục tiêu và phần dư tuy đã giảm bớt với hồi quy tuyến tính thông thường nhưng vẫn còn tồn tại trong mô hình hồi quy đa thức. Như vậy, có thể thấy rằng thêm các biến giải thích là các hàm phi tuyến của các biến giải thích ban đầu vào trong mô hình hồi quy tuyến tính là một phương pháp để mô tả mối quan hệ phi tuyến trong dữ liệu.Các biến đổi phi tuyến thường được dùng có dạng hàm mũ, hàm \\(\\log\\) của biến giải thích. Nghĩa là từ biến giải thích \\(X\\) ban đầu, nếu đồ thị mô tả mối liên hệ giữa \\(X\\) và \\(Y\\) cho thấy có mối liên hệ phi tuyến, tùy theo hình dạng của đồ thị mà chúng ta có thể thêm vào mô hình các biến giải thích như \\(\\sqrt{X}\\), \\(X^2\\), \\(X^3\\), \\(\\log(X)\\), \\(\\cdots\\), để có được mô hình phù hợp hơn. Trong phần sau của cuốn sách chúng ta sẽ thảo luận về các kỹ thuật hiện đại hơn để mô tả tốt hơn mối liên hệ phi tuyến như vậy.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"tồn-tại-tương-quan-giữa-các-phần-dư","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.4.2 Tồn tại tương quan giữa các phần dư","text":"Một giả thiết quan trọng của mô hình hồi quy tuyến tính là các sai số \\(\\epsilon_1\\), \\(\\epsilon_2\\), \\(\\cdots\\), \\(\\epsilon_n\\) không tương quan với nhau. Điều này có nghĩa là kể cả khi đã biết \\(\\epsilon_i\\), chúng ta cũng không có thông tin gì về các \\(\\epsilon_j\\) khi \\(j \\neq \\). Giả thiết các sai số có phân phối chuẩn và không tương quan có ý nghĩa quan trọng trong xây dựng các khoảng tin cậy cho hệ số tuyến tính. Trên thực tế, nếu có mối tương quan giữa các sai số thì phương sai của các hệ số tuyến tính ước lượng bằng phương pháp bình phương nhỏ nhất sẽ nhỏ hơn nhiều cho với phương sai thực. Kết quả là khoảng tin cậy ước lượng được sẽ nhỏ hơn các khoảng tin cậy thực sự.Bạn đọc có thể hình dung việc phần dư có tương quan với nhau cũng giống như việc chúng ta trong quá trình thu thập dữ liệu có sai sót dẫn đến dữ liệu bị trùng lặp. Chẳng hạn như mỗi dòng dữ liệu bị lặp lại một lần, nghĩa là dữ liệu đúng để ước lượng mô hình chỉ có \\(n\\) dòng nhưng chúng ta đã nhân đôi dữ liệu lên trước khi thực hiện ước lượng. Khi tính toán độ lệch chuẩn của sai số, chúng ta sử dụng \\(2 n\\) quan sát để tính toán thay vì \\(n\\) làm cho độ lệch chuẩn bị giảm xuống một tỷ lệ là \\(\\sqrt{2}\\). Các khoảng tin cậy khi tính toán với dữ liệu bị trùng lặp sẽ bị thu hẹp lại với khoảng tin cậy được tính toán với dữ liệu chính xác.Khi nào thì chúng ta sẽ gặp phải hiện tượng phần dư có tương quan với nhau? Ngoài việc sai sót trong quá trình thu thập dữ liệu làm cho dữ liệu vị trùng lặp, chúng ta cũng thường gặp phải hiện tượng phần dư có tương quan khi sử dụng mô hình hồi quy tuyến tính trong dữ liệu dạng chuỗi thời gian. Trong trường hợp mà mỗi dòng dữ liệu là một quan sát thu được tại các thời điểm liền kề nhau thì rất có nhiều khả năng các biến mục tiêu sẽ có tương quan với nhau, dẫn đến tương quan giữa các phần dư trong mô hình tuyến tính.Để xác định xem phần dư từ một mô hình hồi quy tuyến tính có tương quan hay không, chúng ta có thể quan sát đồ thị phần dư. Nếu phần dư không có tương quan thì sẽ không có mối liên hệ rõ ràng nào. Mặt khác, nếu có tồn tại tương quan dương thì chúng ta có thể thấy có sự liên kết giữa các giá trị phần dư.\nHình 9.8: Đồ thị mô tả phần dư có tương quan và không có tương quan. Hình trên: các phần dư có tương quan bằng 0. Hình ở giữa: hai giá trị phần dư cạnh nhau có tương quan 0.5. Hình dưới: hai giá trị phần dư cạnh nhau có tương quan 0.9\nHình ?? minh họa đồ thị phần dư của ba mô hình khác nhau. Trong hình trên cùng, chúng ta thấy phần dư từ mô hình hồi quy tuyến tính tương ứng với dữ liệu mà biến mục tiêu không có tương quan với nhau. Bạn đọc có thể thấy rằng không có mối liên hệ nào rõ ràng về xu hướng của các giá trị phần dư. Ngược lại, phần dư ở hình dưới cùng là từ tập dữ liệu trong đó các sai số liền kề có hệ số tương quan là 0.9. Bạn đọc có thể nhận thấy có một sự liên kết rõ ràng trong phần dư mà trong đó các giá trị liền kề nhau có xu hướng nhận các giá trị tương tự hay cùng dấu. Cuối cùng, hình ở giữa minh họa một trường hợp ít rõ ràng hơn mà trong đó phần dư có hệ số tương quan là 0,5. Vẫn có bằng chứng về sự liên hệ nhưng không rõ ràng như trường hợp có hệ số tương quan 0.9.Nhìn chung giả định về phần dư không tương quan là vô cùng quan trọng đối với mô hình hồi quy tuyến tính nói riêng cũng như đối với các mô hình học máy hiện đại. Ngoài nguyên nhân từ xây dựng mô hình hay cách lựa chọn biến, sự tương quan giữa các phần dư cũng có thể tồn tại ngay trong chính cách dữ liệu được thu thập, đặc biệt là những dữ liệu mà biến mục tiêu và biến giải thích cùng chịu sự tác động từ các yếu tố bên ngoài. Có nhiều phương pháp đã được phát triển để xác định các mối tương quan của phần dư trong mô hình hồi quy tuyến tính, đặc biệt là đối với mô hình tuyến tính có các biến mục tiêu và biến giải thích có dạng dữ liệu chuỗi thời gian. Nội dung của các phương pháp này bạn đọc có thể tham khảo trong các sách tham khảo dành riêng cho mô hình hồi quy tuyến tính.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"phương-sai-của-phần-dư-thay-đổi","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.4.3 Phương sai của phần dư thay đổi","text":"Một giả thiết quan trọng khác của mô hình hồi quy tuyến tính là các phần dư có phương sai không thay đổi: \\(\\mathbb{V}(\\epsilon_i) = \\sigma^2\\) \\(\\forall = 1, 2, \\cdots, n\\). Ước lượng các hệ số tuyến tính, xây dựng các khoảng tin cậy cho hệ số, hay kiểm định các giả thuyết của mô hình tuyến tính đều dựa trên giả định này. Thực tế là chúng ta rất hay gặp phải trường hợp phương sai của phần dư là không cố định. Một nguyên nhân hiện tượng phần dư có phương sai thay đổi đến từ việc mối liên hệ giữa biến mục tiêu và biến giải thích là phi tuyến. Nếu xuất phát từ nguyên nhân này, chúng ta có thể biến đổi biến mục tiêu trước khi thực hiện ước lượng.Một ví dụ điển hình thường gặp phải là khi phương sai của phần dư tăng theo giá trị của biến mục tiêu. Chúng ta có thể xác định được hiện tượng phương sai của phần dư thay đổi bằng cách sử dụng đồ thị của phần dư theo giá trị ước lượng được của biến mục tiêu.\nHình 9.9: Đồ thị mô tả phần dư có phương sai thay đổi. Hình ở trên: cho thấy phần dư có phương sai thay đổi. Hình ở dưới: Phần dư có phương sai ổn định\nMột ví dụ cho phần dư có phương sai thay đổi được thể hiện trong hình 9.9. Khi chúng ta sử dụng biến mục tiêu \\(Y\\), độ lớn của phần dư có xu hướng tăng theo các giá trị của biến mục tiêu. Khi gặp vấn đề này, một giải pháp đơn giản là biến đổi biến mục tiêu \\(Y\\) bằng cách sử dụng \\(\\log(Y)\\) hoặc \\(\\sqrt{Y}\\) làm biến mục tiêu. Các phép biến đổi này có thể làm giảm hiện tượng phương sai thay đổi. Hình phía dưới của Hình 9.9 mô tả phần dư theo giá trị của biến mục tiêu sau khi sử dụng phép biến đổi \\(\\log\\). Phần dư đã trở nên ổn định hơn mặc dù có một số dấu hiệu về mối quan hệ phi tuyến trong giữa biến mục tiêu và biến giải thích.Hiện tượng phương sai của sai số thay đổi có thể là kết quả của quá trình dữ liệu được thu thập, khi mà biến mục tiêu thứ \\(\\) là giá trị trung bình của \\(n_i\\) quan sát độc lập. Ví dụ, dữ liệu về yêu cầu bồi thường của các khách hàng của một công ty bảo hiểm, mỗi khách hàng có thể yêu cầu bồi thường nhiều lần trong khoảng thời gian một năm nhưng dữ liệu chỉ được lưu trữ dưới dạng tổng số tiền khách hàng yêu cầu bồi thường và tổng số lần khách hàng yêu cầu bồi thường. Khi xây dựng mô hình với biến mục tiêu là số tiền yêu cầu bồi thường trung bình thì độ lệch chuẩn của biến mục tiêu sẽ tỷ lệ nghịch với số lần khách hàng yêu cầu bồi thường. Trong trường hợp như vậy, một phương pháp khắc phục đơn giản là ước lượng mô hình sử dụng phương pháp bình phương nhỏ nhất có trọng số. Trọng số được sử dụng tỷ lệ nghịch với phương sai của biến mục tiêu. Chẳng hạn như trong ví dụ về yêu cầu bồi thường, trọng số được sử dụng đối với quan sát thứ \\(\\) chính là số lần khách hàng yêu cầu bồi thường.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"dữ-liệu-có-giá-trị-ngoại-lai","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.4.4 Dữ liệu có giá trị ngoại lai","text":"Điểm ngoại lai là điểm dữ liệu mà giá trị biến mục tiêu \\(y_i\\) khác xa giá trị được dự đoán bởi mô hình \\(\\hat{y}_i\\). Các ngoại lai có thể phát sinh vì nhiều lý , chẳng hạn như sự không chính xác trong quá trình thu thập dữ liệu. Bạn đọc có thể tham khảo thêm về giá trị ngoại lai trong phần @ref(#ourlier)\nHình 9.10: Dữ liệu chứa giá trị ngoại lai là điểm màu đỏ. Hình bên trái: đồ thị mô tả biến mục tiêu theo biến giải thích và các đường hồi quy tuyến tính được xây dụng cho hai trường hợp là có chứa điểm ngoại lai (nét liền màu xanh) và không chứa điểm ngoại lai (nét đứt màu đen). Hình bên phải: Đồ thị phần dư được điều chỉnh theo biến giải thích, điểm ngoại lai có phần dư có giá trị tuyệt đối lớn hơn hẳn các phần dư khác\nĐiểm màu đỏ ở hình bên trái của Hình 9.10 minh họa một ngoại giá trị ngoại lai điển hình. Đường liền màu xanh dương là đường hồi quy tuyến tính sử dụng đầy đủ dữ liệu, trong khi đường nét đứt màu đen là đường hồi quy tuyến tính sau khi loại bỏ đi điểm ngoại lai. Trong trường hợp này, việc loại bỏ giá trị ngoại lai ít ảnh hưởng đến đường hồi quy tuyến tính vì bạn đọc có thể thấy hai đường hồi quy khá gần nhau. Thông thường, một giá trị ngoại lai duy nhất sẽ ít ảnh hưởng đến sự hình dạng của đường hồi quy tuyến tính, tuy nhiên, điểm ngoại lai này lại có thể gây ra các vấn đề khác. Trong ví dụ ở trên, RSE là 1.8 khi giá trị ngoại lai được đưa vào hồi quy, và RSE chỉ bằng 0.9 khi giá trị ngoại lai bị loại bỏ. Vì chúng ta sẽ sử dụng RSE để tính toán các khoảng tin cậy và các p-value, nên sự thay đổi đáng kể của RSE như vậy sẽ có tác động đến việc giải thích sự phù hợp của mô hình. Tương tự, việc đưa giá trị ngoại lai vào làm cho R-squared giảm từ 0.973 xuống 0.89.Chúng ta có thể xác định một quan sát là ngoại lai hay không bằng cách vẽ đồ thị phần dư. Trong ví dụ ở trên, giá trị ngoại lai có thể được xác định rõ ràng trong Hình 9.10. Nhưng trong thực tế, có thể khó đưa ra được quyết định là phần dư cần phải lớn đến mức nào để chúng ta coi điểm đó là điểm bất thường. Để giải quyết vấn đề này, thay vì vẽ đồ thị phần dư, chúng ta có thể vẽ đồ thị phần dư sau khi chia phần dư cho RSE. Nếu các giả thiết của mô hình hồi quy tuyến tính là đúng, phần dư được điều chỉnh (sau khi chia cho RSE) sẽ có phân phối Student. Nếu một giá trị quan sát của phần dư vượt quá các ngưỡng xác suất của phân phối Student, nhiều khả năng đó là giá trị ngoại lai. Trong Hình 9.10, tất cả các quan sát có phần dư nằm trong khoảng -2 đến 2 trong khi giá trị ngoại lai có giá trị là gần 6. Nói một cách khác khả năng điểm có phần dư được điểu chỉnh gần bằng 6 có khả năng rất cao là giá trị ngoại lai.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"đa-cộng-tuyến","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.2.4.5 Đa cộng tuyến","text":"Đa cộng tuyến là sự kiện mà trong đó hai hoặc nhiều biến giải thích có tương quan cao với nhau với nhau. Để giải thích rõ ràng khái niệm này, chúng ta hãy lấy một ví dụ khi xây dựng mô hình hồi quy tuyến tính trên dữ liệu có tên là Credit_Card. Đây là dữ liệu về thông tin thẻ tín dụng của các khách hàng tại một ngân hàng với biến mục tiêu là số dư tài khoản, có tên là Balance, và 10 biến giải thích. Để giải thích về đa cộng tuyến, chúng tôi chỉ sử dụng ba biến giải thích là 1. Độ tuổi của chủ thẻ tín dụng, ký hiệu Age, 2. Hạn mức thẻ tín dụng, ký hiệu Limit, và 3. Điểm tín dụng của khách hàng, ký hiệu Rating. Hiện tượng đa cộng tuyến là hiện tượng mà mô hình có các biến giải thích có mối liên hệ rất chặt chẽ với nhau như được minh họa trên Hình 9.11\nHình 9.11: Mối liên hệ giữa các biến giải thích trong dữ liệu Credit. Hình bên trái: Không cho thấy có mối tương quan giữa hạn mức tín dụng với tuổi của khách hàng. Hình ở giữa: Tương quan giữa hạn mức tín dụng và điểm tính dụng là rất cao. Hình bên phải: Không có tương quan giữa tuổi của khách hàng với xếp hạng tín dụng\nTrong hình bên trái của Hình 9.11, hai biến giải thích là hạn mức tín dụng và độ tuổi không có mối tương quan rõ ràng. Tương tự, trong hình bên phải, cũng không có mối tương quan rõ ràng giữa độ tuổi với xếp hạng tín dụng. Ngược lại, trong hình ở giữa của Hình 9.11, hạn mức tín dụng và điểm tín dụng có mối tương quan rất cao với nhau bởi các điểm gần như nằm trên một đường thẳng.Hiện tượng đa cộng tuyến gây ra các vấn đề khi ước lượng và giải thích mô hình hồi quy bởi khó có thể tách biệt các tác động riêng lẻ của các biến có tương quan cao lên biến mục tiêu. Trong ví dụ ở trên. hạn mức tín dụng và điểm tín dụng có xu hướng tăng hoặc giảm cùng nhau nên khó có thể xác định xem từng biến riêng biệt có liên quan như thế nào đến biến mục tiêu là số dư tài khoản. Một vấn đề đáng kể khác khi gặp hiện tượng đa cộng tuyến đó là phương sai của các hệ số ước lượng sẽ rất lớn dẫn đến các ước lượng trở nên ít tin cậy hơn và chúng ta sẽ rất khó bác bỏ được giả thuyết hệ số tuyến tính bằng 0.\nBảng 9.10: Các hệ số ước lượng trong mô hình hồi quy tuyến tính số dư tài khoản phụ thuộc vào độ tuổi và hạn mức tín dụng\n\nBảng 9.11: Các hệ số ước lượng trong mô hình hồi quy tuyến tính số dư tài khoản phụ thuộc vào hạn mức tín dụng và điểm tín dụng\nBảng 9.10 và 9.11 sánh các hệ số tuyến tính ước lượng được được từ hai mô hình hồi quy riêng biệt. Trước tiên là hồi quy số dư tài khoản thẻ tín dụng theo độ tuổi và hạn mức tín dụng, sau đó là hồi quy số dư tài khoản theo hạn mức tín dụng và điểm tín dụng. Trong mô hình hồi quy đầu tiên, độ tuổi và hạn mức tín dụng đều có ý nghĩa giá trị p-value rất nhỏ. Trong mô hình thứ hai, hiện tượng đa cộng tuyến giữa hạn mức tín dụng và điểm tín dụng đã khiến độ lệch chuẩn của hệ số ước lượng của biến hạn mức tín dụng tăng lên gấp 13 lần và p-value tăng lên thành 0.701. Nói cách khác, sự quan trọng của biến hạn mức tín dụng đã bị che khuất hiện tượng đa cộng tuyến. Để tránh rơi vào tình trạng như vậy, cần xác định và giải quyết vấn đề đa cộng tuyến trước khi ước lượng mô hình.Một cách đơn giản để phát hiện hiện tượng đa cộng tuyến là xem xét ma trận tương quan của các biến giải thích. Một phần tử của ma trận này có giá trị tuyệt đối lớn là dấu hiệu cho thấy một cặp biến có tương quan cao và đó có hiện tượng đa cộng tuyến trong dữ liệu. Tuy nhiên, bạn đọc cần lưu ý là vấn đề về đa cộng tuyến không phải lúc nào cũng có thể được phát hiện bằng cách kiểm tra ma trận tương quan bởi vì có thể tồn tại sự đa cộng tuyến giữa ba hoặc nhiều biến ngay cả khi không có cặp biến nào có tương quan cao. Thay vì kiểm tra ma trận tương quan, cách tốt hơn để đánh giá hiện tượng đa cộng tuyến là tính hệ số lạm phát phương sai, Variance Inflation Factor hay viết tắt là VIF. Hệ số này là tỷ lệ giữa phương sai của hệ số \\(\\hat{\\beta}_j\\) khi ước lượng mô hình đầy đủ biến và hệ số \\(\\hat{\\beta}_j\\) khi ước lượng mô hình với riêng biến đó. Một cách đơn giản hơn để tính VIF là sử dụng hệ số R-squared trong mô hình hồi quy tuyến tính biến \\(X_j\\) theo các biến giải thích còn lại:\n\\[\\begin{align}\nVIF_j = \\cfrac{1}{1 - R^2_{X_j|X_{-j}}}\n\\tag{9.24}\n\\end{align}\\]\ntrong đó \\(R^2_{X_j|X_{-j}}\\) là hệ số R-squared trong mô hình hồi quy biến \\(X_j\\) theo các biến giải thích còn lại. Nếu không tồn tại đa cộng tuyến, hệ số \\(R^2_{X_j|X_{-j}}\\) sẽ gần bằng 0 và \\(VIF_j\\) sẽ lớn hơn 1 một chút. Ngược lại, nếu biến \\(X_j\\) có thể được xấp xỉ bằng tổ hợp tuyến tính của các biến giải thích còn lại, hệ số \\(R^2_{X_j|X_{-j}}\\) sẽ xấp xỉ 1 và dẫn đến \\(VIF_j\\) có giá trị rất lớn.\nBảng 9.12: Hệ số lạm phát phương sai (VIF) của các biến giải thích trong dữ liệu về thẻ tín dụng\nTừ Bảng 9.12 được tính toán từ dữ liệu về thẻ tín dụng, có thể thấy rằng các biến giải thích độ tuổi, hạn mức tín dụng, và điểm tín dụng có giá trị VIF lần lượt là \\(1.01\\), \\(160.67\\) và \\(160.59\\). Có thể kết luận là có hiện tượng đa cộng tuyến trong dữ liệu thẻ tín dụng! Khi gặp hiện tượng đa cộng tuyến như vậy, có hai giải pháp đơn giản thường được sử dụng:Giải pháp trước tiên là loại bỏ một trong các biến có hệ số VIF cao ra khỏi mô hình hồi quy. Giải pháp này thường được thực hiện mà không ảnh hưởng nhiều đến sự phù hợp của mô hình hồi quy. Trong ví dụ về dữ liệu thẻ tín dụng, chúng ta có thể hồi quy số dư tài khoản theo độ tuổi và hạn mức tín dụng và bỏ qua biến điểm tín dụng mà không làm cho hệ số R-squared giảm một cách đáng kể.Giải pháp thứ hai là kết hợp các biến có đa cộng tuyến lại với nhau thành một biến giải thích duy nhất. Chẳng hạn như chúng ta có thể lấy giá trị trung bình biến hạn mức tín dụng và biến điểm tín dụng để tạo ra một biến giải thích mới trong mô hình hồi quy tuyến tính.Trong phần tiếp theo, chúng tôi sẽ đi sâu vào giải thích phương pháp bình phương nhỏ nhất được sử dụng để ước lượng mô hình hồi quy tuyến tính và tính chất của các ước lượng. Mục tiêu là để bạn đọc hiểu rõ hơn những kết quả đã được sử dụng hoặc công nhận ở phần trên. Những bạn đọc cảm thấy không cần thiết có thể bỏ qua và chuyển sang các phần tiếp theo mà không gặp bất kỳ khó khăn nào khi sử dụng các kết quả của mô hình hồi quy tuyến tính.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"leastsquared","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.3 Mô hình hồi quy tuyến tính và phương pháp bình phương nhỏ nhất","text":"Mô hình hồi quy tuyến tính, đúng như tên gọi của nó, cho rằng hàm \\(f\\) được sử dụng để mô tả tác động của các biến giải thích \\(X_1, X_2, \\cdot ,X_p\\) lên biến mục tiêu \\(Y\\) là có dạng hàm tuyến tính\n\\[\\begin{align}\nf(\\textbf{X}) = \\beta_0 + \\beta_1 \\cdot X_1 + \\beta_2 \\cdot X_2 + \\cdots + \\beta_p \\cdot X_p\n\\tag{9.26}\n\\end{align}\\]\nCác hệ số \\(\\beta_i\\) trong phương trình (9.26) được gọi là các tham số của mô hình hồi quy tuyến tính hoặc còn được gọi là các hệ số hồi quy. Các biến \\(X_i\\) có thể được đưa vào mô hình từ những cách như sau:Biến \\(X_i\\) là một biến kiểu số.Biến \\(X_i\\) là một biến kiểu số.Biến \\(X_i\\) là một biến đổi của một biến kiểu số để mối liên hệ giữa \\(Y\\) và \\(X_i\\) trở nên tuyến tính. Các phép biến đổi thường gặp có thể là phép biến đổi \\(\\log\\), phép lấy căn, lấy bình phương, …Biến \\(X_i\\) là một biến đổi của một biến kiểu số để mối liên hệ giữa \\(Y\\) và \\(X_i\\) trở nên tuyến tính. Các phép biến đổi thường gặp có thể là phép biến đổi \\(\\log\\), phép lấy căn, lấy bình phương, …Biến \\(X_i\\) có thể là một đa thức của một biến trong dữ liệu ban đầu. Trong trường hợp này chúng ta thường gọi là mô hình hồi quy đa thức.Biến \\(X_i\\) có thể là một đa thức của một biến trong dữ liệu ban đầu. Trong trường hợp này chúng ta thường gọi là mô hình hồi quy đa thức.Trong trường hợp \\(X_i\\) là một biến kiểu factor và nhận \\(J\\) giá trị khác nhau. Giả sử \\(J\\) giá trị được mã hóa thành \\(1, 2, \\cdots, J\\) thì để mô tả tác động của biến \\(X_i\\) lên biến mục tiêu trong mô hình tuyến tính, chúng ta cần \\(J\\) giá trị hệ số tuyến tính: \\(\\beta_{,1}\\), \\(\\beta_{,2}\\), \\(\\cdots\\), \\(\\beta_{,J}\\); trong đó hệ số tuyến tính \\(\\beta_{,j}\\) mô tả tác động của giá trị \\(X_i = j\\) lên biến mục tiêu.Trong trường hợp \\(X_i\\) là một biến kiểu factor và nhận \\(J\\) giá trị khác nhau. Giả sử \\(J\\) giá trị được mã hóa thành \\(1, 2, \\cdots, J\\) thì để mô tả tác động của biến \\(X_i\\) lên biến mục tiêu trong mô hình tuyến tính, chúng ta cần \\(J\\) giá trị hệ số tuyến tính: \\(\\beta_{,1}\\), \\(\\beta_{,2}\\), \\(\\cdots\\), \\(\\beta_{,J}\\); trong đó hệ số tuyến tính \\(\\beta_{,j}\\) mô tả tác động của giá trị \\(X_i = j\\) lên biến mục tiêu.Biến giải thích được tính toán từ tác động qua lại giữa các biến giải thích khác, chẳng hạn như \\(X_i \\cdot X_j\\).Biến giải thích được tính toán từ tác động qua lại giữa các biến giải thích khác, chẳng hạn như \\(X_i \\cdot X_j\\).","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"ước-lượng-các-hệ-số-tuyến-tính","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.3.1 Ước lượng các hệ số tuyến tính","text":"Dù biến giải thích được tính toán như thế nào, biến mục tiêu \\(Y\\) vẫn là một hàm số tuyến tính của các hệ số \\((\\beta_0, \\beta_1, \\beta_2,\\cdots, \\beta_p)\\). Để dễ dàng triển khai các công thức, chúng tôi sẽ sử dụng ký hiệu \\(\\boldsymbol{\\beta}\\) tương đương như véc-tơ hệ số \\((\\beta_0, \\beta_1, \\beta_2,\\cdots, \\beta_p)\\). Phương pháp thông dụng nhất để ước lượng các hệ số của mô hình hồi quy tuyến tính là phương pháp bình phương nhỏ nhất, nghĩa là tham số \\(\\boldsymbol{\\beta}\\) được tính toán từ bài toán tối ưu\n\\[\\begin{align}\n\\hat{\\boldsymbol{\\beta}} = \\underset{\\boldsymbol{\\beta}}{\\operatorname{argmin}} \\sum\\limits_{=1}^n \\left( y_i - \\beta_0 - \\sum\\limits_{j = 1}^p \\beta_j \\cdot x_{,j} \\right)^2\n\\tag{9.27}\n\\end{align}\\]Sai số giữa \\(y_i\\) và \\(\\beta_0 + \\sum\\limits_{j = 1}^p \\beta_j \\cdot x_{,j}\\) được gọi là phần dư, hay residuals, trong mô hình hồi quy tuyến tính. Vế bên phải của công thức (9.27) là tổng bình phương của các phần dư và được viết tắt là RSS. Nếu coi tổng bình phương sai số là hàm số của các hệ số hồi quy \\(\\boldsymbol{\\beta}\\) và viết công thức tổng bình phương sai số dưới dạng ma trận ta sẽ có\n\\[\\begin{align}\nRSS(\\boldsymbol{\\beta}) = (\\textbf{y} - \\textbf{x} \\boldsymbol{\\beta})^T \\ (\\textbf{y} - \\textbf{x} \\boldsymbol{\\beta})\n\\tag{9.28}\n\\end{align}\\]\nvới\\(\\textbf{x}\\) là dữ liệu huấn luyện mô hình có kích thước \\(n \\times (p+1)\\) với cột đầu tiên bao gồm toàn các giá trị 1;\\(\\textbf{y}\\) là véc-tơ biến mục tiêu có kích thước \\(n \\times 1\\); vàvéc-tơ tham số \\(\\boldsymbol{\\beta}\\) có kích thước \\((p+1) \\times 1\\).Véc-tơ gradient của \\(RSS(\\boldsymbol{\\beta})\\) là véc-tơ có độ dài \\((p+1)\\) mà phần tử thứ \\((j+1)\\) là giá trị đạo hàm của RSS theo \\(\\beta_j\\) với \\(j = 0, 1, \\cdots, p\\); và được xác định như sau\n\\[\\begin{align}\n\\cfrac{\\nabla RSS(\\boldsymbol{\\beta})}{\\nabla \\boldsymbol{\\beta}} &= \\cfrac{\\nabla (\\textbf{y} - \\textbf{x} \\boldsymbol{\\beta})^T (\\textbf{y} - \\textbf{x} \\boldsymbol{\\beta}) }  {\\nabla \\boldsymbol{\\beta}} \\\\\n& = - 2 \\textbf{x}^T \\  (\\textbf{y} - \\textbf{x} \\boldsymbol{\\beta})\n\\tag{9.29}\n\\end{align}\\]Ma trận Hessian là ma trận kích thước \\((p+1) \\times (p+1)\\) mà phần tử hàng \\(+1\\) cột \\(j+1\\) là đạo hàm cấp hai của RSS lần lượt theo \\(\\beta_i\\) rồi theo \\(\\beta_j\\)\n\\[\\begin{align}\n\\cfrac{\\nabla RSS(\\boldsymbol{\\beta})}{\\nabla \\boldsymbol{\\beta} \\ \\nabla \\boldsymbol{\\beta}^T} = 2 \\textbf{x}^T \\ \\textbf{x}\n\\tag{9.30}\n\\end{align}\\]Giả sử rằng ma trận biến giải thích không có cột nào là tổ hợp tuyến tính của các cột còn lại, hay nói cách khác, hạng của ma trận \\(\\textbf{x}\\) là \\((p+1)\\). Khi đó ta có \\((\\textbf{x}^T \\ \\textbf{x})\\) là ma trận xác định dương. Giá trị \\(\\hat{\\boldsymbol{\\beta}}\\) làm tối thiểu hóa \\(RSS(\\boldsymbol{\\beta})\\) là nghiệm của\n\\[\\begin{align}\n\\cfrac{\\nabla RSS(\\boldsymbol{\\beta})}{\\nabla \\boldsymbol{\\beta}} = \\textbf{0}\n\\tag{9.31}\n\\end{align}\\]\nnghĩa là \\(\\hat{\\beta}\\) được tính toán như sau\n\\[\\begin{align}\n\\textbf{x}^T \\  (\\textbf{y} - \\textbf{x} \\hat{\\boldsymbol{\\beta}}) = \\textbf{0} \\\\\n\\rightarrow \\textbf{x}^T \\ \\textbf{y} = \\textbf{x}^T \\ \\textbf{x} \\hat{\\boldsymbol{\\beta}} \\\\\n\\rightarrow \\hat{\\boldsymbol{\\beta}} = (\\textbf{x}^T \\ \\textbf{x} )^{-1} \\textbf{x}^T \\ \\textbf{y}\n\\tag{9.32}\n\\end{align}\\]Với ma trận dữ liệu \\(\\textbf{x}\\), giá trị dự báo \\(\\hat{\\textbf{y}}\\) được tính toán từ công thức dưới đây\n\\[\\begin{align}\n\\hat{\\textbf{y}} = \\textbf{x} \\hat{\\boldsymbol{\\beta}} =   \\textbf{x} \\ (\\textbf{x}^T \\ \\textbf{x} )^{-1} \\textbf{x}^T \\ \\textbf{y}\n\\tag{9.33}\n\\end{align}\\]Điều gì xảy ra nếu hạng của ma trận \\(\\textbf{x}\\) nhỏ hơn \\((p+1)\\), nghĩa là một (hoặc một vài cột dữ liệu) là tổ hợp tuyến tính của các cột dữ liệu khác, hoặc trong trường hợp ma trận \\(\\textbf{x}\\) có số hàng ít hơn số cột. Khi đó ma trận \\(\\textbf{x}^T \\ \\textbf{x}\\) sẽ không khả nghịch và phương trình tuyến tính (9.31) sẽ có vô số nghiệm \\(\\boldsymbol{\\beta}\\). Đa số các hàm có sẵn khi xây dựng và ước lượng mô hình tuyến tính đều tính toán đến vấn đề này, mỗi khi thêm một biến vào trong mô hình, luôn có bước kiểm tra nếu biến được thêm vào có phải là tổ hợp tuyển tính (hoặc xấp xỉ bằng tổ hợp tuyến tính) của các biến sẵn có để loại bỏ biến đó khỏi mô hình.Để có thể đưa ra các suy diễn về véc-tơ hệ số, chúng ta cần có giả thiết về phân phối của biến phụ thuộc \\(Y\\). Mô hình hồi quy tuyến tính có giả thiết quan trọng là biến mục tiêu \\(Y\\) có phân phối chuẩn. Nói một cách khác, biến ngẫu nhiên \\(Y|X = x_i\\), được viết tắt là \\(Y_i\\), là các biến ngẫu nhiên phân phối chuẩn độc lập có giá trị trung bình \\(\\textbf{x}_i^T \\boldsymbol{\\beta}\\) và phương sai cố định là \\(\\sigma^2\\) (không phụ thuộc vào \\(\\)). Mô hình hồi quy tuyến tính được viết như sau\n\\[\\begin{align}\n& Y_i = \\beta_0 + \\beta_1 \\cdot x_{,1} + \\beta_2 \\cdot x_{,2} + \\cdots + \\beta_p \\cdot x_{,p} + \\epsilon_i \\\\\n& \\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2) \\\\\n& Cov(\\epsilon_i, \\epsilon_j) = 0 \\ \\ \\forall \\neq j\n\\tag{9.34}\n\\end{align}\\]Hoặc chúng ta có thể viết mô hình hồi quy tuyến tính dưới dạng ma trận\n\\[\\begin{align}\nY \\sim \\mathcal{N}(\\textbf{x} \\boldsymbol{\\beta}, \\sigma^2 \\ \\textbf{}_n)\n\\tag{9.35}\n\\end{align}\\]\ntrong đó \\(\\textbf{}_n\\) là ma trận đơn vị kích thước \\(n \\times n\\). Với giả thiết phân phối chuẩn của \\(Y\\) trong phương trình (9.35) và kết hợp với (9.32) chúng ta thấy rằng \\(\\hat{\\boldsymbol{\\beta}}\\) là một phép biến đổi tuyến tính của một véc-tơ phân phối chuẩn nên cũng là một véc-tơ phân phối chuẩn. Véc-tơ trung bình của \\(\\hat{\\boldsymbol{\\beta}}\\) được xác định như sau\n\\[\\begin{align}\n\\mathbb{E}(\\hat{\\boldsymbol{\\beta}}) &= \\mathbb{E}\\left((\\textbf{x}^T \\ \\textbf{x} )^{-1} \\textbf{x}^T \\ \\textbf{y}\\right) \\\\\n& = (\\textbf{x}^T \\ \\textbf{x} )^{-1} (\\textbf{x}^T \\textbf{x}) \\ \\boldsymbol{\\beta} \\\\\n& = \\boldsymbol{\\beta}\n\\tag{9.36}\n\\end{align}\\]\nMa trận hiệp phương sai của véc-tơ \\(\\hat{\\boldsymbol{\\beta}}\\)\n\\[\\begin{align}\n\\mathbb{V}ar(\\hat{\\boldsymbol{\\beta}}) &= \\mathbb{V}ar\\left((\\textbf{x}^T \\ \\textbf{x} )^{-1} \\textbf{x}^T \\ \\textbf{y}\\right) \\\\\n&= \\sigma^2 \\ (\\textbf{x}^T \\ \\textbf{x} )^{-1}\n\\tag{9.37}\n\\end{align}\\]Có thể thấy rằng véc-tơ trung bình của \\(\\hat{\\boldsymbol{\\beta}}\\) hoàn toàn phụ thuộc vào dữ liệu trong khi ma trận hiệu phương sai lại phụ thuộc vào một tham số không biết là \\(\\sigma\\). Để xây dựng được các khoảng tin cậy hoặc kiểm định được các hệ số có khác không hay không, chúng ta cần ước lượng tham số \\(\\sigma^2\\).","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"ước-lượng-phương-sai-của-biến-phụ-thuộc.","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.3.2 Ước lượng phương sai của biến phụ thuộc.","text":"Tham số thứ hai của mô hình hồi quy tuyến tính là phương sai của biến phụ thuộc, ký hiệu \\(\\sigma^2\\), được ước lượng như sau\n\\[\\begin{align}\n\\hat{\\sigma}^2 = RSS(\\hat{\\boldsymbol{\\beta}}) = \\cfrac{\\sum \\hat{\\epsilon}_i^2}{n - (p+1)} = \\cfrac{\\hat{\\boldsymbol{\\epsilon}}^{T} \\ \\hat{\\boldsymbol{\\epsilon}}}{n - (p+1)}\n\\tag{9.37}\n\\end{align}\\]\nvới \\(\\hat{\\epsilon}_i = y_i - \\hat{y}_i\\).Với giả thiết phân phối chuẩn của các \\(\\epsilon_i\\) như (9.34), \\(\\hat{\\boldsymbol{\\beta}}\\) được ước lượng từ phương trình (9.32), và \\(\\hat{y}\\) được tính toán từ (9.33), ta có thể chứng minh được rằng \\(\\cfrac{\\sum \\hat{\\epsilon}_i^2}{\\sigma^2}\\) là một biến ngẫu nhiên phân phối \\(\\chi^2\\) với bậc tự là \\(n-(p+1)\\). Thật vậy, ta có\n\\[\\begin{align}\n\\hat{\\boldsymbol{\\epsilon}} &= \\textbf{y} - \\hat{\\textbf{y}} = y - \\textbf{x} \\hat{\\beta} \\\\\n& = \\textbf{y} - \\textbf{x} (\\textbf{x}^T \\ \\textbf{x} )^{-1} \\textbf{x}^T \\ \\textbf{y} \\\\\n& = Q \\textbf{y}\n\\end{align}\\]\nvới ma trận \\(Q = I_n - \\textbf{x} (\\textbf{x}^T \\ \\textbf{x} )^{-1} \\textbf{x}^T\\). Ma trận \\(Q\\) có các tính chất sau:Thứ nhất là Q có vết (\\(Trace\\)) bằng \\(n - (p+1)\\), thật vậy\n\\[\\begin{align}\nTrace(Q) = Trace(\\textbf{}_n) - Trace(\\textbf{x} (\\textbf{x}^T \\ \\textbf{x} )^{-1} \\textbf{x}^T)\n\\end{align}\\]\nđồng thời\n\\[\\begin{align}\nTrace(\\textbf{x} (\\textbf{x}^T \\ \\textbf{x} )^{-1} \\textbf{x}^T) &= Trace( \\textbf{x}^T \\textbf{x} (\\textbf{x}^T \\ \\textbf{x} )^{-1} ) \\\\\n& = Trace(I_{p+1}) = (p+1)\n\\end{align}\\]\nđó \\(Trace(Q) = n - (p+1)\\)Thứ nhất là Q có vết (\\(Trace\\)) bằng \\(n - (p+1)\\), thật vậy\n\\[\\begin{align}\nTrace(Q) = Trace(\\textbf{}_n) - Trace(\\textbf{x} (\\textbf{x}^T \\ \\textbf{x} )^{-1} \\textbf{x}^T)\n\\end{align}\\]\nđồng thời\n\\[\\begin{align}\nTrace(\\textbf{x} (\\textbf{x}^T \\ \\textbf{x} )^{-1} \\textbf{x}^T) &= Trace( \\textbf{x}^T \\textbf{x} (\\textbf{x}^T \\ \\textbf{x} )^{-1} ) \\\\\n& = Trace(I_{p+1}) = (p+1)\n\\end{align}\\]\nđó \\(Trace(Q) = n - (p+1)\\)Thứ hai, có thể thấy rằng \\(Q = Q^{'}\\) và \\(Q = Q^2\\) đó các giá trị riêng của Q chỉ có thể nhận giá trị là 0 hoặc 1. Như vậy, nếu gọi \\(V\\) là ma trận có các cột là các véc-tơ riêng của Q thì chúng ta có’\n\\[\\begin{align}\nV Q V^{'} = \\Delta = diag(1,1,\\cdots,1,0,0,\\cdots,0)\n\\tag{9.38}\n\\end{align}\\]\ntrong đó \\(\\Delta\\) là ma trận đường chéo chỉ chứa 0 và 1 trên đường chéo chính. Kết hợp với kết quả \\(Trace(Q)\\) \\(=\\) \\(n - (p+1)\\) có thể kết luận rằng \\(Q\\) có \\(n - (p+1)\\) giá trị riêng bằng 1 và \\((p+1)\\) giá trị riêng bằng 0.Thứ hai, có thể thấy rằng \\(Q = Q^{'}\\) và \\(Q = Q^2\\) đó các giá trị riêng của Q chỉ có thể nhận giá trị là 0 hoặc 1. Như vậy, nếu gọi \\(V\\) là ma trận có các cột là các véc-tơ riêng của Q thì chúng ta có’\n\\[\\begin{align}\nV Q V^{'} = \\Delta = diag(1,1,\\cdots,1,0,0,\\cdots,0)\n\\tag{9.38}\n\\end{align}\\]\ntrong đó \\(\\Delta\\) là ma trận đường chéo chỉ chứa 0 và 1 trên đường chéo chính. Kết hợp với kết quả \\(Trace(Q)\\) \\(=\\) \\(n - (p+1)\\) có thể kết luận rằng \\(Q\\) có \\(n - (p+1)\\) giá trị riêng bằng 1 và \\((p+1)\\) giá trị riêng bằng 0.Ta có \\(\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\textbf{0}, \\sigma^2 )\\) và \\(\\hat{\\boldsymbol{\\epsilon}} \\sim \\mathcal{N}(\\textbf{0}, \\sigma^2 Q)\\). Từ (9.38) ta có \\(V \\hat{\\boldsymbol{\\epsilon}} ~ \\sim \\mathcal{N}(\\textbf{0}, \\sigma^2 \\Delta)\\). Nói cách khác, nếu cho \\(\\textbf{z} = V \\hat{\\epsilon}\\) thì \\(\\textbf{z}\\) là véc-tơ phân phối chuẩn với trung bình là \\(\\textbf{0}\\) và ma trận hiệp phương sai \\(\\sigma^2 \\Delta\\). Ma trận đường chéo \\(\\Delta\\) có \\(n-(p+1)\\) phần tử nằm trên đường chéo chính bằng 1 và (p+1) phần tử nằm trên đường chéo chính bằng 0. Nói một cách khác, các phần tử từ vị trí thứ \\(1\\) đến \\(n-(p+1)\\) trong \\(\\textbf{z}\\) có phương sai bằng \\(\\sigma^2\\) và \\(p+1\\) phần tử còn lại trong \\(\\textbf{z}\\) có phương sai bằng 0.\\(V\\) là ma trận các giá trị riêng thỏa mãn \\(V V' = I_n\\) nên\n\\[\\begin{align}\n\\hat{\\boldsymbol{\\epsilon}}^{T} \\ \\hat{\\boldsymbol{\\epsilon}} = (V \\hat{\\boldsymbol{\\epsilon}})^T V \\hat{\\boldsymbol{\\epsilon}} = \\textbf{z}^T \\textbf{z} = z_1^2 + z_2^2 + \\cdots + z_{n-(p+1)}^2 \\sim \\sigma^2 \\cdot \\chi^2_{n-(p+1)}\n\\tag{9.39}\n\\end{align}\\]Như vậy, từ phương trình (9.39) chúng ta có\n\\[\\begin{align}\n\\left(n-(p+1)\\right) \\times \\hat{\\sigma}^2 = \\hat{\\boldsymbol{\\epsilon}}^{T} \\ \\hat{\\boldsymbol{\\epsilon}} \\sim \\sigma^2 \\times \\chi^2_{n-(p+1)}\n\\tag{9.40}\n\\end{align}\\]\\(\\hat{\\sigma}^2\\) là ước lượng không chệch của \\(\\sigma^2\\) vì\n\\[\\begin{align}\n\\mathbb{E}\\left(\\hat{\\sigma}^2\\right) & = \\cfrac{1}{(n-(p+1))} \\mathbb{E}\\left(\\sigma^2 \\cdot \\chi^2_{n-(p+1)} \\right) \\\\\n& = \\sigma^2 \\times \\cfrac{\\mathbb{E}\\left(\\chi^2_{n-(p+1)} \\right)}{(n-(p+1))} \\\\\n& = \\sigma^2\n\\end{align}\\]\nvì giá trị trung bình của biến ngẫu nhiên \\(\\chi^2_{n-(p+1)}\\) là \\(n-(p+1)\\).Có thể tóm tắt các ước lượng tham số của mô hình hồi quy tuyến tính, bao gồm các hệ số tuyến tính va phương sai của biến mục tiêu, sử dụng phương pháp bình phương nhỏ nhất như sau\\[\\begin{align}\n\\hat{\\boldsymbol{\\beta}} & = P \\cdot \\textbf{y} \\\\\n\\hat{\\sigma}^2 & = \\cfrac{1}{n-(p+1)} \\ (Q \\cdot \\textbf{y})^T (Q \\cdot \\textbf{y}) \\\\\nP & = (\\textbf{x}^T \\ \\textbf{x} )^{-1} \\textbf{x}^T \\\\\nQ & = \\textbf{}_n - \\textbf{x} \\ (\\textbf{x}^T \\ \\textbf{x} )^{-1} \\textbf{x}^T\n\\tag{9.41}\n\\end{align}\\]Lưu ý rằng \\(P \\cdot Q^T\\) là một ma trận kích thước \\((p+1) \\times n\\) có tất cả các phần tử bằng 0, đó \\(\\hat{\\boldsymbol{\\beta}}\\) và \\(\\hat{\\sigma}^2\\) là các biến ngẫu nhiên độc lập.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"kiểm-định-các-hệ-số-ước-lượng","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.3.3 Kiểm định các hệ số ước lượng","text":"Từ các phương trình (9.36), (9.37), và (9.40), chúng ta có phân phối xác suất của các tham số của mô hình hồi quy tuyến tính:\n\\[\\begin{align}\n& \\hat{\\beta}_j \\sim \\mathcal{N}(\\beta_j, \\sigma^2 a_{jj}) \\ \\ \\forall 1 \\leq j \\leq (p+1) \\\\\n& \\hat{\\sigma}^2 \\sim \\cfrac{\\sigma^2}{n-(p+1)} \\ \\chi^2_{n-(p+1)}\n\\tag{9.42}\n\\end{align}\\]\nvới \\(a_{jj}\\) là phần tử nằm ở hàng \\(j\\) cột \\(j\\) của ma trận \\((\\textbf{x}^T \\ \\textbf{x} )^{-1}\\).Sau khi ước lượng hệ số tuyến tính từ phương trình (9.41), chúng ta thường quan tâm đến sự kiện \\(\\beta_j \\neq 0\\) ở một mức độ tin cậy nào đó, nghĩa là biến độc lập \\(X_j\\) có tác động tuyến tính lên biến mục tiêu \\(Y\\) một cách có ý nghĩa. Để trả lời câu hỏi này, chúng ta cần kiểm định giả thuyết \\(H_0: \\beta_j = 0\\). Dưới giả thuyết \\(H_0\\), \\(\\hat{\\beta}_j\\) là biến ngẫu nhiên phân phối chuẩn có giá trị trung bình bằng 0, tuy nhiên phương sai của \\(\\hat{\\beta}_j\\) phụ thuộc vào giá trị không biết là \\(\\sigma^2\\). Cho biến ngẫu nhiên \\(T_j = \\hat{\\beta}_j/\\left(\\sqrt{a_{jj}} \\cdot \\hat{\\sigma}\\right)\\) thì cùng chia cả tử và mẫu của \\(T_j\\) cho \\(\\sqrt{a_{jj}} \\cdot \\sigma\\) ta có\n\\[\\begin{align}\nT_j = \\hat{\\beta}_j/(\\hat{\\sigma} \\cdot  \\sqrt{a_{jj}})  = \\cfrac{\\hat{\\beta}_j/(\\sigma \\cdot  \\sqrt{a_{jj}})}{\\hat{\\sigma}/\\sigma}\n\\tag{9.43}\n\\end{align}\\]Dưới giả thuyết \\(H_0\\) ta có\n\\[\\begin{align}\n& \\hat{\\beta}_j/(\\sigma \\cdot  \\sqrt{a_{jj}}) \\sim \\mathcal{N}(0,1) \\\\\n& \\hat{\\sigma}/\\sigma \\sim \\sqrt{\\cfrac{\\chi^2_{n-(p+1)}}{n-(p+1)}}\n\\tag{9.44}\n\\end{align}\\]\nđó \\(T_j\\) là biến ngẫu nhiên phân phối Student với bậc tự \\(n-(p+1)\\). Lưu ý rằng khi bậc tự đủ lớn, biến ngẫu nhiên phân phối Student sẽ hội tụ đến phân phối chuẩn với trung bình bằng 0 và phương sai bằng 1. đó trong nhiều trường hợp, người xây dựng mô hình sử dụng phân phối \\(\\mathcal{N}(0,1)\\) để kiểm định giả thuyết \\(H_0: \\beta_j = 0\\).Giá trị của \\(T_j\\) tính từ công thức (9.43) là cơ sở để bác bỏ hoặc không bác bỏ giả thuyết \\(H_0\\). Một cách tự nhiên, nếu giá trị tuyệt đối của \\(T_j\\) lớn, nghĩa là \\(T_j\\) nằm xa giá trị 0, xác suất để bác bỏ giả thuyết \\(H_0\\) là lớn hơn với khi \\(T_j\\) gần 0.Giá trị p-value được tính bởi công thức dưới đây\n\\[\\begin{align}\np-value = 2 \\mathbb{P}(T_{n-(p+1)} > |T_j|)\n\\end{align}\\]\nKhi p-value nhỏ hơn một mức ý nghĩa \\(\\alpha\\) thì có thể kết luận rằng với độ tin cậy \\((1-\\alpha)\\), hệ số \\(\\beta_j\\) là khác 0 một cách có ý nghĩa thống kê.Trong nhiều trường hợp chúng ta cần phải thực hiện kiểm định giả thuyết mà nhiều hệ số tuyến tính đồng thời bằng 0. Chẳng hạn như các hệ số tuyến tính của một nhóm các biến liên tục, hoặc hệ số tuyến tính của 1 biến rời rạc nhận từ ba giá trị trở lên. Giả sử các hệ số cần được kiểm định đồng thời là \\(\\beta_{j_1}, \\beta_{j_2}, \\cdots, \\beta_{j_h}\\), khi đó cặp giả thuyết \\(H_0\\) - \\(H_1\\) sẽ là\n\\[\\begin{align}\n& H_0: \\beta_{j_i} = 0 \\ \\ \\forall = 1,2, \\cdots, h \\\\\n& H_1: \\text{Tồn tại ít nhất } { sao cho} \\ \\beta_{j_i} \\neq 0\n\\end{align}\\]Dưới giả thuyết \\(H_0\\) ta có\n\\[\\begin{align}\n\\cfrac{1}{h} \\sum\\limits_{= 1}^h T^2_{j_i} & =  \\cfrac{ \\cfrac{1}{h}  \\sum\\limits_{= 1}^h \\left( \\hat{\\beta}_{j_i}/(\\sigma \\cdot  \\sqrt{a_{jj}}) \\right)^2}{{\\hat{\\sigma}^2/\\sigma^2}}\n= \\cfrac{\\chi^2_{h}/h}{\\chi^2_{n-(p+1)}/(n-(p+1))} \\sim \\mathcal{F}(h,n-(p+1))\n\\tag{9.45}\n\\end{align}\\]Trong đó \\(\\mathcal{F}(h,n-(p+1))\\) là phân phối \\(\\mathcal{F}\\) với các tham số \\(h\\) và \\(n - (p+1)\\). Một cách tự nhiên, nếu giá trị của \\(\\sum\\limits_{= 1}^h T^2_{j_i}/h\\) đủ lớn, chúng ta sẽ bác bỏ giả thuyết \\(H_0\\), nghĩa là tồn tại ít nhất một \\(\\) sao cho \\(\\beta_{j_i} \\neq 0\\). Nhắc lại rằng chúng tôi đã đề cập đến phân phối \\(\\mathcal{F}\\) khi kiểm định mô hình tuyến tính đa biến. Chúng tôi đã sử dụng thống kê \\(F\\) được tính toán bằng công thức (9.16). Trong trường hợp tổng quát, nếu \\(RSS_0\\) là tổng bình phương sai số của mô hình tuyến tính bao gồm đầy đủ \\(p+1\\) biến giải thích trong khi \\(RSS_1\\) là tổng bình phương sai số của mô hình tuyến tính không bao gồm các biến \\(X_{j_1}, X_{j_2}, \\cdots, X_{j_h}\\), thống kê \\(F\\) được tính toán bằng công thức sau\n\\[\\begin{align}\nF = \\cfrac{(RSS_1 - RSS_0)/h}{RSS_0/\\left(n-(p+1)\\right)}\n\\tag{9.46}\n\\end{align}\\]Nếu giả thuyết \\(H_0\\) là đúng, nghĩa là các hệ số \\(\\beta_{j_i}\\) đều nhận giá trị bằng 0, có thể chứng minh được rằng thống kê \\(F\\) sẽ có phân phối \\(\\mathcal{F}\\) với tham số \\(h\\) và \\(n - (p+1)\\).\nxxxxxxxxxxxxxxx","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"linearmodelselection","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.4 Các phương pháp chọn biến trong mô hình hồi quy tuyến tính.","text":"Có hai lý khiến những người xây dựng mô hình thường không hài lòng với kết quả từ phương pháp bình phương nhỏ nhấtThứ nhất là khả năng dự đoán của mô hình: ước lượng tham số bằng phương pháp bình phương nhỏ nhất thường có sai lệch thấp nhưng phương sai lớn. Độ chính xác của dự đoán đôi khi có thể được cải thiện bằng các phương pháp như thu nhỏ số lượng biến giải thích hoặc các phương pháp shinkage. Bằng cách tiếp cận như vậy, người xây dựng mô hình chấp nhận tăng sai lệch để giảm phương sai của các giá trị dự đoán để có thể cải thiện độ chính xác trong dự đoán.Lý thứ hai là khả năng diễn giải của mô hình. Khi số lượng biến giải thích là quá nhiều, chúng ta thường muốn xác định một tập hợp nhỏ hơn những biến có tác động mạnh đáng kể nhất nhằm diễn giải mô hình một cách tốt nhất.Trong phần này, trước tiên chúng ta sẽ thảo luận một số cách tiếp cận để lựa chọn biến giải thích để đưa vào trong mô hình hồi quy tuyến tính bao gồm các phương pháp như lựa chọn tập hợp con tốt nhất hay best subset selection, forward stepwise selection, backward stepwise selection. Trong phần tiếp theo, chúng ta thảo luận về các phương pháp rút gọn tham số với mục tiêu kiểm soát phương sai của dự đoán. không tìm được từ Tiếng Việt có ý nghĩa hợp lý nên chúng tôi sẽ giữ nguyên tên gọi của hai phương pháp forward stepwise selection và backward stepwise selection.Nhìn chung, khi lựa chọn biến giải thích đưa vào mô hình, chúng ta chỉ giữ lại một tập hợp con của các biến và loại bỏ phần còn lại khỏi mô hình. Phương pháp bình phương nhỏ nhất được sử dụng để ước tính các hệ số tuyến tính. Các tiêu chí đánh giá mô hình sẽ được đưa ra nhằm sánh các tập hợp biến khác nhau.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"phương-pháp-lựa-chọn-tập-hợp-con-tốt-nhất","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.4.1 Phương pháp lựa chọn tập hợp con tốt nhất","text":"Đúng như tên gọi, lựa chọn biến bằng phương pháp lựa chọn tập hợp con tốt nhất có nghĩa là với mỗi giá trị của \\(k \\\\{0,1,2,... ,p\\}\\) người xây dựng mô hình cố gắng tìm tập hợp con có bao gồm đúng \\(k\\) biến giải thích sao cho tổng bình phương phần dư đạt giá trị nhỏ nhất. Điểm bất lợi của phương pháp này là khối lượng tính toán quá lớn bởi vì số lượng mô hình cần ước lượng là \\(2^p\\). Phương pháp tiếp cận của Furnival và Wilson (1974) giúp cho thuật toán này có thể thực hiện được với \\(p\\) lên đến 40. Tuy nhiên, thời gian tính toán chậm vẫn là điểm bất lợi nhất của phương pháp này.Dữ liệu được sử dụng để xây dựng mô hình tuyến tính là dữ liệu Boston trong thư viện MASS. Đây là dữ liệu về giá nhà tại 506 vùng ngoại ô tại Boston. Biến mục tiêu trong xây dựng mô hình là biến medv là giá trị trung vị của giá nhà tại vùng đó, đơn vị là nghìn USD. Mô hình có 13 biến phụ thuộc trong đó có 11 biến kiểu số và 2 biến kiểu rời rạc là rad và chas. Mục tiêu của chúng ta là lựa chọn được \\(k\\) biến trong số 13 biến phụ thuộc sao cho RSE là nhỏ nhất.\nHình 9.12: Phương pháp lựa chọn tập hợp con tốt nhất được thực hiện trên dữ liệu Boston. Đường ranh giới dưới là các mô hình có tổng bình phương phần dư nhỏ nhất\nHình 9.12 hiển thị tất cả các mô hình có tập hợp con \\(k\\) biến, \\(k = 0, 1, \\cdots, 13\\) cho ví dụ về giá nhà ở Boston. Đường ranh giới dưới biểu thị các mô hình đủ điều kiện để lựa chọn theo cách tiếp cận tập hợp con tốt nhất. Lưu ý rằng tập hợp con tốt nhất có kích thước bằng 2 không nhất thiết bao gồm biến nằm trong tập con tốt nhất có kích thước 1. Đường cong tập hợp con tốt nhất tính theo tiêu chí RSE thường giảm theo \\(k\\), đó thường không tối ưu khi sử dụng để chọn kích thước tập hợp con tối ưu.Có một số tiêu chí mà chúng ta có thể cân nhắc khi sánh các mô hình tuyến tính có số lượng biến khác nhau ngoài RSE. Nếu khối lượng tính toán cho phép thì chúng tôi thường sử dụng sai số tính bằng RSE trung bình tính trên xác thực chéo để làm tiêu chí lựa chọn mô hình. Khi khối lượng tính toán cho xác thực chéo quá lớn thì bạn đọc cũng có thể sử dụng tiêu chí AIC là một lựa chọn thay thế. Cách sử dụng sai số xác thực chéo làm tiêu chí lựa chọn sẽ được trình bày trong phần thực hành của chương.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"forward--and-backward-stepwise-selection","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.4.2 Forward- and Backward-Stepwise Selection","text":"Thay vì tìm kiếm qua tất cả các tập hợp con, điều mà này trở nên không khả thi khi số lượng biến \\(p\\) lớn, chúng ta có thể tìm kiếm tập hợp con một cách tuần tự theo từng bước, mà ở đó, kết quả của bước tiếp theo phụ thuộc vào bước trước đó.Forward stepwise selection bắt đầu bằng cách lựa chọn mô hình có 1 biến tốt nhất. Sau đó, phương pháp này tìm kiểm mô hình có \\(k\\) biến bằng cách lấy \\((k-1)\\) biến đã được lựa chọn ở bước trước đó để thêm vào một biến. Như vậy, tại bước thứ \\(k\\), sẽ có \\((p-k+1)\\) mô hình tuyến tính cần được ước lượng. Số mô hình cần được ước lượng trong phương pháp forward stepwise selection là\n\\[\\begin{align}\np + (p-1) + \\cdots + 1 = \\cfrac{p(p+1)}{2}\n\\end{align}\\]Forward stepwise selection bắt đầu bằng cách lựa chọn mô hình có 1 biến tốt nhất. Sau đó, phương pháp này tìm kiểm mô hình có \\(k\\) biến bằng cách lấy \\((k-1)\\) biến đã được lựa chọn ở bước trước đó để thêm vào một biến. Như vậy, tại bước thứ \\(k\\), sẽ có \\((p-k+1)\\) mô hình tuyến tính cần được ước lượng. Số mô hình cần được ước lượng trong phương pháp forward stepwise selection là\n\\[\\begin{align}\np + (p-1) + \\cdots + 1 = \\cfrac{p(p+1)}{2}\n\\end{align}\\]Bước thứ nhất của phương pháp backward stepwise selection bắt đầu bằng ước lượng mô hình có đầy đủ \\(p\\) biến. Sau đó, tại bước thứ \\(k\\), mô hình tìm cách loại bỏ đi 1 biến trong \\((p+2-k)\\) biến trong mô hình được ước lượng tại bước thứ \\((k-1)\\). Như vậy, tại bước thứ \\(k\\) với \\(k >1\\) sẽ có \\((p+2-k)\\) mô hình cần được ước lượng. Tổng số mô hình cần được ước lượng trong phương pháp là\n\\[\\begin{align}\n1 + p + (p-1) + \\cdots + 2 = \\cfrac{p(p+1)}{2}\n\\end{align}\\]Bước thứ nhất của phương pháp backward stepwise selection bắt đầu bằng ước lượng mô hình có đầy đủ \\(p\\) biến. Sau đó, tại bước thứ \\(k\\), mô hình tìm cách loại bỏ đi 1 biến trong \\((p+2-k)\\) biến trong mô hình được ước lượng tại bước thứ \\((k-1)\\). Như vậy, tại bước thứ \\(k\\) với \\(k >1\\) sẽ có \\((p+2-k)\\) mô hình cần được ước lượng. Tổng số mô hình cần được ước lượng trong phương pháp là\n\\[\\begin{align}\n1 + p + (p-1) + \\cdots + 2 = \\cfrac{p(p+1)}{2}\n\\end{align}\\]Hai phương pháp mô tả ở trên có bất lợi với phương pháp lựa chọn tập hợp con tốt nhất là không chắc chắn tìm thấy được mô hình có \\(k\\) biến tốt nhất kết quả của các bước phụ thuộc vào các bước trước đó. Tuy nhiên, lợi thế của các phương pháp này có thể kể đến làNguồn lực tính toán: với \\(p\\) lớn thì thời gian tính toán của hai phương pháp kể trên nhanh hơn nhiều với phương pháp tập hợp con tốt nhất.Về mặt ý nghĩa thống kê: phương pháp lựa chọn tập hợp con tốt nhất tìm kiếm mô hình có \\(k\\) biến tốt nhất trong tất cả các lựa chọn có thể, đó kết quả thường thu được mô hình có phương sai cao hơn. Ngược lại, các phương pháp forward và backward stepwise selection chỉ tìm kiếm mô hình \\(k\\) biến trong một không gian nhỏ hơn (phụ thuộc vào các biến đã được lựa chọn trong các bước trước đó) nên thường có phương sai nhỏ hơn.Hình vẽ 9.13 mô tả các mô hình có \\(k\\) biến tốt nhất với \\(k = 0, 1, \\cdots, 13\\) sử dụng phương pháp forward stepwise selection. Trong trường hợp dữ liệu Boston, ba phương pháp lựa chọn biến chúng tôi mô tả ở trên cho cùng một kết quả!\nHình 9.13: Phương pháp forward stepwise selection được thực hiện trên dữ liệu Boston. Đường ranh giới dưới là các mô hình có sai số trung bình nhỏ nhất.\n","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"hồi-quy-tuyến-tính-có-ràng-buộc-tham-số","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.5 Hồi quy tuyến tính có ràng buộc tham số","text":"Bằng cách tìm kiếm một tập hợp con các biến giải thích, các phương pháp lựa chọn biến trình bày ở phần trên có thể giúp bạn đọc tìm ra các mô hình có khả năng giải thích tốt và có khả năng có sai lệch thấp hơn với mô hình gồm đầy đủ tất cả các biến. Hạn chế của các mô hình này ở chỗ, mỗi biến giải thích chỉ có một trong hai khả năng là có xuất hiện hoặc không xuất hiện, nên các mô hình kết quả vẫn sẽ có phương sai lớn. Các phương pháp ràng buộc tham số được trình bày trong phần này là các phương pháp thường được sử dụng để cải thiện các mô hình có phương sai lớn với mục đích giảm phương sai của các mô hình và chấp nhận đánh đổi khả năng sai lệch có thể tăng.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"hồi-quy-ridge","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.5.1 Hồi quy ridge","text":"Hồi quy ridge hạn chế ảnh hưởng của biến giải thích lên biến mục tiêu bằng cách thêm vào một hàm phạt vào RSS nếu giá trị tuyệt đối của các hệ số tuyến tính tăng lên. Thay vì tìm các hệ số \\(\\hat{\\boldsymbol{\\beta}}\\) để tối thiểu hóa \\(RSS(\\beta)\\), hồi quy ridge tìm các hệ số \\(\\hat{\\boldsymbol{\\beta}}^{ridge}\\) để tối thiểu hóa tổng của \\(RSS(\\beta)\\) với một hàm phạt như sau\n\\[\\begin{align}\n\\hat{\\boldsymbol{\\beta}}^{ridge} = \\underset{\\boldsymbol{\\beta}}{\\operatorname{argmin}} \\sum\\limits_{=1}^n \\left( y_i - \\beta_0 - \\sum\\limits_{j = 1}^p \\beta_j \\cdot x_{,j} \\right)^2 + \\lambda \\cdot \\sum\\limits_{j=1}^p \\beta_j^2\n\\tag{9.47}\n\\end{align}\\]hồi quy ridge sử dụng hàm phạt là \\(PF(\\boldsymbol{\\beta}) = \\sum\\limits_{j=1}^p \\beta_j^2\\). Lưu ý rằng hệ số chặn \\(\\beta_0\\) không có trong hàm phạt bởi vì hệ số này không bị tác động bởi các biến giải thích. Hệ số \\(\\lambda \\geq 0\\) điều khiển mức độ ảnh hưởng của hàm phạt lên giá trị tối ưu. Khi \\(\\lambda\\) nhỏ thì ảnh hưởng của hàm phạt lên giá trị tối ưu không đáng kể và nếu \\(\\lambda\\) lớn thì hàm phạt sẽ chiếm ưu thế trong bài toán tối ưu và làm cho tất cả các hệ số \\(\\hat{\\boldsymbol{\\beta}}^{ridge}\\) gần tới 0.Bài toán tối ưu trong phương trình (9.47) có thể phát biểu dưới dạng bài toán có ràng buộc như sau:\n\\[\\begin{align}\n& \\hat{\\boldsymbol{\\beta}}^{ridge} = \\underset{\\boldsymbol{\\beta}}{\\operatorname{argmin}} \\sum\\limits_{=1}^n \\left( y_i - \\beta_0 - \\sum\\limits_{j = 1}^p \\beta_j \\cdot x_{,j} \\right)^2, \\\\\n& \\text{ với ràng buộc: }  \\sum\\limits_{j=1}^p \\beta_j^2 \\leq c\n\\tag{9.48}\n\\end{align}\\]Trong trường hợp mô hình tuyến tính có các biến độc lập có tương quan cao với nhau ước lượng của các hệ số tuyến tính có độ biến động lớn khiến mô hình tuyến tính kém hiệu quả. Bằng cách sử dụng ràng buộc trên cho tổng bình phương các hệ số, hồi quy ridge kiểm soát được vấn đề các biến giải thích tương quan cao. Ngoài ra, khi thực hiện hồi quy ridge các hệ số tuyến tính sẽ phụ thuộc vào việc có hay không thực hiện biến đổi tuyến tính các biến giải thích, đó trước khi thực hiện hồi quy người xây dựng mô hình thường chuẩn hóa các biến giải thích. Sau khi các biến giải thích được chuẩn hóa, ước lượng cho hệ số chặn là giá trị trung bình của biến mục tiêu, và phương pháp bình phương nhỏ nhất được thực hiện để ước lượng \\(\\beta_1, \\beta_2, \\cdots, \\beta_p\\).Tổng bình phương sai số dưới trong hồi quy ridge được viết như sau\n\\[\\begin{align}\nRSS(\\boldsymbol{\\beta}) = (\\textbf{y} - \\textbf{x} \\boldsymbol{\\beta})^T \\ (\\textbf{y} - \\textbf{x} \\boldsymbol{\\beta}) + \\lambda \\boldsymbol{\\beta}^T \\boldsymbol{\\beta}\n\\end{align}\\]Lưu ý rằng ma trận biến giải thích \\(\\textbf{x}\\) sau khi chuẩn hóa có kích thước \\(n \\times p\\). Tương tự như mô hình tuyến tính, hệ số hồi quy được ước lượng bằng phương pháp bình phương nhỏ nhất\n\\[\\begin{align}\n\\hat{\\boldsymbol{\\beta}}^{ridge} = (\\textbf{x}^T \\ \\textbf{x} + \\lambda I_{p} )^{-1} \\textbf{x}^T \\ \\textbf{y}\n\\end{align}\\]\nvới \\(I_p\\) là ma trận đơn vị có kích thước \\(p \\times p\\). Như vậy, tương tự như hồi quy tuyến tính thông thường, véc-tơ hệ số \\(\\hat{\\boldsymbol{\\beta}}^{ridge}\\) vẫn là tổ hợp tuyến tính của véc-tơ biến mục tiêu \\(\\textbf{y}\\). Sự khác nhau của các hệ số đến ở chỗ hồi quy ridge thêm vào đường chéo chính của ma trận \\(\\textbf{x}^T \\ \\textbf{x}\\) giá trị \\(\\lambda\\) trước khi lấy nghịch đảo.Trong trường hợp các biến giải thích đôi một độc lập, có thể chứng minh được rằng\n\\[\\begin{align}\n\\hat{\\boldsymbol{\\beta}} = \\cfrac{\\hat{\\boldsymbol{\\beta}}^{ridge}}{1 + \\lambda}\n\\end{align}\\]\ntrong đó \\(\\hat{\\boldsymbol{\\beta}}\\) là ước lượng của các hệ số tuyến tính khi không sử dụng hàm phạt. Khi \\(\\lambda\\) đủ lớn sẽ làm cho các giá trị hệ số tuyến tính giảm dần về 0. Điều đó có nghĩa là khi \\(\\lambda\\) càng lớn, bậc tự của mô hình càng nhỏ. Trong mô hình tuyến tính thông thường, bậc tự của mô hình có thể hiểu một cách đơn giản là số lượng tham số và bằng \\((p+1)\\). Với \\(\\lambda > 0\\), vẫn có \\((p+1)\\) hệ số tuyến tính trong hồi quy ridge được ước lượng, tuy nhiên các hệ số bị ràng buộc với nhau làm cho bậc tự của mô hình giảm. Điều này cũng đồng nghĩa với việc mô hình ít bị phụ thuộc vào dữ liệu hơn (phương sai giảm) nhưng đánh đổi lại là sai lệch sẽ tăng.Khái niệm bậc tự trong các mô hình có ràng buộc về tham số thường được gọi là bậc tự hiệu quả thay vì bậc tự thông thường. Bậc tự hiệu quả được định nghĩa bằng tổng độ nhạy (đạo hàm) của các giá trị dự báo \\(\\hat{y}_i = \\hat{f}(x_i)\\) theo các giá trị quan sát của biến mục tiêu\n\\[\\begin{align}\n\\text{Bậc tự hiệu quả} = \\sum\\limits_{=1}^n \\cfrac{\\partial \\hat{y}_i }{\\partial y_i}\n\\tag{9.49}\n\\end{align}\\]Bậc tự hiệu quả lớn có nghĩa là giá trị dự đoán \\(\\hat{y}_i\\) sẽ thay đổi lớn khi các giá trị quan sát \\(y_i\\) thay đổi, ngược lại, bậc tự hiệu quả nhỏ có nghĩa là các giá trị dự đoán \\(\\hat{y}_i\\) sẽ thay đổi nhỏ khi các giá trị quan sát được \\(y_i\\) thay đổi. Tương tự như khái niệm bậc tự trong mô hình tuyến tính thông thường, mô hình có bậc tự hiệu quả lớn nghĩa là mô hình có phương sai lớn.Trong hồi quy tuyến tính thông thường hoặc hồi quy tuyến tính ridge, giá trị dự báo của mô hình có dạng\n\\[\\begin{align}\n\\hat{\\textbf{y}} = \\textbf{y}\n\\end{align}\\]\nvới \\(= \\textbf{x} (\\textbf{x}^T \\ \\textbf{x} )^{-1} \\textbf{x}^T\\) trong mô hình tuyến tính thông thường, và \\(= \\textbf{x} (\\textbf{x}^T \\ \\textbf{x} + \\lambda I_{p} )^{-1} \\textbf{x}^T\\) trong hồi quy tuyến tính ridge.Bậc tự hiệu quả của các mô hình trên chính là vết (trace) của ma trận \\(\\)\n\\[\\begin{align}\n\\sum\\limits_{=1}^n \\cfrac{\\partial \\hat{y}_i }{\\partial y_i} = Trace() = \\sum\\limits_{=1}^n A_{,}\n\\tag{9.50}\n\\end{align}\\]\ntrong đó \\(A_{,}\\) là các phần tử thứ \\(\\) nằm trên đường chéo chính của ma trận \\(\\). Trong ước lượng mô hình tuyến tính thông thường ma trận \\(\\textbf{x}^T \\ \\textbf{x}\\) có hạng bằng \\((p+1)\\), chúng ta đã có \\(trace() = (p+1)\\), nghĩa là bậc tự hiệu quả của mô hình tuyến tính thông thường bằng số tham số trong mô hình.Để trả lời câu hỏi bậc tự hiệu quả của hồi quy ridge phụ thuộc vào \\(\\lambda\\) như thế nào, chúng ta giả sử ma trận \\(\\textbf{x}^T \\ \\textbf{x}\\) có hạng bằng \\(p\\). Khi đó, ma trận \\(\\textbf{x}^T \\ \\textbf{x}\\) có thể được viêt dưới dạng sau\n\\[\\begin{align}\n\\textbf{x}^T \\ \\textbf{x} = U D U^{T}\n\\end{align}\\]\nvới \\(U\\) là ma trận các véc-tơ riêng chuẩn hóa của \\(\\textbf{x}^T \\ \\textbf{x}\\) và \\(D\\) là ma trận đường chéo có các phần tử nằm trên đường chéo chính là các giá trị riêng của ma trận \\(\\textbf{x}^T \\ \\textbf{x}\\).\n\\[\\begin{align}\nD = Diag(\\lambda_1, \\lambda_2, \\cdots, \\lambda_p)\n\\end{align}\\]\nvới \\(\\lambda_i\\) là các giá trị riêng của ma trận \\(\\textbf{x}^T \\ \\textbf{x}\\). Lưu ý rằng ma trận \\(U\\) là ma trận unitary. Hơn thế nữa, ma trận \\(\\textbf{x}^T \\ \\textbf{x}\\) xác định dương nên tất cả các giá trị riêng \\(\\lambda_i\\) đều là các số dương. Chúng ta có bậc tự hiệu quả của hồi quy ridge được xác định như sau:\n\\[\\begin{align}\nTrace\\left(\\textbf{x} (\\textbf{x}^T \\ \\textbf{x} + \\lambda \\textbf{}_p )^{-1}\\right) & = Trace(\\textbf{x}^T \\textbf{x} (\\textbf{x}^T \\ \\textbf{x} + \\lambda \\textbf{}_p )^{-1}) \\\\\n& = Trace\\left[ Diag \\left( \\cfrac{\\lambda_1}{\\lambda_1 + \\lambda}, \\cfrac{\\lambda_2}{\\lambda_2 + \\lambda}, \\cdots, \\cfrac{\\lambda_{p}}{\\lambda_{p} + \\lambda} \\right) \\right] \\\\\n& = \\sum\\limits_{= 1}^{p} \\cfrac{\\lambda_i}{\\lambda_i + \\lambda}\n\\tag{9.51}\n\\end{align}\\]Có thể thấy rằng bậc tự hiệu quả của hồi quy ridge là hàm số giảm theo \\(\\lambda\\). Trong mô hình tuyến tính với \\(p\\) biến giải thích và không có hệ số chặn, bậc tự là \\(p\\). Khi sử dụng ràng buộc trên các hệ số tuyến tính, kể cả khi các hệ số khác 0 một cách có ý nghĩa, các hệ số vẫn bị ràng buộc bởi \\(\\lambda\\). Bậc tự hiệu quả nhận giá trị bằng \\(p\\) khi \\(\\lambda = 0\\), tương đương với bài toán tối ưu không có ràng buộc, trong khi bậc tự hiệu quả sẽ xấp xỉ 0 nếu chúng ta chọn \\(\\lambda\\) đủ lớn.\nHình 9.14: hồi quy ridge tương đương với bài toán tìm RSS nhỏ nhất với ràng buộc các hệ số tuyến tính.\nHình 9.14 mô tả quá trình ước lượng tham số của hồi quy ridge trên một dữ liệu được mô phỏng. Dữ liệu có 500 quan sát và các hệ số \\(\\beta_1\\) và \\(\\beta_2\\) được lựa chọn để sinh dữ liệu là \\(\\beta_1 = 2\\) và \\(\\beta_2 = -1\\). Bạn đọc có thể thấy rằng lời giải của bài toán tối ưu không có ràng buộc là điểm xấp xỉ \\((2,-1)\\). Giá trị \\(RSS(\\boldsymbol{\\beta})\\) tương ứng với điểm tối ưu này là 80. Khi chúng ta thêm ràng buộc với hệ số \\(\\beta_1\\) và \\(\\beta_2\\) như phương trình (9.48) với \\(c = 1\\) thì miền giá trị của các hệ số phải nằm trong hình tròn có tâm tại (0,0) và bán kính bằng 1 giống như trong hình vẽ. Để thỏa mãn được ràng buộc này, chúng ta phải chấp nhận giá trị của \\(RSS(\\boldsymbol{\\beta})\\) tăng lên. Tại mỗi giá trị của \\(RSS(\\boldsymbol{\\beta})\\) lớn hơn giá trị tối thiểu là 80, tập hợp các điểm (\\(\\beta_1\\), \\(\\beta_2\\)) sao cho giá trị của RSS không thay đổi là một hình ellipse khai triển công thức của RSS sẽ thu được phương trình của một ellipse trên các biến (\\(\\beta_1\\), \\(\\beta_2\\)). Hình 9.14 mô tả ba ellipse đồng tâm, có độ lớn tăng dần tương ứng với giá trị của RSS là 100, 230 và 480. Tại giá trị 480, ellipse tiếp xúc với hình tròn mô tả miền ràng buộc tham số tại điểm chính là lời giải của bài toán tối ưu có ràng buộc hay chính là giá trị ước lượng tham số của hồi quy ridge. Bạn đọc có thể thấy rằng nếu hình tròn ràng buộc tham số không chứa điểm \\((2,-1)\\), hồi quy ridge luôn luôn đẩy các hệ số tuyến tính về gần 0 hơn và làm cho mô hình ít bị phụ thuộc hơn vào các tham số tuyến tính.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"phương-pháp-lasso","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.5.2 Phương pháp Lasso","text":"Lasso cũng là một phương pháp để tạo ràng buộc cho các hệ số của mô hình hồi quy tuyến tính. Lasso sử dụng hàm phạt dưới dạng tổng giá trị tuyệt đối của các hệ số thay vì tổng bình phương các hệ số tuyến tính. Lasso có thể được phát biểu dưới dạng bài toán tối ưu với ràng buộc như sau\n\\[\\begin{align}\n& \\hat{\\boldsymbol{\\beta}}^{ridge} = \\underset{\\boldsymbol{\\beta}}{\\operatorname{argmin}} \\sum\\limits_{=1}^n \\left( y_i - \\beta_0 - \\sum\\limits_{j = 1}^p \\beta_j \\cdot x_{,j} \\right)^2, \\\\\n& \\text{ với ràng buộc: }  \\sum\\limits_{j=1}^p |\\beta_j| \\leq c\n\\tag{9.52}\n\\end{align}\\]Tương tự như hồi quy ridge, các biến độc lập cũng sẽ được chuẩn hóa để có giá trị trung bình bằng 0. Khi đó, ước lượng cho \\(\\beta_0\\) là giá trị trung bình của biến phụ thuộc. Ước lượng tham số cho Lasso là quá trình tìm hệ số tuyến tính \\(\\hat{\\boldsymbol{\\beta}}^{Lasso}\\) để tối thiểu hóa tổng bình phương sai số cộng thêm một hàm phạt\\[\\begin{align}\n\\hat{\\boldsymbol{\\beta}}^{Lasso} = \\underset{\\boldsymbol{\\beta}}{\\operatorname{argmin}} \\sum\\limits_{=1}^n \\left( y_i - \\beta_0 - \\sum\\limits_{j = 1}^p \\beta_j \\cdot x_{,j} \\right)^2 + \\lambda \\cdot \\sum\\limits_{j=1}^p |\\beta_j|\n\\tag{9.53}\n\\end{align}\\]Không giống như hồi quy ridge, sử dụng hàm phạt là tổng giá trị tuyệt đối của các hệ số sẽ dẫn đến bài toán tìm \\(\\hat{\\boldsymbol{\\beta}}^{Lasso}\\) không có lời giải chính xác. Các phương pháp giải số thường được áp dụng để ước lượng tham số. Khi hằng số \\(c\\) trong ràng buộc của bài toán tối ưu (9.52) xấp xỉ 0, các hệ số tuyến tính cũng sẽ xấp xỉ 0. Ngược lại khi \\(c\\) đủ lớn, lời giải của bài toán tối ưu sẽ là hệ số của mô hình tuyến tính thông thường.\nHình 9.15: Hồi quy ridge tương đương với bài toán tìm RSS nhỏ nhất với ràng buộc các hệ số tuyến tính.\nHình 9.15 mô tả quá trình ước lượng tham số của hồi quy lasso trên một dữ liệu mô phỏng mà chúng tôi đã sử dụng trong mô tả hồi quy ridge. Các hệ số \\(\\beta_1\\) và \\(\\beta_2\\) được lựa chọn để sinh dữ liệu là \\(\\beta_1 = 2\\) và \\(\\beta_2 = -1\\) và lời giải của bài toán tối ưu không có ràng buộc là điểm xấp xỉ \\((2,-1)\\). Giá trị \\(RSS(\\boldsymbol{\\beta})\\) tương ứng với điểm tối ưu này là 80. Khi chúng ta thêm ràng buộc với hệ số \\(\\beta_1\\) và \\(\\beta_2\\) như phương trình (9.52) với \\(c = 1\\) thì miền giá trị của các hệ số phải nằm trong hình kim cương 4 cạnh được mô tả như trong hình vẽ. Cũng giống như trong hồi quy ridge, để thỏa mãn được ràng buộc chúng ta phải chấp nhận giá trị của \\(RSS(\\boldsymbol{\\beta})\\) tăng lên. Hình 9.14 mô tả ba ellipse đồng tâm, có độ lớn tăng dần tương ứng với giá trị của RSS là 100, 240 và 550. Tại giá trị 550, ellipse tiếp xúc với miền ràng buộc tham số tại một điểm và điểm đó chính là lời giải của phương pháp lasso. Tương tự như hồi quy ridge, phương pháp lasso luôn kéo các hệ số tuyến tính về gần 0 và làm cho mô hình ít bị phụ thuộc hơn vào các tham số tuyến tính. đặc điểm của miền ràng buộc, phương pháp lasso nhiều khi còn hiệu quả hơn hồi quy ridge trong ràng buộc tham số bởi vì điểm tiếp xúc của ellipse với hình kim cương sẽ luôn khiến cho một trong hai hệ số nhận giá trị gần 0 hơn.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"thực-hành-xây-dựng-mô-hình-tuyến-tính","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.6 Thực hành xây dựng mô hình tuyến tính","text":"Chúng ta sẽ thực hành xây dựng mô hình tuyến tính trên dữ liệu Boston trong thư viện MASS là dữ liệu về giá nhà tại các vùng ngoại ô của thành phố Boston. Biến mục tiêu có tên là medv là giá trị trung vị của giá nhà tại mỗi vùng. Có 13 biến giải thích bao gồm 11 biến giải thích là các biến liên tục và hai biến giải thích rời rạc bao gồmchas nhận hai giá trị là 1 nếu vùng ngoại ô nằm trên đường bờ sông và nhận giá trị bằng 0 nếu vùng đó không nằm trên đường bờ sông.rad là chỉ số cho biết khả năng tiếp cận đường cao tốc của mỗi vùng. Chỉ số này càng cao thì vùng càng có khả năng tiếp cận đường cao tốc.Về nguyên tắc, dữ liệu trước khi sử dụng để xây dựng mô hình cần được làm sạch, xử lý giá trị không quan sát được, loại bỏ các giá trị ngoại lai, loại bỏ các biến không cần thiết,… Tuy nhiên, để không lặp lại các kiến thức đã trình bày trong các chương trước, chúng tôi sẽ bỏ qua phần này và trực tiếp đi vào phần xây dựng mô hình.Một lưu ý khác là đa số các hàm số dùng để xây dựng mô hình trên dữ liệu đều đã được phát triển dưới dạng các hàm số có sẵn trên R. Người xây dựng mô hình chỉ cần gọi đúng tên hàm số, khai báo chính xác tham số, và đọc được kết quả trả ra mà không cần phải hiểu chính xác cách viết các hàm số đó như thế nào. Đây là ưu điểm lớn nhất đồng thời cũng là nhược điểm lớn nhất khi sử dụng R để xây dựng mô hình. Là ưu điểm vì bạn đọc chỉ cần một dòng lệnh là đã có thể xây dựng được mô hình phức tạp trên dữ liệu mà không cần hiểu một cách chính xác về mô hình đó. Là nhược điểm bởi vì khi người xây dựng mô hình không hiểu rõ về bản chất có thể dẫn tới sử dụng mô hình không đúng mục đích và dẫn đến các nhận định sai lầm. Để hạn chế được nhược điểm này, trong một số trường hợp, chúng tôi sẽ yêu cầu bạn đọc tự viết các câu lệnh tính toán tham số trước khi gọi các hàm có sẵn.","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"xây-dựng-mô-hình-hồi-quy-đa-biến","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.6.1 Xây dựng mô hình hồi quy đa biến","text":"Trước hết chúng ta sẽ xây dựng mô hình tuyến tính đơn biến mà giá nhà phụ thuộc vào một biến có tên là lstat. Các hệ số tuyến tính trong mô hình hồi quy đơn \\(Y \\sim \\beta_0 + \\beta_1 \\cdot X\\) được ước lượng bằng phương pháp bình phương nhỏ nhất được tính toán như sau:\n\\[\\begin{align}\n\\hat{\\beta}_1 = \\cfrac{cov(X,Y)}{var(X)} \\ \\ \\ ; \\ \\ \\ \\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\cdot \\bar{X}\n\\end{align}\\]Như vậy, chúng ta có mô hình tuyến tính đơn biến mà medv phụ thuộc vào lstat\n\\[\\begin{align}\n\\hat{medv} = 34.5538409 - 0.9500494 \\times \\text{lstat}\n\\end{align}\\]Kết quả mô hình cho thấy khi lstat tăng thêm 1 (%) thì giá nhà trung bình sẽ giảm đi khoảng 0.950 (nghìn USD). Sai số (phần dư) của mô hình là hiệu số giữa giá trị của biến medv được ước lượng từ mô hình và giá trị của medv trong dữ liệu. Chúng ta có đồ thị phần dư như sau\nHình 9.16: Đồ thị phần dư trong mô hình hồi quy đơn medv phụ thuộc vào lstat\nNhìn vào đồ thị phần dư, bạn đọc có thể dễ dàng nhận thấy rằng giả thiết phân phối chuẩn của phần dư và giả thiết các phần dư không tương quan với nhau là không đúng. Điều này có thể cải thiện bằng cách thêm các biến giải thích khác vào mô hình. Chúng ta ước lượng được phương sai (RSE) của phần dư như sau\n\\[\\begin{align}\n\\hat{\\sigma} = RSE = \\sqrt{\\cfrac{RSS}{n-2}}\n\\end{align}\\]\ntrong đó RSS là tổng sai số bình phương và \\(n\\) là số quan sátHệ số R-squared của mô hình được tính toán như sauPhương sai của các hệ số \\(\\beta_0\\), \\(\\beta_1\\), các giá trị của phân phối Student, và p-value được tính toán như sauCó thể thấy rằng các giá trị p-value đều nhỏ, cho thấy các hệ số tuyến tính đều khác không một cách có ý nghĩa.Tất cả các tính toán ở trên đều có thể được thực hiện thông qua hàm có sẵn là lm(). Cách sử dụng hàm lm() xây dựng mô hình tuyến tính mà biến medv phụ thuộc vào biến lstat như sauBạn đọc có thể kiểm tra các tính toán ở trên với kết quả ước lượng từ hàm lm() là hoàn toàn tương tự nhau. Đối tượng lm1 là một list có 12 phần tử trong đó có các phần tử như coefficient chứa giá trị các hệ số ước lượng hay residuals là véc-tơ phần dư.Mô hình tuyến tính đa biến cũng có thể được ước lượng bằng hàm lm() giống như mô hình đơn biến. Chúng ta xây dựng mô hình tuyến tính đa biến mà trong đó biến medv phụ thuộc vào tất cả các biến còn lại như sauTừ giá trị p-value của từng hệ số tuyến tính, có thể nhận thấy rằng hầu hết các biến trong mô hình đều có ý nghĩa ngoại trừ hai biến là indus và age.","code":"\ndat <- Boston\ny <- Boston$medv\nx <- Boston$lstat\nbeta1 <- cov(x,y)/var(x); beta0 <- mean(y) - beta1 * mean(x)\nprint(c(beta0,beta1))## [1] 34.5538409 -0.9500494\nphandu <- (y -  beta0 - beta1 * x)\ndata.frame(x = 1:length(phandu), phandu = phandu)%>%\n  ggplot(aes(x,phandu))+\n  geom_line(color = \"#640514\",alpha = 0.3)+\n  geom_hline(yintercept = 0, col = \"grey30\")+\n  theme_minimal()+\n  xlab(\"Số quan sát\")+ ylab(\"Phần dư\")\nRSS <- sum(phandu^2)\nRSE <- sqrt(RSS/(nrow(Boston)-2))\nprint(paste(\"RSE =\", RSE))## [1] \"RSE = 6.21576040539807\"\nTSS <- sum((y - mean(y))^2)\nR_squared <- 1 - RSS/TSS\nprint(paste(\"Hệ số R-squared: \", R_squared))## [1] \"Hệ số R-squared:  0.54414629758648\"\nn<-nrow(Boston)\nSE_beta0 <- RSE * sqrt(1/n+ mean(x)^2/sum(((x-mean(x))^2)))\nSE_beta1 <- RSE * sqrt(1/sum(((x-mean(x))^2)))\nt_beta0 <- beta0/SE_beta0\nt_beta1 <- beta1/SE_beta1\np_value_beta0 <- 2 * (1-pt(abs(t_beta0), df = n-2))\np_value_beta1 <- 2 * (1-pt(abs(t_beta1), df = n-2))\nprint(paste(\"Các giá trị phân phối student: \", t_beta0, \" - \", t_beta1))## [1] \"Các giá trị phân phối student:  61.4151455186417  -  -24.5278998511877\"\nprint(paste(\"Các giá trị p-value: \", p_value_beta0, \" - \",p_value_beta1))## [1] \"Các giá trị p-value:  0  -  0\"\nlm1<-lm(medv~lstat, data = Boston)\nsummary(lm1)## \n## Call:\n## lm(formula = medv ~ lstat, data = Boston)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -15.168  -3.990  -1.318   2.034  24.500 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) 34.55384    0.56263   61.41   <2e-16 ***\n## lstat       -0.95005    0.03873  -24.53   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 6.216 on 504 degrees of freedom\n## Multiple R-squared:  0.5441, Adjusted R-squared:  0.5432 \n## F-statistic: 601.6 on 1 and 504 DF,  p-value: < 2.2e-16\nBoston$chas<-as.factor(Boston$chas)\nlm.all<-lm(medv~., data = Boston)\nsummary(lm.all)## \n## Call:\n## lm(formula = medv ~ ., data = Boston)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -15.595  -2.730  -0.518   1.777  26.199 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\n## crim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \n## zn           4.642e-02  1.373e-02   3.382 0.000778 ***\n## indus        2.056e-02  6.150e-02   0.334 0.738288    \n## chas1        2.687e+00  8.616e-01   3.118 0.001925 ** \n## nox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\n## rm           3.810e+00  4.179e-01   9.116  < 2e-16 ***\n## age          6.922e-04  1.321e-02   0.052 0.958229    \n## dis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\n## rad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\n## tax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \n## ptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\n## black        9.312e-03  2.686e-03   3.467 0.000573 ***\n## lstat       -5.248e-01  5.072e-02 -10.347  < 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 4.745 on 492 degrees of freedom\n## Multiple R-squared:  0.7406, Adjusted R-squared:  0.7338 \n## F-statistic: 108.1 on 13 and 492 DF,  p-value: < 2.2e-16"},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"lựa-chọn-biến-trong-mô-hình-hồi-quy-tuyến-tính","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.6.2 Lựa chọn biến trong mô hình hồi quy tuyến tính","text":"Chúng ta sẽ sử dụng RSE trung bình khi thực hiện xác thực chéo làm tiêu chí để lựa chọn biến trong mô hình hồi quy tuyến tính. Hàm số dùng để tạo chỉ số tập xác thực trong xác thực chéo là hàm createFolds() của thư viện caret. Dữ liệu sẽ được chia ngẫu nhiên thành \\(k = 5\\) phần theo biến mục tiêu để đảm bảo phân phối của biến mục tiêu trong từng tập xác thực tương tự nhau.Để tính sai số xác thực chéo, với mỗi \\(\\\\{1, 2, 3, 4, 5\\}\\) chúng ta xây dựng mô hình trên dữ liệu Boston loại trừ đi các quan sát thuộc tập xác thực \\(\\). Sau đó tính toán sai số của mô hình trên tập xác thực thứ \\(\\). Sai số trong bài toán hồi quy được tính bằng RMSE. Sai số xác thực chéo là giá trị trung bình của sai số trên các tập xác thực \\(\\), \\(1 \\leq \\leq 5\\). Ví dụ, chúng ta xác định sai số của mô hình đơn biến gồm một biến giải thích lstat và mô hình tuyến tính đa biến bao gồm tất cả các biến như sau:Dữ liệu Boston bao gồm 13 biến độc lập đó thực hiện lựa chọn biến bằng phương pháp lựa chọn tập con tốt nhất là có thể thực hiện được. Nguyên tắc lựa chọn mô hình là dựa trên sai số xác thực chéo, mô hình có sai số xác thực chéo nhỏ nhất sẽ được lựa chọn. Có \\((2^{13} - 1)\\) mô hình cần được xây dựng và tính toán.Như vậy mô hình tuyến tính có sai số xác thực chéo nhỏ nhất là mô hình có 11 biến liệt kê như trên. Lưu ý rằng, dữ liệu có kích thước không lớn nên kết quả của mô hình sẽ phụ thuộc vào việc chia dữ liệu thành các tập xác thực.Lựa chọn biến cho mô hình tuyến tính bằng phương pháp forward stepwise selection được thực hiện như sauBạn đọc có thể dễ dàng nhận thấy rằng thời gian để thực hiện lựa chọn biến bằng phương pháp forward stepwise selection là nhanh hơn rất nhiều với phương pháp lựa chọn tập hợp con tốt nhất.Tương tự, chúng ta có thể thực hiện lựa chọn biến bằng phương pháp backward stepwise selection được thực hiện như sau","code":"\n# Chia dữ liệu ngẫu nhiên thành 5 phần theo biến medv\nset.seed(10)\nfold_number = 5\nindex <- createFolds(Boston$medv, k = fold_number)\n# Sai số giữa hai véc-tơ số tính bằng RMSE\nRMSE <- function(y,y.hat) sqrt(mean((y - y.hat)^2))\n\n# Hàm số tính sai số xác thực chéo hồi quy tuyến tính\ncv.lm<-function(seed = 10, fold_number = 5, dat, target){\n  # seed: khởi tạo ngẫu nhiên\n  # fold_number: số lượng folds\n  # dat: dữ liệu xây dựng mô hình (X)\n  # target: biến mục tiêu (Y)\n  set.seed(seed)\n  n <- nrow(dat) ; p <- ncol(dat)\n  \n  # Tạo dữ liệu xác thực chéo\n  y <- target\n  x <- dat\n  index <- createFolds(y, k = fold_number)\n  \n  # Véc-tơ sai số xác thực chéo\n  error_reg <- rep(0, fold_number) \n  \n  for (i in 1:fold_number){\n    test.index <- index[[i]] # chỉ số tập xác thực\n    test.index <- (1:n) %in% test.index\n    \n    # Dữ liệu huấn luyện\n    x.train <- x %>% filter(!test.index)\n    y.train <- y[!test.index]\n    \n    # Dữ liệu xác thực\n    x.test <- x %>% filter(test.index)\n    y.test <- y[test.index]\n    \n    # Mô hình tuyến tính\n    lm.model <- lm(y.train~., data = x.train) # ước lượng\n    lm.pred <- predict(lm.model, x.test) # dự đoán\n    error_reg[i] <- RMSE(y.test,lm.pred)                \n  }\n  return(mean(error_reg))\n}\n\n# Sai số xác thực chéo hồi quy đơn\nmydat <- dplyr::select(Boston, lstat)\ny <- Boston$medv\ncv.lm(seed = 10, fold_number = 5, dat = mydat, target = y)## [1] 6.200729\n# Sai số xác thực chéo hồi quy bội\nmydat <- dplyr::select(Boston, -medv) # X\ncv.lm(seed = 10, fold_number = 5, dat = mydat, target = y)## [1] 4.857492\np <- ncol(Boston)-1\nnumber_model <- 2^p - 1\nvar_name <- select(Boston, - medv) %>% names() \ncv.error <- rep(0, number_model)\n\nfor (i in 1:1){\n#for (i in 1:number_model){\n  # Véc-tơ chứa tên các biến được lựa chọn\n  selected_variable <- var_name[as.logical(intToBits(i))[1:p]]\n  y <- Boston$medv\n  mydat <- select(Boston, selected_variable)\n  cv.error[i] <- cv.lm(seed = 10, fold_number = 5, dat = mydat, target = y)\n}\n\n# Mô hình có sai số xác thực chéo nhỏ nhất\nbest_model <- which.min(cv.error)\n# Danh sách các biến trong mô hình\nvar_name[as.logical(intToBits(best_model))[1:p]]## [1] \"zn\"\n# Thứ tự chạy mô hình từ ít đến nhiều biến\nM <- matrix(FALSE,number_model,p)\nfor (i in 1:number_model){ \n  M[i,] <- as.logical(intToBits(i))[1:p]\n}\nM <- M[order(apply(M,1,sum)),]\n\n# Kết quả của quá trình forward stepwise được lưu\nfws_result <- data.frame(Model_number = rep(0, p*(p-1)/2), \n                        Number_variable = rep(0, p*(p-1)/2), \n                        CV_error = rep(0, p*(p-1)/2))\ncurrent_best_model <- c()\nj <- 0\n# Lựa chọn mô hình\nfor (i in 1:number_model){\n  number_selected_variable <- sum(M[i,])\n  current_select <- var_name[M[i,]]\n  \n  if ( (i == 1) | all(current_best_model %in% current_select) ){\n    j <- j+1\n    mydat <- select(Boston, current_select)\n    cv.error <- cv.lm(seed = 10, fold_number = 5, dat = mydat, target = y)\n    fws_result[j,] <- c(i, number_selected_variable, cv.error)\n  }  \n  \n  # Lưu lại mô hình có các biến tốt nhất\n  if (i < number_model){\n    if (sum(M[i+1,])-sum(M[i,]) ==  1){\n      dat <- filter(fws_result, Number_variable == number_selected_variable)\n      ind_best_model <- dat$Model_number[which.min(dat$CV_error)]\n      current_best_model <- var_name[M[ind_best_model,]]\n    }\n  } \n}\n# Thứ tự chạy mô hình từ ít đến nhiều biến\nM <- matrix(FALSE,number_model,p)\nfor (i in 1:number_model){ \n  M[i,] <- as.logical(intToBits(i))[1:p]\n}\nM <- M[order(apply(M,1,sum),decreasing = TRUE),]\n\n# Kết quả của quá trình forward stepwise được lưu\nbws_result <- data.frame(Model_number = rep(0, p*(p-1)/2), \n                         Number_variable = rep(0, p*(p-1)/2), \n                         CV_error = rep(0, p*(p-1)/2))\ncurrent_best_model <- var_name\nj <- 0\n# Lựa chọn mô hình\nfor (i in 1:number_model){\n  number_selected_variable <- sum(M[i,])\n  current_select <- var_name[M[i,]]\n  \n  if ( (i == p) | all(current_select %in% current_best_model) ){\n    j <- j+1\n    mydat <- select(Boston, current_select)\n    cv.error <- cv.lm(seed = 10, fold_number = 5, dat = mydat, target = y)\n    bws_result[j,] <- c(i, number_selected_variable, cv.error)\n  }  \n  \n  # Lưu lại mô hình có các biến tốt nhất\n  if (number_selected_variable > 1){\n    if (sum(M[i,])-sum(M[i+1,]) ==  1){\n      dat <- filter(bws_result, Number_variable == number_selected_variable)\n      ind_best_model <- dat$Model_number[which.min(dat$CV_error)]\n      current_best_model <- var_name[M[ind_best_model,]]\n    }\n  } \n}"},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"hồi-quy-ridge-và-lasso","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.6.3 Hồi quy ridge và lasso","text":"Hồi quy ridge và lasso được thực hiện bằng hàm số glmnet() của thư viện cùng tên glmnet. Tham số \\(\\lambda\\) của các phương pháp này được tìm kiếm bằng phương pháp xác thực chéo. Hàm số thực hiện tính toán sai số xác thực chéo của hồi quy ridge và lasso là hàm cv.glmnet().Sai số xác thực chéo tính bằng MSE được lưu trong véc-tơ con có tên là cvm. Chúng ta có sai số xác thực chéo cho mỗi giá trị của \\(\\lambda\\) của hồi quy ridge và lasso như hình (??)\nHình 9.17: Sai số xác thực chéo tương ứng với mỗi giá trị của siêu tham số lambda trong hồi quy ridge và lasso.\nCó thể thấy rằng trong hồi quy ridge và lasso, tham số \\(\\lambda\\) cho sai số xác thực chéo nhỏ nhất lần lượt là 0.14 và 0.027. Sai số xác thực chéo trong hồi quy ridge và lasso không tốt hơn với mô hình hồi quy tuyến tính bội.các phương pháp ràng buộc tham số sẽ tránh được hiện tượng khớp dữ liệu quá mức, chúng ta có thể tạo thêm các biến giải thích cho biến giá nhà bằng cách nhân chéo các biến giải thích hiện có. Tổng số biến mới được tạo thành là \\(p\\times(p+1)/2\\).Chúng ta có sai số xác thực chéo cho mỗi giá trị của \\(\\lambda\\) của hồi quy ridge và lasso với dữ liệu sau khi biến đổi như hình (??)\nHình 9.18: Sai số xác thực chéo tương ứng với mỗi giá trị của siêu tham số lambda trong hồi quy ridge và lasso.\nCó thể thấy rằng việc áp dụng hồi quy ridge và lasso trên dữ liệu có số lượng lớn biến giải thích mới được tạo thành bằng cách nhân chéo các biến hiện có không chỉ tránh được hiện tương mô hình bị khớp quá mức mà còn cải thiện khả năng dự đoán của mô hình. Sai số xác thực chéo đã giảm đáng kể với mô hình chỉ sử dụng các biến ban đầu.","code":"\nlibrary(glmnet)\n\n# Chuẩn hóa dữ liệu về dạng số\ny <- Boston$medv\nx <- model.matrix(medv~.,Boston)\n\n# Các giá trị lambda\nr.lambda<-seq(0,0.3,length=100)\nl.lambda<-seq(0,0.1,length=100)\nset.seed(50)\n\n# Xác thực chéo với ridge (tham số alpha = 0)\ncv.ridge <- cv.glmnet(x, y, alpha = 0, \n                  nfolds = 5, lambda=r.lambda)\n\n\n# Xác thực chéo với lasso (tham số alpha = 1)\ncv.lasso <- cv.glmnet(x, y, alpha = 1, \n                  nfolds = 5, lambda=l.lambda)\ndat <- select(Boston, -medv)\np <- ncol(dat)\n\ndat <- sapply(dat,  \n             function(x){\n               x <- as.numeric(x)\n               return ((x - mean(x))/sd(x))\n             })\n\ndat<-as.data.frame(dat)\n\nfor (i in 1:p){\n  for (j in i:p){\n    dat <- mutate(dat, newcol = dat[,i]*dat[,j])\n    names(dat)[length(dat)] <- paste0(\"X\",i,\"_\",j)\n  }\n}\ndat<-mutate(dat, \"medv\" = Boston$medv)\n# Chuẩn hóa dữ liệu về dạng số\ny <- dat$medv\nx <- model.matrix(medv~.,dat)\n\n# Các giá trị lambda\nr.lambda<-seq(0,0.5,length=100)\nl.lambda<-seq(0,0.2,length=100)\nset.seed(50)\n\n# Xác thực chéo với ridge (tham số alpha = 0)\ncv.ridge <- cv.glmnet(x, y, alpha = 0, \n                  nfolds = 5, lambda=r.lambda)\n\n\n# Xác thực chéo với lasso (tham số alpha = 1)\ncv.lasso <- cv.glmnet(x, y, alpha = 1, \n                  nfolds = 5, lambda=l.lambda)"},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"bài-tập-2","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.7 Bài tập","text":"","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"bài-tập-lý-thuyết","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.7.1 Bài tập lý thuyết","text":"","code":""},{"path":"mô-hình-hồi-quy-tuyến-tính.html","id":"bài-tập-thực-hành","chapter":"Chương 9 Mô hình hồi quy tuyến tính","heading":"9.7.2 Bài tập thực hành","text":"","code":"\nlibrary(readxl)\nlibrary(dplyr)## \n## Attaching package: 'dplyr'## The following objects are masked from 'package:stats':\n## \n##     filter, lag## The following objects are masked from 'package:base':\n## \n##     intersect, setdiff, setequal, union\nlibrary(knitr)\nlibrary(kableExtra)## \n## Attaching package: 'kableExtra'## The following object is masked from 'package:dplyr':\n## \n##     group_rows\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(ggpubr)\nlibrary(grid)\nlibrary(gridExtra)## \n## Attaching package: 'gridExtra'## The following object is masked from 'package:dplyr':\n## \n##     combine\nlibrary(forcats)\nlibrary(pryr)## \n## Attaching package: 'pryr'## The following object is masked from 'package:dplyr':\n## \n##     where\nlibrary(RColorBrewer)\nlibrary(mvtnorm)\nlibrary(caret)## Loading required package: lattice\nlibrary(latex2exp)\nlibrary(gam)## Loading required package: splines## Loading required package: foreach## Loaded gam 1.22-4\ncolorize_style = function(x, color = \"#640514\", font = \"Source Code Pro\", style = NULL) {\n  apply_style = function(text, style) {\n    if (!is.null(style)) {\n      if (style == \"bold\") {\n        text = sprintf(\"\\\\textbf{%s}\", text)\n      }else if (style == \"it\") {\n      text = sprintf(\"\\\\textit{%s}\", text)\n      }else if (style == \"under\") {\n      text = sprintf(\"\\\\underline{%s}\", text)\n      }\n    }\n    return(text)\n  }\n  if(knitr::is_latex_output()){\n    x = apply_style(x, style)\n    if (!is.null(font)) {\n      sprintf(\"\\\\textcolor{%s}{\\\\textsf{%s}{%s}}\", color, font, x)\n    }else {\n      sprintf(\"\\\\textcolor{%s}{%s}\", color, x)\n    }\n  }else if (knitr::is_html_output()){\n    if(!is.null(style)){\n      if(style == \"bold\"){\n        x = sprintf(\"<strong>%s<\/strong>\", x)\n      }else if (style == \"it\"){\n        x = sprintf(\"<em>%s<\/em>\", x)\n      }else if (style == \"under\"){\n        x = sprintf(\"<span style='text-decoration: underline;'>%s<\/span>\", x)\n      }\n    }\n    if (!is.null(font)){\n    sprintf(\"<span style='color: %s; font-family: %s;'>%s<\/span>\", color, font, x)\n    }else{\n    sprintf(\"<span style='color: %s;'>%s<\/span>\", color, x)\n    }\n  }else{\n  x\n  }\n}"},{"path":"các-mô-hình-cộng-tính-tổng-quát.html","id":"các-mô-hình-cộng-tính-tổng-quát","chapter":"Chương 10 Các mô hình cộng tính tổng quát","heading":"Chương 10 Các mô hình cộng tính tổng quát","text":"Trong chương trước, chúng ta đã nghiên cứu về mô hình hồi quy tuyến tính. Đây là lớp các mô hình tương đối đơn giản để hiểu và thực hiện, đồng thời có ưu điểm hơn các phương pháp tiếp cận khác dễ dàng diễn giải và suy luận. Tuy nhiên, các mô hình hồi quy tuyến tính thông thường có thể có những hạn chế về khả năng dự đoán. Điều này là giả định tuyến tính hiếm khi xảy ra trong dữ liệu thực tế. Chúng ta cũng đã nghiên cứu một vài phương pháp để có thể cải thiện khả năng dự báo của các mô hình tuyến tính bằng cách sử dụng hồi quy ridge, hay Lasso …, mà trong đó, khả năng dự báo được cải thiện bằng cách giảm bậc tự của mô hình tuyến tính với mục đích giảm phương sai của mô hình. Tuy nhiên, các phương pháp cải thiện mô hình đó vẫn giữ nguyên giả thuyết tuyến tính.Trong chương này, chúng tôi sẽ từng bước nới lỏng giả định tuyến tính trong xây dựng mô hình trong khi vẫn cố gắng duy trì khả năng diễn giải nhiều nhất có thể bằng cách giữ nguyên nguyên tắc cộng tính trong xây dựng mô hình. Chúng ta sẽ bắt đầu chương sách này với các mở rộng đơn giản của các mô hình tuyến tính bao gồm hồi quy đa thức, hồi quy theo hàm bậc thang, sau đó chuyển sang các phương pháp phức tạp hơn như spline, hồi quy cục bộ và sau cùng là mô hình cộng tính tổng quát.Dữ liệu chúng tôi sử dụng để minh họa các mô hình là dữ liệu về giá nhà tại Boston trong thư viện MASS. Bạn đọc tham khảo mô tả dữ liệu trên R hoặc xem lại chương mô hình tuyến tính để hiểu thêm về dữ liệu.","code":""},{"path":"các-mô-hình-cộng-tính-tổng-quát.html","id":"hồi-quy-splines","chapter":"Chương 10 Các mô hình cộng tính tổng quát","heading":"10.1 Hồi quy splines","text":"Khi thảo luận về xây dựng mô hình tuyến tính, chúng tôi đã đề cập đến vấn đề khi tồn lại mối liên hệ phi tuyến giữa biến mục tiêu và biến giải thích. Một phương pháp giải quyết vấn đề này là mở rộng hồi quy tuyến tính mà trong đó biến mục tiêu được mô tả thông qua biến giải thích và các hàm mũ của biến đó, hay nói một cách khác là được mô tả bằng một đa thức của biến giải thích. Ví dụ như chúng ta thay thế mô hình tuyến tính đơn biến\n\\[\\begin{align}\ny_i = \\beta_0 + \\beta_1 \\cdot x_i + \\epsilon_i\n\\end{align}\\]\nbằng một mô hình hồi quy đa thức\n\\[\\begin{align}\ny_i = \\beta_0 + \\beta_1 \\cdot x_i + \\beta_2 \\cdot x_i^2 + \\cdots + \\beta_d \\cdot x_i^d + \\epsilon_i\n\\tag{10.1}\n\\end{align}\\]\nvới \\(\\epsilon_i\\) là phần dư và \\(d\\) là bậc của đa thức. Khi bậc của đa thức \\(d\\) là lớn, đa thức sẽ có càng nhiều điểm uốn và độ cong đủ lớn để mô tả các mối liên hệ phi tuyến. Lưu ý rằng các hệ số trong (10.1) có thể được ước lượng dễ dàng bằng cách sử dụng phương pháp bình phương nhỏ nhất vì đây là mô hình tuyến tính thông thường với các biến giải thích \\(x_i, x_i^2, \\cdots , x_i^d\\). Khi sử dụng hồi quy đa thức cần lưu ý là khi sử dụng bậc của đa thức quá lớn, ví dụ như \\(d \\geq 4\\), thì đa thức sẽ có hình dạng khá kỳ lạ tại các điểm giới hạn của biến giải thích. Các điểm giới hạn bao gồm các điểm dữ liệu rất nhỏ và rất lớn của biến giải thích.\nHình 10.1: Hồi quy đa thức biến giá nhà (nghìn USD) theo biến tỷ lệ người sống dưới mức trung bình (%) trên dữ liệu Boston. Hình bên trái: sử dụng đa thức bậc ba. Hình ở giữa: sử dụng đa thức bậc bốn. Hình bên phải: sử dụng đa thức bậc năm\nHình 10.1 mô tả mô hình hồi quy đa thức trong đó biến mục tiêu là giá nhà (nghìn USD) theo biến tỷ lệ người sống dưới mức trung bình (%) trên dữ liệu về giá nhà tại Boston. Hình bên trái cho thấy sử dụng đa thức bậc ba mô tả khá đầy đủ hình dạng mối liên hệ tuyến tính giữa hai biến: giá nhà có xu hướng giảm tại các khu vực có tỷ lệ người sống dưới mức trung bình lớn. Tốc độ giảm của giá nhà theo biến giải thích có sự khác biệt, giá nhà giảm nhanh khi tỷ lệ sống dưới mức trung bình tăng từ 5% lên 15%, tốc độ giảm chậm dần khi biến giải thích nhận giá trị trong khoảng 15% đến 25%, sau đó tốc độ giảm của giá nhà lại tăng khi tỷ lệ sống dưới mức trung bình cao hơn 25%. Hình ở giữa trong Hình 10.1 sử dụng đa thức bậc bốn. Bạn đọc có thể nhận thấy ngay rằng đa thức bậc bốn là không phù hợp để mô tả mối liên hệ giữa biến mục tiêu và biến giải thích khi hàm số có giá trị tăng trên khoảng tỷ lệ sống dưới mức trung bình cao hơn 30%. Hình bên phải trong Hình 10.1 sử dụng đa thức bậc năm để mô tả mối liên hệ giữa giá nhà và tỷ lệ sống dưới mức trung bình. Không có sự khác biệt nhiều giữa đa thức bậc ba và đa thức bậc năm trong miền 5% đến 30%, tuy nhiên đa thức bậc năm lại cho hình dạng kỳ lạ khi biến giải thích lớn hơn 25%!Nhìn chung, kinh nghiệm cho thấy rằng sử dụng đa thức bậc lớn hơn ba trong hồi quy đa thức thường không đem lại hiệu quả trong mô tả dữ liệu. Thay vì tăng bậc của đa thức để giải thích tốt hơn mối liên hệ giữa biến mục tiêu và biến giải thích, những người xây dựng mô hình sử dụng một dạng hàm \\(f(x)\\) mà với mỗi khoảng giá trị khác nhau của \\(x\\) hàm \\(f\\) là một đa thức khác nhau. Nói một cách khác, mối liên hệ giữa \\(Y\\) và \\(X\\) được mô tả bằng một splines. Thay vì tăng bậc cho đa thức bậc ba:\n\\[\\begin{align}\ny_i = \\beta_0 + \\beta_1 \\cdot x_i + \\beta_2 \\cdot x_i^2 +\\beta_3 \\cdot x_i^3 + \\epsilon_i\n\\tag{10.2}\n\\end{align}\\]\nchúng ta có thể thay thế bằng cách hồi quy hai đa thức bậc ba trên hai miền giá trị khác nhau của \\(x_i\\)\n\\[\\begin{align}\ny_i = \\begin{cases}\n\\beta_{01} + \\beta_{11} \\cdot x_i + \\beta_{21} \\cdot x_i^2 +\\beta_{31} \\cdot x_i^3 + \\epsilon_i \\text{ nếu } x_i < c \\\\\n\\beta_{02} + \\beta_{12} \\cdot x_i + \\beta_{22} \\cdot x_i^2 +\\beta_{32} \\cdot x_i^3 + \\epsilon_i \\text{ nếu } x_i \\geq c \\\\\n\\end{cases}\n\\tag{10.3}\n\\end{align}\\]Chúng ta chia dữ liệu thành hai phần: phần dữ liệu thứ nhất bao gồm các quan sát có \\(x_i < c\\) và phần dữ liệu thứ hai bao gồm các quan sát có \\(xi \\geq c\\). Đa thức bậc ba thứ nhất có các hệ số \\(\\beta_{01}\\), \\(\\beta_{11}\\), \\(\\beta_{21}\\) và \\(\\beta_{31}\\) được ước lượng trên phần dữ liệu thứ nhất và đa thức bậc ba thứ hai có các hệ số \\(\\beta_{02}\\), \\(\\beta_{12}\\), \\(\\beta_{22}\\) và \\(\\beta_{32}\\) được ước lượng trên phần dữ liệu thứ hai. Cả hai đa thức đều có thể được ước lượng bằng cách sử dụng phương pháp bình phương nhỏ nhất giống như trong hồi quy đa biến. Điểm \\(c\\) chia dữ liệu làm hai miền được gọi là một nút hay một điểm cắt. Việc sử dụng nút sẽ giúp cho mô hình linh hoạt hơn là tăng bậc của đa thức và sử dụng càng nhiều nút sẽ càng làm cho hàm \\(f\\) trở nên linh hoạt. Nếu chúng ta sử dụng \\(k\\) nút khác nhau trên miền giá trị của biến \\(X\\) thì chúng ta có \\(k+1\\) miền dữ liệu và tương ứng là \\(k+1\\) đa thức cần ước lượng. Lưu ý rằng chúng ta không nhất thiết phải sử dụng đa thức bậc ba. Thay vào đó chúng ta có thể sử dụng các hàm tuyến tính hoặc đa thức bậc hai, hoặc thậm chí là một hằng số (đa thức bậc không) trên từng phần của dữ liệu.Hình ?? mô tả sử dụng hồi quy đa thức các đa thức bậc khác nhau trên từng phần dữ liệu. Mặc dù đã hạn chế được hình dạng kỳ lạ của tại các điểm giới hạn của biến \\(X\\), nhưng bạn đọc có thể nhận thấy ngay vấn đề: các đa thức có giá trị không liên tục tại điểm cắt và nếu chúng ta sử dụng hai đa thức bậc ba, sẽ có tổng số tám tham số hay tám bậc tự để mô tả mối liên hệ giữa biến mục tiêu và biến giải thích. Một cách tổng quát, nếu chúng ta sử dụng \\(k\\) nút, và các đa thức từng phần đều là các đa thức bậc ba, thì sẽ có tổng số \\(4 \\times (k+1)\\) tham số cần được ước lượng. Việc này rất dễ dẫn đến hiện tượng mô hình khớp quá mức.Để khắc phục vấn đề giá trị của các đa thức không liên tục tại các điểm cắt, trong quá trình ước lượng tham số chúng ta có thể thêm vào rằng buộc là giá trị của các đa thức tại các điểm cắt phải bằng nhau. Ngoài ràng buộc giá trị của đa thức bằng nhau tại nút \\(c\\), người xây dựng mô hình còn thêm các rằng buộc về sự liên tục của đạo hàm bậc một và đạo hàm bậc hai của các đa thức. Nói cách khác ước lượng các tham số \\(\\beta_{01}\\), \\(\\beta_{11}\\), \\(\\beta_{21}\\) và \\(\\beta_{31}\\) của đa thức thứ nhất và các tham số \\(\\beta_{02}\\), \\(\\beta_{12}\\), \\(\\beta_{22}\\) và \\(\\beta_{32}\\) của đa thức thứ hai trở thành bài toán tối ưu:\n\\[\\begin{align}\n\\hat{\\boldsymbol{\\beta}} = \\underset{\\boldsymbol{\\beta}}{\\operatorname{argmin}} \\sum\\limits_{=1}^n \\left[\\mathbb{}_{\\{x_i < c\\}} \\left(y_i - \\beta_{01} - \\beta_{11} \\cdot x_i - \\beta_{21} \\cdot x_i^2 - \\beta_{31} \\cdot x_i^3 \\right)^2 + \\\\\n\\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\mathbb{}_{\\{x_i \\geq c\\}} \\left(y_i - \\beta_{02} - \\beta_{12} \\cdot x_i - \\beta_{22} \\cdot x_i^2 - \\beta_{32} \\cdot x_i^3 \\right)^2 \\right]\n\\end{align}\\]\nvới các ràng buộc\n\\[\\begin{align}\n& \\beta_{01} + \\beta_{11} \\cdot c + \\beta_{21} \\cdot c^2 +\\beta_{31} \\cdot c^3 = \\beta_{02} + \\beta_{12} \\cdot c + \\beta_{22} \\cdot c^2 +\\beta_{32} \\cdot c^3 \\\\\n& \\beta_{11}  + 2 \\beta_{21} \\cdot c + 3 \\beta_{31} \\cdot c^2 = \\beta_{12} + 2 \\beta_{22} \\cdot c +3 \\beta_{32} \\cdot c^2 \\\\\n& 2 \\beta_{21} + 6 \\beta_{31} \\cdot c = 2 \\beta_{22}  + 6 \\beta_{32} \\cdot c\n\\tag{10.4}\n\\end{align}\\]Mỗi ràng buộc mà chúng ta áp đặt lên các đa thức bậc ba sẽ làm số lượng tham số, hay bậc tự của mô hình, giảm đi một bậc tự . Điều này cũng đồng nghĩa với việc giảm đi sự phức tạp của mô hình và tránh được hiện tượng mô hình khớp quá mức. Với ba ràng buộc trong phương trình (10.4) bao gồm ràng buộc về sự liên tục của đa thức, của đạo hàm bậc nhất và của đạo hàm bậc hai, mô hình sẽ còn năm bậc tự . Hàm số được xây dựng trên cơ sở các đa thức từng phần bậc \\(d\\) với các ràng buộc về sự liên tục của đạo hàm đến bậc \\(d-1\\) tại các nút được gọi chung là các splines bậc \\(d\\). Về lý thuyết bạn đọc có thể chọn \\(d \\geq 4\\) nhưng kinh nghiệm cho thấy bậc của splines không nên vượt quá \\(d = 3\\). Nếu muốn tăng sự phức tạp cho splines, giải pháp là tăng số nút chứ không nên tăng bậc. Trong trường hợp tổng quát, một splines bậc ba với \\(k\\) nút sẽ có \\(4 \\times (k+1)\\) tham số cần được ước lượng, đồng thời có \\(3 \\times k\\) ràng buộc tại \\(k\\) nút, đó số bậc tự sẽ là \\(k + 4\\). Để ước lượng tham số của splines, chúng ta không giải bài toán tối ưu có ràng buộc như phương trình (10.4) mà thực hiện biến đổi tham số và sau đó sử dụng phương pháp bình phương nhỏ nhất thông thường. Bạn đọc tham khảo phần 10.6.1 để hiểu về cách biến đổi tham số.\nHình 10.2: Hồi quy giá nhà (medv) theo splines bậc ba của biến giải thích là tỷ lệ người sống dưới mức trung bình (lstat) trong dữ liệu Boston. Hình bên trái: sử dụng một nút tại 15%. Hình bên phải: sử dụng hai nút tại 10% và 20%\nHình 10.2 mô tả mô hình hồi quy splines giá nhà theo tỷ lệ người sống dưới mức trung bình trên dữ liệu Boston. Hình bên trái mô tả biến mục tiêu là một splines bậc ba với một nút duy nhất là \\(c = 15\\%\\); Hình bên phải mô tả splines bậc ba với hai nút là \\(c_1 = 10\\%\\) và \\(c_2 = 20\\%\\). Với các ràng buộc về sự liên tục của các đa thức và đạo hàm đến bậc hai tại các nút, không thể nhận ra sự khác biệt của các đa thức tại các nút.Khi xây dựng một splines, chúng ta cần trả lời câu hỏi là nên đặt bao nhiêu nút hoặc đặt các nút ở đâu? Tại sao trong ví dụ kể trên chúng ta lại sử dụng một nút tại 15%, hay sử dụng hai nút tại 10% và 20% ? Và sau cùng là giữa các cách đặt nút như vậy thì cách nào tối ưu hơn. Trước hết, có thể thấy rằng đường hồi quy linh hoạt hơn ở những khoảng giá trị có nhiều nút vì ở những khoảng giá trị đó hệ số đa thức có thể thay đổi nhanh chóng. đó, một gợi ý cho việc đặt nút là nên cho nhiều nút hơn ở những nơi mà chúng ta nhận thấy hàm số có thể thay đổi nhanh nhất và đặt ít nút thắt hơn ở những nơi có vẻ ổn định hơn. Hướng tiếp cận này khá cảm tính và đòi hỏi người xây dựng mô hình cần có nhiều kinh nghiệm.Một tiếp cận khác khi đặt nút là dựa theo các quantile của biến giải thích. Khi đặt \\(k\\) nút \\(c_1 < c_2 < \\cdots < c_k\\), nút \\(c_j\\) sẽ là giá trị quantile tương ứng với mức xác suất \\(\\frac{j}{k+1}\\), hay nói một cách khác, có \\(\\frac{n \\times j}{k+1}\\) quan sát của biến giải thích nhỏ hơn \\(c_j\\) và \\(\\frac{n\\times(k+1-j)}{k+1}\\) quan sát của biến giải thích lớn hơn \\(c_j\\) với \\(n\\) là số lượng quan sát.Không có câu trả lời chính xác cho câu hỏi là cần đặt bao nhiêu nút khi xây dựng splines. Kinh nghiệm cho thấy rằng sử dụng xác thực chéo để lựa chọn số lượng nút thường cho lựa chọn tốt. Tham số \\(k\\) tương ứng với sai số xác thực chéo nhỏ nhất sẽ là số nút tối ưu. Tuy nhiên xác thực chéo chỉ có thể thực hiện khi có một hoặc một vài biến giải thích. Khi chúng ta xây dựng mô hình mà biến mục tiêu phụ thuộc vào một số lượng lớn biến giải thích, sử dụng xác thực chéo để lựa chọn số lượng nút cho từng biến giải thích sẽ yêu cầu khối lượng tính toán tăng nhanh theo hàm mũ.\nHình 10.3: Lựa chọn số nút tối ưu bằng xác thực chéo khi hồi quy giá nhà (medv) theo splines của biến giải thích là tỷ lệ số người có mức sống dưới mức trung bình (lstat). Tham số của xác thực chéo (số folds) được lựa chọn là K = 5. Hình bên trái sử dụng splines bậc hai. Hình bên phải sử dụng splines bậc ba.\nHình 10.3 mô tả cách lựa chọn số nút cho mô hình hồi quy biến mục tiêu giá nhà theo splines của biến giải thích là tỷ lệ số người có mức sống dưới trung bình bằng cách sử dụng xác thực chéo. Chúng tôi sử dụng xác thực chéo với tham số \\(K\\) bằng 5. Nếu splines có bậc hai, số lượng nút cho sai số xác thực chéo nhỏ nhất là \\(k = 8\\). Còn khi splines có bậc ba, số lượng nút cho sai số của xác thực chéo nhỏ nhất là \\(k=5\\). Có thể giải thích là khi bậc của splines nhỏ hơn, các đa thức từng phần sẽ ít linh hoạt hơn, đó cần số nút lớn hơn để mô tả tốt mối liên hệ phi tuyến giữa biến mục tiêu và biến giải thích.Khái niệm cuối cùng mà chúng tôi muốn giới thiệu đến bạn đọc trước khi chuyển sang phần chính của chương là khái niệm về natural splines. Bạn đọc có thể nhận thấy rằng với hầu hết các dữ liệu, tại các giá trị giới hạn của biến giải thích, mật độ của các điểm dữ liệu thường khá thưa thớt. đó nếu sử dụng các đa thức bậc lớn hơn hoặc bằng hai để mô tả mối liên hệ giữa biến mục tiêu và biến giải thích có thể dẫn đến các đường cong có hình dạng kỳ lạ. Để tránh gặp phải tình trạng như vậy, người xây dựng mô hình sẽ thêm vào các rằng buộc rằng đa thức phải có bậc một tại các giá trị giới hạn của biến giải thích. Nói một cách khác, hàm \\(f\\) phải là hàm tuyến tính trong các vùng biến giải thích \\(X\\) nhỏ hơn nút nhỏ nhất và \\(X\\) lớn hơn nút lớn nhất. Natural splines đơn giản là một splines với ràng buộc tuyến tính tại các giá trị giới hạn của biến giải thích. Ràng buộc bổ sung này giúp cho hàm \\(f\\) tự nhiên hơn và tạo ra các ước tính ổn định hơn ở điểm biên.Sử dụng natural splines dựa trên đa thức bậc ba thay thế cho Splines bậc ba sẽ giúp giải phóng bốn bậc tự vì ở mỗi vùng giới hạn chúng ta giảm đi hai tham số. Nói một cách khác, natural splines bậc ba sẽ có \\((k+4)-4 = k\\) tham số. Ước lượng tham số cho natural splines không được thực hiện thông qua giải bài toán tối ưu mà được thông qua phép biến đổi tham số giống như khi ước lượng tham số cho splines. Bạn đọc tham khảo chi tiết tại 10.6.2.\nHình 10.4: sánh giữa splines thông thường và natural splines khi sử dụng véc-tơ các nút giống nhau. Hình bên trái: Giá nhà tại Boston là một splines bậc ba theo tỷ lệ sống dưới mức trung bình; splines sử dụng 5 nút tại các giá trị quantile tương ứng với các mức xác suất 1/6, 2/6, 3/6, 4/6, 5/6 của biến giải thích. Hình bên phải: Giá nhà tại Boston là một natural splines; splines sử dụng 5 nút tại các giá trị quantile tương ứng với các mức xác suất 1/6, 2/6, 3/6, 4/6, 5/6 của biến giải thích.\nBạn đọc có thể nhận thấy từ Hình 10.4 rằng natural splines sẽ cho kết quả là một hàm tuyến tính tại các vùng mà biến giải thích lớn hơn nút nhỏ nhất hoặc lớn hơn nút lớn nhất. Không có sự khác biệt nhiều giữa splines thông thường và natural splines trong khoảng biến giải thích nhỏ hơn nút nhỏ nhất, tuy nhiên có sự khác biệt rõ ràng trong vùng biến giải thích lớn hơn nút lớn nhất. Trong vùng này, splines thông thường cho thấy xu thế giảm nhanh sau đó đi ngang và cuối cùng là đi lên khi biến giải thích tăng dần. Trong khi đó khi sử dụng natural splines chỉ có một xu thế duy nhất là giảm tại vùng giá trị giới hạn này. Cần dựa trên sai số khi thực hiện xác thực chéo để biết mô hình nào tốt hơn thay vì dựa trên các nhận xét cảm tính, tuy nhiên chắc chắn rằng mô hình được xây dựng từ natural spline sẽ cho dự đoán ổn định hơn, hay nói một cách khác là có phương sai nhỏ hơn với splines thông thường.Trong phần tiếp theo, chúng ta sẽ thảo luận về một hướng tiếp cận khác khi xây dựng mô hình mô tả mối liên hệ phi tuyến giữa biến mục tiêu và biến giải thích nhưng cũng cho kết quả là một splines. Kết quả này còn được biết đến với tên gọi là smoothing splines.","code":""},{"path":"các-mô-hình-cộng-tính-tổng-quát.html","id":"smoothing-splines","chapter":"Chương 10 Các mô hình cộng tính tổng quát","heading":"10.2 Smoothing splines","text":"Trong các phần trước, chúng ta đã thảo luận về cách xây dựng các đường hồi quy phi tuyến tính được tạo ra bằng cách sử dụng một tập hợp các nút của biến giải thích và các đa thức bậc \\(d\\) trên các vùng được xác định bởi các nút. Tham số của các đường hồi quy phi tuyến được ước lượng bằng phương pháp bình phương nhỏ nhất sau khi thực hiện phép biến đổi tham số. Trong phần này, chúng tôi giới thiệu một cách tiếp cận khác nhưng cũng cho kết quả là một splines. Một cách tổng quát, mục tiêu khi chúng ta muốn xây dựng hàm số mô tả mối liên hệ giữa biến mục tiêu \\(Y\\) và biến giải thích \\(X\\), tạm gọi là hàm \\(f\\), để phù hợp tối đa với dữ liệu được quan sát: nghĩa là chúng ta muốn\\[\\begin{align}\nRSS = \\sum\\limits_{=1}^n (y_i − f(x_i))^2\n\\end{align}\\]càng nhỏ càng tốt. Tuy nhiên, nếu chúng ta không đặt bất kỳ ràng buộc nào lên hàm \\(f\\) thì chúng ta luôn có thể làm cho RSS bằng 0 bằng cách chọn \\(f\\) đủ phức tạp sao cho \\(f(x_i) = y_i \\ \\forall \\). Một hàm \\(f\\) như vậy sẽ quá phù hợp với dữ liệu huấn luyện mô hình nhưng sẽ không cho kết quả tốt trên dữ liệu kiểm thử mô hình. Hàm \\(f\\) mà chúng ta thực sự cần xây dựng là một hàm làm cho RSS nhỏ nhưng cũng cần có sự ràng buộc về sự linh hoạt của hàm \\(f\\). Đường hồi quy được xây dựng trong Hình 10.5 mô tả một hàm \\(f\\) quá khớp với dữ liệu huấn luyện mô hình. Rất khó để các hàm như vậy có thể cho kết quả tốt cho kết quả tốt trên dữ liệu kiểm tra mô hình phương sai của hàm \\(f\\) là quá lớn.\nHình 10.5: Xây dựng hàm f quá linh hoạt. Sai số trên tập huấn luyện mô hình sẽ nhỏ nhưng sai số trên dữ liệu kiểm tra mô hình sẽ lớn.\nLàm thế nào chúng ta có thể đảm bảo rằng hàm \\(f\\) đạt được mức độ linh hoạt cần thiết để mô tả được mối liên hệ giữa biến mục tiêu và biến giải thích nhưng cũng không quá linh hoạt vì dễ dẫn đến mô hình khớp quá mức? Câu trả lời là cần có ràng buộc cho sự linh hoạt của hàm \\(f\\).Nếu như đạo hàm của hàm \\(f\\) tại điểm \\(x_i\\) cho biết độ dốc của hàm \\(f\\) tại điểm này, thì đạo hàm bậc hai của hàm \\(f\\) cho biết độ dốc của hàm \\(f\\) thay đổi nhanh hay chậm. Trên một khoảng giá trị \\([,b]\\) bất kỳ, nếu tổng giá trị tuyệt đối, hoặc tổng bình phương, của các đạo hàm bậc hai của một hàm càng lớn thì hàm số đó sẽ càng linh hoạt. Nói một cách khác, hàm số \\(f\\) sẽ càng linh hoạt nếu \\(\\int\\limits_a^b f^{''}(t)^2 dt\\) càng lớn và ngược lại, giá trị này càng gần 0 thì hàm càng ít linh hoạt. Giá trị \\(\\int\\limits_a^b f^{''}(t)^2 dt\\) có thể được coi như một thước đo cho sự linh hoạt của hàm \\(f\\) trên khoảng \\([,b]\\). Lưu ý rằng bất kỳ hàm tuyến tính nào trên khoảng \\([,b]\\) cũng sẽ có \\(\\int\\limits_a^b f^{''}(t)^2 dt = 0\\), nghĩa là hàm tuyến tính là hàm ít linh hoạt nhất.\nHình 10.6: Sự linh hoạt của các hàm số với hàm không linh hoạt là hàm tuyến tính. Hình bên trái: Hàm số ít linh loạt. Hình bên phải: Hàm số rất linh hoạt.\nHình bên trái của Hình 10.6 mô tả một hàm \\(f\\) có miền xác định trên đoạn \\([-1,1]\\) có độ dốc (đạo hàm cấp một) thay đổi nhưng tốc độ thay đổi của đạo hàm cấp một không quá nhanh. Hình bên phải của Hình 10.6 mô tả một hàm \\(f\\) có độ dốc thay đổi liên tục khi \\(x\\) chạy từ -1 đến 1. Kết quả là độ linh hoạt của hàm số ở hình bên phải đo bằng \\(\\int\\limits_a^b f^{''}(t)^2 dt\\) lớn gấp 40 lần với độ linh hoạt của hàm được mô tả ở hình bên trái. Để cân bằng giữa sai số RSS và độ linh hoạt của hàm \\(f\\), thay vì tìm hàm \\(f\\) để tối thiểu hóa RSS, người xây dựng mô hình sẽ tìm hàm \\(f\\) để tối thiểu hóa giá trị RSS cộng thêm một hàm phạt cho sự linh hoạt\n\\[\\begin{align}\n\\hat{f} = \\underset{f}{\\operatorname{argmin}} \\sum\\limits_{=1}^n (y_i - f(x_i))^2 + \\lambda \\cdot \\int\\limits_a^b f^{''}(t)^2 dt\n\\tag{10.5}\n\\end{align}\\]\ntrong đó \\([,b]\\) là miền giá trị mà người xây dựng mô hình muốn đặt ràng buộc cho sự linh hoạt của hàm \\(f\\). Thông thường thì cận dưới \\(\\) thường được lựa chọn là giá trị nhỏ nhất của biến giải thích trong khi cận trên \\(b\\) là giá trị lớn nhất của biến giải thích. Tham số \\(\\lambda > 0\\) đóng vai trò điều chỉnh sự linh hoạt của hàm \\(f\\): nếu \\(\\lambda\\) nhỏ thì kết quả của bài toán tối ưu (10.5) sẽ là hàm linh hoạt hơn với khi \\(\\lambda\\) nhận giá trị lớn. Khi \\(\\lambda\\) rất lớn thì hàm \\(\\hat{f}\\) sẽ xấp xỉ với hàm tuyến tính trong khi \\(\\lambda\\) xấp xỉ 0 sẽ cho kết quả là một hàm nội suy lại chính xác dữ liệu dùng để huấn luyện mô hình. Tương tự như trong hồi quy ridge hay lasso, tham số \\(\\lambda\\) được sử dụng với vai trò cân bằng giữa sự sai lệch và phương sai của mô hình.Điều thú vị là lời giải \\(\\hat{f}\\) của bài toán tối ưu (10.5) có tính chất đặc biệt:Hàm \\(\\hat{f}\\) là một splines bậc ba với các nút tại các giá trị duy nhất của \\(x_1\\), \\(x_2\\), \\(\\cdots\\), \\(x_n\\)\nHàm \\(\\hat{f}\\) là một splines bậc ba với các nút tại các giá trị duy nhất của \\(x_1\\), \\(x_2\\), \\(\\cdots\\), \\(x_n\\)Hàm \\(\\hat{f}\\) có các đạo hàm bậc nhất và bậc hai liên tục tại mỗi nút.\nHàm \\(\\hat{f}\\) có các đạo hàm bậc nhất và bậc hai liên tục tại mỗi nút.Hơn nữa, tại các khoảng giá trị nhỏ hơn nút nhỏ nhất và lớn hơn nút lớn nhất hàm số là hàm tuyến tính. Hay nói cách khác, hàm \\(\\hat{f}\\) là một natural splines bậc ba với các nút đặt tại \\(x_1\\), \\(x_2\\), \\(\\cdots\\), \\(x_n\\). Tuy nhiên, \\(\\hat{f}\\) không chính xác là một natural splines với \\(n\\) tham số tương ứng với \\(n\\) nút giống như chúng ta đã đề cập ở phần trước của chương, mà các tham số bị ràng buộc theo tham số \\(\\lambda\\). Để tham khảo nguyên nhân tại sao \\(\\hat{f}\\) lại là một natural splines, bạn đọc tham khảo phần 10.6.3\nHơn nữa, tại các khoảng giá trị nhỏ hơn nút nhỏ nhất và lớn hơn nút lớn nhất hàm số là hàm tuyến tính. Hay nói cách khác, hàm \\(\\hat{f}\\) là một natural splines bậc ba với các nút đặt tại \\(x_1\\), \\(x_2\\), \\(\\cdots\\), \\(x_n\\). Tuy nhiên, \\(\\hat{f}\\) không chính xác là một natural splines với \\(n\\) tham số tương ứng với \\(n\\) nút giống như chúng ta đã đề cập ở phần trước của chương, mà các tham số bị ràng buộc theo tham số \\(\\lambda\\). Để tham khảo nguyên nhân tại sao \\(\\hat{f}\\) lại là một natural splines, bạn đọc tham khảo phần 10.6.3Khi thảo luận về bậc tự của các hàm có ràng buộc tham số, cũng giống như trong hồi quy ridge, chúng ta cần nhắc đến khái niệm bậc tự hiệu quả. Tham số \\(\\lambda\\) kiểm soát độ linh hoạt của hàm \\(\\hat{f}\\) đó tham số này cũng quyết định bậc tự hiệu quả của mô hình.Khi \\(\\lambda \\rightarrow + \\infty\\), hàm \\(\\hat{f}\\) sẽ tiến đến một đường tuyến tính có thước đo độ linh hoạt bằng 0 và đó có bậc tự hiệu quả bằng 2, tương ứng với 2 tham số là hệ số chặn và hệ số góc.Khi \\(\\lambda = 0\\), \\(\\hat{f}\\) là một natural splines có \\(n\\) nút và không có ràng buộc, nghĩa là số bậc tự hiệu quả bằng \\(n\\). Nếu định nghĩa \\(d_{\\hat{f}}(\\lambda)\\) là bậc tự hiệu quả của hàm \\(\\hat{f}\\) thì \\(d_{\\hat{f}}(\\lambda)\\) là một hàm giảm từ \\(n\\) về 2 khi \\(\\lambda\\) nhận giá trị từ 0 đến \\(+\\infty\\).Với mỗi giá trị \\(\\lambda > 0\\), hàm \\(\\hat{f}\\) ước lượng được từ dữ liệu được gọi là một smoothing splines. Quá trình ước lượng tham số cho hàm \\(\\hat{f}\\) yêu cầu những chứng minh khá phức tạp. Bạn đọc có thể tham khảo tại 10.6.4. Tuy nhiên, điều thú vị khi ước lượng một hàm smoothing splines là chúng ta không cần phải quan tâm là cần bao nhiêu nút hoặc đặt các nút ở đâu. Tất cả các tham số cần khai báo chỉ là bậc tự hiệu quả của smoothing splines đó! Lựa chọn tham số \\(\\lambda\\) được thực hiện thông qua xác thực chéo, nghĩa là giá trị \\(\\lambda\\) được lựa chọn sao cho sai số xác thực chéo trên dữ liệu huấn luyện mô hình là nhỏ nhất.\nHình 10.7: Giá nhà tại Boston được hồi quy theo smoothing splines của biến giải thích là tỷ lệ người sống dưới mức độ trung bình với bậc tự hiệu quả khác nhau. Hình bên trái: Khi bậc tự hiệu quả bằng 2, smoothing splines là một hàm tuyến tính. Hình ở giữa: bậc tự hiệu quả bằng 10 cho kết quả một đường cong mịn và khớp với dữ liệu. Hình bên phải: Bậc tự hiệu quả quá lớn làm cho hàm số trở nên quá linh hoạt và dễ dẫn đến mô hình khớp quá mức.\nHình 10.7 mô tả mối liên hệ giữa giá nhà và tỷ lệ người có thu nhập thấp trên dữ liệu Boston sử dụng smoothing splines. Khi bậc tự hiệu quả bằng 2 tương đương với tham số \\(\\lambda = +\\infty\\), smoothing splines trở thành đường tuyến tính giống như đồ thị bên trái. Nếu chúng ta tăng bậc tự hiệu quả, hay giảm \\(\\lambda\\), smoothing splines sẽ trở nên linh hoạt hơn và khớp tốt hơn với dữ liệu huấn luyện mô hình, tuy nhiên khi bậc tự hiệu quả quá lớn thì hàm \\(f\\) sẽ trở nên quá linh hoạt như đồ thị phải của Hình 10.7.Trước khi đi vào nội dung chính của chương này là mô hình cộng tính tổng quát, chúng ta sẽ thảo luận về một phương pháp tiếp cận cũng thường được sử dụng và cho hiệu quả tương đương như khi sử dụng splines để mô tả mối liên hệ phi tuyến giữa biến mục tiêu và biến giải thích. Cách tiếp cận này được gọi là hồi quy từng đoạn, local regression hay viết tắt là loess","code":""},{"path":"các-mô-hình-cộng-tính-tổng-quát.html","id":"hồi-quy-từng-đoạn","chapter":"Chương 10 Các mô hình cộng tính tổng quát","heading":"10.3 Hồi quy từng đoạn","text":"Hồi quy từng đoạn hay hồi quy cục bộ là một cách tiếp cận khác để mô tả mối liên hệ phi tuyến tính giữa biến mục tiêu \\(Y\\) và biến giải thích \\(X\\). Khái niệm cục bộ có nghĩa là, tại một điểm \\(x_0\\) nằm trong miền giá trị của biến giải thích \\(X\\), biến mục tiêu \\(Y\\) được mô tả thông qua một hàm tuyến tính \\(\\hat{f}\\) được ước lượng từ những giá trị quan sát được của biến \\(X\\) nằm gần với giá trị \\(x_0\\).Thứ nhất, trong hồi quy cục bộ luôn luôn phải có định nghĩa rõ ràng cho khái niệm các điểm dữ liệu gần và xa với điểm \\(x_0\\). Người xây dựng mô hình phải định nghĩa một tham số \\(k\\); \\(2 \\leq k \\leq n\\), để với mỗi \\(x_0\\) chúng ta sử dụng đúng \\(k\\) điểm dữ liệu quan sát được gần với \\(x_0\\) nhất để ước lượng hàm \\(f\\). Một cách tổng quát hơn là định nghĩa tham số span được tính bằng \\(k/n\\) để mô tả cho tỷ lệ dữ liệu sử dụng trong hồi quy cục bộ. Dễ thấy rằng span nhận giá trị trong khoảng \\((0,1]\\). Đồng thời khi span rất gần 0, số lượng điểm dữ liệu để sử dụng để ước lượng hàm \\(\\hat{f}\\) là rất nhỏ. Ngược lại, khi span rất gần 1 thì số lượng điểm dữ liệu sử dụng để ước lượng hàm \\(\\hat{f}\\) là gần như toàn bộ dữ liệu dùng để huấn luyện mô hình.Thứ nhất, trong hồi quy cục bộ luôn luôn phải có định nghĩa rõ ràng cho khái niệm các điểm dữ liệu gần và xa với điểm \\(x_0\\). Người xây dựng mô hình phải định nghĩa một tham số \\(k\\); \\(2 \\leq k \\leq n\\), để với mỗi \\(x_0\\) chúng ta sử dụng đúng \\(k\\) điểm dữ liệu quan sát được gần với \\(x_0\\) nhất để ước lượng hàm \\(f\\). Một cách tổng quát hơn là định nghĩa tham số span được tính bằng \\(k/n\\) để mô tả cho tỷ lệ dữ liệu sử dụng trong hồi quy cục bộ. Dễ thấy rằng span nhận giá trị trong khoảng \\((0,1]\\). Đồng thời khi span rất gần 0, số lượng điểm dữ liệu để sử dụng để ước lượng hàm \\(\\hat{f}\\) là rất nhỏ. Ngược lại, khi span rất gần 1 thì số lượng điểm dữ liệu sử dụng để ước lượng hàm \\(\\hat{f}\\) là gần như toàn bộ dữ liệu dùng để huấn luyện mô hình.Thứ hai, hồi quy từng đoạn không chỉ loại bỏ các điểm dữ liệu cách xa \\(x_0\\), mà còn ước lượng hàm \\(\\hat{f}\\) bằng phương pháp bình phương nhỏ nhất có trọng số. Trọng số cho các điểm dữ liệu nằm gần \\(x_0\\) thường lớn hơn trọng số của các điểm nằm xa \\(x_0\\) để đảm bảo rằng các điểm nằm gần \\(x_0\\) có tác động mạnh hơn đến hình dạng của hàm \\(\\hat{f}\\). Hàm số được sử dụng để định nghĩa trọng số thường là hàm tính trên khoảng cách từ các điểm dữ liệu đến điểm \\(x_0\\). Hàm số phải đảm bảo tính chất là nhận giá trị trên tập các số thực dương và là hàm tăng. Hàm trọng số trên một điểm dữ liệu \\(x_i\\) khi ước lượng hàm hồi quy cục bộ thường được sử dụng để ước lượng hàm \\(\\hat{f}\\) làThứ hai, hồi quy từng đoạn không chỉ loại bỏ các điểm dữ liệu cách xa \\(x_0\\), mà còn ước lượng hàm \\(\\hat{f}\\) bằng phương pháp bình phương nhỏ nhất có trọng số. Trọng số cho các điểm dữ liệu nằm gần \\(x_0\\) thường lớn hơn trọng số của các điểm nằm xa \\(x_0\\) để đảm bảo rằng các điểm nằm gần \\(x_0\\) có tác động mạnh hơn đến hình dạng của hàm \\(\\hat{f}\\). Hàm số được sử dụng để định nghĩa trọng số thường là hàm tính trên khoảng cách từ các điểm dữ liệu đến điểm \\(x_0\\). Hàm số phải đảm bảo tính chất là nhận giá trị trên tập các số thực dương và là hàm tăng. Hàm trọng số trên một điểm dữ liệu \\(x_i\\) khi ước lượng hàm hồi quy cục bộ thường được sử dụng để ước lượng hàm \\(\\hat{f}\\) là\\[\\begin{align}\nw(x_i) = \\left[(1 - d^3)\\right]^3\n\\end{align}\\]\ntrong đó\\[\\begin{align}\nd = \\cfrac{|x_i - x_0|}{\\text{maxdist}}\n\\end{align}\\]\nvới maxdist là khoảng cách xa nhất từ các điểm được lựa chọn đến điểm \\(x_0\\). Các hình 10.8 và 10.9 mô tả phương pháp hồi quy cục bộ trên một dữ liệu mô phỏng từ hàm \\(f(x) = 2*(x-1)^2\\) với hai lựa chọn khác nhau của tham số span. Dữ liệu được cộng thêm nhiễu có phân phối chuẩn có độ lệch chuẩn bằng 0.5.\nHình 10.8: Hàm số phi tuyến được xây dựng bằng phương pháp hồi quy cục bộ. Đường màu xanh da trời là giá trị thật của hàm f. Tham số span được sử dụng trong hồi quy cục bộ là 0.3\n\nHình 10.9: Hàm số phi tuyến được xây dựng bằng phương pháp hồi quy cục bộ. Đường màu xanh da trời là giá trị thật của hàm f. Tham số span được sử dụng trong hồi quy cục bộ là 0.7\nHình 10.8 và 10.9 minh họa ý tưởng xây dựng hàm \\(\\hat{f}\\) bằng phương pháp hồi quy cục bộ trên một dữ liệu mô phỏng. Hình 10.8 sử dụng tham số span bằng 0.3, nghĩa là mỗi lần ước lượng hàm \\(f\\) chỉ có 30% điểm dữ liệu được đưa vào trong mô hình hồi quy. Đường màu xanh mô tả hàm số được sử dụng để tạo ra dữ liệu trong khi đường nét đứt là hàm được ước lượng bằng phương pháp hồi quy cục bộ. Tại điểm \\(x_0 = 0.25\\) hàm \\(\\hat{f}\\) là đường tiếp tuyến được ước lượng dựa trên phương pháp bình phương nhỏ nhất có trọng số dựa trên 30% điểm nằm gần \\(x_0\\) nhất (là các điểm màu cam). Trong hình 10.9, đường màu cam là ước lượng của hàm \\(f\\) với tham số span bằng 0.7. Đường tiếp tuyến tại điểm \\(x_0 = 1.5\\) là ước lượng của hàm \\(f\\) tại điểm này. Có thể thấy rằng khi tham số span càng gần 1 thì hàm \\(\\hat{f}\\) càng ít linh hoạt.Quá trình ước lượng hàm \\(\\hat{f}\\) tại điểm \\(x_0\\) bằng phương pháp hồi quy cục bộ có thể được mô tả qua các bước sau đâyLựa chọn tham số span và sau đó tính \\(k\\) là phần nguyên của span \\(\\times\\) \\(n\\) với \\(n\\) là số lượng quan sát. Lựa chọn ra \\(k\\) điểm trong số \\(n\\) điểm có khoảng cách gần với điểm \\(x_0\\) nhất.Lựa chọn tham số span và sau đó tính \\(k\\) là phần nguyên của span \\(\\times\\) \\(n\\) với \\(n\\) là số lượng quan sát. Lựa chọn ra \\(k\\) điểm trong số \\(n\\) điểm có khoảng cách gần với điểm \\(x_0\\) nhất.Lựa chọn hàm trọng số \\(w(x_i) = h(d)\\) là hàm số nhận giá trị dương và tăng theo \\(d\\), với \\(d = \\cfrac{|x_i - x_0|}{\\text{maxdist}}\\) là khoảng cách từ một điểm \\(x_i\\) trong \\(k\\) điểm được chọn trong bước (1.) và maxdist là khoảng cách từ điểm xa nhất đến \\(x_0\\) để đảm bảo \\(d\\) luôn nằm trong khoảng (0,1].Lựa chọn hàm trọng số \\(w(x_i) = h(d)\\) là hàm số nhận giá trị dương và tăng theo \\(d\\), với \\(d = \\cfrac{|x_i - x_0|}{\\text{maxdist}}\\) là khoảng cách từ một điểm \\(x_i\\) trong \\(k\\) điểm được chọn trong bước (1.) và maxdist là khoảng cách từ điểm xa nhất đến \\(x_0\\) để đảm bảo \\(d\\) luôn nằm trong khoảng (0,1].Tìm các tham số \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\) để tối thiểu hóa RSS\n\\[\\begin{align}\nRSS  = \\sum\\limits_{= 1}^k w(x_i) \\cdot (y_i - \\beta_0 - \\beta_1 \\cdot x_i)^2\n\\end{align}\\]Tìm các tham số \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\) để tối thiểu hóa RSS\n\\[\\begin{align}\nRSS  = \\sum\\limits_{= 1}^k w(x_i) \\cdot (y_i - \\beta_0 - \\beta_1 \\cdot x_i)^2\n\\end{align}\\]Trả lại giá trị \\(\\hat{f}(x_0) = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot x_1\\).Trả lại giá trị \\(\\hat{f}(x_0) = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot x_1\\).Bạn đọc có thể thấy rằng, để xây dựng được một đường hồi quy liên tục như trong Hình 10.8 và 10.9 chúng ta sẽ phải liên tục cập nhật các điểm \\(x_0\\) mới trên miền giá trị của biến giải thích, và với mỗi một điểm \\(x_0\\) mới, chúng ta lại thực hiện một ước lượng bình phương nhỏ nhất có trọng số trên một tập dữ liệu mới. Điều này khiến cho khối lượng tính toán của phương pháp này lớn hơn rất nhiều với hồi quy splines. Đây cũng là nhược điểm chính của phương pháp hồi quy từng đoạn.Tham số span được sử dụng để điều chỉnh độ sai lệch và phương sai của đường hồi quy. Khi span nhỏ, hàm \\(\\hat{f}\\) sẽ rất linh hoạt nhưng có phương sai lớn và ngược lại, nếu span lớn hàm \\(\\hat{f}\\) sẽ ít linh hoạt hơn và đánh đổi lại là phương sai sẽ nhỏ hơn. Cũng giống như tham số \\(\\lambda\\) của smoothing splines, tham số span cần được lựa chọn dựa trên xác thực chéo.\nHình 10.10: Giá nhà được hồi quy cục bộ theo biến giải thích là tỷ lệ người có thu nhập thấp. Tham số span được lựa chọn bằng xác thực chéo.\nÝ tưởng hồi quy cục bộ có thể được khái quát theo trong trường hợp có nhiều biến giải thích \\(X_1, X_2, \\cdots, X_p\\) và thường cho kết quả tốt hơn với mô hình hồi quy tuyến tính đa biến khi có các biến giải thích có tính chất cục bộ mà điển hình là biến thời gian. Khi có biến mục tiêu phụ thuộc vào biến giải thích là thời gian thì rất thường gặp phải trường hợp mà hệ số tuyến tính liên tục thay đổi, điều mà mô hình tuyến tính đa biến không thể mô tả được. Tuy nhiên, hồi quy cục bộ lại thường hoạt động không hiệu quả khi số lượng biến giải thích \\(p\\) lớn rất khó để tìm được các điểm lân cận có tính chất tương tự điểm \\(x_0\\) khi số chiều tăng lên.Một lưu ý cuối cùng cho bạn đọc về hồi quy cục bộ đó là việc lựa chọn dạng của hàm \\(\\hat{f}\\) trong hồi quy cục bộ không nhất thiết phải là hàm tuyến tính theo \\(x_i\\). Bạn đọc có thể sử dụng các dạng hàm phức tạp hơn, chẳng hạn như sử dụng các đa thức bậc hai. Khi đó, các tham số cần được ước lượng là \\(\\beta_0\\), \\(\\beta_1\\), và \\(\\beta_2\\) để tối thiểu hóa\n\\[\\begin{align}\nRSS  = \\sum\\limits_{= 1}^k w(x_i) \\cdot (y_i - \\beta_0 - \\beta_1 \\cdot x_i - \\beta_2 \\cdot x_i^2)^2\n\\end{align}\\]","code":""},{"path":"các-mô-hình-cộng-tính-tổng-quát.html","id":"gammodel","chapter":"Chương 10 Các mô hình cộng tính tổng quát","heading":"10.4 Mô hình hồi quy cộng tính tổng quát","text":"Trong các phần trước của Chương, chúng tôi trình bày một số phương pháp xây dựng các hàm phi tuyến nhằm mô tả mối liên hệ giữa biến mục tiêu \\(Y\\) dựa vào một biến giải thích \\(X\\) duy nhất. Những phương pháp này có thể được coi là sự mở rộng của hồi quy tuyến tính đơn biến. Trong mô hình cộng tính tổng quát, chúng ta thảo luận về vấn đề dự đoán hay đánh giá một biến mục tiêu Y trên cơ sở các hàm phi tuyến của \\(p\\) biến giải thích \\(X_1\\), \\(X_2\\), \\(\\cdots\\) , \\(X_p\\). Mô hình cộng tính tổng quát cũng có thể hiểu như là một sự mở rộng của hồi quy tuyến tính đa biến. Các mô hình cộng tính tổng quát (Genaralized Additive Model hay viết tắt là GAM) mở rộng mô hình tuyến tính tiêu chuẩn bằng cách mô tả biến mục tiêu thông qua tổng các hàm phi tuyến tính của từng biến giải thích. Nếu như mô hình hồi quy tuyến tính mô tả biến mục tiêu bằng phương trình\n\\[\\begin{align}\nY = \\beta_0 + \\beta_1 \\cdot X_1 + \\beta_2 \\cdot X_2 + \\cdots + \\beta_p  \\cdot X_p + \\epsilon\n\\end{align}\\]\nthì mô hình GAM mô tả biến giải thích thông qua phương trình\n\\[\\begin{align}\nY = \\beta_0 + f_1(X_1) + f_2(X_2) + \\cdots + f_p(X_p) + \\epsilon\n\\tag{10.6}\n\\end{align}\\]\ntrong đó \\(f_j\\) có thể là hàm phi tuyến với mọi \\(1 \\leq j \\leq p\\). Cụ thể hơn, \\(f_j\\) có thể là bất kỳ hàm số nào trong các hàm số mà chúng ta đã thảo luận trong khác phần trước của chương: \\(f_j(x)\\) có thể đơn giản là một đa thức bậc \\(d\\) của \\(x\\), có thể là một splines bậc \\(d\\), một natural splines, smoothing splines, hay là một hàm hồi quy cục bộ theo các miền giá trị của \\(x\\). Và điều quan trọng là, với \\(p\\) lựa chọn khác nhau cho dạng hàm \\(f_i\\), có thể sử dụng một phương pháp được gọi là backfitting để ước lượng tất cả các hàm \\(f_i\\) mà người xây dựng mô hình lựa chọn. Phương pháp backfitting được giới thiệu trong nghiên cứu của Leo Breiman (1985) với mục tiêu để ước lượng các mô hình cộng tính tổng quát được mô tả bởi phương trình (10.6). Các ràng buộc bổ sung cho các hàm \\(f_j\\) cho quá trình backfitting là\n\\[\\begin{align}\n\\sum\\limits_{=1}^n \\ f_j(X_{,j}) = 0 \\ \\ \\ \\forall{j}  \n\\tag{10.7}\n\\end{align}\\]\nđể đảm bảo nghiệm của quá trình ước lượng tham số cho kết quả duy nhất. Với ràng buộc (10.7) chúng ta có thể ước lượng các hàm \\(f_j\\) như sau:Bước thứ nhất: Tính toán ước lượng cho tham số \\(\\beta_0\\) bằng trung bình biến mục tiêu:\n\\[\\begin{align}\n\\beta_0 = \\cfrac{1}{n} \\sum\\limits_{=1}^n y_i\n\\tag{10.8}\n\\end{align}\\]\nvà cho \\(\\hat{f}_j = 0\\) với mọi \\(1 \\leq j \\leq p\\).Bước thứ nhất: Tính toán ước lượng cho tham số \\(\\beta_0\\) bằng trung bình biến mục tiêu:\n\\[\\begin{align}\n\\beta_0 = \\cfrac{1}{n} \\sum\\limits_{=1}^n y_i\n\\tag{10.8}\n\\end{align}\\]\nvà cho \\(\\hat{f}_j = 0\\) với mọi \\(1 \\leq j \\leq p\\).Bước thứ hai: Với mỗi \\(j\\) bằng \\(1, 2, \\cdots, p\\): Ước lượng hàm \\(\\hat{f}_j\\) theo dạng hàm đã lựa chọn với biến mục tiêu là\n\\[\\begin{align}\ny_i - \\hat{\\beta}_0 - \\sum\\limits_{m=1,m \\neq j}^{p} \\hat{f}_m(x_{,m})\n\\tag{10.9}\n\\end{align}\\]\nvà sau đó để đảm bảo ràng buộc (10.7) chúng ta điều chỉnh \\(\\hat{f}_j\\) như sau\n\\[\\begin{align}\n\\hat{f}_j = \\hat{f}_j - \\sum\\limits_{=1}^n \\hat{f}_j(x_{,j})\n\\tag{10.10}\n\\end{align}\\]Bước thứ hai: Với mỗi \\(j\\) bằng \\(1, 2, \\cdots, p\\): Ước lượng hàm \\(\\hat{f}_j\\) theo dạng hàm đã lựa chọn với biến mục tiêu là\n\\[\\begin{align}\ny_i - \\hat{\\beta}_0 - \\sum\\limits_{m=1,m \\neq j}^{p} \\hat{f}_m(x_{,m})\n\\tag{10.9}\n\\end{align}\\]\nvà sau đó để đảm bảo ràng buộc (10.7) chúng ta điều chỉnh \\(\\hat{f}_j\\) như sau\n\\[\\begin{align}\n\\hat{f}_j = \\hat{f}_j - \\sum\\limits_{=1}^n \\hat{f}_j(x_{,j})\n\\tag{10.10}\n\\end{align}\\]Bước thứ ba: Lặp lại bước thứ hai cho đến khi các hàm \\(\\hat{f}_j\\) không thay đổi đáng kể sau mỗi lần cập nhật.Bước thứ ba: Lặp lại bước thứ hai cho đến khi các hàm \\(\\hat{f}_j\\) không thay đổi đáng kể sau mỗi lần cập nhật.Chi tiết của phương pháp backfitting sẽ được thảo luận trong phần ??. Bạn đọc có thể hiểu quá trình backfitting một cách đơn giản như khi chúng ta ước lượng mô hình hồi quy tuyến tính thông thường biến \\(Y\\) phụ thuộc vào hai biến giải thích là \\(X_1\\) và \\(X_2\\) mà không ước lượng các hệ số \\(\\beta_1\\) của \\(X_1\\) và \\(\\beta_2\\) của \\(X_2\\) một cách đồng thời trong mô hình đa biến bằng tính toán ma trận, mà chúng ta sử dụng lặp đi lặp lại các việc ước lượng mô hình hồi quy đơn biến. Thật vậy,Bước thứ nhất: tương tự như thuật toán phát biểu ở trên, chúng ta cho \\(\\hat{\\beta_0} = \\bar{y}\\)Bước thứ nhất: tương tự như thuật toán phát biểu ở trên, chúng ta cho \\(\\hat{\\beta_0} = \\bar{y}\\)Bước thứ hai: Ước lượng mô hình tuyến tính\n\\[\\begin{align}\n(Y - \\hat{\\beta}_0) \\sim X_1\n\\end{align}\\]\nvà thu được hệ số chặn \\(\\hat{\\beta}_{10}\\) và hệ số góc \\(\\hat{\\beta}_{11}\\). biến mục tiêu \\((Y - \\hat{\\beta}_0)\\) có trung bình bằng 0 nên ta có \\(\\hat{\\beta}_{10} + \\hat{\\beta}_{11} \\cdot \\bar{x_1} = 0\\). Nói cách khác, hàm \\(\\hat{f}_1(x) = \\hat{\\beta}_{10} + \\hat{\\beta}_{11} \\cdot x\\) đã được tự động điều chỉnh để thỏa mãn ràng buộc (10.7). Với \\(\\hat{\\beta}_{10}\\) và \\(\\hat{\\beta}_{11}\\) ước lượng được chúng ta ước lượng mô hình tuyến tính\n\\[\\begin{align}\n(Y - \\hat{\\beta}_0 - \\hat{\\beta}_{10} + \\hat{\\beta}_{11} \\cdot X_1) \\sim X_2\n\\end{align}\\]\nđể thu được hệ số chặn \\(\\hat{\\beta}_{20}\\) và hệ số góc \\(\\hat{\\beta}_{21}\\). Tương tự như hàm \\(\\hat{f}_1(x)\\), hàm \\(\\hat{f}_2(x)\\) cũng tự động thỏa mãn ràng buộc (10.7).Bước thứ hai: Ước lượng mô hình tuyến tính\n\\[\\begin{align}\n(Y - \\hat{\\beta}_0) \\sim X_1\n\\end{align}\\]\nvà thu được hệ số chặn \\(\\hat{\\beta}_{10}\\) và hệ số góc \\(\\hat{\\beta}_{11}\\). biến mục tiêu \\((Y - \\hat{\\beta}_0)\\) có trung bình bằng 0 nên ta có \\(\\hat{\\beta}_{10} + \\hat{\\beta}_{11} \\cdot \\bar{x_1} = 0\\). Nói cách khác, hàm \\(\\hat{f}_1(x) = \\hat{\\beta}_{10} + \\hat{\\beta}_{11} \\cdot x\\) đã được tự động điều chỉnh để thỏa mãn ràng buộc (10.7). Với \\(\\hat{\\beta}_{10}\\) và \\(\\hat{\\beta}_{11}\\) ước lượng được chúng ta ước lượng mô hình tuyến tính\n\\[\\begin{align}\n(Y - \\hat{\\beta}_0 - \\hat{\\beta}_{10} + \\hat{\\beta}_{11} \\cdot X_1) \\sim X_2\n\\end{align}\\]\nđể thu được hệ số chặn \\(\\hat{\\beta}_{20}\\) và hệ số góc \\(\\hat{\\beta}_{21}\\). Tương tự như hàm \\(\\hat{f}_1(x)\\), hàm \\(\\hat{f}_2(x)\\) cũng tự động thỏa mãn ràng buộc (10.7).Bước thứ ba: Lặp lại bước thứ hai cho đến khi các hệ số \\(\\hat{\\beta}_{10}\\), \\(\\hat{\\beta}_{11}\\), \\(\\hat{\\beta}_{20}\\) và \\(\\hat{\\beta}_{21}\\) không thay đổi đáng kể sau mỗi bước lặp.Bước thứ ba: Lặp lại bước thứ hai cho đến khi các hệ số \\(\\hat{\\beta}_{10}\\), \\(\\hat{\\beta}_{11}\\), \\(\\hat{\\beta}_{20}\\) và \\(\\hat{\\beta}_{21}\\) không thay đổi đáng kể sau mỗi bước lặp.\nHình 10.11: Tốc độ hội tụ khi sử dụng phương pháp backfitting trong ước lượng tham số của mô hình hồi quy đa biến với biến giải thích là medv và các biến phụ thuộc là rm và lstat. Hình trên bên trái: Hệ số chặn của hàm tuyến tính của biến rm. Hình trên bên phải: Hệ số góc của hàm tuyến tính của biến rm. Hình dưới bên trái: Hệ số chặn của hàm tuyến tính của biến lstat. Hình dưới bên phải: Hệ số góc của hàm tuyến tính của biến lstat.\nHình 10.11 mô tả sự hội tụ của các hệ số chặn và hệ số góc của các hàm \\(f_1\\) và \\(f_2\\) lần lượt là các hàm tuyến tính của biến rm và biến lstat trong mô hình hồi quy đa biến với biến mục tiêu là biến medv trên dữ liệu Boston. Trước hết bạn đọc có thể thấy rằng các hệ số tuyến tính hội tụ rất nhanh chỉ sau hơn 10 bước lặp. Thứ hai, các hàm ước lượng được từ backfitting là\n\\[\\begin{align}\n\\hat{\\beta}_0 &= \\bar{y} = 22.533 \\\\\n\\hat{f}_1(rm) &= \\hat{\\beta}_{10} + \\hat{\\beta}_{11} \\cdot rm = -32.019 + 5.095 \\cdot rm \\\\\n\\hat{f}_2(lstat) &= \\hat{\\beta}_{20} + \\hat{\\beta}_{21} \\cdot lstat = 8.127 - 0.642 \\cdot lstat\n\\tag{10.11}\n\\end{align}\\]\nsẽ cho ước lượng cộng tính cho hàm \\(f\\) là\n\\[\\begin{align}\n\\hat{f}(rm, lstat) & = \\hat{\\beta}_0 + \\hat{f}_1(rm) + \\hat{f}_2(lstat) \\\\\n& = - 1.358 +  5.095 \\cdot rm - 0.642 \\cdot lstat\n\\tag{10.12}\n\\end{align}\\]Bạn đọc có thể sử dụng ước lượng hồi quy đa biến thông thường để xác nhận rằng kết quả của hồi quy đa biến băng phương pháp bình phương nhỏ nhất cho kết quả không khác với phương trình (10.12).Trong thực tế, bạn đọc không cần phải viết vòng lặp để ước lượng mô hình cộng tính tổng quát mà sử dụng thư viện gam. Hàm số được sử dụng để xây dựng và ước lượng mô hình cộng tính tổng quát trên R là hàm cùng tên với thư viện, hàm gam(). Chúng ta sẽ sử dụng hàm số này nhiều hơn trong phần thực hành.Đối với mô hình cộng tính tổng quát, thách thức với người xây dựng mô hình là chọn dạng hàm cho từng biến giải thích và số bậc tự tương ứng. Tiêu chí để đánh giá mô hình thường được sử dụng là sai số xác thực chéo. Tuy nhiên, cần nhắc lại với bạn đọc rằng sử dụng xác thực chéo khi số lượng biến giải thích lớn sẽ khiến cho thời gian tính toán tăng lên đáng kể.Quay trở lại ví dụ khi chúng ta xây dựng mô hình cộng tính tổng quát khi biến mục tiêu medv phụ thuộc vào hai biến giải thích là lstat và rm. Giả sử chúng ta lựa chọn dạng hàm cho lstat và rm đều là các smoothing spline. Tham số duy nhất của smoothing spline là bậc tự hiệu quả. Tìm bậc tự hiệu quả cho lstat và rm phải thực hiện đồng thời và dựa trên sai số xác thực chéo\nHình 10.12: Sai số xác thực chéo khi lựa chọn tham số bậc tự hiệu quả cho smoothing spline của biến lstat và bậc tự hiệu quả cho smoothing spline của biến rm.\nHình 10.12 mô tả quá trình tìm kiếm tham số bậc tự hiệu quả cho biến lstat và tham số bậc tự hiệu quả cho biến rm dựa trên sai số xác thực chéo. Có thể thấy rằng tham số cho sai số xác thực chéo nhỏ nhất là \\(df = 7.9\\) đối với biến lstat và \\(df = 5.9\\) đối với biến rm.Cũng giống như mô hình tuyến tính thông thường, mô hình cộng tính tổng quát hoàn toàn có thể sử dụng trong các bài toán phân loại. Mô hình tuyến tính thông thường không thể sử dụng trực tiếp cho bài toán phân loại mà cần có sự biến đổi cho phù hợp với phân phối xác suất của biến mục tiêu. Các mô hình tuyến tính dùng cho mục đích phân loại là lớp các mô hình thường được gọi là mô hình tuyến tính tổng quát mà ở đó chúng ta có thể bỏ qua giả thuyết về phân phối chuẩn của biến mục tiêu. Các mô hình này sẽ được trình bày trong phần sau của cuốn sách. Mô hình GAM cho mục đích phân loại cũng cần xây dựng dựa trên nền tảng của mô hình tuyến tính tổng quát đó sẽ được đề cập trong các chương tiếp theo.","code":""},{"path":"các-mô-hình-cộng-tính-tổng-quát.html","id":"thực-hành","chapter":"Chương 10 Các mô hình cộng tính tổng quát","heading":"10.5 Thực hành","text":"","code":""},{"path":"các-mô-hình-cộng-tính-tổng-quát.html","id":"hồi-quy-spline-trên-dữ-liệu-boston","chapter":"Chương 10 Các mô hình cộng tính tổng quát","heading":"10.5.1 Hồi quy spline trên dữ liệu Boston","text":"","code":""},{"path":"các-mô-hình-cộng-tính-tổng-quát.html","id":"hồi-quy-cục-bộ-trên-dữ-liệu-boston","chapter":"Chương 10 Các mô hình cộng tính tổng quát","heading":"10.5.2 Hồi quy cục bộ trên dữ liệu Boston","text":"","code":""},{"path":"các-mô-hình-cộng-tính-tổng-quát.html","id":"mô-hình-công-tính-tổng-quát-trên-dữ-liệu-boston","chapter":"Chương 10 Các mô hình cộng tính tổng quát","heading":"10.5.3 Mô hình công tính tổng quát trên dữ liệu Boston","text":"","code":""},{"path":"các-mô-hình-cộng-tính-tổng-quát.html","id":"phụ-lục-4","chapter":"Chương 10 Các mô hình cộng tính tổng quát","heading":"10.6 Phụ lục","text":"","code":""},{"path":"các-mô-hình-cộng-tính-tổng-quát.html","id":"gamapen1","chapter":"Chương 10 Các mô hình cộng tính tổng quát","heading":"10.6.1 Ước lượng tham số cho splines bậc ba và \\(k\\) nút","text":"Ước lượng tham số cho splines bậc ba không được thực hiện thông qua bài toán tối ưu như phương trình (10.4) mà cần có sự biến đổi tham số. Giả sử \\(k=1\\) và nút duy nhất được lựa chọn là \\(c\\). Các tham số (\\(\\beta_{01}\\), \\(\\beta_{11}\\), \\(\\beta_{21}\\), \\(\\beta_{31}\\)) của đa thức thứ nhất và các tham số (\\(\\beta_{02}\\), \\(\\beta_{12}\\), \\(\\beta_{22}\\), \\(\\beta_{32}\\)) của đa thức thứ hai thỏa mãn các ràng buộc trong bài toán tối ưu như phương trình (10.4), có thể chứng minh được rằng tồn tại các tham số \\(\\beta_0\\), \\(\\beta_1\\), \\(\\cdots\\), \\(\\beta_4\\) sao cho hàm số \\(f\\) là nghiệm của bài tối ưu thỏa mãn\n\\[\\begin{align}\nf(x) = \\beta_0 + \\beta_1 \\cdot x + \\beta_2 \\cdot x^2 + \\beta_3 \\cdot x^3 + \\beta_4 \\cdot \\left[(x-c)^3\\right]^+\n\\end{align}\\]\nNói một cách khác, thay vì giải bài toán tối ưu có điều kiện ràng buộc, chúng ta chỉ cần sử dụng phương pháp bình phương nhỏ nhất thông thường để tìm các hệ số tuyến tính \\(\\beta_0\\), \\(\\beta_1\\), \\(\\cdots\\), \\(\\beta_4\\) tương ứng với các biến giải thích lần lượt là \\(1\\), \\(x_i\\), \\(x_i^2\\), \\(x_i^3\\), \\(\\left[(x_i-c)^3\\right]^+\\).Để tránh sự nhầm lẫn khi viết các hệ số \\(\\beta\\) với chỉ số, chúng ta viết lại bài toán hai đa thức như sau: Cho hai đa thức bậc ba \\(P_1\\) và \\(P_2\\) như sau\n\\[\\begin{align}\n& P_1(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 \\\\\n& P_2(x) = b_0 + b_1 x + b_2 x^2 + b_3 x^3\n\\end{align}\\]\nvà nút \\(c\\) sao cho\n\\[\\begin{align}\nP_1(c) = P_2(c); \\ \\ \\ P^{'}_1(c) = P{'}_2(c); \\ \\ \\ P{''}_1(c) = P{''}_2(c)\n\\end{align}\\]\nHàm số \\(f\\) được xác định bởi\n\\[\\begin{align}\nf(x) = \\mathbb{}_{\\{x_i < c\\}} \\cdot P_1(x) + \\mathbb{}_{\\{x_i \\geq c\\}} \\cdot P_2(x)\n\\end{align}\\]\nChúng ta sẽ chứng minh rằng \\(f(x)\\) có thể được viết dưới dạng\n\\[\\begin{align}\nf(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + (b_3 - a_3) \\cdot \\left[(x-c)^3\\right]^{+}\n\\end{align}\\]Trước hết, chúng ta viết lại đa thức \\(P_2(x)\\) như sau\n\\[\\begin{align}\nP_2(x) = d_0 + d_1 (x-c) + d_2 (x-c)^2 + b_3 (x-c)^3\n\\end{align}\\]\n\\(P_1(c) = P_2(c)\\), \\(P^{'}_1(c) = P{'}_2(c)\\), và \\(P{''}_1(c) = P{''}_2(c)\\) nên chúng ta có \\(d_0 = P_1(c)\\); \\(d_1 = P^{'}_1(c)\\), và \\(d_2 = P{''}_1(c)/2\\).Khi \\(x < c\\) có thể dễ dàng thấy rằng \\(f(x) = P_1(x)\\). Với \\(x > c\\), chúng ta có\n\\[\\begin{align}\nf(x) & = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + (b_3 - a_3) \\cdot (x-c)^3 \\\\\n& = (a_0 + a_3 c^3) + (a_1 - 3 a_3 c^2) x + (a_2 + 3 a_3 c) x^2 + b_3 (x-c)^3\n\\end{align}\\]Với \\(t = x - c\\),\n\\[\\begin{align}\nf(x) & = (a_0 + a_3 c^3) + (a_1 - 3 a_3 c^2) (y + c) + (a_2 + 3 a_3 c) (y + c)^2 + b_3 y^3 \\\\\n& = (a_0 + a_3 c^3 + a_1 c + a_2 c^2) + (a_1 + 3 a_3 c^2 + 2 a_2) y + (a_2 + 3 a_3 c) y^2 + b_3 y^3 \\\\\n& = d_0 + d_1 y + d_2 y^2 + b_3 y^3\n\\end{align}\\]\nhay nói cách khác \\(f(x) = P_2(x)\\) khi \\(x > c\\)!Trong trường hợp tổng quát, ước lượng một splines bậc ba với \\(k\\) nút \\(c_1 < c_2 < \\cdots < c_k\\) sẽ tương đương với ước lượng \\(k+4\\) tham số \\(\\beta_0\\), \\(\\beta_1\\), \\(\\cdots\\), \\(\\beta_{(k+3)}\\) với các biến giải thích \\(1\\), \\(x_i\\), \\(x_i^2\\), \\(x_i^3\\), \\(\\left[(x_i-c_1)^3\\right]^+\\), \\(\\left[(x_i-c_2)^3\\right]^+\\), \\(\\cdots\\), \\(\\left[(x_i-c_k)^3\\right]^+\\).","code":""},{"path":"các-mô-hình-cộng-tính-tổng-quát.html","id":"gamapen2","chapter":"Chương 10 Các mô hình cộng tính tổng quát","heading":"10.6.2 Ước lượng tham số cho natural splines bậc ba có \\(k\\) nút","text":"Ước lượng tham số cho một \\(natural\\) \\(splines\\) không được thực hiện thông qua bài toán tối ưu có ràng buộc tại \\(k\\) nút, mà được thực hiện thông qua giải bài toán bình phương nhỏ nhất thông thường của biến mục tiêu \\(Y\\) với \\(k\\) biến giải thích được tính toán từ biến giải thích \\(X\\). Giả sử \\(k\\) nút được xắp xếp theo thứ tự tăng dần \\(c_1 < c_2 < \\cdots < c_k\\), ta có \\(k\\) biến giải thích: \\(X_1 = 1\\), \\(X_2 = x\\) và với \\(j = 3, \\cdots, k\\)\n\\[\\begin{align}\nX_j = \\cfrac{\\left[(x-c_{j-2})^3\\right]^+ - \\left[(x-c_k)^3\\right]^+ }{c_k - c_{j-2}} - \\cfrac{\\left[(x-c_{k-1})^3\\right]^+ - \\left[(x-c_k)^3\\right]^+}{c_k - c_{k-1}}\n\\end{align}\\]Hàm \\(\\hat{f}\\) thu được bằng cách hồi quy tuyến tính \\(Y\\) theo \\(X_1\\), \\(X_2\\), \\(\\cdots\\), \\(X_k\\) có dạng\n\\[\\begin{align}\n\\hat{f}(x) = \\hat{\\beta}_1 \\cdot X_1(x) + \\hat{\\beta}_2 \\cdot X_2(x) + \\cdots + \\hat{\\beta}_k \\cdot X_k(x)\n\\end{align}\\]\nlà một natural splines vì:Khi \\(x\\) nhỏ hơn \\(c_1\\) hoặc \\(x\\) lớn hơn \\(c_k\\) hàm \\(f\\) là một hàm tuyến tính. Thật vậyVới \\(x < c_1\\) ta có \\(X_j(x) = 0\\) với mọi \\(j \\geq 3\\), đó\n\\[\\begin{align}\n\\hat{f}(x) = \\hat{\\beta}_1 \\cdot X_1(x) + \\hat{\\beta}_2 \\cdot X_2(x) = \\hat{\\beta}_1 + \\hat{\\beta}_2 \\cdot x\n\\end{align}\\]\nlà một hàm tuyến tính.Với \\(x < c_1\\) ta có \\(X_j(x) = 0\\) với mọi \\(j \\geq 3\\), đó\n\\[\\begin{align}\n\\hat{f}(x) = \\hat{\\beta}_1 \\cdot X_1(x) + \\hat{\\beta}_2 \\cdot X_2(x) = \\hat{\\beta}_1 + \\hat{\\beta}_2 \\cdot x\n\\end{align}\\]\nlà một hàm tuyến tính.Với \\(x > c_k\\) ta có: hệ số của \\(x^3\\) của \\(X_j\\) là\n\\[\\begin{align}\n\\cfrac{1 - 1}{c_k - c_{j-2}} - \\cfrac{1 - 1}{c_k - c_{k-1}} = 0 - 0 = 0\n\\end{align}\\]\nvà hệ số của \\(x^2\\) của \\(X_j\\) là\n\\[\\begin{align}\n\\cfrac{-3c_{j-2} + 3c_k}{c_k - c_{j-2}} - \\cfrac{-3c_{k-1} + 3c_k}{c_k - c_{k-1}} = 3 - 3 = 0\n\\end{align}\\]Với \\(x > c_k\\) ta có: hệ số của \\(x^3\\) của \\(X_j\\) là\n\\[\\begin{align}\n\\cfrac{1 - 1}{c_k - c_{j-2}} - \\cfrac{1 - 1}{c_k - c_{k-1}} = 0 - 0 = 0\n\\end{align}\\]\nvà hệ số của \\(x^2\\) của \\(X_j\\) là\n\\[\\begin{align}\n\\cfrac{-3c_{j-2} + 3c_k}{c_k - c_{j-2}} - \\cfrac{-3c_{k-1} + 3c_k}{c_k - c_{k-1}} = 3 - 3 = 0\n\\end{align}\\]Nói cách khác, hàm \\(\\hat{f}(x)\\) là một hàm tuyến tính theo \\(x\\) khi \\(x\\) nhỏ hơn \\(c_1\\) hoặc \\(x\\) lớn hơn \\(c_k\\).Khi \\(x\\) nhận giá trị bất kỳ giữa hai nút \\(c_{j-1}\\) và \\(c_j\\), hàm \\(f\\) là một đa thức bậc ba.Khi \\(x\\) nhận giá trị bất kỳ giữa hai nút \\(c_{j-1}\\) và \\(c_j\\), hàm \\(f\\) là một đa thức bậc ba.Hàm \\(f\\) có liên tục, và có các đạo hàm đến bậc hai liên tục tại nút \\(c_j\\) bất kỳ. Điều này hiển nhiên vì tất cả các hàm \\(X_j(x)\\) đều liên tục và có đạo hàm đến bậc hai liên tục tại nút \\(c_j\\) bất kỳ, đó tổ hợp tuyến tính của các hàm \\(X_j(x)\\) cũng có tính chất này.Hàm \\(f\\) có liên tục, và có các đạo hàm đến bậc hai liên tục tại nút \\(c_j\\) bất kỳ. Điều này hiển nhiên vì tất cả các hàm \\(X_j(x)\\) đều liên tục và có đạo hàm đến bậc hai liên tục tại nút \\(c_j\\) bất kỳ, đó tổ hợp tuyến tính của các hàm \\(X_j(x)\\) cũng có tính chất này.","code":""},{"path":"các-mô-hình-cộng-tính-tổng-quát.html","id":"gamapen3","chapter":"Chương 10 Các mô hình cộng tính tổng quát","heading":"10.6.3 Tại sao smoothing splines lại là một natural spline","text":"Trước hết, nếu \\(f(x)\\) là một natural spline trên đoạn \\([,b]\\) đi qua \\(n\\) điểm \\((x_i, z_i)\\) với \\(n\\) nút thắt tại \\(x_1, x_2, \\cdots, x_n\\) thì với mọi hàm số \\(g(x)\\) có đạo hàm bậc hai liên tục và cũng đi qua \\(n\\) điểm \\((x_i, z_i)\\), ta sẽ có\n\\[\\begin{align}\n\\int\\limits_{}^b \\ \\left[g^{''}(x)\\right]^2 dx \\geq \\int\\limits_{}^b \\ \\left[f^{''}(x)\\right]^2 dx\n\\end{align}\\]\nnói một cách khác, trong tất cả các hàm có đạo hàm bậc hai liên tục đi qua \\(n\\) điểm cho trước \\((x_i, z_i)\\), natural spline là hàm số ít linh hoạt nhất.Thật vậy, cho \\(h(x) = g(x) - f(x)\\), ta có \\(h^{''}(x) = g^{''}(x) - f(x)^{''}\\) và\n\\[\\begin{align}\n\\int\\limits_{}^b f^{''}(x) h^{''}(x) dx = \\left[f^{''}(x) h'(x) \\right]^b_a - \\int\\limits_{}^b f^{'''}(x) h^{'}(x) dx\n\\end{align}\\]Dễ thấy\n\\[\\begin{align}\n\\left[f^{''}(x) h'(x) \\right]^b_a = f^{''}(b) h'(b) - f^{''}() h'() = 0\n\\end{align}\\]\n\\(f^{''}(b) = f^{''}() = 0\\) vì \\(f\\) là hàm tuyến tính khi \\(x < x_1\\) và \\(x > x_n\\). Thêm vào đó\n\\[\\begin{align}\n\\int\\limits_{}^b f^{'''}(x) h^{'}(x) dx & = \\int\\limits_{x_1}^{x_n} f^{'''}(x) h^{'}(x) dx \\\\\n& = \\sum\\limits_{=1}^n \\int\\limits_{x_1}^{x_{+1}} f^{'''}(x) h^{'}(x) dx \\\\\n& = \\sum\\limits_{=1}^n \\left[f^{'''}(x) h(x) \\right]^{x_{+1}}_{x_i} -  \\sum\\limits_{=1}^n \\int\\limits_{x_1}^{x_{+1}} f^{(4)}(x) h(x) dx\n\\end{align}\\]Ta có \\(h(x_i) = g(x_i) - f(x_i) = z_i - z_i = 0\\) cả hai hàm \\(g\\) và \\(f\\) đều đi qua điểm \\((x_i, z_i)\\). Đồng thời \\(f^{(4)}(x) = 0\\) với mọi \\(x\\) \\(f\\) là một hàm bậc 3. Nói cách khác, giá trị của biểu thức \\(\\int\\limits_{}^b f^{''}(x) h^{''}(x) dx\\) cũng bằng 0.Dựa vào kết quả trên, có thể thấy rằng\n\\[\\begin{align}\n\\int\\limits_{}^b \\ \\left[g^{''}(x)\\right]^2 dx & = \\int\\limits_{}^b \\ \\left[f^{''}(x) + h^{''}(x)\\right]^2 dx \\\\\n& = \\int\\limits_{}^b \\ \\left[f^{''}(x)\\right]^2 dx + 2 \\cdot \\int\\limits_{}^b f^{''}(x) h^{''}(x) dx + \\int\\limits_{}^b \\ \\left[h^{''}(x)\\right]^2 dx \\\\\n& = \\int\\limits_{}^b \\ \\left[f^{''}(x)\\right]^2 dx + \\int\\limits_{}^b \\ \\left[h^{''}(x)\\right]^2 dx \\\\\n& \\geq \\int\\limits_{}^b \\ \\left[f^{''}(x)\\right]^2 dx\n\\end{align}\\]\nvà dấu bằng xảy ra chỉ khi \\(h^{''}(x) = 0\\) với mọi \\(x\\). Điều này chỉ xảy ra khi \\(h\\) là một hàm tuyến tính. Tuy nhiên, ta lại có \\(h(x_i) = 0\\) với mọi \\(\\), đó \\(h(x) = 0\\) với mọi \\(x\\).Quay trở lại với Smoothing spline, giả sử \\(\\hat{f}\\) là lời giải của bài toán tối ưu\n\\[\\begin{align}\n\\hat{f} = \\underset{f}{\\operatorname{argmin}} \\sum\\limits_{=1}^n (y_i - f(x_i))^2 + \\lambda \\cdot \\int\\limits_a^b f^{''}(t)^2 dt\n\\end{align}\\]Gọi \\(\\tilde{f}\\) là natural spline đi qua các điểm \\((x_i, \\hat{f}(x_i))\\) và có nút tại tất cả các \\(x_i\\) với \\(1 \\leq \\leq n\\) thì theo kết quả ở trên ta có\n\\[\\begin{align}\n\\int\\limits_{}^b \\ \\left[\\hat{f}^{''}(x)\\right]^2 dx \\geq \\int\\limits_{}^b \\ \\left[\\tilde{f}^{''}(x)\\right]^2 dx\n\\end{align}\\]\nngoài ra\n\\[\\begin{align}\n\\sum\\limits_{=1}^n (y_i - \\hat{f}(x_i))^2 = \\sum\\limits_{=1}^n (y_i - \\tilde{f}(x_i))^2\n\\end{align}\\]\nhay nói một cách khác\n\\[\\begin{align}\n\\sum\\limits_{=1}^n (y_i - \\hat{f}(x_i))^2 + \\lambda \\cdot \\int\\limits_a^b \\hat{f}^{''}(t)^2 dt \\geq \\sum\\limits_{=1}^n (y_i - \\tilde{f}(x_i))^2 + \\lambda \\cdot \\int\\limits_a^b \\tilde{f}^{''}(t)^2 dt\n\\end{align}\\]\nđiều này chỉ có thể xảy ra khi \\(\\hat{f}(x) = \\tilde{f}(x)\\) với mọi \\(x\\)","code":""},{"path":"các-mô-hình-cộng-tính-tổng-quát.html","id":"gamapen4","chapter":"Chương 10 Các mô hình cộng tính tổng quát","heading":"10.6.4 Ước lượng smoothing splines","text":"smoothing splines là một natural spline nên dạng hàm của smoothing spline có thể viết dưới dạng\n\\[\\begin{align}\n\\hat{f}(x) = \\hat{\\beta}_1 \\cdot X_1(x) + \\hat{\\beta}_2 \\cdot X_2(x) + \\cdots + \\hat{\\beta}_k \\cdot X_k(x)\n\\end{align}\\]\nvới\n\\[\\begin{align}\nX_j = \\cfrac{\\left[(x-c_{j-2})^3\\right]^+ - \\left[(x-c_k)^3\\right]^+ }{c_k - c_{j-2}} - \\cfrac{\\left[(x-c_{k-1})^3\\right]^+ - \\left[(x-c_k)^3\\right]^+}{c_k - c_{k-1}}\n\\end{align}\\]Có thể chứng minh được rằng các hệ số \\(\\boldsymbol{\\hat\\beta}\\) để hàm \\(\\hat{f}\\) là nghiệm của bài toán tối ưu\n\\[\\begin{align}\n\\hat{f} = \\underset{f}{\\operatorname{argmin}} \\sum\\limits_{=1}^n (y_i - f(x_i))^2 + \\lambda \\cdot \\int\\limits_a^b f^{''}(t)^2 dt\n\\end{align}\\]\nlà nghiệm của bài toán tối ưu tương ứng\n\\[\\begin{align}\n\\boldsymbol{\\hat\\beta} = \\underset{\\boldsymbol{\\beta}}{\\operatorname{argmin}} \\left(\\textbf{y} - \\textbf{x} \\boldsymbol{\\beta}\\right)^T \\left(\\textbf{y} - \\textbf{x} \\boldsymbol{\\beta}\\right) + \\lambda \\cdot \\boldsymbol{\\beta}^T \\Omega \\boldsymbol{\\beta}\n\\end{align}\\]\nvới \\(\\lambda > 0\\), \\(\\textbf{x}\\) là ma trận kích thước \\(n \\times k\\) các biến giải thích có phần tử nằm ở hàng thứ \\(\\) cột thứ \\(j\\) là \\(X_j(x_i)\\) và \\(\\Omega\\) là ma trận kích thước \\(k \\times k\\) và\n\\[\\begin{align}\n\\Omega_{j,l} = \\int\\limits_{}^b X_j(t) X_l(t) dt\n\\end{align}\\]\nvới \\(1 \\leq j,l \\leq n\\). Có thể thấy rằng ước lượng smoothing spline cũng tương tự như ước lượng tham số của hồi quy ridge. Ta có lời giải chính xác cho các hệ số tuyến tính:\n\\[\\begin{align}\n\\boldsymbol{\\hat\\beta} = \\left( \\textbf{x}^T \\textbf{x} + \\lambda \\Omega \\right)^{-1} \\textbf{x}^T \\textbf{y}\n\\end{align}\\]Tương tự như hồi quy ridge, giá trị \\(\\lambda\\) sẽ quyết định mức độ linh hoạt của smoothing spline: nếu \\(\\lambda\\) lớn thì sự linh hoạt của các smoothing spline sẽ giảm và ngược lại, nếu \\(\\lambda\\) giảm thì mức độ linh hoạt của hàm sẽ tăng. Mức độ linh hoạt thường được đo lường bằng khái niệm bậc tự hiệu quả. Với hệ số \\(\\boldsymbol{\\hat\\beta}\\) ước lượng được như trên, chúng ta có giá trị ước lượng cho biến mục tiêu \\(\\hat{y}\\) như sau\n\\[\\begin{align}\n\\hat{y} & = \\textbf{x} \\boldsymbol{\\hat\\beta} \\\\\n& = \\textbf{x} \\left( \\textbf{x}^T \\textbf{x} + \\lambda \\Omega \\right)^{-1} \\textbf{x}^T \\textbf{y} \\\\\n& = \\textbf{S}_{\\lambda} \\textbf{y}\n\\end{align}\\]\nvới\n\\[\\begin{align}\n\\textbf{S}_{\\lambda} = \\textbf{x} \\left( \\textbf{x}^T \\textbf{x} + \\lambda \\Omega \\right)^{-1} \\textbf{x}^T\n\\end{align}\\]Bậc tự hiệu quả của smoothing spline được xác định cũng giống như trong hồi quy ridge, là vết của ma trận \\(\\textbf{S}_{\\lambda}\\), được ký hiệu là \\(trace\\left(\\textbf{S}_{\\lambda}\\right)\\).","code":""}]
